# PROJECT STRUCTURE AND CONTENTS
# Project: F:\Full Stack Meeting App  with login

## FOLDER STRUCTURE

ğŸ“„ .gitignore
ğŸ“„ IMPLEMENTATION_REPORT.md
ğŸ“„ README.md
ğŸ“„ TROUBLESHOOTING.md
ğŸ“„ docker-compose.test.yml
ğŸ“„ docker-compose.yml
ğŸ“„ start.txt
ğŸ“„ test-backend.dockerfile
ğŸ“„ test-websocket.dockerfile
ğŸ“ backend/
  ğŸ“ auth-service/
    ğŸ“„ .dockerignore
    ğŸ“„ .env.example
    ğŸ“„ Dockerfile
    ğŸ“„ alembic.ini
    ğŸ“„ requirements.txt
    ğŸ“„ setup.py
    ğŸ“ auth_service.egg-info/
      ğŸ“„ PKG-INFO
      ğŸ“„ SOURCES.txt
      ğŸ“„ dependency_links.txt
      ğŸ“„ requires.txt
      ğŸ“„ top_level.txt
    ğŸ“ instance/
    ğŸ“ migrations/
      ğŸ“„ alembic.ini
      ğŸ“„ env.py
      ğŸ“„ script.py.mako
      ğŸ“ versions/
        ğŸ“„ 001_initial.py
    ğŸ“ scripts/
    ğŸ“ src/
      ğŸ“„ app.py
      ğŸ“„ database.py
      ğŸ“ core/
        ğŸ“„ __init__.py
        ğŸ“„ config.py
        ğŸ“„ errors.py
        ğŸ“„ health.py
      ğŸ“ models/
        ğŸ“„ auth.py
      ğŸ“ routes/
        ğŸ“„ auth.py
      ğŸ“ schemas/
        ğŸ“„ auth.py
        ğŸ“„ base.py
      ğŸ“ tasks/
        ğŸ“„ cleanup.py
      ğŸ“ utils/
        ğŸ“„ auth.py
        ğŸ“„ data_seeder.py
        ğŸ“„ database.py
        ğŸ“„ email_service.py
        ğŸ“„ migrations_manager.py
        ğŸ“„ rate_limiter.py
        ğŸ“„ service_integration.py
        ğŸ“„ session_service.py
        ğŸ“„ token_service.py
  ğŸ“ flask-service/
    ğŸ“„ .dockerignore
    ğŸ“„ .env.example
    ğŸ“„ Dockerfile
    ğŸ“„ README.md
    ğŸ“„ fixed_app.py
    ğŸ“„ requirements.txt
    ğŸ“ migrations/
      ğŸ“„ alembic.ini
      ğŸ“„ env.py
      ğŸ“ versions/
        ğŸ“„ initial_schema.py
    ğŸ“ models/
    ğŸ“ scripts/
      ğŸ“„ migration_validator.py
      ğŸ“„ show_migration_chain.py
      ğŸ“„ test_migrations.py
    ğŸ“ src/
      ğŸ“„ __init__.py
      ğŸ“„ app.py
      ğŸ“„ fixed_app.py
      ğŸ“ core/
        ğŸ“„ __init__.py
        ğŸ“„ config.py
        ğŸ“„ errors.py
        ğŸ“„ health.py
      ğŸ“ models/
        ğŸ“„ __init__.py
        ğŸ“„ meeting.py
        ğŸ“„ meeting_audit_log.py
        ğŸ“„ meeting_co_host.py
        ğŸ“„ meeting_participant.py
        ğŸ“„ user.py
      ğŸ“ routes/
        ğŸ“„ __init__.py
        ğŸ“„ auth.py
        ğŸ“„ auth_integration.py
        ğŸ“„ health.py
        ğŸ“„ meetings.py
      ğŸ“ schemas/
        ğŸ“„ audit_log.py
        ğŸ“„ base.py
        ğŸ“„ co_host.py
        ğŸ“„ meeting.py
        ğŸ“„ participant.py
      ğŸ“ tasks/
        ğŸ“„ __init__.py
        ğŸ“„ cleanup.py
        ğŸ“„ metrics.py
      ğŸ“ utils/
        ğŸ“„ auth_integration.py
        ğŸ“„ data_seeder.py
        ğŸ“„ database.py
        ğŸ“„ logger.py
        ğŸ“„ metrics.py
        ğŸ“„ migrations_manager.py
        ğŸ“„ responses.py
        ğŸ“„ socket_events.py
  ğŸ“ node-service/
    ğŸ“„ .dockerignore
    ğŸ“„ .env.example
    ğŸ“„ Dockerfile
    ğŸ“„ package-lock.json
    ğŸ“„ package.json
    ğŸ“ src/
      ğŸ“„ config.js
      ğŸ“„ server.js
      ğŸ“ services/
        ğŸ“„ chat.js
        ğŸ“„ webrtc.js
        ğŸ“„ whiteboard.js
      ğŸ“ utils/
        ğŸ“„ logger.js
        ğŸ“„ metrics.js
  ğŸ“ shared/
    ğŸ“„ __init__.py
    ğŸ“„ config.py
    ğŸ“„ database.py
    ğŸ“„ errors.py
    ğŸ“ discovery/
      ğŸ“„ README.md
      ğŸ“„ __init__.py
      ğŸ“„ base.py
      ğŸ“„ consul.py
      ğŸ“„ env.py
      ğŸ“„ kubernetes.py
      ğŸ“„ static.py
    ğŸ“ logging/
      ğŸ“„ __init__.py
      ğŸ“„ config.py
    ğŸ“ middleware/
      ğŸ“„ __init__.py
      ğŸ“„ auth.py
      ğŸ“„ error_handler.py
      ğŸ“„ rate_limiter.py
      ğŸ“„ request_id.py
      ğŸ“„ validation.py
    ğŸ“ models/
      ğŸ“„ base.py
    ğŸ“ schemas/
      ğŸ“„ base.py
    ğŸ“ secrets/
      ğŸ“„ README.md
      ğŸ“„ __init__.py
      ğŸ“„ aws.py
      ğŸ“„ base.py
      ğŸ“„ env.py
      ğŸ“„ file.py
      ğŸ“„ vault.py
    ğŸ“ utils/
      ğŸ“„ __init__.py
      ğŸ“„ data_seeder.py
      ğŸ“„ database.py
      ğŸ“„ http.py
      ğŸ“„ migrations_manager.py
ğŸ“ config/
  ğŸ“„ .env.development
  ğŸ“„ secrets.production
ğŸ“ frontend/
  ğŸ“„ .dockerignore
  ğŸ“„ .eslintrc.json
  ğŸ“„ DEBUGGING.md
  ğŸ“„ Dockerfile
  ğŸ“„ next-env.d.ts
  ğŸ“„ next.config.js
  ğŸ“„ package.json
  ğŸ“„ postcss.config.js
  ğŸ“„ tailwind.config.js
  ğŸ“„ tsconfig.json
  ğŸ“ .next/
  ğŸ“ public/
  ğŸ“ src/
    ğŸ“ components/
      ğŸ“„ ErrorBoundary.tsx
      ğŸ“ layout/
        ğŸ“„ Layout.tsx
      ğŸ“ meeting/
        ğŸ“„ Chat.tsx
        ğŸ“„ VideoConference.tsx
        ğŸ“„ Whiteboard.tsx
    ğŸ“ config/
      ğŸ“„ environment.ts
    ğŸ“ contexts/
      ğŸ“„ AuthContext.tsx
      ğŸ“„ ChatContext.tsx
      ğŸ“„ DebugContext.tsx
      ğŸ“„ WebRTCContext.tsx
      ğŸ“„ WebSocketContext.tsx
      ğŸ“„ WhiteboardContext.tsx
    ğŸ“ hooks/
    ğŸ“ pages/
      ğŸ“„ _app.tsx
      ğŸ“„ _error.tsx
      ğŸ“„ dashboard.tsx
      ğŸ“„ forgot-password.tsx
      ğŸ“„ index.tsx
      ğŸ“„ login.tsx
      ğŸ“„ register.tsx
      ğŸ“„ resend-verification.tsx
      ğŸ“ api/
        ğŸ“„ health.ts
      ğŸ“ meeting/
        ğŸ“„ [id].tsx
      ğŸ“ reset-password/
        ğŸ“„ [token].tsx
      ğŸ“ verify-email/
        ğŸ“„ [token].tsx
    ğŸ“ services/
      ğŸ“ api/
        ğŸ“„ client.ts
    ğŸ“ styles/
      ğŸ“„ globals.css
    ğŸ“ types/
      ğŸ“„ custom.d.ts
      ğŸ“„ events.ts
      ğŸ“„ globals.d.ts
      ğŸ“„ jsx.d.ts
      ğŸ“„ user.ts
    ğŸ“ utils/
      ğŸ“„ logger.ts
ğŸ“ k8s/
  ğŸ“„ flask-backend-deployment.yaml
  ğŸ“„ hpa.yaml
  ğŸ“„ ingress.yaml
  ğŸ“„ node-backend-deployment.yaml
  ğŸ“„ postgres-deployment.yaml
  ğŸ“„ secrets.yaml
  ğŸ“ config/
    ğŸ“ development/
      ğŸ“„ configmap.yaml
      ğŸ“„ deployment.yaml
      ğŸ“„ frontend-deployment.yaml
      ğŸ“„ ingress.yaml
      ğŸ“„ network-policies.yaml
      ğŸ“„ postgres.yaml
      ğŸ“„ redis.yaml
      ğŸ“„ secrets.yaml
      ğŸ“„ volumes.yaml
  ğŸ“ logging/
    ğŸ“„ elasticsearch-deployment.yaml
    ğŸ“„ filebeat-daemonset.yaml
    ğŸ“„ logstash-deployment.yaml
  ğŸ“ monitoring/
    ğŸ“„ grafana-deployment.yaml
    ğŸ“„ prometheus-config.yaml
    ğŸ“„ prometheus-deployment.yaml
  ğŸ“ network-policies/
    ğŸ“„ flask-backend-policy.yaml
    ğŸ“„ frontend-policy.yaml
    ğŸ“„ logging-policy.yaml
    ğŸ“„ monitoring-policy.yaml
    ğŸ“„ node-backend-policy.yaml
    ğŸ“„ postgres-policy.yaml
    ğŸ“„ redis-policy.yaml
  ğŸ“ scripts/
ğŸ“ monitoring/
  ğŸ“ grafana/
    ğŸ“ provisioning/
  ğŸ“ prometheus/
    ğŸ“„ prometheus.yml
ğŸ“ scripts/


## FILE CONTENTS



### FILE: .gitignore
```
# Environment files
.env
.env.*
config/secrets.*
!.env.example

# Logs
logs/
*.log

# Dependencies
node_modules/
vendor/

# Build outputs
dist/
build/
*.pyc
__pycache__/

# IDE and editor files
.vscode/
.idea/
*.swp
*.swo

# Operating System
.DS_Store
Thumbs.db 

# Data files of the project generated by the backend services
# Used for testing purposes
data/


# Documentation files
docs/

```


### FILE: IMPLEMENTATION_REPORT.md
```
# Implementation Report

## Completed Tasks

### 1. Infrastructure Stabilization

- âœ… Updated `docker-compose.yml` with improved health checks and startup sequence
- âœ… Enhanced `auth-service` Dockerfile with dependency checks and debugging info
- âœ… Verified `backend/flask-service/Dockerfile.fixed` properly addresses the OS module issue
- âœ… Added appropriate container dependencies to ensure proper startup order

### 2. Service Management Scripts

- âœ… Created `start.ps1` and `start.sh` scripts to enforce proper service startup sequence
- âœ… Created `migrate.ps1` and `migrate.sh` scripts to manage database migrations
- âœ… Made scripts compatible with both Windows and Unix-like systems

### 3. Documentation

- âœ… Created comprehensive `TROUBLESHOOTING.md` guide
- âœ… Updated `README.md` with clear setup and usage instructions
- âœ… Added detailed instructions for both Windows and Unix-like systems

## Next Steps

### 1. Complete Database Migration Implementation

- [ ] Implement migration code in backend service
- [ ] Test migration scripts with actual databases
- [ ] Create sample data seeder scripts for development

### 2. Auth Service Enhancements

- [ ] Enhance JWT token handling and validation
- [ ] Implement rate limiting for authentication endpoints
- [ ] Update session management and cleanup tasks
- [ ] Improve integration with the backend service

### 3. Backend Service Optimization

- [ ] Add Redis caching for frequently accessed data
- [ ] Implement performance monitoring with Prometheus metrics
- [ ] Enhance error handling with structured logging
- [ ] Optimize database queries

### 4. Testing and Validation

- [ ] Create automated tests for critical components
- [ ] Implement CI/CD pipeline for continuous testing
- [ ] Create test-docker-compose.yml for isolated testing

### 5. Monitoring and Maintenance

- [ ] Configure Prometheus metrics collection
- [ ] Set up Grafana dashboards for service monitoring
- [ ] Create maintenance scripts for backup and recovery

## Conclusion

The initial stabilization and infrastructure improvements have been completed. The core services have been enhanced for better reliability and maintainability. The updated documentation provides clear instructions for setup and troubleshooting.

The next phase of work should focus on the specific service enhancements outlined in the next steps section, particularly around authentication, performance optimization, and testing. 
```


### FILE: README.md
```
# Meeting Application

A comprehensive meeting management application with authentication, real-time communication, and calendar integration.

## System Architecture

The application is built using a microservices architecture consisting of:

- **Frontend**: Next.js application for the user interface
- **Backend API**: Flask-based API for meeting management
- **Auth Service**: Flask-based microservice for authentication and user management
- **WebSocket Service**: Node.js-based WebSocket server for real-time communication
- **Databases**: PostgreSQL for persistent data storage
- **Redis**: For caching, pub/sub messaging, and session storage
- **Monitoring**: Prometheus and Grafana for metrics and monitoring

### Advanced Features

The application includes several advanced features for enterprise-grade deployments:

- **Service Discovery**: Dynamic service location and communication between microservices
- **Secret Management**: Secure handling of sensitive information across various backends
- **Integration Testing**: Comprehensive testing of service interactions
- **Centralized Logging**: Structured logging with correlation IDs across services
- **Circuit Breaking**: Resilient service communication with automatic failure handling
- **Performance Monitoring**: Real-time metrics and monitoring

## Prerequisites

- Docker and Docker Compose
- Git
- Make (optional, for using Makefile)

### Windows-Specific Requirements

- Docker Desktop
- PowerShell 5.0 or higher for running scripts
- Git Bash for bash scripts (optional)

## Quick Start

### Setting Up Environment

1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/meeting-app.git
   cd meeting-app
   ```

2. Create a `.env` file by copying the example:
   ```bash
   # For Linux/macOS
   cp .env.example .env
   
   # For Windows
   copy .env.example .env
   ```

3. Modify the `.env` file with your desired configuration values.

### Starting the Application

#### Using Scripts (Recommended)

For Windows:
```powershell
# Ensure PowerShell execution policy allows running scripts
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser

# Run the start script
.\start.ps1
```

For Linux/macOS:
```bash
# Make the script executable
chmod +x start.sh

# Run the start script
./start.sh
```

#### Manual Startup

Start the services in the following order:

```bash
# 1. Start database services
docker-compose up -d postgres auth-db redis

# 2. Wait for databases to initialize
sleep 15

# 3. Start the auth service
docker-compose up -d auth-service

# 4. Wait for auth service
sleep 10

# 5. Start the backend service
docker-compose up -d backend

# 6. Start remaining services
docker-compose up -d websocket frontend prometheus grafana
```

### Database Migrations

Run migrations to initialize the database schema:

For Windows:
```powershell
.\migrate.ps1 -ForceInit -Upgrade
```

For Linux/macOS:
```bash
chmod +x migrate.sh
./migrate.sh --force-init --upgrade
```

## Accessing the Application

Once all services are started, you can access the application at:

- **Frontend**: [http://localhost:3000](http://localhost:3000)
- **Backend API**: [http://localhost:5000](http://localhost:5000)
- **Auth Service**: [http://localhost:5001](http://localhost:5001)
- **WebSocket Service**: [http://localhost:3001](http://localhost:3001)
- **Prometheus**: [http://localhost:9090](http://localhost:9090)
- **Grafana**: [http://localhost:3002](http://localhost:3002)

## Development

### Rebuilding Services

If you need to rebuild a specific service after code changes:

```bash
docker-compose build <service-name>
docker-compose up -d <service-name>
```

### Viewing Logs

To view logs for a specific service:

```bash
docker-compose logs <service-name>
```

To follow logs in real-time:

```bash
docker-compose logs -f <service-name>
```

### Running Tests

#### Unit Tests

```bash
docker-compose -f docker-compose.test.yml up
```

#### Integration Tests

Run integration tests to verify service interactions:

```bash
# For Windows
.\run-integration-tests.ps1

# For Linux/macOS
chmod +x run-integration-tests.sh
./run-integration-tests.sh
```

## Advanced Features

### Service Discovery

The application includes a flexible service discovery system that supports multiple backends:

- **Environment Variables**: Simple configuration for development
- **Static Configuration**: JSON/YAML-based configuration for Docker Compose
- **Consul**: For production deployments with health checks
- **Kubernetes**: Native service discovery in Kubernetes environments

For more information, see the [Service Discovery Documentation](backend/shared/discovery/README.md).

### Secret Management

Secure handling of sensitive information with support for multiple backends:

- **Environment Variables**: Simple configuration for development
- **File-Based**: For Docker and Kubernetes secrets
- **HashiCorp Vault**: Advanced secret management with rotation
- **AWS Secrets Manager**: Cloud-native secret management

For more information, see the [Secret Management Documentation](backend/shared/secrets/README.md).

### Integration Testing

The application includes a comprehensive integration testing framework:

- **Service Mocking**: Mock responses from dependent services
- **Authentication Testing**: Verify authentication flows
- **End-to-End Testing**: Test complete user journeys

To run integration tests:

```bash
# For auth service
cd backend/auth-service
python -m pytest tests/integration

# For backend service
cd backend/flask-service
python -m pytest tests/integration
```

## Troubleshooting

For common issues and solutions, please refer to the [Troubleshooting Guide](TROUBLESHOOTING.md).

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

# Backend Architecture Standardization

This document summarizes the standardization changes implemented to improve consistency, reliability, and maintainability across backend services.

## Key Improvements

1. **Standardized Configuration System**
   - Unified configuration classes across services
   - Environment-specific configs (development, testing, production)
   - Service-specific configs (auth, flask, websocket)
   - Consistent environment variable handling

2. **Unified Logging Framework**
   - Structured JSON logging with consistent formatting
   - Request ID and correlation ID tracking in logs
   - Configurable log levels and outputs
   - Third-party library log level management

3. **Consistent Middleware Architecture**
   - Standard middleware interface
   - Centralized middleware registration
   - Request ID middleware for request tracking
   - Fallback mechanisms for backward compatibility

4. **Standardized Error Handling**
   - Common error classes with consistent responses
   - Structured error responses with request IDs
   - Detailed logging of exceptions
   - Consistent HTTP status codes

5. **HTTP Utilities Standardization**
   - Request ID propagation in HTTP requests
   - Retry mechanisms for transient failures
   - Consistent logging of HTTP requests
   - Simplified API for common HTTP methods

6. **Import System Improvements**
   - Fallback mechanisms for backward compatibility
   - Clear import paths for shared modules
   - Graceful handling of missing dependencies

7. **Application Factory Standardization**
   - Consistent initialization across services
   - Standard health check endpoints
   - Unified extension registration
   - Proper error handling during startup

## Project Structure

```
backend/
â”œâ”€â”€ shared/                      # Shared modules used across services
â”‚   â”œâ”€â”€ __init__.py              # Shared module import helpers
â”‚   â”œâ”€â”€ config.py                # Standardized configuration
â”‚   â”œâ”€â”€ errors.py                # Common error classes
â”‚   â”œâ”€â”€ logging/                 # Logging framework
â”‚   â”‚   â”œâ”€â”€ __init__.py          # Logging module exports
â”‚   â”‚   â””â”€â”€ config.py            # Logging configuration
â”‚   â”œâ”€â”€ middleware/              # Shared middleware
â”‚   â”‚   â”œâ”€â”€ __init__.py          # Middleware registration
â”‚   â”‚   â””â”€â”€ request_id.py        # Request ID middleware
â”‚   â””â”€â”€ utils/                   # Utility functions
â”‚       â”œâ”€â”€ __init__.py          # Utils module exports
â”‚       â””â”€â”€ http.py              # HTTP request utilities
â”œâ”€â”€ auth-service/                # Authentication service
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ app.py               # Main application factory
â”‚       â””â”€â”€ core/                # Core functionality
â””â”€â”€ flask-service/               # Main backend API service
    â””â”€â”€ src/
        â”œâ”€â”€ app.py               # Main application factory
        â””â”€â”€ core/                # Core functionality
```

## Benefits of Standardization

1. **Improved Maintainability**
   - Consistent patterns make code easier to understand
   - Reduced duplication across services
   - Centralized configuration and error handling

2. **Enhanced Reliability**
   - Robust error handling and logging
   - Request tracking across services
   - Proper fallback mechanisms

3. **Better Observability**
   - Structured logs with request context
   - Consistent health check endpoints
   - Detailed error information

4. **Simplified Development**
   - Standard interfaces for common functionality
   - Reduced cognitive load for developers
   - Easier onboarding for new team members

## Next Steps

1. Add comprehensive test coverage for shared modules
2. Implement distributed tracing with OpenTelemetry
3. Add centralized metrics collection
4. Create deployment automation for shared modules
5. Add comprehensive documentation 
```


### FILE: TROUBLESHOOTING.md
```
# Troubleshooting Guide

This document outlines common issues you might encounter when setting up or running the Meeting Application and provides solutions for resolving them.

## Table of Contents

1. [Docker Issues](#docker-issues)
2. [Database Issues](#database-issues)
3. [Service Connectivity Issues](#service-connectivity-issues)
4. [Authentication Issues](#authentication-issues)
5. [Frontend Issues](#frontend-issues)
6. [Windows-Specific Issues](#windows-specific-issues)

## Docker Issues

### Issue: Docker containers fail to build

**Symptoms:**
- `docker-compose build` fails with permission errors or "unknown file mode" errors
- Errors about missing files during build

**Solutions:**
- Make sure you're using the correct `.dockerignore` files in each service directory
- On Windows, use `Dockerfile.fixed` for the backend service
- Ensure line endings are consistent (LF, not CRLF) in scripts copied to containers

### Issue: Docker containers exit immediately after starting

**Symptoms:**
- `docker-compose up` shows containers starting but then stopping
- `docker-compose ps` shows containers in "Exit" state

**Solutions:**
- Check container logs with `docker-compose logs <service-name>`
- Verify environment variables are properly set in `.env` file
- Make sure entrypoint scripts have proper execute permissions
- Ensure database connectivity (containers may exit if DB connection fails)

### Issue: Services can't connect to each other

**Symptoms:**
- Logs show connection refused errors
- Services can't find each other by hostname

**Solutions:**
- Ensure all services are on the same Docker network
- Use correct service hostnames (as defined in docker-compose.yml)
- Verify ports are exposed correctly
- Check that service dependencies are properly defined in docker-compose.yml

## Database Issues

### Issue: Database migrations fail

**Symptoms:**
- Flask migrations show "Multiple heads" error
- Services exit with "database not ready" or "database not initialized"

**Solutions:**
- Merge migration heads using `./migrate.ps1 -Merge` or `./migrate.sh --merge`
- Verify database credentials in `.env` file
- Check that migrations are properly initialized with `./migrate.ps1 -ForceInit`
- Ensure PostgreSQL is running and accessible

### Issue: Database connection timeouts

**Symptoms:**
- Services report "database connection timeout"
- Intermittent database errors

**Solutions:**
- Increase healthcheck timeouts and retries in docker-compose.yml
- Ensure PostgreSQL has adequate resources
- Check for network issues between services
- Verify connection string format in environment variables

## Service Connectivity Issues

### Issue: Auth service not responding

**Symptoms:**
- Authentication fails
- Backend logs show auth service connectivity issues

**Solutions:**
- Check if auth-service is running with `docker-compose ps`
- Verify `AUTH_SERVICE_URL` environment variable is set correctly
- Ensure auth-service is healthy with `curl http://localhost:5001/health`
- Check auth-service logs with `docker-compose logs auth-service`

### Issue: Backend API not accessible

**Symptoms:**
- Frontend can't connect to backend
- `curl http://localhost:5000/health` fails

**Solutions:**
- Verify backend service is running with `docker-compose ps`
- Check backend logs with `docker-compose logs backend`
- Ensure port 5000 is exposed and not blocked by firewall
- Verify `NEXT_PUBLIC_API_URL` is set correctly for frontend

## Authentication Issues

### Issue: JWT token validation fails

**Symptoms:**
- Users get logged out unexpectedly
- API requests return 401 Unauthorized

**Solutions:**
- Ensure `JWT_SECRET_KEY` is identical across all services
- Check token expiration settings
- Verify clock synchronization between services
- Make sure `SERVICE_KEY` for inter-service communication is correct

### Issue: User registration fails

**Symptoms:**
- New users can't register
- Registration form submits but returns errors

**Solutions:**
- Check auth-service logs
- Verify email validation settings
- Ensure database connectivity for auth-service
- Check for duplicate email prevention logic

## Frontend Issues

### Issue: Frontend fails to build

**Symptoms:**
- `docker-compose build frontend` fails
- Next.js build errors

**Solutions:**
- Check for proper Node.js version in frontend Dockerfile
- Ensure all dependencies are correctly installed
- Verify proper volume mounts for node_modules
- Check if `.next` directory has correct permissions

### Issue: Frontend can't connect to backend services

**Symptoms:**
- API requests fail
- Console shows CORS errors or connection refused

**Solutions:**
- Verify environment variables in frontend service:
  - `NEXT_PUBLIC_API_URL`
  - `NEXT_PUBLIC_WS_URL`
  - `NEXT_PUBLIC_AUTH_URL`
- Ensure CORS is properly configured in backend and auth services
- Check network connectivity between containers

## Windows-Specific Issues

### Issue: File permission errors in Docker

**Symptoms:**
- "unknown file mode" errors
- Permission denied when copying files

**Solutions:**
- Use `.dockerignore` files to exclude problem files/directories
- Use explicit COPY commands in Dockerfile rather than copying entire directories
- Set Git to use LF line endings: `git config --global core.autocrlf input`

### Issue: Scripts won't execute

**Symptoms:**
- PowerShell scripts show security errors
- Bash scripts fail with "bad interpreter"

**Solutions:**
- For PowerShell: Set execution policy with `Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser`
- For bash scripts in Windows: Use `bash script.sh` instead of `./script.sh`
- Ensure scripts have correct line endings (LF for bash scripts)
- Make sure scripts have executable permission: `chmod +x script.sh` (in WSL or Git Bash)

## Getting Help

If you're still experiencing issues:
1. Check the service logs: `docker-compose logs -f`
2. Review the application logs in `logs/` directory
3. Check the GitHub issues
4. Contact the development team 
```


### FILE: docker-compose.test.yml
```
# yaml-language-server: $schema=https://raw.githubusercontent.com/compose-spec/compose-spec/master/schema/compose-spec.json
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=meetingapp
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres123
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d meetingapp"]
      interval: 5s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    command: redis-server --requirepass dev-redis-123
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "dev-redis-123", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5

  backend:
    image: test-backend-with-apscheduler
    command: python -c "import flask; print('Flask version:', flask.__version__); import flask_wtf; print('Flask-WTF version:', flask_wtf.__version__); import apscheduler; print('APScheduler version:', apscheduler.__version__); import sys; print(sys.path)"
    volumes:
      - ./backend/flask-service:/app
      - ./backend/shared:/app/shared
    environment:
      - PYTHONPATH=/app:/app/shared
    depends_on:
      - postgres
      - redis

  websocket:
    image: node:18-slim
    command: bash -c "cd /app && npm install && npm install prom-client && node -e \"console.log('Node version:', process.version); try { require('prom-client'); console.log('prom-client is installed'); } catch(e) { console.log('Error loading prom-client:', e.message); }; console.log('Keeping container alive...'); setInterval(() => {}, 1000);\""
    volumes:
      - ./backend/node-service:/app
    environment:
      - NODE_ENV=production
      - REDIS_URL=redis://:dev-redis-123@redis:6379/0
    depends_on:
      - redis 
```


### FILE: docker-compose.yml
```
version: '3.8'

services:
  # Databases
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 10s
      retries: 10

  auth-db:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=${AUTH_DB_NAME}
      - POSTGRES_USER=${AUTH_DB_USER}
      - POSTGRES_PASSWORD=${AUTH_DB_PASSWORD}
    ports:
      - "5433:5432"
    volumes:
      - auth_db_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${AUTH_DB_USER} -d ${AUTH_DB_NAME}"]
      interval: 10s
      timeout: 10s
      retries: 10

  redis:
    image: redis:7-alpine
    command: redis-server --requirepass ${REDIS_PASSWORD}
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 10s
      retries: 10

  # Backend Services
  auth-service:
    build:
      context: ./backend/auth-service
      dockerfile: Dockerfile
    environment:
      - FLASK_APP=src.app
      - FLASK_DEBUG=1
      - DATABASE_URL=${AUTH_DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - SERVICE_KEY=${SERVICE_KEY}
      - CORS_ORIGINS=${CORS_ORIGINS}
      - SMTP_SERVER=${SMTP_SERVER}
      - SMTP_PORT=${SMTP_PORT}
      - SMTP_USERNAME=${SMTP_USERNAME}
      - SMTP_PASSWORD=${SMTP_PASSWORD}
      - FRONTEND_URL=${FRONTEND_URL}
      - PYTHONPATH=/app:/app/shared
      - AUTH_DB_USER=${AUTH_DB_USER}
      - AUTH_DB_PASSWORD=${AUTH_DB_PASSWORD}
      - AUTH_DB_NAME=${AUTH_DB_NAME}
    volumes:
      - auth_service_data:/app
      - ./backend/shared:/app/shared
      - auth_service_logs:/app/logs
    ports:
      - "5001:5001"
    depends_on:
      auth-db:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 30s

  backend:
    build:
      context: ./backend/flask-service
      dockerfile: Dockerfile
    volumes:
      - backend_data:/app
      - ./backend/shared:/app/shared
      - backend_logs:/app/logs
    ports:
      - "5000:5000"
    environment:
      - FLASK_APP=src.app
      - FLASK_DEBUG=1
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - SERVICE_KEY=${SERVICE_KEY}
      - AUTH_SERVICE_URL=${AUTH_SERVICE_URL}
      - CORS_ORIGINS=${CORS_ORIGINS}
      - PYTHONPATH=/app:/app/shared
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      auth-service:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 30s

  websocket:
    build:
      context: ./backend/node-service
      dockerfile: Dockerfile
    volumes:
      - websocket_data:/app
      - websocket_logs:/app/logs
    ports:
      - "3001:3001"
    environment:
      - NODE_ENV=production
      - REDIS_URL=${REDIS_URL}
    depends_on:
      redis:
        condition: service_healthy
      backend:
        condition: service_started
    healthcheck:
      test: ["CMD", "/healthcheck.sh"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 30s

  # Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    environment:
      - NODE_ENV=development
      - PORT=3000
      - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL}
      - NEXT_PUBLIC_WS_URL=${NEXT_PUBLIC_WS_URL}
      - NEXT_PUBLIC_AUTH_URL=${NEXT_PUBLIC_AUTH_URL}
      - NEXT_PUBLIC_BASE_URL=${NEXT_PUBLIC_BASE_URL}
    volumes:
      - frontend_data:/app
      - frontend_node_modules:/app/node_modules
      - frontend_next:/app/.next
    ports:
      - "3000:3000"
    depends_on:
      backend:
        condition: service_started
      websocket:
        condition: service_started
      auth-service:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s

  # Monitoring
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./monitoring/prometheus:/etc/prometheus:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    ports:
      - "9090:9090"
    depends_on:
      - backend
      - auth-service

  grafana:
    image: grafana/grafana:latest
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - grafana_data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    ports:
      - "3003:3000"
    depends_on:
      - prometheus

volumes:
  postgres_data:
  auth_db_data:
  redis_data:
  auth_service_data:
  backend_data:
  auth_service_logs:
  backend_logs:
  websocket_data:
  websocket_logs:
  frontend_data:
  frontend_node_modules:
  frontend_next:
  prometheus_data:
  grafana_data: 
```


### FILE: start.txt
```
# Build all services
docker-compose build

# Start the core services first
docker-compose up -d postgres auth-db redis

# Wait for about 10 seconds for databases to initialize
sleep 10

# Start the auth service
docker-compose up -d auth-service

# Wait for auth service to be ready
sleep 10

# Start remaining services
docker-compose up -d backend websocket frontend

# Wait for all services to be ready
sleep 10

# Start monitoring services
docker-compose up -d prometheus grafana

# Wait for monitoring services to be ready
sleep 10

```


### FILE: test-backend.dockerfile
```
FROM python:3.11-slim

WORKDIR /app

RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    postgresql-client \
    curl \
    && rm -rf /var/lib/apt/lists/*

COPY backend/flask-service/requirements.txt .
RUN pip install --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

ENV PYTHONPATH=/app:/app/shared
ENV FLASK_APP=src.app
ENV FLASK_DEBUG=1

CMD ["python", "-c", "import sys; print(sys.path); from flask import Flask; print('Flask version:', Flask.__version__); import flask_wtf; print('Flask-WTF version:', flask_wtf.__version__)"] 
```


### FILE: test-websocket.dockerfile
```
FROM node:18-slim

WORKDIR /app

RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    curl \
    && rm -rf /var/lib/apt/lists/*

COPY backend/node-service/package.json .
RUN npm install && \
    npm install prom-client && \
    npm cache clean --force

ENV NODE_ENV=production
ENV PORT=3001

CMD ["node", "-e", "console.log('Node version:', process.version); try { require('prom-client'); console.log('prom-client is installed'); } catch(e) { console.log('Error loading prom-client:', e.message); }"] 
```


### FILE: backend\auth-service\.dockerignore
```
# Git
.git
.gitignore

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
*.egg-info/
.installed.cfg
*.egg

# Docker
docker-compose*
.dockerignore

# IDE
.idea/
.vscode/
*.swp
*.swo

# Logs
logs/
*.log

# Data
data/
**/*.pyc
venv/
.pytest_cache/
.coverage 
```


### FILE: backend\auth-service\.env.example
```
# Database
AUTH_DATABASE_URL=postgresql://postgres:postgres@localhost:5432/auth_db

# JWT
JWT_SECRET_KEY=your-secret-key-here

# Google OAuth
GOOGLE_CLIENT_ID=your-google-client-id
GOOGLE_CLIENT_SECRET=your-google-client-secret

# Redis (for session management)
REDIS_URL=redis://localhost:6379/0

# Email Configuration
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-specific-password
FRONTEND_URL=http://localhost:3000

# Service Integration
FLASK_SERVICE_URL=http://backend:5000
SERVICE_SYNC_ENABLED=true

# Service
PORT=5001
FLASK_ENV=development
FLASK_APP=src/app.py 
```


### FILE: backend\auth-service\Dockerfile
```
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    postgresql-client \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first for better caching
COPY requirements.txt .
RUN pip install --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt && \
    pip install APScheduler==3.10.4

# Create necessary directories
RUN mkdir -p /app/migrations/versions /app/logs /app/src /app/scripts /app/instance /app/shared

# Copy files by directory to avoid permission issues
COPY src/ /app/src/
COPY migrations/ /app/migrations/
COPY scripts/ /app/scripts/
COPY instance/ /app/instance/
COPY *.py /app/
COPY *.ini /app/

# Create shared module directories (will be mounted as volumes in docker-compose)
RUN mkdir -p /app/shared/middleware /app/shared/utils /app/shared/models /app/shared/schemas

# Create entrypoint script with explicit Unix line endings
RUN echo '#!/bin/bash\n\
\n\
# Wait for database\n\
echo "Waiting for auth-db..."\n\
until PGPASSWORD=$AUTH_DB_PASSWORD psql -h auth-db -U $AUTH_DB_USER -d $AUTH_DB_NAME -c "\q"; do\n\
  >&2 echo "Postgres is unavailable - sleeping"\n\
  sleep 1\n\
done\n\
\n\
>&2 echo "Postgres is up - executing command"\n\
\n\
# Print directory structure for debugging\n\
echo "Directory structure in /app:"\n\
ls -la /app\n\
echo "Directory structure in /app/src:"\n\
ls -la /app/src\n\
echo "Directory structure in /app/shared:"\n\
ls -la /app/shared\n\
\n\
# Check if shared modules are properly mounted\n\
if [ ! -f "/app/shared/database.py" ]; then\n\
    echo "WARNING: Shared modules not properly mounted. Volume mount issue possible."\n\
fi\n\
\n\
# Set Python path\n\
export PYTHONPATH=/app:/app/shared:$PYTHONPATH\n\
\n\
# Initialize migrations if they dont exist\n\
if [ ! -f migrations/alembic.ini ]; then\n\
    flask db init\n\
fi\n\
\n\
# Run migrations\n\
flask db upgrade || echo "Warning: Migrations failed, but continuing..."\n\
\n\
# Start the application\n\
exec gunicorn --bind 0.0.0.0:5001 --workers 2 --threads 4 --timeout 120 "src.app:create_app()"\n\
' > /entrypoint.sh

# Make entrypoint executable
RUN chmod +x /entrypoint.sh

# Set environment variables
ENV FLASK_APP=src.app
ENV FLASK_DEBUG=0
ENV PYTHONPATH=/app:/app/shared

# Health check with increased timeout
HEALTHCHECK --interval=30s --timeout=30s --start-period=15s --retries=3 \
  CMD curl -f http://localhost:5001/health || exit 1

# Expose port
EXPOSE 5001

# Set entrypoint
ENTRYPOINT ["/entrypoint.sh"] 
```


### FILE: backend\auth-service\alembic.ini
```
[alembic]
script_location = migrations
# Let the application handle the database URL
sqlalchemy.url = 

[post_write_hooks]
hooks = black
black.type = console_scripts
black.entrypoint = black
black.options = -l 79 REVISION_SCRIPT_FILENAME

[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S 
```


### FILE: backend\auth-service\requirements.txt
```
Flask==2.3.3
Flask-SQLAlchemy==3.0.5
Flask-Migrate==4.0.4
Flask-Cors==4.0.0
Flask-WTF==1.2.1
psycopg2-binary==2.9.7
python-dotenv==1.0.0
PyJWT==2.8.0
bcrypt==4.0.1
google-auth-oauthlib==1.0.0
requests==2.31.0
email-validator==2.0.0.post2
redis==5.0.0
pydantic>=2.5.2
gunicorn==21.2.0
APScheduler==3.10.4
tenacity==8.2.3
circuitbreaker==1.4.0
prometheus-client==0.19.0
sentry-sdk==1.39.1
python-consul==1.1.0
kubernetes==28.1.0
hvac==1.1.1     
boto3==1.29.6   
pytest==7.4.3
pytest-flask==1.3.0
pytest-cov==4.1.0
responses==0.23.3   
```


### FILE: backend\auth-service\setup.py
```
from setuptools import setup, find_packages

setup(
    name="auth-service",
    version="0.1.0",
    packages=find_packages(),
    install_requires=[
        'Flask==2.3.3',
        'Flask-SQLAlchemy==3.0.5',
        'Flask-Migrate==4.0.4',
        'Flask-Cors==4.0.0',
        'Flask-WTF==1.2.1',
        'psycopg2-binary==2.9.7',
        'python-dotenv==1.0.0',
        'PyJWT==2.8.0',
        'bcrypt==4.0.1',
        'google-auth-oauthlib==1.0.0',
        'requests==2.31.0',
        'email-validator==2.0.0.post2',
        'redis==5.0.0',
        'pydantic>=2.5.2',
        'gunicorn==21.2.0',
        'APScheduler==3.10.4',
        'tenacity==8.2.3',
        'circuitbreaker==1.4.0',
        'prometheus-client==0.19.0',
        'sentry-sdk==1.39.1'
    ],
) 
```


### FILE: backend\auth-service\auth_service.egg-info\PKG-INFO
```
Metadata-Version: 2.1
Name: auth-service
Version: 0.1.0

```


### FILE: backend\auth-service\auth_service.egg-info\SOURCES.txt
```
setup.py
auth_service.egg-info/PKG-INFO
auth_service.egg-info/SOURCES.txt
auth_service.egg-info/dependency_links.txt
auth_service.egg-info/requires.txt
auth_service.egg-info/top_level.txt
```


### FILE: backend\auth-service\auth_service.egg-info\dependency_links.txt
```


```


### FILE: backend\auth-service\auth_service.egg-info\requires.txt
```
Flask==2.3.3
Flask-SQLAlchemy==3.0.5
Flask-Migrate==4.0.4
Flask-Cors==4.0.0
Flask-WTF==1.2.1
psycopg2-binary==2.9.7
python-dotenv==1.0.0
PyJWT==2.8.0
bcrypt==4.0.1
google-auth-oauthlib==1.0.0
requests==2.31.0
email-validator==2.0.0.post2
redis==5.0.0
pydantic>=2.5.2
gunicorn==21.2.0
APScheduler==3.10.4
tenacity==8.2.3
circuitbreaker==1.4.0
prometheus-client==0.19.0
sentry-sdk==1.39.1

```


### FILE: backend\auth-service\auth_service.egg-info\top_level.txt
```


```


### FILE: backend\auth-service\migrations\alembic.ini
```
[alembic]
script_location = migrations
sqlalchemy.url = driver://user:pass@localhost/dbname

[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S 
```


### FILE: backend\auth-service\migrations\env.py
```
from logging.config import fileConfig

from sqlalchemy import engine_from_config
from sqlalchemy import pool

from alembic import context
from src.app import create_app
from src.database import db

config = context.config

if config.config_file_name is not None:
    fileConfig(config.config_file_name)

app = create_app(initialize_db=False)
target_metadata = db.metadata

def run_migrations_offline() -> None:
    url = app.config["SQLALCHEMY_DATABASE_URI"]
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()

def run_migrations_online() -> None:
    configuration = config.get_section(config.config_ini_section)
    configuration["sqlalchemy.url"] = app.config["SQLALCHEMY_DATABASE_URI"]
    connectable = engine_from_config(
        configuration,
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection,
            target_metadata=target_metadata
        )

        with context.begin_transaction():
            context.run_migrations()

if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online() 
```


### FILE: backend\auth-service\migrations\script.py.mako
```
"""${message}

Revision ID: ${up_revision}
Revises: ${down_revision | comma,n}
Create Date: ${create_date}

"""
from alembic import op
import sqlalchemy as sa
${imports if imports else ""}

# revision identifiers, used by Alembic.
revision = ${repr(up_revision)}
down_revision = ${repr(down_revision)}
branch_labels = ${repr(branch_labels)}
depends_on = ${repr(depends_on)}


def upgrade() -> None:
    ${upgrades if upgrades else "pass"}


def downgrade() -> None:
    ${downgrades if downgrades else "pass"} 
```


### FILE: backend\auth-service\migrations\versions\001_initial.py
```
"""Initial migration

Revision ID: 001
Revises: 
Create Date: 2024-02-07 19:56:00.000000

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '001'
down_revision = None
branch_labels = None
depends_on = None

def upgrade():
    # Create auth_users table
    op.create_table('auth_users',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('email', sa.String(length=255), nullable=False),
        sa.Column('password_hash', sa.Text(), nullable=True),
        sa.Column('is_google_user', sa.Boolean(), nullable=False, default=False),
        sa.Column('first_login', sa.Boolean(), nullable=False, default=True),
        sa.Column('is_email_verified', sa.Boolean(), nullable=False, default=False),
        sa.Column('created_at', sa.DateTime(), nullable=False),
        sa.Column('updated_at', sa.DateTime(), nullable=False),
        sa.Column('last_login', sa.DateTime(), nullable=True),
        sa.Column('first_name', sa.String(length=100), nullable=True),
        sa.Column('last_name', sa.String(length=100), nullable=True),
        sa.Column('profile_picture', sa.String(length=255), nullable=True),
        sa.Column('google_id', sa.String(length=255), nullable=True),
        sa.Column('google_refresh_token', sa.Text(), nullable=True),
        sa.Column('failed_login_attempts', sa.Integer(), nullable=False, default=0),
        sa.Column('locked_until', sa.DateTime(), nullable=True),
        sa.Column('password_last_changed', sa.DateTime(), nullable=True),
        sa.Column('require_password_change', sa.Boolean(), nullable=False, default=False),
        sa.Column('last_failed_login', sa.DateTime(), nullable=True),
        sa.Column('security_audit_log', postgresql.JSON(astext_type=sa.Text()), nullable=True),
        sa.PrimaryKeyConstraint('id'),
        sa.UniqueConstraint('email'),
        sa.UniqueConstraint('google_id')
    )

    # Create password_reset_tokens table
    op.create_table('password_reset_tokens',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('user_id', sa.Integer(), nullable=False),
        sa.Column('token', sa.Text(), nullable=False),
        sa.Column('expires_at', sa.DateTime(), nullable=False),
        sa.Column('created_at', sa.DateTime(), nullable=False),
        sa.Column('used', sa.Boolean(), nullable=False, default=False),
        sa.ForeignKeyConstraint(['user_id'], ['auth_users.id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id')
    )

    # Create user_sessions table
    op.create_table('user_sessions',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('user_id', sa.Integer(), nullable=False),
        sa.Column('token', sa.Text(), nullable=False),
        sa.Column('refresh_token', sa.Text(), nullable=True),
        sa.Column('device_info', postgresql.JSON(astext_type=sa.Text()), nullable=True),
        sa.Column('ip_address', sa.String(length=45), nullable=True),
        sa.Column('created_at', sa.DateTime(), nullable=False),
        sa.Column('expires_at', sa.DateTime(), nullable=False),
        sa.Column('refresh_token_expires_at', sa.DateTime(), nullable=True),
        sa.Column('revoked', sa.Boolean(), nullable=False, default=False),
        sa.Column('revoked_at', sa.DateTime(), nullable=True),
        sa.Column('revocation_reason', sa.String(length=100), nullable=True),
        sa.Column('last_used_at', sa.DateTime(), nullable=True),
        sa.Column('device_name', sa.String(length=100), nullable=True),
        sa.Column('device_type', sa.String(length=50), nullable=True),
        sa.Column('user_agent', sa.Text(), nullable=True),
        sa.ForeignKeyConstraint(['user_id'], ['auth_users.id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id')
    )

    # Create email_verifications table
    op.create_table('email_verifications',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('user_id', sa.Integer(), nullable=False),
        sa.Column('token', sa.String(length=255), nullable=False),
        sa.Column('expires_at', sa.DateTime(), nullable=False),
        sa.Column('created_at', sa.DateTime(), nullable=False),
        sa.Column('is_used', sa.Boolean(), nullable=False, default=False),
        sa.ForeignKeyConstraint(['user_id'], ['auth_users.id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id'),
        sa.UniqueConstraint('token')
    )

    # Create password_history table
    op.create_table('password_history',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('user_id', sa.Integer(), nullable=False),
        sa.Column('password_hash', sa.Text(), nullable=False),
        sa.Column('created_at', sa.DateTime(), nullable=False),
        sa.ForeignKeyConstraint(['user_id'], ['auth_users.id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id')
    )

def downgrade():
    op.drop_table('password_history')
    op.drop_table('email_verifications')
    op.drop_table('user_sessions')
    op.drop_table('password_reset_tokens')
    op.drop_table('auth_users') 
```


### FILE: backend\auth-service\src\app.py
```
"""
Main application factory for the Auth Service.
"""

import os
import sys
import logging
from typing import Optional, Dict, Any

# Configure import paths for shared modules
shared_module_paths = [
    os.path.abspath(os.path.join(os.path.dirname(__file__), '../../..')),
    os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../backend'))
]

for path in shared_module_paths:
    if path not in sys.path:
        sys.path.append(path)

# Import core modules
from flask import Flask, jsonify, g
from flask_cors import CORS
from werkzeug.middleware.proxy_fix import ProxyFix

# Try to import from shared modules with fallbacks
try:
    from shared.config import get_config
except ImportError:
    from core.config import get_config

try:
    from shared.logging import setup_logging
except ImportError:
    from core.logging import setup_logging

try:
    from shared.middleware import register_middleware
except ImportError:
    from core.middleware import register_middleware

# Import local modules
from core import (
    db, jwt, migrate, mail, limiter, csrf,
    register_error_handlers, register_cli_commands
)
from api.auth import auth_bp
from api.users import users_bp

# Configure logger
logger = logging.getLogger(__name__)

def create_app(config_name: Optional[str] = None) -> Flask:
    """
    Create and configure the Flask application.

    Args:
        config_name: Configuration environment name (default: from FLASK_ENV)

    Returns:
        Configured Flask application
    """
    # Create Flask app
    app = Flask(__name__)
    
    # Load configuration
    config_obj = get_config(config_name or os.getenv('FLASK_ENV', 'development'))
    app.config.from_object(config_obj)
    
    # Override database URL from environment if provided
    app.config['SQLALCHEMY_DATABASE_URI'] = os.getenv(
        'AUTH_DATABASE_URL', 
        app.config.get('SQLALCHEMY_DATABASE_URI', 'sqlite:///auth.db')
    )
    
    # Configure logging
    setup_logging(
        app=app, 
        service_name='auth-service',
        log_level=app.config.get('LOG_LEVEL', 'INFO')
    )
    
    # Configure proxy settings for running behind a reverse proxy
    app.wsgi_app = ProxyFix(app.wsgi_app, x_for=1, x_proto=1, x_host=1, x_port=1, x_prefix=1)
    
    # Register middleware
    register_middleware(app)
    
    # Initialize extensions
    CORS(app)
    db.init_app(app)
    jwt.init_app(app)
    migrate.init_app(app, db)
    mail.init_app(app)
    limiter.init_app(app)
    csrf.init_app(app)
    
    # Exempt the entire auth blueprint from CSRF protection
    # This includes OAuth callbacks, token endpoints, etc.
    csrf.exempt(auth_bp)
    
    # Register blueprints
    app.register_blueprint(auth_bp, url_prefix='/api/auth')
    app.register_blueprint(users_bp, url_prefix='/api/users')
    
    # Register error handlers
    register_error_handlers(app)
    
    # Register CLI commands
    register_cli_commands(app)
    
    # Add healthcheck endpoint
    @app.route('/health')
    def health():
        """Health check endpoint for the auth service."""
        health_data = {
            'status': 'ok',
            'service': 'auth-service',
            'version': os.getenv('VERSION', '0.1.0'),
            'request_id': getattr(g, 'request_id', 'none')
        }
        
        # Add database status check
        try:
            db.session.execute('SELECT 1')
            health_data['database'] = 'ok'
        except Exception as e:
            health_data['database'] = 'error'
            health_data['database_error'] = str(e)
            health_data['status'] = 'degraded'
            
        return jsonify(health_data)
    
    # Log application startup
    logger.info(f"Auth service started in {app.config.get('ENV')} mode")
    
    return app

if __name__ == '__main__':
    app = create_app()
    app.run(host='0.0.0.0', port=5001) 
```


### FILE: backend\auth-service\src\database.py
```
"""
This module re-exports the shared database module to maintain
backward compatibility with code that imports from here.
"""

from shared.database import db, transaction, init_db

# No need to initialize another SQLAlchemy instance
# as we're using the one from the shared module 
```


### FILE: backend\auth-service\src\core\__init__.py
```
"""
Core module for auth service functionality and initialization.
Provides centralized logging, error handling, and configuration.
"""

import logging
import os
import sys
import json
from pathlib import Path

# Try to import shared modules
try:
    from backend.shared.logging import configure_logging, get_logger
    from backend.shared.middleware.request_id import RequestIdMiddleware
    SHARED_MODULES_AVAILABLE = True
except ImportError:
    SHARED_MODULES_AVAILABLE = False

# Configure application-wide logging
def setup_logging(log_level=None):
    """
    Configure application-wide logging with appropriate handlers and formatters.
    
    Args:
        log_level: Optional override for log level (default is from environment or INFO)
    """
    if not log_level:
        log_level = os.environ.get('LOG_LEVEL', 'INFO').upper()
    
    # Use shared logging if available
    if SHARED_MODULES_AVAILABLE:
        # Configure using shared module
        config = {
            'level': log_level,
            'service_name': 'auth-service',
            'json_enabled': os.environ.get('JSON_LOGS', 'true').lower() == 'true',
            'file_enabled': os.environ.get('LOG_TO_FILE', 'false').lower() == 'true',
            'file_path': os.environ.get('LOG_FILE', 'logs/auth-service.log'),
        }
        configure_logging(config)
        logger = get_logger(__name__)
    else:
        # Fall back to basic logging
        logging_format = os.environ.get(
            'LOG_FORMAT', 
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        # Configure root logger
        root_logger = logging.getLogger()
        root_logger.setLevel(getattr(logging, log_level))
        
        # Remove existing handlers
        for handler in list(root_logger.handlers):
            root_logger.removeHandler(handler)
        
        # Add console handler
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(getattr(logging, log_level))
        console_formatter = logging.Formatter(logging_format)
        console_handler.setFormatter(console_formatter)
        root_logger.addHandler(console_handler)
        
        # Add file handler if requested
        if os.environ.get('LOG_TO_FILE', 'false').lower() == 'true':
            log_file = os.environ.get('LOG_FILE', 'logs/auth-service.log')
            os.makedirs(os.path.dirname(log_file), exist_ok=True)
            
            file_handler = logging.FileHandler(log_file)
            file_handler.setLevel(getattr(logging, log_level))
            file_formatter = logging.Formatter(logging_format)
            file_handler.setFormatter(file_formatter)
            root_logger.addHandler(file_handler)
        
        logger = logging.getLogger(__name__)
    
    logger.info(f"Logging initialized at level {log_level}")
    
    return logger

def log_system_info():
    """
    Log system and environment information for debugging purposes.
    """
    import platform
    import socket
    from datetime import datetime
    
    logger = logging.getLogger(__name__)
    
    # Collect system information
    system_info = {
        'timestamp': datetime.utcnow().isoformat() + 'Z',
        'hostname': socket.gethostname(),
        'platform': platform.platform(),
        'python_version': platform.python_version(),
        'environment': os.environ.get('FLASK_ENV', 'production'),
        'debug': os.environ.get('DEBUG', 'false').lower() == 'true',
    }
    
    # Log system information
    logger.info(f"System info: {json.dumps(system_info)}")
    
    # Log environment variables (filtered)
    safe_vars = {k: v for k, v in os.environ.items() 
               if not any(secret in k.lower() 
                        for secret in ['key', 'secret', 'token', 'password', 'auth'])}
    
    logger.debug(f"Environment variables: {json.dumps(safe_vars)}")

def log_directory_structure(base_path='/app', max_depth=2):
    """
    Log the directory structure for debugging purposes.
    """
    logger = logging.getLogger(__name__)
    logger.info(f"Directory structure of {base_path} (max depth: {max_depth})")
    
    def _log_dir(path, depth=0):
        if depth > max_depth:
            return
        
        try:
            path_obj = Path(path)
            
            # Skip if path doesn't exist
            if not path_obj.exists():
                logger.warning(f"Path does not exist: {path}")
                return
            
            # Log directory entries
            if path_obj.is_dir():
                indent = '  ' * depth
                
                # Get directory contents
                try:
                    contents = list(path_obj.iterdir())
                    
                    # Log count of items
                    logger.info(f"{indent}{path} ({len(contents)} items)")
                    
                    # Sort contents (directories first)
                    contents.sort(key=lambda p: (0 if p.is_dir() else 1, p.name))
                    
                    # Log each item
                    for item in contents:
                        if item.is_dir():
                            _log_dir(item, depth + 1)
                        else:
                            try:
                                stat = item.stat()
                                size_kb = stat.st_size / 1024
                                logger.info(f"{indent}  {item.name} ({size_kb:.1f} KB)")
                            except Exception as e:
                                logger.info(f"{indent}  {item.name} (error: {str(e)})")
                except Exception as e:
                    logger.error(f"Error listing directory {path}: {str(e)}")
        except Exception as e:
            logger.error(f"Error logging directory structure: {str(e)}")
    
    # Start logging directory structure
    _log_dir(base_path)

def register_extensions(app):
    """
    Register Flask extensions with the app.
    
    Args:
        app: Flask application instance
    """
    # Register request ID middleware if available
    if SHARED_MODULES_AVAILABLE:
        RequestIdMiddleware(app)
        app.logger.info("Registered RequestIdMiddleware")

def init_app(app):
    """
    Initialize the Flask application with core functionality.
    
    Args:
        app: Flask application instance
    """
    # Set up logging
    setup_logging()
    
    # Register extensions
    register_extensions(app)
    
    # Log system information
    log_system_info()
    
    # Log directory structure for debugging
    if app.debug:
        log_directory_structure()
    
    # Register error handlers
    from .errors import register_error_handlers
    register_error_handlers(app)
    
    app.logger.info("Core initialization complete") 
```


### FILE: backend\auth-service\src\core\config.py
```
"""
Centralized configuration management for the auth service.
Handles environment variables and provides environment-specific settings.
"""

import os
import logging
from pathlib import Path

logger = logging.getLogger(__name__)

class BaseConfig:
    """Base configuration settings shared across all environments"""
    # Application settings
    APP_NAME = "Auth Service"
    API_PREFIX = "/api"
    
    # Environment settings
    DEBUG = False
    TESTING = False
    
    # Security settings
    SECRET_KEY = os.environ.get("JWT_SECRET_KEY")
    SERVICE_KEY = os.environ.get("SERVICE_KEY")
    JWT_ALGORITHM = "HS256"
    JWT_ACCESS_TOKEN_EXPIRES = 60 * 60  # 1 hour
    JWT_REFRESH_TOKEN_EXPIRES = 30 * 24 * 60 * 60  # 30 days
    BCRYPT_LOG_ROUNDS = 13
    
    # Database settings 
    SQLALCHEMY_DATABASE_URI = os.environ.get("AUTH_DATABASE_URL")
    SQLALCHEMY_TRACK_MODIFICATIONS = False
    
    # Redis settings
    REDIS_URL = os.environ.get("REDIS_URL", "redis://localhost:6379/0")
    REDIS_TOKEN_BLACKLIST_DB = 1
    
    # CORS settings
    CORS_ORIGINS = os.environ.get("CORS_ORIGINS", "http://localhost:3000").split(",")
    CORS_METHODS = ["GET", "POST", "PUT", "DELETE", "OPTIONS"]
    CORS_HEADERS = ["Content-Type", "Authorization", "X-Service-Key"]
    
    # Email settings
    SMTP_SERVER = os.environ.get("SMTP_SERVER", "smtp.gmail.com")
    SMTP_PORT = int(os.environ.get("SMTP_PORT", 587))
    SMTP_USERNAME = os.environ.get("SMTP_USERNAME", "")
    SMTP_PASSWORD = os.environ.get("SMTP_PASSWORD", "")
    SMTP_USE_TLS = True
    EMAIL_SENDER = os.environ.get("EMAIL_SENDER", "noreply@example.com")
    
    # Frontend settings
    FRONTEND_URL = os.environ.get("FRONTEND_URL", "http://localhost:3000")
    
    # Authentication settings
    PASSWORD_RESET_TOKEN_EXPIRES = 24 * 60 * 60  # 24 hours
    EMAIL_VERIFICATION_TOKEN_EXPIRES = 48 * 60 * 60  # 48 hours
    FAILED_LOGIN_ATTEMPTS = 5
    ACCOUNT_LOCKOUT_TIME = 15 * 60  # 15 minutes
    
    # File paths
    ROOT_DIR = Path("/app")
    LOG_DIR = ROOT_DIR / "logs"
    
    # Ensure directories exist
    LOG_DIR.mkdir(exist_ok=True)

    # OAuth settings
    GOOGLE_CLIENT_ID = os.environ.get("GOOGLE_CLIENT_ID", "")
    GOOGLE_CLIENT_SECRET = os.environ.get("GOOGLE_CLIENT_SECRET", "")

class DevelopmentConfig(BaseConfig):
    """Development environment specific configuration"""
    DEBUG = True
    LOG_LEVEL = "DEBUG"
    
    # More lenient security settings for development
    BCRYPT_LOG_ROUNDS = 4
    JWT_ACCESS_TOKEN_EXPIRES = 24 * 60 * 60  # 24 hours in development
    
    # Enable detailed error messages and SQL query logging
    SQLALCHEMY_ECHO = True
    
    # Development-specific settings
    PRESERVE_CONTEXT_ON_EXCEPTION = False
    
    # Extended CORS settings for development
    CORS_ORIGINS = os.environ.get("CORS_ORIGINS", 
                                 "http://localhost:3000,http://localhost:3001,http://localhost:5000,http://localhost:5001").split(",")

class TestingConfig(BaseConfig):
    """Testing environment specific configuration"""
    TESTING = True
    DEBUG = True
    
    # Use in-memory database for testing
    SQLALCHEMY_DATABASE_URI = os.environ.get("TEST_AUTH_DATABASE_URL", "sqlite:///:memory:")
    
    # Disable CSRF protection for testing
    WTF_CSRF_ENABLED = False
    
    # Faster password hashing for tests
    BCRYPT_LOG_ROUNDS = 4
    
    # Shorter token expiration for testing
    JWT_ACCESS_TOKEN_EXPIRES = 300  # 5 minutes
    JWT_REFRESH_TOKEN_EXPIRES = 600  # 10 minutes
    
    # Mock external services
    REDIS_URL = os.environ.get("TEST_REDIS_URL", "redis://localhost:6379/2")
    
    # Disable email sending in tests
    MAIL_SUPPRESS_SEND = True

class ProductionConfig(BaseConfig):
    """Production environment specific configuration"""
    LOG_LEVEL = "INFO"
    
    # Production security settings
    WTF_CSRF_SSL_STRICT = True
    PREFERRED_URL_SCHEME = 'https'
    
    # Set stricter CORS
    CORS_ORIGINS = os.environ.get("CORS_ORIGINS", "https://yourdomain.com").split(",")
    
    # Production database settings
    SQLALCHEMY_ENGINE_OPTIONS = {
        'pool_size': 10,
        'pool_recycle': 3600,
        'pool_pre_ping': True
    }

# Dictionary of available configurations
config = {
    "development": DevelopmentConfig,
    "testing": TestingConfig,
    "production": ProductionConfig,
    # Default to development
    "default": DevelopmentConfig
}

def get_config(config_name=None):
    """
    Get the configuration for the current environment.
    
    Args:
        config_name: Optional configuration name override
        
    Returns:
        Configuration class
    """
    if not config_name:
        config_name = os.environ.get("FLASK_ENV", "development").lower()
    
    selected_config = config.get(config_name, config["default"])
    logger.info(f"Using '{config_name}' configuration for auth service")
    
    # Validate critical settings
    if not selected_config.SECRET_KEY and config_name == "production":
        logger.critical("JWT_SECRET_KEY not set in production environment!")
    
    if not selected_config.SQLALCHEMY_DATABASE_URI:
        logger.critical("AUTH_DATABASE_URL not set! Application may fail to start")
    
    return selected_config 
```


### FILE: backend\auth-service\src\core\errors.py
```
"""
Centralized error handling for the auth service.
Provides standardized error responses and detailed logging of exceptions.
"""

import traceback
import logging
import json
import os
from datetime import datetime
from flask import jsonify, request, current_app

logger = logging.getLogger(__name__)

# Try to import standardized errors from shared module
try:
    # Try to import from backend.shared first
    from backend.shared.errors import (
        APIError, ValidationError, AuthenticationError, AuthorizationError,
        UserExistsError, UserNotFoundError, TokenError, ResourceNotFoundError,
        ResourceExistsError, ServiceError, ConfigurationError, DependencyError,
        RateLimitError, EmailError, HAS_REQUEST_ID
    )
    SHARED_ERRORS_AVAILABLE = True
    logger.info("Successfully imported shared error classes")
except ImportError:
    try:
        # Try to import from shared as fallback
        from shared.errors import (
            APIError, ValidationError, AuthenticationError, AuthorizationError,
            UserExistsError, UserNotFoundError, TokenError, ResourceNotFoundError,
            ResourceExistsError, ServiceError, ConfigurationError, DependencyError,
            RateLimitError, EmailError, HAS_REQUEST_ID
        )
        SHARED_ERRORS_AVAILABLE = True
        logger.info("Successfully imported shared error classes using fallback path")
    except ImportError:
        SHARED_ERRORS_AVAILABLE = False
        logger.warning("Could not import shared error classes, using local definitions")
        
        # Try to import request ID functionality
        try:
            from backend.shared.middleware.request_id import get_request_id
            HAS_REQUEST_ID = True
        except ImportError:
            try:
                from shared.middleware.request_id import get_request_id
                HAS_REQUEST_ID = True
            except ImportError:
                HAS_REQUEST_ID = False

        # Define error classes locally if shared module is not available
        class APIError(Exception):
            """Base exception class for API errors with status code and message"""
            
            def __init__(self, message, status_code=400, details=None):
                self.message = message
                self.status_code = status_code
                self.details = details or {}
                self.timestamp = datetime.utcnow().isoformat() + 'Z'
                
                # Add request ID if available
                if HAS_REQUEST_ID:
                    self.request_id = get_request_id()
                else:
                    self.request_id = None
            
            def to_dict(self):
                """Convert exception to dictionary representation"""
                error_dict = {
                    'error': True,
                    'status_code': self.status_code,
                    'message': self.message,
                    'timestamp': self.timestamp
                }
                
                # Include request ID if available
                if hasattr(self, 'request_id') and self.request_id:
                    error_dict['request_id'] = self.request_id
                
                # Include request URL and method if in a request context
                try:
                    error_dict['path'] = request.path
                    error_dict['method'] = request.method
                except RuntimeError:
                    # Not in a request context
                    pass
                
                # Include additional details if provided
                if self.details:
                    error_dict['details'] = self.details
                
                return error_dict

        class ValidationError(APIError):
            """Exception for data validation errors"""
            
            def __init__(self, message="Validation error", details=None):
                super().__init__(message, status_code=422, details=details)

        class AuthenticationError(APIError):
            """Exception for authentication failures"""
            
            def __init__(self, message="Authentication required", details=None):
                super().__init__(message, status_code=401, details=details)

        class AuthorizationError(APIError):
            """Exception for authorization failures"""
            
            def __init__(self, message="Not authorized", details=None):
                super().__init__(message, status_code=403, details=details)

        class UserExistsError(APIError):
            """Exception for duplicate user registration"""
            
            def __init__(self, message="User already exists", details=None):
                super().__init__(message, status_code=409, details=details)

        class UserNotFoundError(APIError):
            """Exception for user not found"""
            
            def __init__(self, message="User not found", details=None):
                super().__init__(message, status_code=404, details=details)

        class TokenError(APIError):
            """Exception for token validation failures"""
            
            def __init__(self, message="Invalid or expired token", details=None):
                super().__init__(message, status_code=401, details=details)

        class RateLimitError(APIError):
            """Exception for rate limiting"""
            
            def __init__(self, message="Rate limit exceeded", details=None):
                super().__init__(message, status_code=429, details=details)

        class ServiceError(APIError):
            """Exception for service failures"""
            
            def __init__(self, message="Service error", details=None):
                super().__init__(message, status_code=500, details=details)

        class EmailError(APIError):
            """Exception for email sending failures"""
            
            def __init__(self, message="Failed to send email", details=None):
                super().__init__(message, status_code=500, details=details)
                
        class ResourceNotFoundError(APIError):
            """Exception for resource not found"""
            
            def __init__(self, message="Resource not found", details=None):
                super().__init__(message, status_code=404, details=details)
                
        class ResourceExistsError(APIError):
            """Exception for resource already exists"""
            
            def __init__(self, message="Resource already exists", details=None):
                super().__init__(message, status_code=409, details=details)
                
        class ConfigurationError(APIError):
            """Exception for configuration errors"""
            
            def __init__(self, message="Configuration error", details=None):
                super().__init__(message, status_code=500, details=details)
                
        class DependencyError(APIError):
            """Exception for dependency failures"""
            
            def __init__(self, message="Dependency error", details=None):
                super().__init__(message, status_code=503, details=details)

def register_error_handlers(app):
    """
    Register all error handlers with the Flask app.
    
    Args:
        app: Flask application instance
    """
    # Custom exceptions
    app.register_error_handler(APIError, handle_api_error)
    app.register_error_handler(ValidationError, handle_api_error)
    app.register_error_handler(AuthenticationError, handle_api_error)
    app.register_error_handler(AuthorizationError, handle_api_error)
    app.register_error_handler(UserExistsError, handle_api_error)
    app.register_error_handler(UserNotFoundError, handle_api_error)
    app.register_error_handler(TokenError, handle_api_error)
    app.register_error_handler(RateLimitError, handle_api_error)
    app.register_error_handler(ServiceError, handle_api_error)
    app.register_error_handler(EmailError, handle_api_error)
    app.register_error_handler(ResourceNotFoundError, handle_api_error)
    app.register_error_handler(ResourceExistsError, handle_api_error)
    app.register_error_handler(ConfigurationError, handle_api_error)
    app.register_error_handler(DependencyError, handle_api_error)
    
    # Standard HTTP errors
    app.register_error_handler(400, handle_bad_request)
    app.register_error_handler(401, handle_unauthorized)
    app.register_error_handler(403, handle_forbidden)
    app.register_error_handler(404, handle_not_found)
    app.register_error_handler(405, handle_method_not_allowed)
    app.register_error_handler(422, handle_unprocessable_entity)
    app.register_error_handler(429, handle_rate_limit_exceeded)
    app.register_error_handler(500, handle_server_error)
    
    # Catch-all for any other exceptions
    app.register_error_handler(Exception, handle_exception)
    
    logger.info("Registered error handlers")

def handle_api_error(error):
    """
    Handler for API errors.
    
    Args:
        error: APIError instance
        
    Returns:
        JSON response with error details
    """
    response = jsonify(error.to_dict())
    response.status_code = error.status_code
    
    # Add request ID header if available
    if hasattr(error, 'request_id') and error.request_id:
        response.headers['X-Request-ID'] = error.request_id
    
    # Log the error
    if error.status_code >= 500:
        logger.error(f"API Error: {error.message}", extra={'status_code': error.status_code})
    else:
        logger.info(f"API Error: {error.message}", extra={'status_code': error.status_code})
    
    return response

def handle_bad_request(error):
    """
    Handler for 400 Bad Request errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = APIError("Bad request", status_code=400)
    return handle_api_error(api_error)

def handle_unauthorized(error):
    """
    Handler for 401 Unauthorized errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = AuthenticationError("Authentication required")
    return handle_api_error(api_error)

def handle_forbidden(error):
    """
    Handler for 403 Forbidden errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = AuthorizationError("Access forbidden")
    return handle_api_error(api_error)

def handle_not_found(error):
    """
    Handler for 404 Not Found errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = ResourceNotFoundError("Resource not found")
    return handle_api_error(api_error)

def handle_method_not_allowed(error):
    """
    Handler for 405 Method Not Allowed errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = APIError("Method not allowed", status_code=405)
    return handle_api_error(api_error)

def handle_unprocessable_entity(error):
    """
    Handler for 422 Unprocessable Entity errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    # Extract validation errors from WTForms if available
    details = {}
    if hasattr(error, 'data') and 'errors' in error.data:
        details = {'fields': error.data['errors']}
    
    api_error = ValidationError("Validation error", details=details)
    return handle_api_error(api_error)

def handle_rate_limit_exceeded(error):
    """
    Handler for 429 Too Many Requests errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = RateLimitError("Rate limit exceeded")
    return handle_api_error(api_error)

def handle_server_error(error):
    """
    Handler for 500 Internal Server Error errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    # Log the full stack trace
    logger.error(f"Server error: {str(error)}", exc_info=True)
    
    # Create a more detailed error in development
    is_development = current_app.config.get('ENV') == 'development'
    
    details = None
    if is_development:
        details = {
            'traceback': traceback.format_exc(),
            'error_type': error.__class__.__name__
        }
    
    api_error = ServiceError("Internal server error", details=details)
    return handle_api_error(api_error)

def handle_exception(error):
    """
    Catch-all handler for uncaught exceptions.
    
    Args:
        error: Exception instance
        
    Returns:
        JSON response with error details
    """
    # Log the full stack trace
    logger.error(f"Uncaught exception: {str(error)}", exc_info=True)
    
    # Create a more detailed error in development
    is_development = current_app.config.get('ENV') == 'development'
    
    details = None
    if is_development:
        details = {
            'traceback': traceback.format_exc(),
            'error_type': error.__class__.__name__
        }
    
    message = str(error) if is_development else "An unexpected error occurred"
    
    api_error = ServiceError(message, details=details)
    return handle_api_error(api_error) 
```


### FILE: backend\auth-service\src\core\health.py
```
"""
Health check module for auth service health monitoring and diagnostics.
Provides comprehensive health checks for all auth service dependencies.
"""

import logging
import time
import os
import socket
import platform
import psutil
from datetime import datetime
from flask import Blueprint, jsonify, current_app, request, g

from .config import get_config

logger = logging.getLogger(__name__)

# Try to import request ID functionality
try:
    from backend.shared.middleware.request_id import get_request_id
    HAS_REQUEST_ID = True
except ImportError:
    HAS_REQUEST_ID = False

# Create health blueprint
health_bp = Blueprint('health', __name__)

@health_bp.route('/health', methods=['GET'])
def health_check():
    """
    Health check endpoint for the auth service.
    Performs comprehensive checks on all dependencies.
    
    Returns:
        JSON response with health status and checks
    """
    start_time = time.time()
    
    # Initialize response
    response = {
        'service': 'auth-service',
        'status': 'healthy',
        'version': os.environ.get('VERSION', 'dev'),
        'environment': current_app.config.get('ENV', 'production'),
        'timestamp': datetime.utcnow().isoformat() + 'Z',
        'checks': {}
    }
    
    # Add request ID if available
    if HAS_REQUEST_ID:
        request_id = get_request_id()
        if request_id:
            response['request_id'] = request_id
    
    # Perform database check
    db_status = _check_database()
    response['checks']['database'] = db_status
    
    # Perform Redis check
    redis_status = _check_redis()
    response['checks']['redis'] = redis_status
    
    # Perform email service check
    email_status = _check_email_service()
    response['checks']['email'] = email_status
    
    # Perform OAuth check
    oauth_status = _check_oauth()
    response['checks']['oauth'] = oauth_status
    
    # Add system information
    response['system'] = _get_system_info()
    
    # Determine overall status
    if any(check.get('status') == 'critical' for check in response['checks'].values()):
        response['status'] = 'critical'
    elif any(check.get('status') == 'warning' for check in response['checks'].values()):
        response['status'] = 'warning'
    
    # Add response time
    response['response_time_ms'] = round((time.time() - start_time) * 1000, 2)
    
    # Set appropriate status code
    status_code = 200
    if response['status'] == 'critical':
        status_code = 503  # Service Unavailable
    elif response['status'] == 'warning':
        status_code = 200  # Still OK but with warnings
    
    # Log health check result
    logger_fn = logger.error if response['status'] == 'critical' else \
               logger.warning if response['status'] == 'warning' else \
               logger.info
    
    logger_fn(f"Health check result: {response['status']}")
    
    # Create response
    json_response = jsonify(response)
    
    # Add request ID to response headers if available
    if HAS_REQUEST_ID and get_request_id():
        json_response.headers['X-Request-ID'] = get_request_id()
    
    return json_response, status_code

def _check_database():
    """
    Check database connection and health.
    
    Returns:
        dict: Database health check result
    """
    from flask_sqlalchemy import SQLAlchemy
    from sqlalchemy import text
    from sqlalchemy.exc import SQLAlchemyError
    
    start_time = time.time()
    db = SQLAlchemy(current_app)
    
    try:
        # Execute simple query to check database connection
        with db.engine.connect() as conn:
            result = conn.execute(text("SELECT 1"))
            assert result.scalar() == 1
        
        # Check connection pool statistics
        pool_info = {
            'size': db.engine.pool.size(),
            'checkedin': db.engine.pool.checkedin(),
            'overflow': db.engine.pool.overflow(),
            'checkedout': db.engine.pool.checkedout(),
        }
        
        # Database connection string (mask sensitive info)
        db_url = _mask_connection_string(current_app.config['SQLALCHEMY_DATABASE_URI'])
        
        return {
            'status': 'healthy',
            'response_time_ms': round((time.time() - start_time) * 1000, 2),
            'pool': pool_info,
            'database_url': db_url
        }
    except SQLAlchemyError as e:
        logger.error(f"Database health check failed: {str(e)}")
        return {
            'status': 'critical',
            'error': str(e),
            'response_time_ms': round((time.time() - start_time) * 1000, 2)
        }
    except Exception as e:
        logger.error(f"Unexpected error during database health check: {str(e)}")
        return {
            'status': 'critical',
            'error': str(e),
            'response_time_ms': round((time.time() - start_time) * 1000, 2)
        }

def _check_redis():
    """
    Check Redis connection and health.
    
    Returns:
        dict: Redis health check result
    """
    import redis
    from redis.exceptions import RedisError
    
    start_time = time.time()
    redis_url = current_app.config.get('REDIS_URL')
    
    if not redis_url:
        return {
            'status': 'warning',
            'error': 'Redis URL not configured',
            'response_time_ms': 0
        }
    
    try:
        # Connect to Redis
        r = redis.from_url(redis_url)
        
        # Test connection with a ping
        assert r.ping()
        
        # Get Redis info
        info = r.info()
        
        redis_info = {
            'version': info.get('redis_version'),
            'used_memory_human': info.get('used_memory_human'),
            'connected_clients': info.get('connected_clients'),
            'uptime_in_seconds': info.get('uptime_in_seconds'),
        }
        
        return {
            'status': 'healthy',
            'response_time_ms': round((time.time() - start_time) * 1000, 2),
            'info': redis_info,
            'redis_url': _mask_connection_string(redis_url)
        }
    except RedisError as e:
        logger.error(f"Redis health check failed: {str(e)}")
        return {
            'status': 'critical' if current_app.config.get('REDIS_REQUIRED', True) else 'warning',
            'error': str(e),
            'response_time_ms': round((time.time() - start_time) * 1000, 2)
        }
    except Exception as e:
        logger.error(f"Unexpected error during Redis health check: {str(e)}")
        return {
            'status': 'critical' if current_app.config.get('REDIS_REQUIRED', True) else 'warning',
            'error': str(e),
            'response_time_ms': round((time.time() - start_time) * 1000, 2)
        }

def _check_email_service():
    """
    Check email service configuration and connectivity.
    
    Returns:
        dict: Email service health check result
    """
    start_time = time.time()
    
    # Check if email is configured
    smtp_server = current_app.config.get('SMTP_SERVER')
    smtp_port = current_app.config.get('SMTP_PORT')
    smtp_username = current_app.config.get('SMTP_USERNAME')
    
    if not smtp_server or not smtp_port:
        return {
            'status': 'warning',
            'error': 'Email service not fully configured',
            'response_time_ms': 0
        }
    
    # Only check connectivity if email is configured
    if smtp_server and smtp_port:
        import socket
        
        try:
            # Try to connect to the SMTP server
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(3.0)  # 3 second timeout
            
            # Only test connectivity, don't try to authenticate
            result = sock.connect_ex((smtp_server, int(smtp_port)))
            sock.close()
            
            if result == 0:
                return {
                    'status': 'healthy',
                    'response_time_ms': round((time.time() - start_time) * 1000, 2),
                    'smtp_server': smtp_server,
                    'smtp_port': smtp_port,
                    'configured': True
                }
            else:
                return {
                    'status': 'warning',
                    'error': f'Could not connect to SMTP server (error code: {result})',
                    'response_time_ms': round((time.time() - start_time) * 1000, 2),
                    'smtp_server': smtp_server,
                    'smtp_port': smtp_port,
                    'configured': True
                }
        except Exception as e:
            logger.warning(f"Email service check failed: {str(e)}")
            return {
                'status': 'warning',
                'error': str(e),
                'response_time_ms': round((time.time() - start_time) * 1000, 2),
                'smtp_server': smtp_server,
                'smtp_port': smtp_port,
                'configured': True
            }
    
    return {
        'status': 'warning',
        'message': 'Email service not configured',
        'response_time_ms': round((time.time() - start_time) * 1000, 2),
        'configured': False
    }

def _check_oauth():
    """
    Check OAuth provider configuration.
    
    Returns:
        dict: OAuth provider health check result
    """
    start_time = time.time()
    
    # Check if Google OAuth is configured
    google_client_id = current_app.config.get('GOOGLE_CLIENT_ID')
    google_client_secret = current_app.config.get('GOOGLE_CLIENT_SECRET')
    
    google_configured = bool(google_client_id and google_client_secret)
    
    oauth_providers = {
        'google': {
            'configured': google_configured
        }
    }
    
    # Determine status based on configuration
    if not any(provider['configured'] for provider in oauth_providers.values()):
        status = 'warning'
        message = 'No OAuth providers configured'
    else:
        status = 'healthy'
        message = 'OAuth providers configured'
    
    return {
        'status': status,
        'message': message,
        'response_time_ms': round((time.time() - start_time) * 1000, 2),
        'providers': oauth_providers
    }

def _get_system_info():
    """
    Get system information for diagnostics.
    
    Returns:
        dict: System information
    """
    # Get CPU and memory info
    try:
        memory = psutil.virtual_memory()
        memory_info = {
            'total_gb': round(memory.total / (1024**3), 2),
            'available_gb': round(memory.available / (1024**3), 2),
            'used_percent': memory.percent
        }
        
        cpu_info = {
            'percent': psutil.cpu_percent(interval=0.1),
            'count': psutil.cpu_count(),
            'load': _get_load_avg()
        }
        
        disk = psutil.disk_usage('/')
        disk_info = {
            'total_gb': round(disk.total / (1024**3), 2),
            'free_gb': round(disk.free / (1024**3), 2),
            'used_percent': disk.percent
        }
    except Exception as e:
        logger.warning(f"Error getting system metrics: {str(e)}")
        memory_info = cpu_info = disk_info = {'error': str(e)}
    
    return {
        'hostname': socket.gethostname(),
        'os': platform.platform(),
        'python_version': platform.python_version(),
        'uptime': _get_uptime(),
        'memory': memory_info,
        'cpu': cpu_info,
        'disk': disk_info
    }

def _get_load_avg():
    """
    Get system load average if available.
    
    Returns:
        list: Load averages for 1, 5, and 15 minutes
    """
    try:
        if hasattr(os, 'getloadavg'):
            return list(os.getloadavg())
        return None
    except (AttributeError, OSError):
        return None

def _get_uptime():
    """
    Get system uptime if available.
    
    Returns:
        float: System uptime in seconds
    """
    try:
        return psutil.boot_time()
    except Exception:
        return None

def _mask_connection_string(conn_string):
    """
    Mask sensitive information in connection strings.
    
    Args:
        conn_string: Connection string to mask
        
    Returns:
        str: Masked connection string
    """
    if not conn_string:
        return None
    
    try:
        # Simple approach: just mask anything after : or @ and before the next /
        import re
        masked = re.sub(r'(?<=:)[^/]+(?=/)', '***', conn_string)
        masked = re.sub(r'(?<=@)[^/]+(?=/)', '***', masked)
        return masked
    except Exception:
        # If anything goes wrong, return a fully masked string
        return "***MASKED***" 
```


### FILE: backend\auth-service\src\models\auth.py
```
from datetime import datetime, timedelta
from sqlalchemy.sql import func
import bcrypt
from ..schemas.auth import AuthUserCreate, AuthUserUpdate, AuthUserResponse, SessionCreate, EmailVerificationCreate
from ..database import db
from flask import current_app

class AuthUser(db.Model):
    __tablename__ = 'auth_users'

    id = db.Column(db.Integer, primary_key=True)
    email = db.Column(db.String(255), unique=True, nullable=False)
    password_hash = db.Column(db.Text, nullable=True)
    is_google_user = db.Column(db.Boolean, default=False)
    first_login = db.Column(db.Boolean, default=True)
    is_email_verified = db.Column(db.Boolean, default=False)
    created_at = db.Column(db.DateTime, default=func.now())
    updated_at = db.Column(db.DateTime, default=func.now(), onupdate=func.now())
    last_login = db.Column(db.DateTime)
    
    # Profile fields
    first_name = db.Column(db.String(100))
    last_name = db.Column(db.String(100))
    profile_picture = db.Column(db.String(255))
    
    # OAuth fields
    google_id = db.Column(db.String(255), unique=True, nullable=True)
    google_refresh_token = db.Column(db.Text, nullable=True)

    # Account security fields
    failed_login_attempts = db.Column(db.Integer, default=0)
    locked_until = db.Column(db.DateTime, nullable=True)
    password_last_changed = db.Column(db.DateTime, default=func.now())
    require_password_change = db.Column(db.Boolean, default=False)
    last_failed_login = db.Column(db.DateTime, nullable=True)
    security_audit_log = db.Column(db.JSON, nullable=True)

    @classmethod
    def from_schema(cls, user_create: AuthUserCreate):
        """Create a new user from schema"""
        user = cls(
            email=user_create.email.lower(),
            first_name=user_create.first_name,
            last_name=user_create.last_name
        )
        user.set_password(user_create.password)
        return user

    def update_from_schema(self, user_update: AuthUserUpdate):
        """Update user from schema"""
        for field, value in user_update.model_dump(exclude_unset=True).items():
            setattr(self, field, value)

    def to_schema(self) -> AuthUserResponse:
        """Convert to response schema"""
        return AuthUserResponse.model_validate(self)

    def set_password(self, password: str):
        """Hash and set the user's password with history tracking"""
        if not password:
            raise ValueError("Password cannot be empty")
            
        # Check password history
        if self.password_hash:
            # Store old password in history
            history = PasswordHistory(
                user_id=self.id,
                password_hash=self.password_hash
            )
            db.session.add(history)
            
            # Check if password was used recently
            recent_passwords = PasswordHistory.query.filter_by(
                user_id=self.id
            ).order_by(PasswordHistory.created_at.desc()).limit(5).all()
            
            for old_pw in recent_passwords:
                if bcrypt.checkpw(password.encode('utf-8'), old_pw.password_hash.encode('utf-8')):
                    raise ValueError("Password was used recently. Please choose a different password.")

        salt = bcrypt.gensalt()
        self.password_hash = bcrypt.hashpw(password.encode('utf-8'), salt).decode('utf-8')
        self.password_last_changed = datetime.utcnow()
        self.require_password_change = False
        
        # Log password change
        self._log_security_event("password_changed")

    def check_password(self, password: str) -> bool:
        """Verify the user's password with account lockout"""
        if self.is_locked():
            return False
            
        if not self.password_hash:
            return False
            
        is_valid = bcrypt.checkpw(password.encode('utf-8'), self.password_hash.encode('utf-8'))
        
        if not is_valid:
            self.failed_login_attempts += 1
            self.last_failed_login = datetime.utcnow()
            
            # Lock account after 5 failed attempts
            if self.failed_login_attempts >= 5:
                self.locked_until = datetime.utcnow() + timedelta(minutes=15)
                self._log_security_event("account_locked", {"reason": "too_many_failed_attempts"})
            
            db.session.commit()
            return False
            
        # Reset failed attempts on successful login
        self.failed_login_attempts = 0
        self.locked_until = None
        db.session.commit()
        return True

    def is_locked(self) -> bool:
        """Check if the account is locked"""
        if not self.locked_until:
            return False
        return datetime.utcnow() < self.locked_until

    def unlock(self):
        """Unlock the account"""
        self.locked_until = None
        self.failed_login_attempts = 0
        self._log_security_event("account_unlocked")
        db.session.commit()

    def force_password_change(self):
        """Force user to change password on next login"""
        self.require_password_change = True
        self._log_security_event("password_change_required")
        db.session.commit()

    def _log_security_event(self, event_type: str, details: dict = None):
        """Log security-related events"""
        if self.security_audit_log is None:
            self.security_audit_log = []
            
        event = {
            "type": event_type,
            "timestamp": datetime.utcnow().isoformat(),
            "details": details or {}
        }
        
        self.security_audit_log.append(event)
        if len(self.security_audit_log) > 100:  # Keep last 100 events
            self.security_audit_log = self.security_audit_log[-100:]

    def create_session(self, device_info=None, expires_at=None) -> 'UserSession':
        """Create a new session for the user"""
        session_data = SessionCreate(
            user_id=self.id,
            device_info=device_info,
            ip_address=device_info.get('ip_address') if device_info else None,
            expires_at=expires_at or datetime.utcnow() + timedelta(days=7)
        )
        session = UserSession.from_schema(session_data)
        db.session.add(session)
        return session

    def create_verification_token(self) -> 'EmailVerification':
        """Create a new email verification token"""
        import secrets
        token_data = EmailVerificationCreate(
            user_id=self.id,
            token=secrets.token_urlsafe(32),
            expires_at=datetime.utcnow() + timedelta(hours=24)
        )
        verification = EmailVerification.from_schema(token_data)
        db.session.add(verification)
        return verification

class PasswordResetToken(db.Model):
    __tablename__ = 'password_reset_tokens'

    id = db.Column(db.Integer, primary_key=True)
    user_id = db.Column(db.Integer, db.ForeignKey('auth_users.id', ondelete='CASCADE'), nullable=False)
    token = db.Column(db.Text, nullable=False)
    expires_at = db.Column(db.DateTime, nullable=False)
    created_at = db.Column(db.DateTime, default=func.now())
    used = db.Column(db.Boolean, default=False)

    user = db.relationship('AuthUser', backref=db.backref('reset_tokens', lazy=True))

    @classmethod
    def from_schema(cls, token_data):
        return cls(
            user_id=token_data.user_id,
            token=token_data.token,
            expires_at=token_data.expires_at
        )

class UserSession(db.Model):
    __tablename__ = 'user_sessions'

    id = db.Column(db.Integer, primary_key=True)
    user_id = db.Column(db.Integer, db.ForeignKey('auth_users.id', ondelete='CASCADE'), nullable=False)
    token = db.Column(db.Text, nullable=False)
    refresh_token = db.Column(db.Text, nullable=True)
    device_info = db.Column(db.JSON, nullable=True)
    ip_address = db.Column(db.String(45), nullable=True)
    created_at = db.Column(db.DateTime, default=func.now())
    expires_at = db.Column(db.DateTime, nullable=False)
    refresh_token_expires_at = db.Column(db.DateTime, nullable=True)
    revoked = db.Column(db.Boolean, default=False)
    revoked_at = db.Column(db.DateTime, nullable=True)
    revocation_reason = db.Column(db.String(100), nullable=True)
    last_used_at = db.Column(db.DateTime, nullable=True)
    device_name = db.Column(db.String(100), nullable=True)
    device_type = db.Column(db.String(50), nullable=True)
    user_agent = db.Column(db.Text, nullable=True)

    user = db.relationship('AuthUser', backref=db.backref('sessions', lazy=True))

    @classmethod
    def from_schema(cls, session_data: SessionCreate):
        import secrets
        return cls(
            user_id=session_data.user_id,
            token=secrets.token_urlsafe(32),
            refresh_token=secrets.token_urlsafe(32) if session_data.include_refresh_token else None,
            device_info=session_data.device_info,
            ip_address=session_data.ip_address,
            expires_at=session_data.expires_at,
            refresh_token_expires_at=session_data.refresh_token_expires_at,
            device_name=session_data.device_info.get('name') if session_data.device_info else None,
            device_type=session_data.device_info.get('type') if session_data.device_info else None,
            user_agent=session_data.device_info.get('user_agent') if session_data.device_info else None
        )

    def revoke(self, reason: str = None):
        """Revoke the session"""
        self.revoked = True
        self.revoked_at = datetime.utcnow()
        self.revocation_reason = reason
        db.session.commit()

    def refresh(self) -> 'UserSession':
        """Create a new session using the refresh token"""
        if self.revoked or not self.refresh_token or datetime.utcnow() > self.refresh_token_expires_at:
            raise ValueError("Invalid or expired refresh token")
        
        import secrets
        new_session = UserSession(
            user_id=self.user_id,
            token=secrets.token_urlsafe(32),
            refresh_token=secrets.token_urlsafe(32),
            device_info=self.device_info,
            ip_address=self.ip_address,
            expires_at=datetime.utcnow() + timedelta(days=1),
            refresh_token_expires_at=datetime.utcnow() + timedelta(days=30),
            device_name=self.device_name,
            device_type=self.device_type,
            user_agent=self.user_agent
        )
        
        self.revoke("Refreshed")
        db.session.add(new_session)
        db.session.commit()
        return new_session

    def update_last_used(self):
        """Update the last used timestamp"""
        self.last_used_at = datetime.utcnow()
        try:
            db.session.commit()
        except Exception as e:
            db.session.rollback()
            current_app.logger.error(f"Error updating session last_used timestamp: {str(e)}")
            return False
        return True

class EmailVerification(db.Model):
    __tablename__ = 'email_verifications'

    id = db.Column(db.Integer, primary_key=True)
    user_id = db.Column(db.Integer, db.ForeignKey('auth_users.id', ondelete='CASCADE'), nullable=False)
    token = db.Column(db.String(255), unique=True, nullable=False)
    expires_at = db.Column(db.DateTime, nullable=False)
    created_at = db.Column(db.DateTime, default=func.now())
    is_used = db.Column(db.Boolean, default=False)

    user = db.relationship('AuthUser', backref=db.backref('email_verifications', lazy=True))

    @classmethod
    def from_schema(cls, verification_data: EmailVerificationCreate):
        return cls(
            user_id=verification_data.user_id,
            token=verification_data.token,
            expires_at=verification_data.expires_at
        )

class PasswordHistory(db.Model):
    __tablename__ = 'password_history'

    id = db.Column(db.Integer, primary_key=True)
    user_id = db.Column(db.Integer, db.ForeignKey('auth_users.id', ondelete='CASCADE'), nullable=False)
    password_hash = db.Column(db.Text, nullable=False)
    created_at = db.Column(db.DateTime, default=func.now())

    user = db.relationship('AuthUser', backref=db.backref('password_history', lazy=True)) 
```


### FILE: backend\auth-service\src\routes\auth.py
```
from flask import Blueprint, request, jsonify, current_app, g
from datetime import datetime, timedelta
import bcrypt
import jwt
from google.oauth2 import id_token
from google.auth.transport import requests as google_requests
import re
import secrets
from ..models.auth import AuthUser, PasswordResetToken, UserSession, EmailVerification
from shared.database import db, transaction
from shared.middleware.validation import validate_schema
from shared.middleware.rate_limiter import rate_limit
from shared.middleware.auth import jwt_required
from shared.schemas.base import ErrorResponse, SuccessResponse
from ..schemas.auth import (
    AuthUserCreate, AuthUserUpdate, AuthUserResponse, SessionCreate,
    EmailVerificationCreate, AuthUserLogin, GoogleLogin, PasswordReset,
    PasswordResetConfirm, TokenRefresh, SessionRevoke
)
from ..utils.email_service import send_verification_email
from ..utils.auth import get_current_user, get_current_session
import logging
from ..utils.rate_limiter import rate_limit as custom_rate_limit
from ..utils.database import with_transaction
import string
from functools import wraps
from ..utils.token_service import TokenService

logger = logging.getLogger(__name__)
auth_bp = Blueprint('auth', __name__)

def token_service():
    """Get token service instance"""
    return TokenService()

def service_auth_required(f):
    """Decorator to require service authentication key"""
    @wraps(f)
    def decorated(*args, **kwargs):
        service_key = request.headers.get('X-Service-Key')
        expected_key = current_app.config.get('SERVICE_KEY')
        
        if not service_key or service_key != expected_key:
            logger.warning(f"Invalid service key attempt from {request.remote_addr}")
            return jsonify({"error": "Invalid service key"}), 403
            
        return f(*args, **kwargs)
    
    return decorated

def validate_password(password):
    """Validate password strength"""
    if len(password) < 12:
        return False, "Password must be at least 12 characters long"
    
    if not any(c.isupper() for c in password):
        return False, "Password must contain at least one uppercase letter"
    
    if not any(c.islower() for c in password):
        return False, "Password must contain at least one lowercase letter"
    
    if not any(c.isdigit() for c in password):
        return False, "Password must contain at least one number"
    
    return True, None

def generate_verification_token():
    """Generate a secure verification token"""
    alphabet = string.ascii_letters + string.digits
    return ''.join(secrets.choice(alphabet) for _ in range(32))

@auth_bp.route('/register', methods=['POST'])
@custom_rate_limit(limit=5, window=3600)  # 5 registrations per hour
def register():
    data = request.get_json()
    
    # Validate request data
    try:
        user_data = AuthUserCreate(**data)
    except Exception as e:
        return jsonify({"error": str(e)}), 400
    
    # Validate password strength
    is_valid, error = validate_password(user_data.password)
    if not is_valid:
        return jsonify({"error": error}), 400
    
    # Check if user exists
    if AuthUser.query.filter_by(email=user_data.email).first():
        return jsonify({"error": "Email already registered"}), 409
    
    # Create user
    user = AuthUser.from_schema(user_data)
    current_app.db.session.add(user)
    current_app.db.session.commit()
    
    # Generate and send verification email
    verification = user.create_verification_token()
    if send_verification_email(user.email, verification.token):
        return jsonify({"message": "Registration successful. Please check your email to verify your account."}), 201
    else:
        return jsonify({"error": "Failed to send verification email"}), 500

@auth_bp.route('/verify-email/<token>', methods=['GET'])
@custom_rate_limit(limit=10, window=3600)  # 10 verification attempts per hour
@with_transaction
def verify_email(token):
    verification = EmailVerification.query.filter_by(
        token=token,
        is_used=False
    ).first()
    
    if not verification or verification.is_expired():
        return jsonify({"error": "Invalid or expired verification token"}), 400
    
    user = verification.user
    user.is_email_verified = True
    verification.is_used = True
    
    return jsonify({"message": "Email verified successfully"})

@auth_bp.route('/resend-verification', methods=['POST'])
@custom_rate_limit(limit=3, window=3600)  # 3 resend attempts per hour
def resend_verification():
    data = request.get_json()
    if not data or 'email' not in data:
        return jsonify({"error": "Email is required"}), 400
    
    user = AuthUser.query.filter_by(email=data['email']).first()
    if not user:
        return jsonify({"error": "User not found"}), 404
    
    if user.is_email_verified:
        return jsonify({"error": "Email is already verified"}), 400
    
    # Create new verification token
    verification = user.create_verification_token()
    
    # Send verification email
    if send_verification_email(user.email, verification.token):
        return jsonify({"message": "Verification email sent"})
    else:
        return jsonify({"error": "Failed to send verification email"}), 500

@auth_bp.route('/login', methods=['POST'])
@custom_rate_limit(limit=10, window=300)  # 10 login attempts per 5 minutes
def login():
    data = request.get_json()
    
    try:
        login_data = AuthUserLogin(**data)
    except Exception as e:
        return jsonify({"error": str(e)}), 400
    
    user = AuthUser.query.filter_by(email=login_data.email).first()
    if not user or not user.check_password(login_data.password):
        return jsonify({"error": "Invalid email or password"}), 401
    
    if not user.is_email_verified:
        return jsonify({"error": "Please verify your email before logging in"}), 403
    
    # Create session
    session = user.create_session(
        device_info=login_data.device_info
    )
    current_app.db.session.add(session)
    current_app.db.session.commit()
    
    return jsonify({
        "token": session.token,
        "refresh_token": session.refresh_token,
        "user": AuthUserResponse.from_orm(user).dict()
    })

@auth_bp.route('/google/login', methods=['POST'])
@validate_schema(GoogleLogin)
def google_login(data: GoogleLogin):
    """Handle Google OAuth login"""
    try:
        # Verify Google token
        idinfo = id_token.verify_oauth2_token(
            data.token,
            google_requests.Request(),
            current_app.config['GOOGLE_CLIENT_ID']
        )

        email = idinfo['email']
        
        with transaction():
            # Check if user exists
            user = AuthUser.query.filter_by(email=email).first()
            
            if not user:
                # Create new user
                user = AuthUser(
                    email=email,
                    is_google_user=True,
                    is_email_verified=True,
                    first_name=idinfo.get('given_name'),
                    last_name=idinfo.get('family_name'),
                    profile_picture=idinfo.get('picture'),
                    google_id=idinfo['sub']
                )
                db.session.add(user)
                db.session.flush()
            
            # Update Google info if needed
            if user.google_id != idinfo['sub']:
                user.google_id = idinfo['sub']
                user.is_google_user = True
            
            # Create session
            session = user.create_session(data.device_info)
            user.last_login = datetime.utcnow()
            
            return jsonify(SuccessResponse(
                message="Google login successful",
                data={
                    "token": session.token,
                    "refresh_token": session.refresh_token,
                    "user": user.to_schema().model_dump()
                }
            ).model_dump())

    except ValueError as e:
        # Invalid token
        logger.error(f"Invalid Google token: {str(e)}")
        return jsonify(ErrorResponse(
            error="Authentication Error",
            message="Invalid Google token"
        ).model_dump()), 401
    except Exception as e:
        logger.error(f"Google login error: {str(e)}")
        return jsonify(ErrorResponse(
            error="Authentication Error",
            message="Google login failed"
        ).model_dump()), 500

@auth_bp.route('/reset-password', methods=['POST'])
@custom_rate_limit(limit=3, window=3600)  # 3 reset attempts per hour
@validate_schema(PasswordReset)
def reset_password(data: PasswordReset):
    """Initiate password reset"""
    try:
        user = AuthUser.query.filter_by(email=data.email.lower()).first()
        if not user:
            # Return success even if user doesn't exist (security)
            return jsonify(SuccessResponse(
                message="If your email is registered, you will receive reset instructions"
            ).model_dump())

        with transaction():
            # Create reset token
            token = PasswordResetToken(
                user_id=user.id,
                token=secrets.token_urlsafe(32),
                expires_at=datetime.utcnow() + timedelta(hours=24)
            )
            db.session.add(token)
            
            # Send reset email (implement this)
            # send_password_reset_email(user.email, token.token)
            
            return jsonify(SuccessResponse(
                message="If your email is registered, you will receive reset instructions"
            ).model_dump())

    except Exception as e:
        logger.error(f"Password reset error: {str(e)}")
        return jsonify(ErrorResponse(
            error="Reset Error",
            message="Failed to process password reset"
        ).model_dump()), 500

@auth_bp.route('/reset-password/confirm', methods=['POST'])
@validate_schema(PasswordResetConfirm)
def confirm_reset_password(data: PasswordResetConfirm):
    """Confirm password reset"""
    try:
        # Find valid token
        token = PasswordResetToken.query.filter_by(
            token=data.token,
            used=False
        ).filter(PasswordResetToken.expires_at > datetime.utcnow()).first()

        if not token:
            return jsonify(ErrorResponse(
                error="Reset Error",
                message="Invalid or expired token"
            ).model_dump()), 400

        with transaction():
            # Update password
            user = token.user
            user.set_password(data.new_password)
            
            # Invalidate token
            token.used = True
            
            # Revoke all sessions
            UserSession.query.filter_by(user_id=user.id).update({
                'revoked': True,
                'revoked_at': datetime.utcnow(),
                'revocation_reason': 'Password reset'
            })
            
            return jsonify(SuccessResponse(
                message="Password has been reset successfully"
            ).model_dump())

    except Exception as e:
        logger.error(f"Password reset confirmation error: {str(e)}")
        return jsonify(ErrorResponse(
            error="Reset Error",
            message="Failed to reset password"
        ).model_dump()), 500

@auth_bp.route('/refresh-token', methods=['POST'])
@validate_schema(TokenRefresh)
def refresh_token(data: TokenRefresh):
    """Refresh access token using refresh token"""
    try:
        # Find valid session by refresh token
        session = UserSession.query.filter_by(
            refresh_token=data.refresh_token,
            revoked=False
        ).filter(UserSession.refresh_token_expires_at > datetime.utcnow()).first()

        if not session:
            return jsonify(ErrorResponse(
                error="Authentication Error",
                message="Invalid or expired refresh token"
            ).model_dump()), 401

        with transaction():
            # Create new session
            new_session = session.refresh()
            
            return jsonify(SuccessResponse(
                message="Token refreshed successfully",
                data={
                    "token": new_session.token,
                    "refresh_token": new_session.refresh_token
                }
            ).model_dump())

    except Exception as e:
        logger.error(f"Token refresh error: {str(e)}")
        return jsonify(ErrorResponse(
            error="Authentication Error",
            message="Failed to refresh token"
        ).model_dump()), 500

@auth_bp.route('/sessions', methods=['GET'])
@jwt_required
def list_sessions():
    """List all active sessions for the current user"""
    try:
        current_user = get_current_user()
        sessions = UserSession.query.filter_by(
            user_id=current_user.id,
            revoked=False
        ).filter(UserSession.expires_at > datetime.utcnow()).all()
        
        return jsonify(SuccessResponse(
            message="Sessions retrieved successfully",
            data={
                "sessions": [session.to_schema().model_dump() for session in sessions],
                "total_count": len(sessions)
            }
        ).model_dump())

    except Exception as e:
        logger.error(f"Error listing sessions: {str(e)}")
        return jsonify(ErrorResponse(
            error="Session Error",
            message="Failed to list sessions"
        ).model_dump()), 500

@auth_bp.route('/sessions/<int:session_id>/revoke', methods=['POST'])
@jwt_required
@validate_schema(SessionRevoke)
def revoke_session(session_id: int, data: SessionRevoke):
    """Revoke a specific session"""
    try:
        current_user = get_current_user()
        current_session = get_current_session()
        
        # Find session
        session = UserSession.query.filter_by(
            id=session_id,
            user_id=current_user.id,
            revoked=False
        ).first()
        
        if not session:
            return jsonify(ErrorResponse(
                error="Session Error",
                message="Session not found"
            ).model_dump()), 404
            
        with transaction():
            session.revoke(reason=data.reason or "User initiated revocation")
            
            return jsonify(SuccessResponse(
                message="Session revoked successfully"
            ).model_dump())

    except Exception as e:
        logger.error(f"Error revoking session: {str(e)}")
        return jsonify(ErrorResponse(
            error="Session Error",
            message="Failed to revoke session"
        ).model_dump()), 500

@auth_bp.route('/sessions/revoke-all', methods=['POST'])
@jwt_required
def revoke_all_sessions():
    """Revoke all sessions except the current one"""
    try:
        current_user = get_current_user()
        current_session = get_current_session()
        
        with transaction():
            # Revoke all other sessions
            UserSession.query.filter(
                UserSession.user_id == current_user.id,
                UserSession.id != current_session.id,
                UserSession.revoked == False
            ).update({
                'revoked': True,
                'revoked_at': datetime.utcnow(),
                'revocation_reason': 'User revoked all sessions'
            })
            
            return jsonify(SuccessResponse(
                message="All other sessions revoked successfully"
            ).model_dump())

    except Exception as e:
        logger.error(f"Error revoking all sessions: {str(e)}")
        return jsonify(ErrorResponse(
            error="Session Error",
            message="Failed to revoke sessions"
        ).model_dump()), 500

@auth_bp.route('/logout', methods=['POST'])
@jwt_required
def logout():
    """Log out user by revoking current session"""
    try:
        current_session = get_current_session()
        
        with transaction():
            current_session.revoke(reason="User logout")
            
            return jsonify(SuccessResponse(
                message="Logged out successfully"
            ).model_dump())

    except Exception as e:
        logger.error(f"Logout error: {str(e)}")
        return jsonify(ErrorResponse(
            error="Logout Error",
            message="Failed to logout"
        ).model_dump()), 500

@auth_bp.route('/validate-token', methods=['POST'])
@service_auth_required
def validate_token():
    """
    Validate a JWT token
    This endpoint is used by other services to validate tokens
    """
    try:
        data = request.get_json()
        if not data or 'token' not in data:
            return jsonify({"error": "Token is required"}), 400
            
        token = data['token']
        
        try:
            # First, try to decode the token
            payload = jwt.decode(
                token,
                current_app.config['JWT_SECRET_KEY'],
                algorithms=['HS256']
            )
            
            # Check if user exists
            user_id = payload.get('user_id')
            if not user_id:
                return jsonify({"error": "Invalid token: missing user_id"}), 401
                
            user = AuthUser.query.get(user_id)
            if not user:
                return jsonify({"error": "User not found"}), 401
                
            # Verify if token belongs to a valid session
            session = UserSession.query.filter_by(
                token=token,
                revoked=False
            ).first()
            
            if not session:
                return jsonify({"error": "Invalid or revoked session"}), 401
                
            # Update last_used timestamp for the session
            session.update_last_used()
            
            # Return payload with additional user info
            response_data = {
                **payload,
                "is_active": not user.is_locked(),
                "is_email_verified": user.is_email_verified,
                "roles": user.roles
            }
            
            return jsonify({"data": response_data}), 200
            
        except jwt.ExpiredSignatureError:
            return jsonify({"error": "Token has expired"}), 401
        except jwt.InvalidTokenError as e:
            return jsonify({"error": f"Invalid token: {str(e)}"}), 401
            
    except Exception as e:
        logger.error(f"Error validating token: {str(e)}")
        return jsonify({"error": "Server error occurred during token validation"}), 500 
```


### FILE: backend\auth-service\src\schemas\auth.py
```
from datetime import datetime
from typing import Optional, Dict, Any, List
from pydantic import BaseModel, EmailStr, Field, validator, root_validator
from shared.schemas.base import BaseSchema
from pydantic.types import SecretStr

class AuthUserBase(BaseSchema):
    email: EmailStr
    is_google_user: bool = False
    first_login: bool = True
    is_email_verified: bool = False
    first_name: Optional[str] = Field(None, min_length=1, max_length=100)
    last_name: Optional[str] = Field(None, min_length=1, max_length=100)
    profile_picture: Optional[str] = None
    last_login: Optional[datetime] = None

class AuthUserCreate(BaseModel):
    email: EmailStr
    password: str = Field(..., min_length=12, max_length=72)
    first_name: Optional[str] = Field(None, min_length=1, max_length=100)
    last_name: Optional[str] = Field(None, min_length=1, max_length=100)

    @validator('password')
    def validate_password(cls, v):
        if not any(c.isupper() for c in v):
            raise ValueError('Password must contain at least one uppercase letter')
        if not any(c.islower() for c in v):
            raise ValueError('Password must contain at least one lowercase letter')
        if not any(c.isdigit() for c in v):
            raise ValueError('Password must contain at least one number')
        if not any(c in '@$!%*?&' for c in v):
            raise ValueError('Password must contain at least one special character (@$!%*?&)')
        return v

class AuthUserUpdate(BaseModel):
    first_name: Optional[str] = Field(None, min_length=1, max_length=100)
    last_name: Optional[str] = Field(None, min_length=1, max_length=100)
    profile_picture: Optional[str] = None

class AuthUserLogin(BaseModel):
    email: EmailStr
    password: str = Field(..., min_length=12, max_length=72)
    device_info: Optional[Dict[str, Any]] = None

class GoogleLogin(BaseModel):
    token: str
    device_info: Optional[Dict[str, Any]] = None

class PasswordReset(BaseModel):
    email: EmailStr

class PasswordResetConfirm(BaseModel):
    token: str
    new_password: str = Field(..., min_length=12, max_length=72)

    @validator('new_password')
    def validate_password(cls, v):
        if not any(c.isupper() for c in v):
            raise ValueError('Password must contain at least one uppercase letter')
        if not any(c.islower() for c in v):
            raise ValueError('Password must contain at least one lowercase letter')
        if not any(c.isdigit() for c in v):
            raise ValueError('Password must contain at least one number')
        if not any(c in '@$!%*?&' for c in v):
            raise ValueError('Password must contain at least one special character (@$!%*?&)')
        return v

class SessionCreate(BaseModel):
    user_id: int
    device_info: Optional[Dict[str, Any]] = None
    ip_address: Optional[str] = Field(None, max_length=45)
    expires_at: datetime
    include_refresh_token: bool = True
    refresh_token_expires_at: Optional[datetime] = None

class SessionResponse(BaseModel):
    token: str
    refresh_token: Optional[str] = None
    expires_at: datetime
    refresh_token_expires_at: Optional[datetime] = None
    device_info: Optional[Dict[str, Any]] = None
    device_name: Optional[str] = None
    device_type: Optional[str] = None
    created_at: datetime
    last_used_at: Optional[datetime] = None

class TokenRefresh(BaseModel):
    refresh_token: str
    device_info: Optional[Dict[str, Any]] = None

class SessionRevoke(BaseModel):
    session_id: int
    reason: Optional[str] = None

class ActiveSessionsResponse(BaseModel):
    sessions: List[SessionResponse]
    total_count: int

class EmailVerificationCreate(BaseModel):
    user_id: int
    token: str = Field(..., min_length=32)
    expires_at: datetime

class AuthUserResponse(AuthUserBase):
    id: int
    created_at: datetime
    updated_at: datetime 
```


### FILE: backend\auth-service\src\schemas\base.py
```
from datetime import datetime
from typing import Optional
from pydantic import BaseModel, ConfigDict

class BaseSchema(BaseModel):
    """Base schema class with common fields and configuration"""
    model_config = ConfigDict(from_attributes=True)
    
    id: Optional[int] = None
    created_at: Optional[datetime] = None
    updated_at: Optional[datetime] = None

    model_config = ConfigDict(json_encoders={
        datetime: lambda dt: dt.isoformat()
    }) 
```


### FILE: backend\auth-service\src\tasks\cleanup.py
```
import logging
from datetime import datetime, timedelta
from flask import current_app
from sqlalchemy.sql import text
from ..database import db
from ..models.auth import UserSession, EmailVerification, PasswordResetToken
from ..utils.database import transaction_context
from ..utils.session_service import SessionService
from ..utils.service_integration import ServiceIntegration

logger = logging.getLogger(__name__)

def cleanup_expired_data():
    """Cleanup expired sessions, tokens, and other temporary data"""
    try:
        start_time = datetime.utcnow()
        session_service = SessionService()
        service_integration = ServiceIntegration()
        
        logger.info("Starting cleanup of expired data")

        # Use direct SQL for more efficient deletion of expired sessions
        with transaction_context() as session:
            # Get count of sessions to be cleaned up for logging
            session_count_query = text("""
                SELECT COUNT(*) FROM user_sessions 
                WHERE expires_at < :now AND revoked = FALSE
            """)
            session_count = session.execute(
                session_count_query, 
                {"now": datetime.utcnow()}
            ).scalar() or 0
            
            # If there are sessions to clean up, process them in batches
            if session_count > 0:
                logger.info(f"Found {session_count} expired sessions to clean up")
                
                # Process in batches of 500 to avoid long-running transactions
                batch_size = 500
                batches_processed = 0
                total_processed = 0
                
                while total_processed < session_count:
                    # Update in batches
                    update_query = text("""
                        UPDATE user_sessions
                        SET revoked = TRUE,
                            revoked_at = :now,
                            revocation_reason = 'Expired'
                        WHERE id IN (
                            SELECT id FROM user_sessions
                            WHERE expires_at < :now AND revoked = FALSE
                            LIMIT :batch_size
                        )
                        RETURNING id
                    """)
                    
                    result = session.execute(
                        update_query, 
                        {
                            "now": datetime.utcnow(),
                            "batch_size": batch_size
                        }
                    )
                    
                    batch_processed = result.rowcount
                    if batch_processed == 0:
                        break  # No more to process
                        
                    total_processed += batch_processed
                    batches_processed += 1
                    
                    session.commit()  # Commit each batch
                    
                logger.info(f"Cleaned up {total_processed} expired sessions in {batches_processed} batches")
            else:
                logger.info("No expired sessions to clean up")
            
            # Cleanup expired email verifications
            expired_verifications = EmailVerification.query.filter(
                EmailVerification.expires_at < datetime.utcnow(),
                EmailVerification.is_used == False
            ).update({
                'is_used': True
            })
            
            if expired_verifications > 0:
                logger.info(f"Cleaned up {expired_verifications} expired email verifications")
            
            # Cleanup expired password reset tokens
            expired_tokens = PasswordResetToken.query.filter(
                PasswordResetToken.expires_at < datetime.utcnow(),
                PasswordResetToken.used == False
            ).update({
                'used': True
            })
            
            if expired_tokens > 0:
                logger.info(f"Cleaned up {expired_tokens} expired password reset tokens")
            
            # Sync cleanup with main service
            cleanup_data = {
                'expired_sessions': session_count,
                'expired_verifications': expired_verifications,
                'expired_tokens': expired_tokens,
                'cleanup_timestamp': datetime.utcnow().isoformat()
            }
            
            service_integration.sync_user_session(None, None, cleanup_data)
            
            # Calculate duration for monitoring
            duration = (datetime.utcnow() - start_time).total_seconds()
            logger.info(
                f"Cleanup completed in {duration:.2f} seconds - "
                f"Cleaned up {session_count} sessions, "
                f"{expired_verifications} verifications, "
                f"{expired_tokens} reset tokens"
            )
            
            # Store metrics in Redis for monitoring
            try:
                redis_client = current_app.extensions.get('redis')
                if redis_client:
                    metrics = {
                        'expired_sessions': session_count,
                        'expired_verifications': expired_verifications,
                        'expired_tokens': expired_tokens,
                        'duration_seconds': duration,
                        'timestamp': datetime.utcnow().isoformat()
                    }
                    redis_client.hmset('metrics:last_cleanup', metrics)
                    redis_client.expire('metrics:last_cleanup', 86400)  # Keep for 24 hours
                    
                    # Store history for trend analysis
                    redis_client.lpush('metrics:cleanup_history', session_count)
                    redis_client.ltrim('metrics:cleanup_history', 0, 30)  # Keep last 30 entries
            except Exception as e:
                logger.error(f"Failed to store cleanup metrics: {str(e)}")
            
    except Exception as e:
        logger.error(f"Error during cleanup: {str(e)}")
        db.session.rollback() 
```


### FILE: backend\auth-service\src\utils\auth.py
```
from functools import wraps
from flask import request, jsonify, current_app, g
import jwt
from ..models.auth import AuthUser, UserSession
from ..database import db

def jwt_required(f):
    @wraps(f)
    def decorated(*args, **kwargs):
        token = None
        if 'Authorization' in request.headers:
            token = request.headers['Authorization'].split(' ')[1]
        
        if not token:
            return jsonify({'error': 'Token is missing'}), 401
        
        try:
            data = jwt.decode(token, current_app.config['JWT_SECRET_KEY'], algorithms=['HS256'])
            current_user = AuthUser.query.get(data['user_id'])
            if not current_user:
                return jsonify({'error': 'User not found'}), 401
                
            # Store user in flask g object
            g.current_user = current_user
            
            # Get current session
            current_session = UserSession.query.filter_by(
                token=token,
                revoked=False
            ).first()
            if not current_session:
                return jsonify({'error': 'Invalid session'}), 401
            
            g.current_session = current_session
            
        except jwt.ExpiredSignatureError:
            return jsonify({'error': 'Token has expired'}), 401
        except jwt.InvalidTokenError:
            return jsonify({'error': 'Invalid token'}), 401
        
        return f(*args, **kwargs)
    
    return decorated

def get_current_user():
    """Get the current authenticated user"""
    return getattr(g, 'current_user', None)

def get_current_session():
    """Get the current user session"""
    return getattr(g, 'current_session', None) 
```


### FILE: backend\auth-service\src\utils\data_seeder.py
```
import logging
from flask import Flask
from sqlalchemy.exc import IntegrityError
from ..models.auth import AuthUser

logger = logging.getLogger(__name__)

class DataSeeder:
    def __init__(self, app: Flask, db):
        self.app = app
        self.db = db

    def seed_admin_user(self):
        """Seed admin user if not exists"""
        try:
            with self.app.app_context():
                if not AuthUser.query.filter_by(email='admin@example.com').first():
                    admin = AuthUser(
                        email='admin@example.com',
                        first_name='Admin',
                        last_name='User',
                        is_email_verified=True
                    )
                    admin.set_password('Admin123!')
                    self.db.session.add(admin)
                    self.db.session.commit()
                    logger.info("Admin user seeded successfully")
                    return True
                return True
        except Exception as e:
            logger.error(f"Error seeding admin user: {str(e)}")
            return False

    def run_all_seeders(self):
        """Run all data seeders"""
        try:
            success = True
            if not self.seed_admin_user():
                success = False
            return success
        except Exception as e:
            logger.error(f"Error running seeders: {str(e)}")
            return False 
```


### FILE: backend\auth-service\src\utils\database.py
```
from functools import wraps
from typing import Any, Callable, Optional, TypeVar
from flask import current_app
from sqlalchemy.exc import SQLAlchemyError
from contextlib import contextmanager
import logging

# Import from shared modules if available, otherwise use local implementation
try:
    from shared.database import db, transaction
    from shared.utils.database import transaction_context as shared_transaction_context
    from shared.utils.database import with_transaction as shared_with_transaction
    from shared.utils.database import DatabaseManager
    
    # Re-export shared functions
    transaction_context = shared_transaction_context
    with_transaction = shared_with_transaction
    
    logger = logging.getLogger(__name__)
    logger.info("Using shared database utilities")
except ImportError as e:
    logger.warning(f"Could not import shared database modules: {e}. Using local implementation.")
    from ..database import db
    
    logger = logging.getLogger(__name__)

    @contextmanager
    def transaction_context():
        """
        Context manager for database transactions.
        Automatically handles commit and rollback.
        
        Usage:
            with transaction_context() as session:
                session.add(user)
        """
        try:
            yield db.session
            db.session.commit()
        except Exception as e:
            db.session.rollback()
            logger.error(f"Transaction error: {str(e)}")
            raise
        finally:
            db.session.close()

    def with_transaction(f: Callable[..., T]) -> Callable[..., T]:
        """
        Decorator to wrap a function in a database transaction.
        Automatically handles commit and rollback.
        
        Usage:
            @with_transaction
            def create_user(data):
                user = User(**data)
                db.session.add(user)
                return user
        """
        @wraps(f)
        def decorated(*args: Any, **kwargs: Any) -> T:
            try:
                result = f(*args, **kwargs)
                db.session.commit()
                return result
            except Exception as e:
                db.session.rollback()
                logger.error(f"Database error in {f.__name__}: {str(e)}")
                raise
            finally:
                db.session.close()
        return decorated

# Common database utility functions (these should work with either implementation)
def safe_commit() -> bool:
    """Safely commit database changes"""
    try:
        db.session.commit()
        return True
    except SQLAlchemyError as e:
        db.session.rollback()
        logger.error(f"Database commit error: {str(e)}")
        return False

def safe_add(obj: Any, auto_commit: bool = True) -> bool:
    """Safely add an object to the database"""
    try:
        db.session.add(obj)
        if auto_commit:
            return safe_commit()
        return True
    except SQLAlchemyError as e:
        db.session.rollback()
        logger.error(f"Database add error: {str(e)}")
        return False

def safe_delete(obj: Any, auto_commit: bool = True) -> bool:
    """Safely delete an object from the database"""
    try:
        db.session.delete(obj)
        if auto_commit:
            return safe_commit()
        return True
    except SQLAlchemyError as e:
        db.session.rollback()
        logger.error(f"Database delete error: {str(e)}")
        return False

def cleanup_expired_sessions() -> int:
    """
    Cleanup expired sessions from the database.
    Returns the number of sessions cleaned up.
    """
    from datetime import datetime
    from ..models.auth import UserSession
    
    try:
        count = UserSession.query.filter(
            UserSession.expires_at < datetime.utcnow(),
            UserSession.revoked == False
        ).update({
            'revoked': True,
            'revocation_reason': 'Expired'
        })
        db.session.commit()
        return count
    except SQLAlchemyError as e:
        db.session.rollback()
        logger.error(f"Error cleaning up expired sessions: {str(e)}")
        raise
    finally:
        db.session.close() 
```


### FILE: backend\auth-service\src\utils\email_service.py
```
import os
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from flask import current_app

def send_verification_email(to_email: str, verification_token: str) -> bool:
    """Send verification email to user."""
    try:
        smtp_server = os.getenv('SMTP_SERVER', 'smtp.gmail.com')
        smtp_port = int(os.getenv('SMTP_PORT', '587'))
        smtp_username = os.getenv('SMTP_USERNAME')
        smtp_password = os.getenv('SMTP_PASSWORD')
        
        if not all([smtp_username, smtp_password]):
            current_app.logger.error("SMTP credentials not configured")
            return False

        verification_url = f"{os.getenv('FRONTEND_URL', 'http://localhost:3000')}/verify-email/{verification_token}"
        
        msg = MIMEMultipart()
        msg['From'] = smtp_username
        msg['To'] = to_email
        msg['Subject'] = "Verify your email address"

        html = f"""
        <html>
            <body>
                <h2>Welcome to Meeting App!</h2>
                <p>Please verify your email address by clicking the link below:</p>
                <p>
                    <a href="{verification_url}">Verify Email Address</a>
                </p>
                <p>If you didn't create an account, you can safely ignore this email.</p>
                <p>This link will expire in 24 hours.</p>
            </body>
        </html>
        """
        
        msg.attach(MIMEText(html, 'html'))

        with smtplib.SMTP(smtp_server, smtp_port) as server:
            server.starttls()
            server.login(smtp_username, smtp_password)
            server.send_message(msg)
            
        return True
    except Exception as e:
        current_app.logger.error(f"Failed to send verification email: {str(e)}")
        return False 
```


### FILE: backend\auth-service\src\utils\migrations_manager.py
```
import os
import sys
import logging
from flask import Flask
from flask_migrate import Migrate, upgrade
from sqlalchemy import text
from sqlalchemy.exc import OperationalError
import time

logger = logging.getLogger(__name__)

class MigrationsManager:
    def __init__(self, app: Flask, db, max_retries=5, retry_interval=5):
        self.app = app
        self.db = db
        self.migrate = Migrate(app, db)
        self.max_retries = max_retries
        self.retry_interval = retry_interval

    def wait_for_db(self):
        """Wait for database to be ready"""
        logger.info("Waiting for database...")
        for attempt in range(self.max_retries):
            try:
                with self.app.app_context():
                    self.db.session.execute(text('SELECT 1'))
                logger.info("Database is ready!")
                return True
            except OperationalError as e:
                if attempt == self.max_retries - 1:
                    logger.error(f"Database connection failed after {self.max_retries} attempts: {e}")
                    return False
                logger.warning(f"Database not ready (attempt {attempt + 1}/{self.max_retries}), waiting...")
                time.sleep(self.retry_interval)

    def run_migrations(self):
        """Run database migrations"""
        try:
            with self.app.app_context():
                logger.info("Starting database migrations...")
                upgrade()
                logger.info("Database migrations completed successfully!")
                return True
        except Exception as e:
            logger.error(f"Error running migrations: {e}")
            return False

    def verify_migrations(self):
        """Verify all migrations have been applied"""
        try:
            with self.app.app_context():
                for table in self.db.metadata.tables:
                    if not self.db.engine.dialect.has_table(self.db.engine, table):
                        logger.error(f"Table {table} does not exist!")
                        return False
                logger.info("All database tables verified!")
                return True
        except Exception as e:
            logger.error(f"Error verifying migrations: {e}")
            return False

    def initialize_database(self):
        """Initialize database with migrations and basic data"""
        if not self.wait_for_db():
            logger.error("Could not connect to database")
            sys.exit(1)

        if not self.run_migrations():
            logger.error("Failed to run migrations")
            sys.exit(1)

        if not self.verify_migrations():
            logger.error("Failed to verify migrations")
            sys.exit(1)

        logger.info("Database initialization completed successfully!") 
```


### FILE: backend\auth-service\src\utils\rate_limiter.py
```
"""
This module re-exports the shared rate limiter middleware to maintain
backward compatibility with code that imports from here.
"""

import logging
from functools import wraps
from shared.middleware.rate_limiter import RateLimiter, rate_limit as shared_rate_limit

logger = logging.getLogger(__name__)

# Add any auth-service specific rate limiting functionality here if needed

# For backward compatibility, re-export the get_client_identifier function
def get_client_identifier():
    """
    Create a unique client identifier based on IP and user agent
    This helps prevent rate limit circumvention
    """
    from flask import request
    import hashlib
    
    ip = request.remote_addr or 'unknown'
    user_agent = request.headers.get('User-Agent', 'unknown')
    
    # Create a hash of the combined values for privacy
    client_id = hashlib.md5(f"{ip}:{user_agent}".encode()).hexdigest()
    return client_id

# Re-export the shared rate_limit with potential customization
def rate_limit(limit: int, window: int, key_func=None):
    """
    Rate limiting decorator that uses the shared implementation
    but allows for custom key generation via key_func
    
    Args:
        limit: Number of requests allowed
        window: Time window in seconds
        key_func: Optional custom function to generate rate limit key
    """
    if key_func:
        # If a custom key_func is provided, wrap the shared implementation
        def custom_wrapper(f):
            @wraps(f)
            def wrapper(*args, **kwargs):
                # Use the shared implementation with our custom key function
                return shared_rate_limit(limit, window, key_func=key_func)(f)(*args, **kwargs)
            return wrapper
        return custom_wrapper
    else:
        # Otherwise, use the shared implementation directly
        return shared_rate_limit(limit, window)

# Alias for backward compatibility
custom_rate_limit = rate_limit 
```


### FILE: backend\auth-service\src\utils\service_integration.py
```
from typing import Optional, Dict, Any
from flask import current_app
import requests
from datetime import datetime
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from circuitbreaker import circuit
import logging
import json
from redis import Redis
from ..models.auth import AuthUser, UserSession
from ..database import db
from .database import transaction_context

logger = logging.getLogger(__name__)

class ServiceIntegrationError(Exception):
    """Base exception for service integration errors"""
    pass

class ServiceConnectionError(ServiceIntegrationError):
    """Raised when connection to service fails"""
    pass

class ServiceTimeoutError(ServiceIntegrationError):
    """Raised when service request times out"""
    pass

class ServiceResponseError(ServiceIntegrationError):
    """Raised when service returns unexpected response"""
    pass

class ServiceIntegration:
    def __init__(self):
        self.flask_service_url = current_app.config.get('FLASK_SERVICE_URL', 'http://backend:5000')
        self.timeout = current_app.config.get('SERVICE_TIMEOUT', 5)
        self.enabled = current_app.config.get('SERVICE_SYNC_ENABLED', True)
        # Initialize Redis for metrics
        self.redis_client = None
        try:
            redis_url = current_app.config.get('REDIS_URL')
            if redis_url:
                self.redis_client = Redis.from_url(redis_url)
        except Exception as e:
            logger.error(f"Failed to initialize Redis for service integration metrics: {e}")

    def _record_metric(self, name: str, success: bool, duration_ms: float):
        """Record service integration metrics in Redis"""
        if not self.redis_client:
            return
            
        try:
            # Record the outcome (success/failure)
            status = "success" if success else "failure"
            self.redis_client.hincrby(f"metrics:service_integration:{name}", status, 1)
            
            # Record the response time
            self.redis_client.lpush(f"metrics:service_integration:{name}:duration", duration_ms)
            self.redis_client.ltrim(f"metrics:service_integration:{name}:duration", 0, 99)  # Keep last 100
            
            # Calculate and update average response time
            durations = self.redis_client.lrange(f"metrics:service_integration:{name}:duration", 0, -1)
            if durations:
                avg_duration = sum(float(d) for d in durations) / len(durations)
                self.redis_client.hset(f"metrics:service_integration:{name}", "avg_duration_ms", avg_duration)
                
            # Set expiry for metrics
            self.redis_client.expire(f"metrics:service_integration:{name}", 86400 * 7)  # 7 days
            self.redis_client.expire(f"metrics:service_integration:{name}:duration", 86400 * 7)  # 7 days
        except Exception as e:
            logger.error(f"Failed to record metric: {e}")

    def _make_request(self, method: str, endpoint: str, **kwargs) -> requests.Response:
        """Make HTTP request with error handling"""
        start_time = datetime.utcnow()
        success = False
        
        try:
            # Add service key to headers if available
            service_key = current_app.config.get('SERVICE_KEY')
            if service_key and 'headers' not in kwargs:
                kwargs['headers'] = {'X-Service-Key': service_key}
            elif service_key and 'headers' in kwargs:
                kwargs['headers'].update({'X-Service-Key': service_key})
                
            response = requests.request(
                method,
                f"{self.flask_service_url}{endpoint}",
                timeout=self.timeout,
                **kwargs
            )
            response.raise_for_status()
            success = True
            return response
        except requests.ConnectionError as e:
            raise ServiceConnectionError(f"Failed to connect to service: {str(e)}")
        except requests.Timeout as e:
            raise ServiceTimeoutError(f"Service request timed out: {str(e)}")
        except requests.HTTPError as e:
            raise ServiceResponseError(f"Service returned error response: {str(e)}")
        except Exception as e:
            raise ServiceIntegrationError(f"Unexpected error in service request: {str(e)}")
        finally:
            # Record metrics
            duration_ms = (datetime.utcnow() - start_time).total_seconds() * 1000
            endpoint_name = endpoint.split('/')[-1]
            self._record_metric(f"{method}_{endpoint_name}", success, duration_ms)

    @retry(
        stop=stop_after_attempt(5),
        wait=wait_exponential(multiplier=1, min=4, max=60),
        retry=retry_if_exception_type((ServiceConnectionError, ServiceTimeoutError))
    )
    @circuit(failure_threshold=5, recovery_timeout=60)
    def sync_user_session(self, user_id: int, token: str, session_data: Dict[str, Any]) -> bool:
        """
        Synchronize user session with main service with retry logic and circuit breaker
        """
        if not self.enabled:
            logger.info("Service synchronization is disabled")
            return True

        try:
            # For bulk operations, add a bulk flag to optimize
            is_bulk = user_id is None and token is None
            
            response = self._make_request(
                'POST',
                '/api/auth/sync-session',
                json={
                    "user_id": user_id,
                    "token": token,
                    "session_data": session_data,
                    "is_bulk": is_bulk,
                    "timestamp": datetime.utcnow().isoformat()
                }
            )
            
            # For successful responses, record successful sync
            if self.redis_client and user_id:
                sync_key = f"last_sync:user:{user_id}"
                self.redis_client.hset(sync_key, "timestamp", datetime.utcnow().isoformat())
                self.redis_client.hset(sync_key, "status", "success")
                self.redis_client.expire(sync_key, 86400)  # 24 hours
                
            return response.status_code == 200
        except ServiceIntegrationError as e:
            logger.error(f"Failed to sync session: {str(e)}")
            
            # For failures, record the failed sync
            if self.redis_client and user_id:
                sync_key = f"last_sync:user:{user_id}"
                self.redis_client.hset(sync_key, "timestamp", datetime.utcnow().isoformat())
                self.redis_client.hset(sync_key, "status", "failure")
                self.redis_client.hset(sync_key, "error", str(e))
                self.redis_client.expire(sync_key, 86400)  # 24 hours
                
                # Queue for retry if appropriate
                if isinstance(e, (ServiceConnectionError, ServiceTimeoutError)):
                    retry_key = f"sync_retry:user:{user_id}"
                    self.redis_client.lpush(retry_key, json.dumps({
                        "user_id": user_id,
                        "token": token,
                        "session_data": session_data,
                        "timestamp": datetime.utcnow().isoformat()
                    }))
                    self.redis_client.expire(retry_key, 86400)  # 24 hours
            
            return False

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    @circuit(failure_threshold=5, recovery_timeout=60)
    def validate_token(self, token: str) -> Optional[dict]:
        """
        Validate token with main service with retry logic and circuit breaker
        """
        if not self.enabled:
            return None

        try:
            response = self._make_request(
                'POST',
                '/api/auth/validate-token',
                json={"token": token}
            )
            return response.json()
        except ServiceIntegrationError as e:
            logger.error(f"Failed to validate token: {str(e)}")
            return None

    @retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=4, max=30))
    def sync_user_data(self, user: AuthUser) -> bool:
        """
        Synchronize user data with main service with enhanced retry logic
        """
        if not self.enabled:
            return True

        try:
            user_data = {
                "id": user.id,
                "email": user.email,
                "is_active": not user.is_locked(),
                "is_email_verified": user.is_email_verified,
                "first_name": user.first_name,
                "last_name": user.last_name,
                "profile_picture": user.profile_picture,
                "last_sync": datetime.utcnow().isoformat()
            }

            response = self._make_request(
                'POST',
                '/api/auth/sync-user',
                json=user_data
            )
            
            # Record successful sync
            if self.redis_client:
                sync_key = f"last_sync:user:{user.id}"
                self.redis_client.hset(sync_key, "timestamp", datetime.utcnow().isoformat())
                self.redis_client.hset(sync_key, "status", "success")
                self.redis_client.expire(sync_key, 86400)  # 24 hours
                
            return response.status_code == 200
        except ServiceIntegrationError as e:
            logger.error(f"Failed to sync user data: {str(e)}")
            
            # Record failed sync
            if self.redis_client:
                sync_key = f"last_sync:user:{user.id}"
                self.redis_client.hset(sync_key, "timestamp", datetime.utcnow().isoformat())
                self.redis_client.hset(sync_key, "status", "failure")
                self.redis_client.hset(sync_key, "error", str(e))
                self.redis_client.expire(sync_key, 86400)  # 24 hours
            
            return False

    def verify_user_consistency(self, user_id: int) -> bool:
        """
        Verify user data consistency across services
        """
        if not self.enabled:
            return True

        try:
            # Get user data from auth service
            auth_user = AuthUser.query.get(user_id)
            if not auth_user:
                return False

            # Get user data from main service
            response = self._make_request('GET', f'/api/users/{user_id}')
            flask_user = response.json()

            # Compare critical fields
            return all([
                auth_user.email == flask_user.get('email'),
                auth_user.is_email_verified == flask_user.get('is_email_verified'),
                not auth_user.is_locked() == flask_user.get('is_active')
            ])
        except ServiceIntegrationError as e:
            logger.error(f"Failed to verify user consistency: {str(e)}")
            return False

    @retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=4, max=30))
    def revoke_user_sessions(self, user_id: int, reason: str = None) -> bool:
        """
        Revoke all user sessions in main service with enhanced retry logic
        """
        if not self.enabled:
            return True

        try:
            response = self._make_request(
                'POST',
                '/api/auth/revoke-user-sessions',
                json={
                    "user_id": user_id,
                    "reason": reason,
                    "timestamp": datetime.utcnow().isoformat()
                }
            )
            return response.status_code == 200
        except ServiceIntegrationError as e:
            logger.error(f"Failed to revoke sessions: {str(e)}")
            
            # Queue for retry if appropriate
            if isinstance(e, (ServiceConnectionError, ServiceTimeoutError)) and self.redis_client:
                retry_key = f"revoke_retry:user:{user_id}"
                self.redis_client.lpush(retry_key, json.dumps({
                    "user_id": user_id,
                    "reason": reason,
                    "timestamp": datetime.utcnow().isoformat()
                }))
                self.redis_client.expire(retry_key, 86400)  # 24 hours
            
            return False
            
    def process_pending_syncs(self) -> int:
        """
        Process any pending sync operations that failed previously
        Returns the number of operations processed
        """
        if not self.enabled or not self.redis_client:
            return 0
            
        try:
            # Get all retry keys
            retry_keys = self.redis_client.keys("sync_retry:user:*")
            processed = 0
            
            for key in retry_keys:
                # Process up to 5 pending operations per user
                for _ in range(5):
                    retry_data = self.redis_client.lpop(key)
                    if not retry_data:
                        break
                        
                    try:
                        data = json.loads(retry_data)
                        if self.sync_user_session(
                            data.get("user_id"), 
                            data.get("token"), 
                            data.get("session_data")
                        ):
                            processed += 1
                    except Exception as e:
                        logger.error(f"Failed to process pending sync: {e}")
                        # Push back to queue
                        self.redis_client.rpush(key, retry_data)
                        break
                        
            # Similar logic for revocation retries
            revoke_keys = self.redis_client.keys("revoke_retry:user:*")
            for key in revoke_keys:
                for _ in range(5):
                    retry_data = self.redis_client.lpop(key)
                    if not retry_data:
                        break
                        
                    try:
                        data = json.loads(retry_data)
                        if self.revoke_user_sessions(
                            data.get("user_id"),
                            data.get("reason")
                        ):
                            processed += 1
                    except Exception as e:
                        logger.error(f"Failed to process pending revocation: {e}")
                        self.redis_client.rpush(key, retry_data)
                        break
                        
            return processed
        except Exception as e:
            logger.error(f"Error processing pending syncs: {e}")
            return 0 
```


### FILE: backend\auth-service\src\utils\session_service.py
```
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Any
from flask import current_app
import logging
from ..models.auth import UserSession
from ..database import db
from .service_integration import ServiceIntegration
from .database import transaction_context, safe_commit

logger = logging.getLogger(__name__)

class SessionService:
    def __init__(self):
        self.service_integration = ServiceIntegration()

    def create_session(self, user_id: int, device_info: Optional[Dict[str, Any]] = None) -> Optional[UserSession]:
        """Create a new user session"""
        try:
            with transaction_context() as session:
                user_session = UserSession(
                    user_id=user_id,
                    device_info=device_info,
                    expires_at=datetime.utcnow() + timedelta(days=1)
                )
                session.add(user_session)
                session.flush()  # Get the session ID

                # Sync with main service
                if not self.service_integration.sync_user_session(
                    user_id, 
                    user_session.token,
                    {
                        'session_id': user_session.id,
                        'device_info': device_info,
                        'expires_at': user_session.expires_at.isoformat()
                    }
                ):
                    logger.error("Failed to sync session with main service")
                    raise Exception("Session sync failed")

                return user_session
        except Exception as e:
            logger.error(f"Error creating session: {str(e)}")
            return None

    def get_active_sessions(self, user_id: int) -> List[UserSession]:
        """Get all active sessions for a user"""
        return UserSession.query.filter(
            UserSession.user_id == user_id,
            UserSession.revoked == False,
            UserSession.expires_at > datetime.utcnow()
        ).all()

    def revoke_session(self, session_id: int, reason: str = None) -> bool:
        """Revoke a specific session"""
        try:
            with transaction_context() as session:
                user_session = UserSession.query.get(session_id)
                if not user_session:
                    return False

                user_session.revoke(reason)
                
                # Sync with main service
                if not self.service_integration.revoke_user_sessions(
                    user_session.user_id,
                    reason=f"Session {session_id} revoked: {reason}"
                ):
                    logger.error("Failed to sync session revocation with main service")
                    raise Exception("Session revocation sync failed")

                return True
        except Exception as e:
            logger.error(f"Error revoking session: {str(e)}")
            return False

    def revoke_all_user_sessions(self, user_id: int, reason: str = None) -> bool:
        """Revoke all sessions for a user"""
        try:
            with transaction_context() as session:
                UserSession.query.filter(
                    UserSession.user_id == user_id,
                    UserSession.revoked == False
                ).update({
                    'revoked': True,
                    'revoked_at': datetime.utcnow(),
                    'revocation_reason': reason
                })

                # Sync with main service
                if not self.service_integration.revoke_user_sessions(user_id, reason=reason):
                    logger.error("Failed to sync session revocations with main service")
                    raise Exception("Session revocations sync failed")

                return True
        except Exception as e:
            logger.error(f"Error revoking all sessions: {str(e)}")
            return False

    def cleanup_expired_sessions(self) -> int:
        """Clean up expired sessions"""
        try:
            with transaction_context() as session:
                result = UserSession.query.filter(
                    UserSession.expires_at < datetime.utcnow(),
                    UserSession.revoked == False
                ).update({
                    'revoked': True,
                    'revoked_at': datetime.utcnow(),
                    'revocation_reason': 'Expired'
                })

                # Sync cleanup with main service if any sessions were cleaned up
                if result > 0:
                    self.service_integration.sync_user_session(
                        None,
                        None,
                        {'cleanup_timestamp': datetime.utcnow().isoformat()}
                    )

                return result
        except Exception as e:
            logger.error(f"Error cleaning up sessions: {str(e)}")
            return 0

    def extend_session(self, session_id: int, duration: timedelta = None) -> bool:
        """Extend a session's expiration time"""
        if duration is None:
            duration = timedelta(days=1)

        try:
            with transaction_context() as session:
                user_session = UserSession.query.get(session_id)
                if not user_session or user_session.revoked:
                    return False

                new_expiry = datetime.utcnow() + duration
                user_session.expires_at = new_expiry

                # Sync with main service
                if not self.service_integration.sync_user_session(
                    user_session.user_id,
                    user_session.token,
                    {'expires_at': new_expiry.isoformat()}
                ):
                    logger.error("Failed to sync session extension with main service")
                    raise Exception("Session extension sync failed")

                return True
        except Exception as e:
            logger.error(f"Error extending session: {str(e)}")
            return False 
```


### FILE: backend\auth-service\src\utils\token_service.py
```
from datetime import datetime, timedelta
import jwt
from typing import Optional, Dict, Any
from flask import current_app
import logging
from .service_integration import ServiceIntegration

logger = logging.getLogger(__name__)

class TokenService:
    def __init__(self):
        self.secret_key = current_app.config['JWT_SECRET_KEY']
        self.algorithm = 'HS256'
        self.service_integration = ServiceIntegration()

    def generate_token(self, user_id: int, expires_delta: timedelta = None) -> str:
        """Generate a new JWT token"""
        if expires_delta is None:
            expires_delta = timedelta(days=1)

        data = {
            'user_id': user_id,
            'exp': datetime.utcnow() + expires_delta,
            'iat': datetime.utcnow(),
            'type': 'access'
        }
        
        return jwt.encode(data, self.secret_key, algorithm=self.algorithm)

    def generate_refresh_token(self, user_id: int, session_id: int) -> str:
        """Generate a refresh token"""
        data = {
            'user_id': user_id,
            'session_id': session_id,
            'exp': datetime.utcnow() + timedelta(days=30),
            'iat': datetime.utcnow(),
            'type': 'refresh'
        }
        
        return jwt.encode(data, self.secret_key, algorithm=self.algorithm)

    def validate_token(self, token: str, verify_type: str = None) -> Optional[Dict[str, Any]]:
        """Validate a JWT token"""
        try:
            payload = jwt.decode(token, self.secret_key, algorithms=[self.algorithm])
            
            if verify_type and payload.get('type') != verify_type:
                logger.warning(f"Invalid token type: expected {verify_type}, got {payload.get('type')}")
                return None

            # Sync validation with main service
            if not self.service_integration.validate_token(token):
                logger.warning("Token validation failed in main service")
                return None

            return payload
        except jwt.ExpiredSignatureError:
            logger.warning("Token has expired")
            return None
        except jwt.InvalidTokenError as e:
            logger.warning(f"Invalid token: {str(e)}")
            return None

    def refresh_access_token(self, refresh_token: str) -> Optional[str]:
        """Generate new access token from refresh token"""
        payload = self.validate_token(refresh_token, verify_type='refresh')
        if not payload:
            return None

        return self.generate_token(payload['user_id'])

    def revoke_token(self, token: str) -> bool:
        """Revoke a token"""
        try:
            payload = jwt.decode(token, self.secret_key, algorithms=[self.algorithm])
            user_id = payload.get('user_id')
            
            # Revoke in main service
            return self.service_integration.revoke_user_sessions(user_id, reason='Token revoked')
        except jwt.InvalidTokenError:
            return False 
```


### FILE: backend\flask-service\.dockerignore
```
# Git
.git
.gitignore

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
*.egg-info/
.installed.cfg
*.egg

# Docker
Dockerfile*
docker-compose*
.dockerignore

# IDE
.idea/
.vscode/
*.swp
*.swo

# Logs
logs/
*.log

# Data
data/
**/*.pyc
venv/
.pytest_cache/
.coverage

# Data
data/ 
```


### FILE: backend\flask-service\.env.example
```
# Flask Service Environment Variables

# Database Configuration
DATABASE_URL=postgresql://dev_user:dev-password-123@postgres:5432/meetingapp
BACKUP_DIR=/app/backups

# Security
JWT_SECRET_KEY=your-secret-key-here
SERVICE_KEY=your-service-key-here

# Redis Configuration
REDIS_URL=redis://redis:6379/0

# Service Integration
AUTH_SERVICE_URL=http://auth-service:5001
AUTH_SERVICE_KEY=your-auth-service-key

# Server Configuration
PORT=5000
FLASK_ENV=development  # development, testing, production
FLASK_APP=src/app.py

# CORS Configuration
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8080

# Logging
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s
LOG_FILE=/app/logs/flask-service.log

# Metrics (Prometheus)
ENABLE_METRICS=true
METRICS_PORT=9090 
```


### FILE: backend\flask-service\Dockerfile
```
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    postgresql-client \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first for better caching
COPY requirements.txt .
RUN pip install --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt && \
    pip install APScheduler==3.10.4

# Create necessary directories
RUN mkdir -p /app/shared /app/logs /app/src /app/migrations

# Copy fixed app.py file with explicit import modifications
COPY fixed_app.py /app/src/app.py

# Copy application code by directory to avoid permission issues
COPY src/ /app/src/
COPY migrations/ /app/migrations/
COPY *.py /app/
COPY *.sh /app/

# Copy shared module files 
# Note: In docker-compose, we'll mount these as volumes, but this ensures they exist if volume mount fails
RUN mkdir -p /app/shared/middleware /app/shared/utils /app/shared/models /app/shared/schemas

# Create entrypoint script with explicit Unix line endings
RUN echo '#!/bin/bash\n\
\n\
# Wait for postgres\n\
echo "Waiting for postgres..."\n\
while ! pg_isready -h postgres -p 5432 -U $POSTGRES_USER -d $POSTGRES_DB; do\n\
    echo "Postgres is unavailable - sleeping"\n\
    sleep 1\n\
done\n\
echo "Postgres is up - executing command"\n\
\n\
# Print directory structure for debugging\n\
echo "Directory structure in /app:"\n\
ls -la /app\n\
echo "Directory structure in /app/shared:"\n\
ls -la /app/shared\n\
\n\
# Check if shared modules are properly mounted\n\
if [ ! -f "/app/shared/database.py" ]; then\n\
    echo "WARNING: Shared modules not properly mounted. Volume mount issue possible."\n\
fi\n\
\n\
# Set Python path\n\
export PYTHONPATH=/app:/app/shared:$PYTHONPATH\n\
\n\
# Run database migrations\n\
echo "Running database migrations..."\n\
cd /app\n\
flask db upgrade || echo "Warning: Migrations failed, but continuing..."\n\
\n\
# Start the application\n\
echo "Starting application..."\n\
exec gunicorn --bind 0.0.0.0:5000 --workers 2 --threads 4 --timeout 120 "src.app:create_app()"\n\
' > /entrypoint.sh

# Make entrypoint executable
RUN chmod +x /entrypoint.sh

# Set environment variables
ENV FLASK_APP=src.app
ENV FLASK_DEBUG=0
ENV PYTHONPATH=/app:/app/shared

# Health check with increased timeout
HEALTHCHECK --interval=30s --timeout=30s --start-period=15s --retries=3 \
  CMD curl -f http://localhost:5000/health || exit 1

# Expose port
EXPOSE 5000

# Set entrypoint
ENTRYPOINT ["/entrypoint.sh"] 
```


### FILE: backend\flask-service\README.md
```
# Meeting API Service

## Overview

The Meeting API Service is a Flask-based backend for managing meetings in the Meeting App platform. It provides REST API endpoints for creating, updating, and managing meetings, integrates with the authentication service, and handles real-time updates via Redis and WebSockets.

## Architecture

The service follows a modular architecture with well-defined responsibilities:

```
backend/
â”œâ”€â”€ flask-service/         # Meeting API Service
â”‚   â”œâ”€â”€ src/               # Application code
â”‚   â”‚   â”œâ”€â”€ core/          # Core functionality
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py    # Logging and initialization
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py      # Environment-specific configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ errors.py      # Error handling
â”‚   â”‚   â”‚   â””â”€â”€ health.py      # Health checks
â”‚   â”‚   â”œâ”€â”€ routes/        # API routes and endpoints
â”‚   â”‚   â”œâ”€â”€ utils/         # Utility functions
â”‚   â”‚   â””â”€â”€ app.py         # Flask application factory
â”‚   â”œâ”€â”€ shared/            # Shared modules with auth service
â”‚   â”œâ”€â”€ migrations/        # Database migrations
â”‚   â””â”€â”€ tests/             # Unit and integration tests
```

## Enhanced Debugging

This service includes comprehensive logging and debugging capabilities:

1. **Centralized Logging**: All logging is handled through the `src.core` module, with appropriate log levels for each environment.

2. **Detailed Health Checks**: The `/health` endpoint provides detailed diagnostics for all dependencies and service components.

3. **Error Handling**: A robust error handling system provides consistent error responses and detailed logging of exceptions.

4. **Environment Diagnostics**: System information, environment variables, and configuration is logged at startup to aid in debugging deployment issues.

## Getting Started

### Prerequisites

- Python 3.10+
- PostgreSQL
- Redis

### Installation

1. Clone the repository
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Set up environment variables (see `.env.example`)

4. Initialize the database:
   ```bash
   flask db upgrade
   ```

5. Run the development server:
   ```bash
   flask run
   ```

### Docker

The service can be run with Docker using the provided Dockerfile:

```bash
# Build the image
docker build -t meeting-api-service .

# Run the container
docker run -p 5000:5000 --env-file .env meeting-api-service
```

Or with docker-compose:

```bash
docker-compose up -d backend
```

## API Endpoints

### Health Check

- **GET** `/health`
  - Returns detailed health information about the service and its dependencies
  - Response: 200 OK (healthy) or 503 Service Unavailable (unhealthy)

### Meeting Endpoints

- **GET** `/api/meetings`
  - Lists all meetings for the authenticated user
  - Response: 200 OK

- **POST** `/api/meetings`
  - Creates a new meeting
  - Response: 201 Created

- **GET** `/api/meetings/{id}`
  - Gets details of a specific meeting
  - Response: 200 OK

- **PUT** `/api/meetings/{id}`
  - Updates a meeting
  - Response: 200 OK

- **DELETE** `/api/meetings/{id}`
  - Deletes a meeting
  - Response: 204 No Content

## Debugging Guidance

### Common Issues

1. **Database Connection Errors**
   - Check PostgreSQL connection string in `.env`
   - Verify PostgreSQL service is running
   - Check database logs for connection rejections

2. **Redis Connection Issues**
   - Verify Redis is running and accessible
   - Check Redis connection string in `.env`
   - Check for authentication failures in Redis logs

3. **Auth Service Integration**
   - Ensure AUTH_SERVICE_URL is correct
   - Verify SERVICE_KEY matches between services
   - Check auth service logs for connection attempts

### Enhanced Logging

To enable detailed logging, set `LOG_LEVEL=DEBUG` in your environment. This will provide:

- Detailed request and response information
- SQL queries and execution times
- Redis operations
- Authentication flow details

Log files are stored in the `/app/logs` directory:
- `app.log` - All application logs
- `error.log` - Error logs only
- `error_TIMESTAMP.json` - Detailed error reports (in development)

## Testing

Run the test suite with pytest:

```bash
pytest
```

With coverage:

```bash
pytest --cov=src
```

## Error Handling

The service uses standardized error responses:

```json
{
  "error": true,
  "message": "Error message",
  "status_code": 400,
  "timestamp": "2023-01-01T12:00:00.000Z",
  "details": {
    "field": "Error details"
  }
}
```

Error types include:
- ValidationError (422)
- AuthenticationError (401)
- AuthorizationError (403)
- NotFoundError (404)
- ServiceError (500)
- ConfigurationError (500)

## Performance Monitoring

The service includes basic performance metrics:
- Response times for key endpoints
- Database query times
- Redis operation latency
- External service call durations

For production monitoring, consider integrating Prometheus or similar. 
```


### FILE: backend\flask-service\fixed_app.py
```
import os
import sys
import logging
import traceback
from datetime import datetime, timedelta

from flask import Flask, jsonify
from flask_cors import CORS
from flask_migrate import Migrate
from flask_wtf.csrf import CSRFProtect
from redis import Redis

# Configure logging with more detailed format
logging.basicConfig(
    level=logging.DEBUG,  # Set to DEBUG for more verbose logging
    format='%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s'
)
logger = logging.getLogger(__name__)
logger.info("Initializing Flask application module")
logger.debug(f"Python version: {sys.version}")
logger.debug(f"Current working directory: {os.getcwd()}")
logger.debug(f"Initial sys.path: {sys.path}")

# Log current environment variables
env_vars = {}
critical_vars = ['DATABASE_URL', 'JWT_SECRET_KEY', 'REDIS_URL', 'SERVICE_KEY', 'AUTH_SERVICE_URL',
                'FLASK_APP', 'FLASK_DEBUG', 'PYTHONPATH']
for var in critical_vars:
    value = os.environ.get(var)
    if value:
        # Mask sensitive values
        if 'SECRET' in var or 'PASSWORD' in var:
            env_vars[var] = '***MASKED***'
        else:
            env_vars[var] = value
    else:
        env_vars[var] = 'NOT SET'

logger.info(f"Environment variables: {env_vars}")

# Add paths for shared modules - try multiple approaches for Windows compatibility
potential_paths = [
    os.path.abspath(os.path.dirname(__file__)),  # Current directory
    os.path.abspath(os.path.join(os.path.dirname(__file__), '../')),  # Parent directory
    os.path.abspath(os.path.join(os.path.dirname(__file__), '../../')),  # Grandparent directory
    '/app',  # Docker container path
    '/app/shared'  # Docker shared volume path
]

for path in potential_paths:
    if path not in sys.path:
        sys.path.append(path)
        logger.info(f"Added {path} to sys.path")

logger.info(f"Updated sys.path: {sys.path}")

# Try multiple import patterns to handle different environments
try:
    # Try absolute import first (when PYTHONPATH includes shared)
    logger.info("Attempting to import shared modules using absolute import...")
    from shared.database import db, init_db
    from shared.middleware.error_handler import handle_api_errors
    from shared.middleware.validation import validate_schema
    from shared.middleware.rate_limiter import RateLimiter
    from shared.config import config
    logger.info("Successfully imported shared modules using absolute import")
except ImportError as e:
    logger.warning(f"Absolute import failed: {e}, trying relative import")
    try:
        # Fallback to relative path
        logger.info("Attempting to import shared modules using relative import...")
        from backend.shared.database import db, init_db
        from backend.shared.middleware.error_handler import handle_api_errors
        from backend.shared.middleware.validation import validate_schema
        from backend.shared.middleware.rate_limiter import RateLimiter
        from backend.shared.config import config
        logger.info("Successfully imported shared modules using relative import")
    except ImportError as e:
        logger.error(f"All import approaches failed: {e}")
        logger.error(f"Current sys.path: {sys.path}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        # We'll handle this in create_app() to provide a meaningful error message

# Import local modules
try:
    logger.info("Attempting to import local modules...")
    from .routes.meetings import meetings_bp
    from .routes.auth_integration import bp as auth_integration_bp
    from .routes.health import health_bp
    from .utils.migrations_manager import MigrationsManager
    from .utils.data_seeder import DataSeeder
    from .utils.auth_integration import AuthIntegration
    logger.info("Successfully imported local modules")
except ImportError as e:
    logger.error(f"Failed to import local modules: {e}")
    logger.error(f"Traceback: {traceback.format_exc()}")
    # We'll handle this in create_app()

# Try to import APScheduler, but continue if it's not available
try:
    logger.info("Attempting to import APScheduler...")
    from apscheduler.schedulers.background import BackgroundScheduler
    from apscheduler.triggers.interval import IntervalTrigger
    has_apscheduler = True
    logger.info("Successfully imported APScheduler")
except ImportError as e:
    has_apscheduler = False
    logger.warning(f"APScheduler not available, some features will be disabled: {e}")

# Initialize extensions
migrate = Migrate()
csrf = CSRFProtect()
rate_limiter = None
cors = CORS()
redis_client = None

def get_redis_client():
    """Get or create Redis client singleton"""
    global redis_client
    logger.debug("get_redis_client called")
    if redis_client is None:
        redis_url = os.environ.get("REDIS_URL", "redis://localhost:6379/0")
        logger.info(f"Initializing Redis client with URL: {redis_url.replace('redis://:', 'redis://***:')}")
        try:
            redis_client = Redis.from_url(redis_url)
            redis_client.ping()  # Test connection
            logger.info("Redis connection established successfully")
        except Exception as e:
            logger.error(f"Failed to connect to Redis: {str(e)}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            redis_client = None
    return redis_client

def create_app(config_name='development', initialize_db=True):
    """Create and configure the Flask application"""
    # Import os again to ensure it's available in this function's scope
    import os
    logger.info(f"create_app called with config_name={config_name}, initialize_db={initialize_db}")
    logger.debug(f"'os' module is available in create_app scope: {os is not None}")
    
    try:
        app = Flask(__name__)
        logger.info("Flask app instance created")
        
        # In case of import errors, return a minimal app that explains the issue
        import_errors = []
        
        # Check if critical modules were imported
        if 'db' not in globals():
            import_errors.append("Failed to import shared database module")
        if 'meetings_bp' not in globals():
            import_errors.append("Failed to import meetings blueprint")
        
        if import_errors:
            logger.error(f"Critical import errors detected: {import_errors}")
            @app.route('/')
            def import_error():
                return jsonify({
                    'status': 'error',
                    'message': 'Application failed to start due to import errors',
                    'errors': import_errors,
                    'python_path': sys.path
                }), 500
                
            @app.route('/health')
            def minimal_health():
                return jsonify({
                    'status': 'error',
                    'message': 'Application is running but with import errors',
                    'errors': import_errors
                }), 500
                
            return app

        # Ensure required environment variables are set
        required_env_vars = [
            'DATABASE_URL',
            'JWT_SECRET_KEY',
            'REDIS_URL',
            'SERVICE_KEY',
            'AUTH_SERVICE_URL'
        ]
        
        logger.info("Checking required environment variables...")
        
        # Check for missing environment variables
        missing_vars = []
        for var in required_env_vars:
            value = os.environ.get(var)
            if not value:
                missing_vars.append(var)
                logger.error(f"Required environment variable not set: {var}")
            else:
                if 'SECRET' in var or 'PASSWORD' in var:
                    logger.info(f"Environment variable {var} is set")
                else:
                    logger.info(f"Environment variable {var}={value}")
        
        if missing_vars:
            logger.error(f"Missing required environment variables: {', '.join(missing_vars)}")
            raise RuntimeError(f"Missing required environment variables: {', '.join(missing_vars)}")
        
        # Load configuration from shared config
        logger.info(f"Loading configuration from config[{config_name}]")
        app.config.from_object(config[config_name])
        
        # Ensure backup directory is configured
        backup_dir = os.environ.get('BACKUP_DIR', os.path.join(app.root_path, 'db_backups'))
        logger.info(f"Setting backup directory to: {backup_dir}")
        app.config['BACKUP_DIR'] = backup_dir
        
        # Initialize rate limiter
        logger.info("Initializing rate limiter...")
        global rate_limiter
        rate_limiter = RateLimiter(app.config['REDIS_URL'])
        
        # Initialize Redis client and store in app extensions
        logger.info("Initializing Redis client...")
        redis = get_redis_client()
        if redis:
            app.extensions['redis'] = redis
            logger.info("Redis client added to app extensions")
        else:
            logger.warning("Redis client initialization failed")
        
        # Configure cache settings
        logger.info("Configuring cache settings...")
        app.config['CACHE_TYPE'] = 'redis'
        app.config['CACHE_REDIS_URL'] = app.config['REDIS_URL']
        
        # CORS configuration from shared config
        logger.info("Configuring CORS...")
        CORS(app, resources={
            r"/api/*": {
                "origins": app.config['CORS_ORIGINS'],
                "methods": app.config['CORS_METHODS'],
                "allow_headers": app.config['CORS_HEADERS'],
                "supports_credentials": True
            }
        })
        logger.info(f"CORS configured with origins: {app.config['CORS_ORIGINS']}")
        
        # CSRF configuration
        logger.info("Configuring CSRF protection...")
        csrf.init_app(app)
        app.config['WTF_CSRF_TIME_LIMIT'] = 3600  # 1 hour
        app.config['WTF_CSRF_SSL_STRICT'] = True
        
        # Exempt non-browser endpoints from CSRF
        logger.info("Exempting auth_integration_bp from CSRF protection")
        csrf.exempt(auth_integration_bp)
        
        # Initialize database and migrations
        logger.info("Initializing database and migrations...")
        init_db(app)  # Using shared database initialization
        migrate.init_app(app, db)
        
        # Register error handlers
        logger.info("Registering error handlers...")
        handle_api_errors(app)
        
        # Initialize database if needed
        if initialize_db:
            logger.info("Initializing database...")
            with app.app_context():
                try:
                    migrations_manager = MigrationsManager(app, db)
                    migrations_manager.initialize_database()
                    logger.info("Database initialized successfully")

                    # Seed data in development
                    if app.config.get("FLASK_ENV") == "development":
                        logger.info("Seeding development data...")
                        data_seeder = DataSeeder(app, db)
                        if not data_seeder.run_all_seeders():
                            logger.error("Failed to seed data")
                        else:
                            logger.info("Data seeding completed successfully")
                except Exception as e:
                    logger.error(f"Database initialization error: {str(e)}")
                    logger.error(f"Traceback: {traceback.format_exc()}")
        
        # Register blueprints
        logger.info("Registering blueprints...")
        app.register_blueprint(meetings_bp, url_prefix='/api/meetings')
        app.register_blueprint(auth_integration_bp, url_prefix='/api')
        logger.info("Blueprints registered successfully")
        
        # Initialize background tasks if APScheduler is available
        if has_apscheduler:
            try:
                logger.info("Initializing background tasks...")
                from .tasks import initialize_tasks
                initialize_tasks(app)
                logger.info("Background tasks initialized successfully")
            except ImportError as e:
                logger.warning(f"Could not import tasks modules. Background tasks disabled: {e}")
        
        # Register health endpoint
        logger.info("Registering health endpoint...")
        @app.route("/health")
        def health_check():
            """Health check endpoint"""
            try:
                # Check database connection
                with app.app_context():
                    db.session.execute("SELECT 1")
                logger.debug("Database health check: OK")
                
                # Check Redis connection
                redis_status = "unavailable"
                if app.extensions.get("redis"):
                    try:
                        app.extensions["redis"].ping()
                        redis_status = "connected"
                        logger.debug("Redis health check: OK")
                    except Exception as e:
                        redis_status = f"error: {str(e)}"
                        logger.error(f"Redis health check failed: {str(e)}")
                
                health_data = {
                    "status": "healthy",
                    "service": "flask",
                    "database": "connected",
                    "redis": redis_status,
                    "apscheduler": "available" if has_apscheduler else "unavailable",
                    "timestamp": datetime.utcnow().isoformat()
                }
                logger.debug(f"Health check response: {health_data}")
                return health_data, 200
            except Exception as e:
                logger.error(f"Health check failed: {str(e)}")
                logger.error(f"Traceback: {traceback.format_exc()}")
                return {
                    "status": "unhealthy",
                    "service": "flask",
                    "error": str(e),
                    "timestamp": datetime.utcnow().isoformat()
                }, 500
        
        logger.info("Application initialized successfully")
        return app
        
    except Exception as e:
        logger.error(f"Error in create_app: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        raise 
```


### FILE: backend\flask-service\requirements.txt
```
Flask==2.2.5
Flask-SQLAlchemy==3.0.5
Flask-Migrate==4.0.4
Flask-Cors==4.0.0
psycopg2-binary==2.9.7
python-dotenv==1.0.0
PyJWT==2.8.0
bcrypt==4.0.1
gunicorn==21.2.0
python-jose==3.3.0
email-validator>=2.1.0
redis==5.0.0
bleach==6.0.0
google-auth-oauthlib==1.0.0
requests==2.31.0
pydantic>=2.5.2
marshmallow==3.20.1
Flask-WTF==1.1.1
Werkzeug==2.2.3
APScheduler==3.10.4
psutil==5.9.5
pytest==7.4.0
pytest-cov==4.1.0
sentry-sdk[flask]==1.28.1
structlog==23.1.0
logging-formatter-anticrlf==1.3.1
python-json-logger==2.0.7
typing-extensions>=4.7.1
python-consul==1.1.0
kubernetes==28.1.0
hvac==1.1.1     
boto3==1.29.6       
pytest-flask==1.3.0
responses==0.23.3 
```


### FILE: backend\flask-service\migrations\alembic.ini
```
# A generic, single database configuration.

[alembic]
# path to migration scripts
script_location = migrations

# template used to generate migration files
# file_template = %%(rev)s_%%(slug)s

# sys.path path, will be prepended to sys.path if present.
# defaults to the current working directory.
prepend_sys_path = .

# timezone to use when rendering the date within the migration file
# as well as the filename.
# If specified, requires the python-dateutil library that can be
# installed by adding `alembic[tz]` to the pip requirements
# timezone =

# max length of characters to apply to the
# "slug" field
# truncate_slug_length = 40

# set to 'true' to run the environment during
# the 'revision' command, regardless of autogenerate
# revision_environment = false

# set to 'true' to allow .pyc and .pyo files without
# a source .py file to be detected as revisions in the
# versions/ directory
# sourceless = false

# version location specification; This defaults
# to migrations/versions.  When using multiple version
# directories, initial revisions must be specified with --version-path.
# The path separator used here should be the separator specified by "version_path_separator" below.
# version_locations = %(here)s/bar:%(here)s/bat:migrations/versions

# version path separator; As mentioned above, this is the character used to split
# version_locations. The default within new alembic.ini files is "os", which uses os.pathsep.
# If this key is omitted entirely, it falls back to the legacy behavior of splitting on spaces and/or colons.
# Valid values for version_path_separator are:
#
# version_path_separator = :
# version_path_separator = ;
# version_path_separator = space
version_path_separator = os  # Use os.pathsep. Default configuration used for new projects.

# the output encoding used when revision files
# are written from script.py.mako
# output_encoding = utf-8

# URL will be overridden by environment variable in env.py
sqlalchemy.url = driver://user:pass@localhost/dbname

[post_write_hooks]
# post_write_hooks defines scripts or Python functions that are run
# on newly generated revision scripts.  See the documentation for further
# detail and examples

# format using "black" - use the console_scripts runner, against the "black" entrypoint
# hooks = black
# black.type = console_scripts
# black.entrypoint = black
# black.options = -l 79 REVISION_SCRIPT_FILENAME

# Logging configuration
[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S 
```


### FILE: backend\flask-service\migrations\env.py
```
from logging.config import fileConfig
from sqlalchemy import engine_from_config
from sqlalchemy import pool
from alembic import context
import os

# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# Interpret the config file for Python logging.
# This line sets up loggers basically.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# Get database URL from environment
config.set_main_option('sqlalchemy.url', os.getenv('DATABASE_URL'))

# Import the Flask app and get the metadata
from src import app, db
with app.app_context():
    # add your model's MetaData object here
    # for 'autogenerate' support
    target_metadata = db.Model.metadata

def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.
    """
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()

def run_migrations_online() -> None:
    """Run migrations in 'online' mode.

    In this scenario we need to create an Engine
    and associate a connection with the context.
    """
    connectable = engine_from_config(
        config.get_section(config.config_ini_section, {}),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection, target_metadata=target_metadata
        )

        with context.begin_transaction():
            context.run_migrations()

if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online() 
```


### FILE: backend\flask-service\migrations\versions\initial_schema.py
```
"""Initial schema

Revision ID: initial_schema
Revises: None
Create Date: 2024-01-09 02:35:00.000000
"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects.postgresql import JSONB

# revision identifiers, used by Alembic
revision = 'initial_schema'
down_revision = None

def upgrade():
    # Create users table
    op.create_table(
        'users',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('email', sa.String(120), nullable=False),
        sa.Column('name', sa.String(100), nullable=False),
        sa.Column('password_hash', sa.String(128), nullable=False),
        sa.Column('created_at', sa.DateTime(), nullable=False, server_default=sa.func.now()),
        sa.Column('updated_at', sa.DateTime(), nullable=False, server_default=sa.func.now(), onupdate=sa.func.now()),
        
        # Security fields
        sa.Column('is_active', sa.Boolean(), nullable=False, server_default='true'),
        sa.Column('is_email_verified', sa.Boolean(), nullable=False, server_default='false'),
        sa.Column('email_verification_token', sa.String(100), nullable=True),
        sa.Column('email_verification_sent_at', sa.DateTime(), nullable=True),
        sa.Column('password_reset_token', sa.String(100), nullable=True),
        sa.Column('password_reset_sent_at', sa.DateTime(), nullable=True),
        sa.Column('last_login_at', sa.DateTime(), nullable=True),
        sa.Column('failed_login_attempts', sa.Integer(), nullable=False, server_default='0'),
        sa.Column('locked_until', sa.DateTime(), nullable=True),
        sa.Column('last_password_change', sa.DateTime(), nullable=False, server_default=sa.func.now()),
        sa.Column('last_login_ip', sa.String(45), nullable=True),
        sa.Column('login_count', sa.Integer(), nullable=False, server_default='0'),
        
        # User preferences
        sa.Column('preferences', JSONB(), nullable=False, server_default='{}'),
        
        sa.PrimaryKeyConstraint('id'),
        sa.UniqueConstraint('email'),
        sa.UniqueConstraint('name')
    )

    # Create meetings table
    op.create_table(
        'meetings',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('title', sa.String(200), nullable=False),
        sa.Column('description', sa.Text(), nullable=True),
        sa.Column('start_time', sa.DateTime(), nullable=False),
        sa.Column('end_time', sa.DateTime(), nullable=False),
        sa.Column('created_by', sa.Integer(), nullable=False),
        sa.Column('created_at', sa.DateTime(), nullable=False, server_default=sa.func.now()),
        sa.Column('updated_at', sa.DateTime(), nullable=False, server_default=sa.func.now(), onupdate=sa.func.now()),
        sa.Column('ended_at', sa.DateTime(), nullable=True),
        sa.Column('meeting_type', sa.String(20), nullable=False, server_default='regular'),
        sa.Column('max_participants', sa.Integer(), nullable=True),
        sa.Column('requires_approval', sa.Boolean(), nullable=False, server_default='false'),
        sa.Column('is_recorded', sa.Boolean(), nullable=False, server_default='false'),
        sa.Column('recording_url', sa.String(500), nullable=True),
        sa.Column('recurring_pattern', sa.String(50), nullable=True),
        sa.Column('parent_meeting_id', sa.Integer(), nullable=True),
        sa.ForeignKeyConstraint(['created_by'], ['users.id'], ondelete='CASCADE'),
        sa.ForeignKeyConstraint(['parent_meeting_id'], ['meetings.id'], ondelete='SET NULL'),
        sa.PrimaryKeyConstraint('id')
    )

    # Create meeting_participants table
    op.create_table(
        'meeting_participants',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('meeting_id', sa.Integer(), nullable=False),
        sa.Column('user_id', sa.Integer(), nullable=False),
        sa.Column('status', sa.String(20), nullable=False, server_default='pending'),
        sa.Column('role', sa.String(20), nullable=False, server_default='attendee'),
        sa.Column('joined_at', sa.DateTime(), nullable=True),
        sa.Column('left_at', sa.DateTime(), nullable=True),
        sa.Column('is_banned', sa.Boolean(), nullable=False, server_default='false'),
        sa.Column('created_at', sa.DateTime(), nullable=False, server_default=sa.func.now()),
        sa.Column('updated_at', sa.DateTime(), nullable=False, server_default=sa.func.now(), onupdate=sa.func.now()),
        sa.Column('total_time', sa.Integer(), nullable=True),
        sa.Column('connection_quality', sa.Float(), nullable=True),
        sa.Column('participation_score', sa.Float(), nullable=True),
        sa.Column('feedback', sa.Text(), nullable=True),
        sa.ForeignKeyConstraint(['meeting_id'], ['meetings.id'], ondelete='CASCADE'),
        sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id')
    )

    # Create meeting_co_hosts table
    op.create_table(
        'meeting_co_hosts',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('meeting_id', sa.Integer(), nullable=False),
        sa.Column('user_id', sa.Integer(), nullable=False),
        sa.Column('created_at', sa.DateTime(), nullable=False, server_default=sa.func.now()),
        sa.Column('updated_at', sa.DateTime(), nullable=False, server_default=sa.func.now(), onupdate=sa.func.now()),
        sa.ForeignKeyConstraint(['meeting_id'], ['meetings.id'], ondelete='CASCADE'),
        sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id'),
        sa.UniqueConstraint('meeting_id', 'user_id', name='uq_meeting_co_hosts')
    )

    # Create meeting_audit_logs table
    op.create_table(
        'meeting_audit_logs',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('meeting_id', sa.Integer(), nullable=False),
        sa.Column('user_id', sa.Integer(), nullable=False),
        sa.Column('action', sa.String(50), nullable=False),
        sa.Column('details', JSONB(), nullable=True),
        sa.Column('created_at', sa.DateTime(), nullable=False, server_default=sa.func.now()),
        sa.ForeignKeyConstraint(['meeting_id'], ['meetings.id'], ondelete='CASCADE'),
        sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id')
    )

    # Create indexes
    op.create_index('idx_users_email', 'users', ['email'])
    op.create_index('idx_users_name', 'users', ['name'])
    op.create_index('idx_users_is_active', 'users', ['is_active'])
    op.create_index('idx_users_is_email_verified', 'users', ['is_email_verified'])
    op.create_index('idx_users_email_verification_token', 'users', ['email_verification_token'])
    op.create_index('idx_users_password_reset_token', 'users', ['password_reset_token'])
    op.create_index('idx_users_preferences', 'users', ['preferences'], postgresql_using='gin')

    op.create_index('idx_meetings_created_by', 'meetings', ['created_by'])
    op.create_index('idx_meetings_start_time', 'meetings', ['start_time'])
    op.create_index('idx_meetings_end_time', 'meetings', ['end_time'])
    op.create_index('idx_meetings_meeting_type', 'meetings', ['meeting_type'])
    op.create_index('idx_meetings_parent_id', 'meetings', ['parent_meeting_id'])

    op.create_index('idx_meeting_participants_meeting_id', 'meeting_participants', ['meeting_id'])
    op.create_index('idx_meeting_participants_user_id', 'meeting_participants', ['user_id'])
    op.create_index('idx_meeting_participants_status', 'meeting_participants', ['status'])

    op.create_index('idx_meeting_co_hosts_meeting_id', 'meeting_co_hosts', ['meeting_id'])
    op.create_index('idx_meeting_co_hosts_user_id', 'meeting_co_hosts', ['user_id'])

    op.create_index('idx_meeting_audit_logs_meeting_id', 'meeting_audit_logs', ['meeting_id'])
    op.create_index('idx_meeting_audit_logs_user_id', 'meeting_audit_logs', ['user_id'])
    op.create_index('idx_meeting_audit_logs_created_at', 'meeting_audit_logs', ['created_at'])

def downgrade():
    # Drop indexes first
    op.drop_index('idx_meeting_audit_logs_created_at')
    op.drop_index('idx_meeting_audit_logs_user_id')
    op.drop_index('idx_meeting_audit_logs_meeting_id')
    op.drop_index('idx_meeting_co_hosts_user_id')
    op.drop_index('idx_meeting_co_hosts_meeting_id')
    op.drop_index('idx_meeting_participants_status')
    op.drop_index('idx_meeting_participants_user_id')
    op.drop_index('idx_meeting_participants_meeting_id')
    op.drop_index('idx_meetings_parent_id')
    op.drop_index('idx_meetings_meeting_type')
    op.drop_index('idx_meetings_end_time')
    op.drop_index('idx_meetings_start_time')
    op.drop_index('idx_meetings_created_by')
    op.drop_index('idx_users_preferences')
    op.drop_index('idx_users_password_reset_token')
    op.drop_index('idx_users_email_verification_token')
    op.drop_index('idx_users_is_email_verified')
    op.drop_index('idx_users_is_active')
    op.drop_index('idx_users_name')
    op.drop_index('idx_users_email')

    # Drop tables
    op.drop_table('meeting_audit_logs')
    op.drop_table('meeting_co_hosts')
    op.drop_table('meeting_participants')
    op.drop_table('meetings')
    op.drop_table('users') 
```


### FILE: backend\flask-service\scripts\migration_validator.py
```
#!/usr/bin/env python
import os
import sys
import re
from pathlib import Path
import ast
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MigrationValidator:
    def __init__(self, migrations_dir):
        self.migrations_dir = Path(migrations_dir)
        self.errors = []
        self.warnings = []

    def validate_migration_files(self):
        """Validate all migration files in the directory"""
        migration_files = sorted(self.migrations_dir.glob('*.py'))
        
        for migration_file in migration_files:
            logger.info(f"Validating migration file: {migration_file.name}")
            self.validate_single_migration(migration_file)

        return len(self.errors) == 0

    def validate_single_migration(self, file_path):
        """Validate a single migration file"""
        try:
            with open(file_path, 'r') as f:
                content = f.read()
                
            # Parse the Python file
            tree = ast.parse(content)
            
            # Check for basic requirements
            self._check_revision(tree, file_path)
            self._check_upgrade_downgrade(tree, file_path)
            self._check_dangerous_operations(content, file_path)
            self._check_transaction_safety(content, file_path)
            
        except Exception as e:
            self.errors.append(f"Error parsing {file_path.name}: {str(e)}")

    def _check_revision(self, tree, file_path):
        """Check if revision and dependencies are properly defined"""
        revision_found = False
        for node in ast.walk(tree):
            if isinstance(node, ast.Assign):
                for target in node.targets:
                    if isinstance(target, ast.Name) and target.id == 'revision':
                        revision_found = True
                        if not isinstance(node.value, ast.Str):
                            self.errors.append(f"{file_path.name}: revision should be a string")
        
        if not revision_found:
            self.errors.append(f"{file_path.name}: missing revision identifier")

    def _check_upgrade_downgrade(self, tree, file_path):
        """Check if upgrade and downgrade functions are defined"""
        functions = set()
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                functions.add(node.name)
        
        if 'upgrade' not in functions:
            self.errors.append(f"{file_path.name}: missing upgrade function")
        if 'downgrade' not in functions:
            self.warnings.append(f"{file_path.name}: missing downgrade function")

    def _check_dangerous_operations(self, content, file_path):
        """Check for potentially dangerous operations"""
        dangerous_patterns = [
            (r'drop\s+table', 'table drop'),
            (r'truncate\s+table', 'table truncate'),
            (r'delete\s+from', 'delete without where clause'),
            (r'alter\s+table\s+\w+\s+drop\s+column', 'column drop')
        ]
        
        for pattern, operation in dangerous_patterns:
            if re.search(pattern, content, re.IGNORECASE):
                self.warnings.append(
                    f"{file_path.name}: contains potentially dangerous operation: {operation}"
                )

    def _check_transaction_safety(self, content, file_path):
        """Check for transaction safety"""
        if 'op.execute' in content and 'op.get_bind().execute' not in content:
            self.warnings.append(
                f"{file_path.name}: uses raw execute - ensure statements are transaction-safe"
            )

    def print_report(self):
        """Print validation report"""
        if self.errors:
            logger.error("Validation Errors:")
            for error in self.errors:
                logger.error(f"  - {error}")
        
        if self.warnings:
            logger.warning("Validation Warnings:")
            for warning in self.warnings:
                logger.warning(f"  - {warning}")
        
        if not self.errors and not self.warnings:
            logger.info("All migrations validated successfully!")

def main():
    if len(sys.argv) != 2:
        print("Usage: python migration_validator.py <migrations_directory>")
        sys.exit(1)

    migrations_dir = sys.argv[1]
    if not os.path.exists(migrations_dir):
        print(f"Error: Directory {migrations_dir} does not exist")
        sys.exit(1)

    validator = MigrationValidator(migrations_dir)
    is_valid = validator.validate_migration_files()
    validator.print_report()

    sys.exit(0 if is_valid else 1)

if __name__ == '__main__':
    main() 
```


### FILE: backend\flask-service\scripts\show_migration_chain.py
```
#!/usr/bin/env python
import os
import sys
import re
from datetime import datetime
import graphviz
import logging
from pathlib import Path

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MigrationChainVisualizer:
    def __init__(self, migrations_dir):
        self.migrations_dir = Path(migrations_dir)
        self.migrations = {}
        self.graph = graphviz.Digraph(comment='Migration Chain')
        self.graph.attr(rankdir='LR')

    def parse_migration_files(self):
        """Parse all migration files to extract revision information"""
        for migration_file in sorted(self.migrations_dir.glob('*.py')):
            if migration_file.name.startswith('__'):
                continue

            with open(migration_file, 'r') as f:
                content = f.read()

            # Extract revision and dependencies
            revision_match = re.search(r"revision = '([^']*)'", content)
            down_revision_match = re.search(r"down_revision = '([^']*)'", content)
            
            if revision_match:
                revision = revision_match.group(1)
                down_revision = down_revision_match.group(1) if down_revision_match else None
                
                # Extract timestamp and description from filename
                timestamp_match = re.match(r'(\d{14})_(.+)\.py', migration_file.name)
                if timestamp_match:
                    timestamp = datetime.strptime(timestamp_match.group(1), '%Y%m%d%H%M%S')
                    description = timestamp_match.group(2).replace('_', ' ').title()
                else:
                    timestamp = None
                    description = migration_file.stem

                self.migrations[revision] = {
                    'down_revision': down_revision,
                    'file': migration_file.name,
                    'timestamp': timestamp,
                    'description': description
                }

    def create_graph(self, output_file='migration_chain'):
        """Create a visual representation of the migration chain"""
        self.parse_migration_files()

        # Add nodes
        for revision, info in self.migrations.items():
            label = f"{info['description']}\n{info['timestamp'].strftime('%Y-%m-%d %H:%M') if info['timestamp'] else ''}"
            self.graph.node(revision, label=label)

        # Add edges
        for revision, info in self.migrations.items():
            if info['down_revision']:
                self.graph.edge(info['down_revision'], revision)

        # Save the graph
        try:
            self.graph.render(output_file, view=True, format='png')
            logger.info(f"Migration chain visualization saved to {output_file}.png")
        except Exception as e:
            logger.error(f"Failed to create visualization: {e}")

    def print_chain(self):
        """Print text representation of the migration chain"""
        self.parse_migration_files()

        # Find head revision(s)
        heads = set(self.migrations.keys()) - {
            m['down_revision'] for m in self.migrations.values() if m['down_revision']
        }

        def print_branch(revision, level=0):
            """Recursively print migration chain"""
            if revision not in self.migrations:
                return

            info = self.migrations[revision]
            indent = '  ' * level
            timestamp = info['timestamp'].strftime('%Y-%m-%d %H:%M') if info['timestamp'] else 'N/A'
            print(f"{indent}â”œâ”€â”€ {info['description']} ({timestamp})")
            
            # Find children
            children = [
                rev for rev, data in self.migrations.items()
                if data['down_revision'] == revision
            ]
            
            for child in sorted(children):
                print_branch(child, level + 1)

        print("\nMigration Chain:")
        print("---------------")
        for head in sorted(heads):
            print_branch(head)

def main():
    if len(sys.argv) != 2:
        print("Usage: python show_migration_chain.py <migrations_directory>")
        sys.exit(1)

    migrations_dir = sys.argv[1]
    if not os.path.exists(migrations_dir):
        print(f"Error: Directory {migrations_dir} does not exist")
        sys.exit(1)

    visualizer = MigrationChainVisualizer(migrations_dir)
    visualizer.print_chain()
    visualizer.create_graph()

if __name__ == '__main__':
    main() 
```


### FILE: backend\flask-service\scripts\test_migrations.py
```
#!/usr/bin/env python
import os
import sys
import logging
import subprocess
import docker
import psycopg2
from datetime import datetime
import time

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MigrationTester:
    def __init__(self, migrations_dir, app_dir):
        self.migrations_dir = migrations_dir
        self.app_dir = app_dir
        self.docker_client = docker.from_env()
        self.test_db_name = f"test_migrations_{int(time.time())}"
        self.container = None

    def setup_test_database(self):
        """Create a temporary PostgreSQL container for testing"""
        try:
            logger.info("Setting up test database container...")
            self.container = self.docker_client.containers.run(
                'postgres:15-alpine',
                environment={
                    'POSTGRES_DB': self.test_db_name,
                    'POSTGRES_USER': 'test_user',
                    'POSTGRES_PASSWORD': 'test_password'
                },
                ports={'5432/tcp': None},
                detach=True
            )

            # Wait for container to be ready
            time.sleep(5)
            port = self.container.ports['5432/tcp'][0]['HostPort']
            
            return f"postgresql://test_user:test_password@localhost:{port}/{self.test_db_name}"
        except Exception as e:
            logger.error(f"Failed to setup test database: {e}")
            self.cleanup()
            sys.exit(1)

    def test_migration(self, migration_id):
        """Test a specific migration"""
        try:
            # Set up test environment
            database_url = self.setup_test_database()
            os.environ['DATABASE_URL'] = database_url

            logger.info(f"Testing migration: {migration_id}")

            # Run migrations up to the target
            result = subprocess.run(
                ['flask', 'db', 'upgrade', migration_id],
                cwd=self.app_dir,
                capture_output=True,
                text=True
            )

            if result.returncode != 0:
                logger.error(f"Migration upgrade failed: {result.stderr}")
                return False

            # Test downgrade
            result = subprocess.run(
                ['flask', 'db', 'downgrade', '-1'],
                cwd=self.app_dir,
                capture_output=True,
                text=True
            )

            if result.returncode != 0:
                logger.error(f"Migration downgrade failed: {result.stderr}")
                return False

            # Test upgrade again
            result = subprocess.run(
                ['flask', 'db', 'upgrade'],
                cwd=self.app_dir,
                capture_output=True,
                text=True
            )

            if result.returncode != 0:
                logger.error(f"Second migration upgrade failed: {result.stderr}")
                return False

            logger.info(f"Migration {migration_id} tested successfully!")
            return True

        except Exception as e:
            logger.error(f"Error testing migration: {e}")
            return False
        finally:
            self.cleanup()

    def test_all_migrations(self):
        """Test all migrations in sequence"""
        try:
            database_url = self.setup_test_database()
            os.environ['DATABASE_URL'] = database_url

            logger.info("Testing all migrations in sequence...")

            # Get list of migrations
            result = subprocess.run(
                ['flask', 'db', 'history'],
                cwd=self.app_dir,
                capture_output=True,
                text=True
            )

            if result.returncode != 0:
                logger.error(f"Failed to get migration history: {result.stderr}")
                return False

            migrations = [
                line.split(' ')[0] 
                for line in result.stdout.split('\n') 
                if line.strip() and not line.startswith('>')
            ]

            # Test each migration
            for migration_id in migrations:
                logger.info(f"Testing migration {migration_id}...")
                
                # Upgrade to this migration
                result = subprocess.run(
                    ['flask', 'db', 'upgrade', migration_id],
                    cwd=self.app_dir,
                    capture_output=True,
                    text=True
                )

                if result.returncode != 0:
                    logger.error(f"Failed to upgrade to {migration_id}: {result.stderr}")
                    return False

                # Verify database state
                if not self.verify_database_state():
                    logger.error(f"Database verification failed after migration {migration_id}")
                    return False

            logger.info("All migrations tested successfully!")
            return True

        except Exception as e:
            logger.error(f"Error testing migrations: {e}")
            return False
        finally:
            self.cleanup()

    def verify_database_state(self):
        """Verify database state after migration"""
        try:
            # Run application's verification logic
            result = subprocess.run(
                ['python', '-c', 'from src.app import create_app; app = create_app(); app.test_client()'],
                cwd=self.app_dir,
                capture_output=True,
                text=True
            )
            return result.returncode == 0
        except Exception as e:
            logger.error(f"Database verification failed: {e}")
            return False

    def cleanup(self):
        """Clean up test environment"""
        if self.container:
            try:
                self.container.stop()
                self.container.remove()
                logger.info("Test database container cleaned up")
            except Exception as e:
                logger.error(f"Error cleaning up container: {e}")

def main():
    if len(sys.argv) < 2:
        print("Usage: python test_migrations.py <app_directory> [migration_id]")
        sys.exit(1)

    app_dir = sys.argv[1]
    migrations_dir = os.path.join(app_dir, 'migrations')

    if not os.path.exists(migrations_dir):
        print(f"Error: Migrations directory not found in {app_dir}")
        sys.exit(1)

    tester = MigrationTester(migrations_dir, app_dir)

    if len(sys.argv) > 2:
        # Test specific migration
        success = tester.test_migration(sys.argv[2])
    else:
        # Test all migrations
        success = tester.test_all_migrations()

    sys.exit(0 if success else 1)

if __name__ == '__main__':
    main() 
```


### FILE: backend\flask-service\src\__init__.py
```
from flask import Flask, jsonify
from flask_cors import CORS
from flask_sqlalchemy import SQLAlchemy
from flask_migrate import Migrate
import os
import redis
import logging

# Import from shared modules
from shared.database import db

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Required environment variables
REQUIRED_ENV_VARS = [
    'DATABASE_URL',
    'JWT_SECRET_KEY',
    'REDIS_URL'
]

# Check for required environment variables
missing_vars = [var for var in REQUIRED_ENV_VARS if not os.getenv(var)]
if missing_vars:
    raise RuntimeError(f"Missing required environment variables: {', '.join(missing_vars)}")

app = Flask(__name__)

# Configure CORS
CORS(app, resources={
    r"/api/*": {
        "origins": os.getenv('CORS_ORIGINS', 'http://localhost:3000').split(","),
        "methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
        "allow_headers": ["Content-Type", "Authorization"],
        "supports_credentials": True
    }
})

# Database configuration
app.config['SQLALCHEMY_DATABASE_URI'] = os.getenv('DATABASE_URL')
app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False
app.config['JWT_SECRET_KEY'] = os.getenv('JWT_SECRET_KEY')

try:
    # Initialize extensions
    migrate = Migrate(app, db)
    logger.info("Database initialized successfully")
except Exception as e:
    logger.error(f"Failed to initialize database: {str(e)}")
    raise

try:
    # Initialize Redis
    redis_client = redis.from_url(os.getenv('REDIS_URL'))
    redis_client.ping()  # Test connection
    logger.info("Redis connection established successfully")
except Exception as e:
    logger.error(f"Failed to connect to Redis: {str(e)}")
    raise

# Health check endpoints
@app.route('/health')
def health_check():
    return jsonify({'status': 'healthy'}), 200

@app.route('/health/db')
def db_health_check():
    try:
        # Execute a simple query
        db.session.execute('SELECT 1')
        return jsonify({'status': 'healthy', 'message': 'Database connection successful'}), 200
    except Exception as e:
        return jsonify({'status': 'unhealthy', 'message': str(e)}), 500

@app.route('/health/redis')
def redis_health_check():
    try:
        # Try to ping Redis
        redis_client.ping()
        return jsonify({'status': 'healthy', 'message': 'Redis connection successful'}), 200
    except Exception as e:
        return jsonify({'status': 'unhealthy', 'message': str(e)}), 500

# Import and register blueprints
from .routes.auth import auth_bp
from .routes.meetings import meetings_bp

app.register_blueprint(auth_bp, url_prefix='/api/auth')
app.register_blueprint(meetings_bp, url_prefix='/api/meetings')

# Error handlers
@app.errorhandler(500)
def internal_error(error):
    logger.error(f"Internal Server Error: {str(error)}")
    return jsonify({'error': 'Internal Server Error'}), 500

@app.errorhandler(404)
def not_found_error(error):
    return jsonify({'error': 'Not Found'}), 404

logger.info("Application initialized successfully") 
```


### FILE: backend\flask-service\src\app.py
```
"""
Main application factory for the Flask Backend Service.
"""

import os
import sys
import logging
from typing import Optional, Dict, Any

# Configure import paths for shared modules
shared_module_paths = [
    os.path.abspath(os.path.join(os.path.dirname(__file__), '../../..')),
    os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../backend'))
]

for path in shared_module_paths:
    if path not in sys.path:
        sys.path.append(path)

# Import core modules
from flask import Flask, jsonify, g
from flask_cors import CORS
from werkzeug.middleware.proxy_fix import ProxyFix

# Try to import from shared modules with fallbacks
try:
    from shared.config import get_config
except ImportError:
    from core.config import get_config

try:
    from shared.logging import setup_logging
except ImportError:
    from core.logging import setup_logging

try:
    from shared.middleware import register_middleware
except ImportError:
    from core.middleware import register_middleware

# Import local modules
from core import (
    db, jwt, migrate, limiter, csrf,
    register_error_handlers, register_cli_commands
)

# Import API modules
from api.meetings import meetings_bp
from api.participants import participants_bp
from api.agendas import agendas_bp
from api.actions import actions_bp
from api.notes import notes_bp

# Configure logger
logger = logging.getLogger(__name__)

def create_app(config_name: Optional[str] = None) -> Flask:
    """
    Create and configure the Flask application.

    Args:
        config_name: Configuration environment name (default: from FLASK_ENV)

    Returns:
        Configured Flask application
    """
    # Create Flask app
    app = Flask(__name__)
    
    # Load configuration
    config_obj = get_config(config_name or os.getenv('FLASK_ENV', 'development'))
    app.config.from_object(config_obj)
    
    # Override database URL from environment if provided
    app.config['SQLALCHEMY_DATABASE_URI'] = os.getenv(
        'BACKEND_DATABASE_URL', 
        app.config.get('SQLALCHEMY_DATABASE_URI', 'sqlite:///backend.db')
    )
    
    # Configure logging
    setup_logging(
        app=app, 
        service_name='backend-service',
        log_level=app.config.get('LOG_LEVEL', 'INFO')
    )
    
    # Configure proxy settings for running behind a reverse proxy
    app.wsgi_app = ProxyFix(app.wsgi_app, x_for=1, x_proto=1, x_host=1, x_port=1, x_prefix=1)
    
    # Register middleware
    register_middleware(app)
    
    # Initialize extensions
    CORS(app)
    db.init_app(app)
    jwt.init_app(app)
    migrate.init_app(app, db)
    limiter.init_app(app)
    csrf.init_app(app)
    
    # Register blueprints
    app.register_blueprint(meetings_bp, url_prefix='/api/meetings')
    app.register_blueprint(participants_bp, url_prefix='/api/participants')
    app.register_blueprint(agendas_bp, url_prefix='/api/agendas')
    app.register_blueprint(actions_bp, url_prefix='/api/actions')
    app.register_blueprint(notes_bp, url_prefix='/api/notes')
    
    # Register error handlers
    register_error_handlers(app)
    
    # Register CLI commands
    register_cli_commands(app)
    
    # Add healthcheck endpoint
    @app.route('/health')
    def health():
        """Health check endpoint for the backend service."""
        health_data = {
            'status': 'ok',
            'service': 'backend-service',
            'version': os.getenv('VERSION', '0.1.0'),
            'request_id': getattr(g, 'request_id', 'none')
        }
        
        # Add database status check
        try:
            db.session.execute('SELECT 1')
            health_data['database'] = 'ok'
        except Exception as e:
            health_data['database'] = 'error'
            health_data['database_error'] = str(e)
            health_data['status'] = 'degraded'
            
        return jsonify(health_data)
    
    # Log application startup
    logger.info(f"Backend service started in {app.config.get('ENV')} mode")
    
    return app

if __name__ == '__main__':
    app = create_app()
    app.run(host='0.0.0.0', port=int(os.getenv('PORT', 5000)), debug=app.config.get('DEBUG', False)) 
```


### FILE: backend\flask-service\src\fixed_app.py
```
import os
import sys
import logging
from datetime import datetime, timedelta

from flask import Flask, jsonify
from flask_cors import CORS
from flask_migrate import Migrate
from flask_wtf.csrf import CSRFProtect
from redis import Redis

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Add paths for shared modules - try multiple approaches for Windows compatibility
potential_paths = [
    os.path.abspath(os.path.dirname(__file__)),  # Current directory
    os.path.abspath(os.path.join(os.path.dirname(__file__), '../')),  # Parent directory
    os.path.abspath(os.path.join(os.path.dirname(__file__), '../../')),  # Grandparent directory
    '/app',  # Docker container path
    '/app/shared'  # Docker shared volume path
]

for path in potential_paths:
    if path not in sys.path:
        sys.path.append(path)
        logger.info(f"Added {path} to sys.path")

# Try multiple import patterns to handle different environments
try:
    # Try absolute import first (when PYTHONPATH includes shared)
    from shared.database import db, init_db
    from shared.middleware.error_handler import handle_api_errors
    from shared.middleware.validation import validate_schema
    from shared.middleware.rate_limiter import RateLimiter
    from shared.config import config
    logger.info("Successfully imported shared modules using absolute import")
except ImportError as e:
    logger.warning(f"Absolute import failed: {e}, trying relative import")
    try:
        # Fallback to relative path
        from backend.shared.database import db, init_db
        from backend.shared.middleware.error_handler import handle_api_errors
        from backend.shared.middleware.validation import validate_schema
        from backend.shared.middleware.rate_limiter import RateLimiter
        from backend.shared.config import config
        logger.info("Successfully imported shared modules using relative import")
    except ImportError as e:
        logger.error(f"All import approaches failed: {e}")
        logger.error(f"Current sys.path: {sys.path}")
        # We'll handle this in create_app() to provide a meaningful error message

# Import local modules
try:
    from .routes.meetings import meetings_bp
    from .routes.auth_integration import bp as auth_integration_bp
    from .routes.health import health_bp
    from .utils.migrations_manager import MigrationsManager
    from .utils.data_seeder import DataSeeder
    from .utils.auth_integration import AuthIntegration
except ImportError as e:
    logger.error(f"Failed to import local modules: {e}")
    # We'll handle this in create_app()

# Try to import APScheduler, but continue if it's not available
try:
    from apscheduler.schedulers.background import BackgroundScheduler
    from apscheduler.triggers.interval import IntervalTrigger
    has_apscheduler = True
    logger.info("Successfully imported APScheduler")
except ImportError:
    has_apscheduler = False
    logger.warning("APScheduler not available, some features will be disabled")

# Initialize extensions
migrate = Migrate()
csrf = CSRFProtect()
rate_limiter = None
cors = CORS()
redis_client = None

def get_redis_client():
    """Get or create Redis client singleton"""
    global redis_client
    if redis_client is None:
        redis_url = os.environ.get("REDIS_URL", "redis://localhost:6379/0")
        try:
            redis_client = Redis.from_url(redis_url)
            redis_client.ping()  # Test connection
            logger.info("Redis connection established successfully")
        except Exception as e:
            logger.error(f"Failed to connect to Redis: {str(e)}")
            redis_client = None
    return redis_client

def create_app(config_name='development', initialize_db=True):
    """Create and configure the Flask application"""
    # Import os again to ensure it's available in this function's scope
    import os
    
    app = Flask(__name__)
    
    # In case of import errors, return a minimal app that explains the issue
    import_errors = []
    
    # Check if critical modules were imported
    if 'db' not in globals():
        import_errors.append("Failed to import shared database module")
    if 'meetings_bp' not in globals():
        import_errors.append("Failed to import meetings blueprint")
    
    if import_errors:
        @app.route('/')
        def import_error():
            return jsonify({
                'status': 'error',
                'message': 'Application failed to start due to import errors',
                'errors': import_errors,
                'python_path': sys.path
            }), 500
            
        @app.route('/health')
        def minimal_health():
            return jsonify({
                'status': 'error',
                'message': 'Application is running but with import errors',
                'errors': import_errors
            }), 500
            
        return app

    # Ensure required environment variables are set
    required_env_vars = [
        'DATABASE_URL',
        'JWT_SECRET_KEY',
        'REDIS_URL',
        'SERVICE_KEY',
        'AUTH_SERVICE_URL'
    ]
    
    # Check for missing environment variables
    missing_vars = []
    for var in required_env_vars:
        if not os.environ.get(var):
            missing_vars.append(var)
    
    if missing_vars:
        raise RuntimeError(f"Missing required environment variables: {', '.join(missing_vars)}")
    
    # Load configuration from shared config
    app.config.from_object(config[config_name])
    
    # Ensure backup directory is configured
    app.config['BACKUP_DIR'] = os.environ.get('BACKUP_DIR', os.path.join(app.root_path, 'db_backups'))
    
    # Initialize rate limiter
    global rate_limiter
    rate_limiter = RateLimiter(app.config['REDIS_URL'])
    
    # Initialize Redis client and store in app extensions
    redis = get_redis_client()
    if redis:
        app.extensions['redis'] = redis
    
    # Configure cache settings
    app.config['CACHE_TYPE'] = 'redis'
    app.config['CACHE_REDIS_URL'] = app.config['REDIS_URL']
    
    # CORS configuration from shared config
    CORS(app, resources={
        r"/api/*": {
            "origins": app.config['CORS_ORIGINS'],
            "methods": app.config['CORS_METHODS'],
            "allow_headers": app.config['CORS_HEADERS'],
            "supports_credentials": True
        }
    })
    
    # CSRF configuration
    csrf.init_app(app)
    app.config['WTF_CSRF_TIME_LIMIT'] = 3600  # 1 hour
    app.config['WTF_CSRF_SSL_STRICT'] = True
    
    # Exempt non-browser endpoints from CSRF
    csrf.exempt(auth_integration_bp)
    
    # Initialize database and migrations
    init_db(app)  # Using shared database initialization
    migrate.init_app(app, db)
    
    # Register error handlers
    handle_api_errors(app)
    
    # Initialize database if needed
    if initialize_db:
        with app.app_context():
            migrations_manager = MigrationsManager(app, db)
            migrations_manager.initialize_database()

            # Seed data in development
            if app.config.get("FLASK_ENV") == "development":
                data_seeder = DataSeeder(app, db)
                if not data_seeder.run_all_seeders():
                    logger.error("Failed to seed data")
    
    # Register blueprints
    app.register_blueprint(meetings_bp, url_prefix='/api/meetings')
    app.register_blueprint(auth_integration_bp, url_prefix='/api')
    
    # Initialize background tasks if APScheduler is available
    if has_apscheduler:
        try:
            from .tasks import initialize_tasks
            initialize_tasks(app)
        except ImportError:
            logger.warning("Could not import tasks modules. Background tasks disabled.")
    
    # Register health endpoint
    @app.route("/health")
    def health_check():
        """Health check endpoint"""
        try:
            # Check database connection
            with app.app_context():
                db.session.execute("SELECT 1")
            
            # Check Redis connection
            redis_status = "unavailable"
            if app.extensions.get("redis"):
                try:
                    app.extensions["redis"].ping()
                    redis_status = "connected"
                except Exception as e:
                    redis_status = f"error: {str(e)}"
            
            return {
                "status": "healthy",
                "service": "flask",
                "database": "connected",
                "redis": redis_status,
                "apscheduler": "available" if has_apscheduler else "unavailable",
                "timestamp": datetime.utcnow().isoformat()
            }, 200
        except Exception as e:
            logger.error(f"Health check failed: {str(e)}")
            return {
                "status": "unhealthy",
                "service": "flask",
                "error": str(e),
                "timestamp": datetime.utcnow().isoformat()
            }, 500
    
    logger.info("Application initialized successfully")
    return app 
```


### FILE: backend\flask-service\src\core\__init__.py
```
"""
Core module for Flask service functionality and initialization.
Provides centralized logging, error handling, and configuration.
"""

import logging
import os
import sys
import json
from pathlib import Path

# Try to import shared modules
try:
    from backend.shared.logging import configure_logging, get_logger
    from backend.shared.middleware.request_id import RequestIdMiddleware, get_request_id
    SHARED_MODULES_AVAILABLE = True
except ImportError:
    SHARED_MODULES_AVAILABLE = False

# Configure application-wide logging
def setup_logging(log_level=None):
    """
    Configure application-wide logging with appropriate handlers and formatters.
    
    Args:
        log_level: Optional override for log level (default is from environment or INFO)
        
    Returns:
        logging.Logger: Logger instance
    """
    if not log_level:
        log_level = os.environ.get('LOG_LEVEL', 'INFO').upper()
    
    # Use shared logging if available
    if SHARED_MODULES_AVAILABLE:
        # Configure using shared module
        config = {
            'level': log_level,
            'service_name': 'flask-service',
            'json_enabled': os.environ.get('JSON_LOGS', 'true').lower() == 'true',
            'file_enabled': os.environ.get('LOG_TO_FILE', 'false').lower() == 'true',
            'file_path': os.environ.get('LOG_FILE', 'logs/flask-service.log'),
        }
        configure_logging(config)
        logger = get_logger(__name__)
    else:
        # Fall back to basic logging
        logging_format = os.environ.get(
            'LOG_FORMAT', 
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        # Configure root logger
        root_logger = logging.getLogger()
        root_logger.setLevel(getattr(logging, log_level))
        
        # Remove existing handlers
        for handler in list(root_logger.handlers):
            root_logger.removeHandler(handler)
        
        # Add console handler
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(getattr(logging, log_level))
        console_formatter = logging.Formatter(logging_format)
        console_handler.setFormatter(console_formatter)
        root_logger.addHandler(console_handler)
        
        # Add file handler if requested
        if os.environ.get('LOG_TO_FILE', 'false').lower() == 'true':
            log_file = os.environ.get('LOG_FILE', 'logs/flask-service.log')
            os.makedirs(os.path.dirname(log_file), exist_ok=True)
            
            file_handler = logging.FileHandler(log_file)
            file_handler.setLevel(getattr(logging, log_level))
            file_formatter = logging.Formatter(logging_format)
            file_handler.setFormatter(file_formatter)
            root_logger.addHandler(file_handler)
        
        logger = logging.getLogger(__name__)
    
    logger.info(f"Logging initialized at level {log_level}")
    
    return logger

def log_system_info():
    """
    Log system and environment information for debugging purposes.
    """
    import platform
    import socket
    from datetime import datetime
    
    logger = logging.getLogger(__name__)
    
    # Collect system information
    system_info = {
        'timestamp': datetime.utcnow().isoformat() + 'Z',
        'hostname': socket.gethostname(),
        'platform': platform.platform(),
        'python_version': platform.python_version(),
        'environment': os.environ.get('FLASK_ENV', 'production'),
        'debug': os.environ.get('DEBUG', 'false').lower() == 'true',
    }
    
    # Log system information
    logger.info(f"System info: {json.dumps(system_info)}")
    
    # Log environment variables (filtered)
    safe_vars = {k: v for k, v in os.environ.items() 
                if not any(secret in k.lower() 
                        for secret in ['key', 'secret', 'token', 'password', 'auth'])}
    
    logger.debug(f"Environment variables: {json.dumps(safe_vars)}")

def log_directory_structure(base_path='/app', max_depth=2):
    """
    Log the directory structure for debugging purposes.
    """
    logger = logging.getLogger(__name__)
    logger.info(f"Directory structure of {base_path} (max depth: {max_depth})")
    
    def _log_dir(path, depth=0):
        if depth > max_depth:
            return
        
        try:
            path_obj = Path(path)
            
            # Skip if path doesn't exist
            if not path_obj.exists():
                logger.warning(f"Path does not exist: {path}")
                return
            
            # Log directory entries
            if path_obj.is_dir():
                indent = '  ' * depth
                
                # Get directory contents
                try:
                    contents = list(path_obj.iterdir())
                    
                    # Log count of items
                    logger.info(f"{indent}{path} ({len(contents)} items)")
                    
                    # Sort contents (directories first)
                    contents.sort(key=lambda p: (0 if p.is_dir() else 1, p.name))
                    
                    # Log each item
                    for item in contents:
                        if item.is_dir():
                            _log_dir(item, depth + 1)
                        else:
                            try:
                                stat = item.stat()
                                size_kb = stat.st_size / 1024
                                logger.info(f"{indent}  {item.name} ({size_kb:.1f} KB)")
                            except Exception as e:
                                logger.info(f"{indent}  {item.name} (error: {str(e)})")
                except Exception as e:
                    logger.error(f"Error listing directory {path}: {str(e)}")
        except Exception as e:
            logger.error(f"Error logging directory structure: {str(e)}")
    
    # Start logging directory structure
    _log_dir(base_path)

def register_extensions(app):
    """
    Register Flask extensions with the app.
    
    Args:
        app: Flask application instance
    """
    # Register request ID middleware if available
    if SHARED_MODULES_AVAILABLE:
        RequestIdMiddleware(app)
        app.logger.info("Registered RequestIdMiddleware")

def init_app(app):
    """
    Initialize the Flask application with core functionality.
    
    Args:
        app: Flask application instance
    """
    # Set up logging
    setup_logging()
    
    # Register extensions
    register_extensions(app)
    
    # Log system information
    log_system_info()
    
    # Log directory structure for debugging
    if app.debug:
        log_directory_structure()
    
    # Register error handlers
    from .errors import register_error_handlers
    register_error_handlers(app)
    
    app.logger.info("Core initialization complete") 
```


### FILE: backend\flask-service\src\core\config.py
```
"""
Centralized configuration management for the application.
Handles environment variables and provides environment-specific settings.
"""

import os
import logging
from pathlib import Path

logger = logging.getLogger(__name__)

class BaseConfig:
    """Base configuration settings shared across all environments"""
    # Application settings
    APP_NAME = "Meeting API Service"
    API_PREFIX = "/api"
    
    # Environment settings
    DEBUG = False
    TESTING = False
    
    # Security settings
    SECRET_KEY = os.environ.get("JWT_SECRET_KEY")
    SERVICE_KEY = os.environ.get("SERVICE_KEY")
    
    # Database settings 
    SQLALCHEMY_DATABASE_URI = os.environ.get("DATABASE_URL")
    SQLALCHEMY_TRACK_MODIFICATIONS = False
    
    # Redis settings
    REDIS_URL = os.environ.get("REDIS_URL", "redis://localhost:6379/0")
    
    # CORS settings
    CORS_ORIGINS = os.environ.get("CORS_ORIGINS", "http://localhost:3000").split(",")
    CORS_METHODS = ["GET", "POST", "PUT", "DELETE", "OPTIONS"]
    CORS_HEADERS = ["Content-Type", "Authorization", "X-Service-Key"]
    
    # Auth Service integration
    AUTH_SERVICE_URL = os.environ.get("AUTH_SERVICE_URL", "http://auth-service:5001")
    
    # File paths
    ROOT_DIR = Path("/app")
    LOG_DIR = ROOT_DIR / "logs"
    BACKUP_DIR = ROOT_DIR / "backups"
    
    # Ensure directories exist
    LOG_DIR.mkdir(exist_ok=True)
    BACKUP_DIR.mkdir(exist_ok=True)

    # Healthcheck settings
    HEALTH_DATABASE_TIMEOUT = 3  # seconds
    HEALTH_REDIS_TIMEOUT = 2     # seconds

class DevelopmentConfig(BaseConfig):
    """Development environment specific configuration"""
    DEBUG = True
    LOG_LEVEL = "DEBUG"
    
    # Enable detailed error messages and SQL query logging
    SQLALCHEMY_ECHO = True
    
    # Development-specific settings
    PRESERVE_CONTEXT_ON_EXCEPTION = False
    
    # Extended CORS settings for development
    CORS_ORIGINS = os.environ.get("CORS_ORIGINS", 
                                 "http://localhost:3000,http://localhost:3001,http://localhost:5000").split(",")

class TestingConfig(BaseConfig):
    """Testing environment specific configuration"""
    TESTING = True
    DEBUG = True
    
    # Use in-memory database for testing
    SQLALCHEMY_DATABASE_URI = os.environ.get("TEST_DATABASE_URL", "sqlite:///:memory:")
    
    # Disable CSRF protection for testing
    WTF_CSRF_ENABLED = False
    
    # Mock external services
    AUTH_SERVICE_URL = os.environ.get("TEST_AUTH_SERVICE_URL", "http://localhost:5001")
    REDIS_URL = os.environ.get("TEST_REDIS_URL", "redis://localhost:6379/1")

class ProductionConfig(BaseConfig):
    """Production environment specific configuration"""
    LOG_LEVEL = "INFO"
    
    # Production security settings
    WTF_CSRF_SSL_STRICT = True
    
    # Set stricter CORS
    CORS_ORIGINS = os.environ.get("CORS_ORIGINS", "https://yourdomain.com").split(",")

# Dictionary of available configurations
config = {
    "development": DevelopmentConfig,
    "testing": TestingConfig,
    "production": ProductionConfig,
    # Default to development
    "default": DevelopmentConfig
}

def get_config(config_name=None):
    """
    Get the configuration for the current environment.
    
    Args:
        config_name: Optional configuration name override
        
    Returns:
        Configuration class
    """
    if not config_name:
        config_name = os.environ.get("FLASK_ENV", "development").lower()
    
    selected_config = config.get(config_name, config["default"])
    logger.info(f"Using '{config_name}' configuration")
    
    # Validate critical settings
    if not selected_config.SECRET_KEY and config_name == "production":
        logger.critical("SECRET_KEY not set in production environment!")
    
    if not selected_config.SQLALCHEMY_DATABASE_URI:
        logger.critical("DATABASE_URL not set! Application may fail to start")
    
    return selected_config 
```


### FILE: backend\flask-service\src\core\errors.py
```
"""
Centralized error handling for the Flask service.
Provides standardized error responses and detailed logging of exceptions.
"""

import traceback
import logging
import json
import os
from datetime import datetime
from flask import jsonify, request, current_app

logger = logging.getLogger(__name__)

# Try to import standardized errors from shared module
try:
    # Try to import from backend.shared first
    from backend.shared.errors import (
        APIError, ValidationError, AuthenticationError, AuthorizationError,
        UserExistsError, UserNotFoundError, TokenError, ResourceNotFoundError,
        ResourceExistsError, ServiceError, ConfigurationError, DependencyError,
        RateLimitError, EmailError, HAS_REQUEST_ID
    )
    SHARED_ERRORS_AVAILABLE = True
    logger.info("Successfully imported shared error classes")
except ImportError:
    try:
        # Try to import from shared as fallback
        from shared.errors import (
            APIError, ValidationError, AuthenticationError, AuthorizationError,
            UserExistsError, UserNotFoundError, TokenError, ResourceNotFoundError,
            ResourceExistsError, ServiceError, ConfigurationError, DependencyError,
            RateLimitError, EmailError, HAS_REQUEST_ID
        )
        SHARED_ERRORS_AVAILABLE = True
        logger.info("Successfully imported shared error classes using fallback path")
    except ImportError:
        SHARED_ERRORS_AVAILABLE = False
        logger.warning("Could not import shared error classes, using local definitions")
        
        # Try to import request ID functionality
        try:
            from backend.shared.middleware.request_id import get_request_id
            HAS_REQUEST_ID = True
        except ImportError:
            try:
                from shared.middleware.request_id import get_request_id
                HAS_REQUEST_ID = True
            except ImportError:
                HAS_REQUEST_ID = False

        # Define error classes locally if shared module is not available
        class APIError(Exception):
            """Base exception class for API errors with status code and message"""
            
            def __init__(self, message, status_code=400, details=None):
                self.message = message
                self.status_code = status_code
                self.details = details or {}
                self.timestamp = datetime.utcnow().isoformat() + 'Z'
                
                # Add request ID if available
                if HAS_REQUEST_ID:
                    self.request_id = get_request_id()
                else:
                    self.request_id = None
            
            def to_dict(self):
                """Convert exception to dictionary representation"""
                error_dict = {
                    'error': True,
                    'status_code': self.status_code,
                    'message': self.message,
                    'timestamp': self.timestamp
                }
                
                # Include request ID if available
                if hasattr(self, 'request_id') and self.request_id:
                    error_dict['request_id'] = self.request_id
                
                # Include request URL and method if in a request context
                try:
                    error_dict['path'] = request.path
                    error_dict['method'] = request.method
                except RuntimeError:
                    # Not in a request context
                    pass
                
                # Include additional details if provided
                if self.details:
                    error_dict['details'] = self.details
                
                return error_dict

        class ValidationError(APIError):
            """Exception for data validation errors"""
            
            def __init__(self, message="Validation error", details=None):
                super().__init__(message, status_code=422, details=details)

        class AuthenticationError(APIError):
            """Exception for authentication failures"""
            
            def __init__(self, message="Authentication required", details=None):
                super().__init__(message, status_code=401, details=details)

        class AuthorizationError(APIError):
            """Exception for authorization failures"""
            
            def __init__(self, message="Not authorized", details=None):
                super().__init__(message, status_code=403, details=details)

        class ResourceNotFoundError(APIError):
            """Exception for resource not found"""
            
            def __init__(self, message="Resource not found", details=None):
                super().__init__(message, status_code=404, details=details)

        class ResourceExistsError(APIError):
            """Exception for duplicate resource"""
            
            def __init__(self, message="Resource already exists", details=None):
                super().__init__(message, status_code=409, details=details)

        class RateLimitError(APIError):
            """Exception for rate limiting"""
            
            def __init__(self, message="Rate limit exceeded", details=None):
                super().__init__(message, status_code=429, details=details)

        class ServiceError(APIError):
            """Exception for service failures"""
            
            def __init__(self, message="Service error", details=None):
                super().__init__(message, status_code=500, details=details)

        class ConfigurationError(APIError):
            """Exception for configuration errors"""
            
            def __init__(self, message="Configuration error", details=None):
                super().__init__(message, status_code=500, details=details)

        class DependencyError(APIError):
            """Exception for dependency failures"""
            
            def __init__(self, message="Dependency error", details=None):
                super().__init__(message, status_code=503, details=details)
                
        class UserExistsError(APIError):
            """Exception for duplicate user registration"""
            
            def __init__(self, message="User already exists", details=None):
                super().__init__(message, status_code=409, details=details)
                
        class UserNotFoundError(APIError):
            """Exception for user not found"""
            
            def __init__(self, message="User not found", details=None):
                super().__init__(message, status_code=404, details=details)
                
        class TokenError(APIError):
            """Exception for token validation failures"""
            
            def __init__(self, message="Invalid or expired token", details=None):
                super().__init__(message, status_code=401, details=details)
                
        class EmailError(APIError):
            """Exception for email sending failures"""
            
            def __init__(self, message="Failed to send email", details=None):
                super().__init__(message, status_code=500, details=details)

def register_error_handlers(app):
    """
    Register all error handlers with the Flask app.
    
    Args:
        app: Flask application instance
    """
    # Custom exceptions
    app.register_error_handler(APIError, handle_api_error)
    app.register_error_handler(ValidationError, handle_api_error)
    app.register_error_handler(AuthenticationError, handle_api_error)
    app.register_error_handler(AuthorizationError, handle_api_error)
    app.register_error_handler(ResourceNotFoundError, handle_api_error)
    app.register_error_handler(ResourceExistsError, handle_api_error)
    app.register_error_handler(RateLimitError, handle_api_error)
    app.register_error_handler(ServiceError, handle_api_error)
    app.register_error_handler(ConfigurationError, handle_api_error)
    app.register_error_handler(DependencyError, handle_api_error)
    app.register_error_handler(UserExistsError, handle_api_error)
    app.register_error_handler(UserNotFoundError, handle_api_error)
    app.register_error_handler(TokenError, handle_api_error)
    app.register_error_handler(EmailError, handle_api_error)
    
    # Standard HTTP errors
    app.register_error_handler(400, handle_bad_request)
    app.register_error_handler(401, handle_unauthorized)
    app.register_error_handler(403, handle_forbidden)
    app.register_error_handler(404, handle_not_found)
    app.register_error_handler(405, handle_method_not_allowed)
    app.register_error_handler(422, handle_unprocessable_entity)
    app.register_error_handler(429, handle_rate_limit_exceeded)
    app.register_error_handler(500, handle_server_error)
    
    # Catch-all for any other exceptions
    app.register_error_handler(Exception, handle_exception)
    
    logger.info("Registered error handlers")

def handle_api_error(error):
    """
    Handler for API errors.
    
    Args:
        error: APIError instance
        
    Returns:
        JSON response with error details
    """
    response = jsonify(error.to_dict())
    response.status_code = error.status_code
    
    # Add request ID header if available
    if hasattr(error, 'request_id') and error.request_id:
        response.headers['X-Request-ID'] = error.request_id
    
    # Log the error
    if error.status_code >= 500:
        logger.error(f"API Error: {error.message}", extra={'status_code': error.status_code})
    else:
        logger.info(f"API Error: {error.message}", extra={'status_code': error.status_code})
    
    return response

def handle_bad_request(error):
    """
    Handler for 400 Bad Request errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = APIError("Bad request", status_code=400)
    return handle_api_error(api_error)

def handle_unauthorized(error):
    """
    Handler for 401 Unauthorized errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = AuthenticationError("Authentication required")
    return handle_api_error(api_error)

def handle_forbidden(error):
    """
    Handler for 403 Forbidden errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = AuthorizationError("Access forbidden")
    return handle_api_error(api_error)

def handle_not_found(error):
    """
    Handler for 404 Not Found errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = ResourceNotFoundError("Resource not found")
    return handle_api_error(api_error)

def handle_method_not_allowed(error):
    """
    Handler for 405 Method Not Allowed errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = APIError("Method not allowed", status_code=405)
    return handle_api_error(api_error)

def handle_unprocessable_entity(error):
    """
    Handler for 422 Unprocessable Entity errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    # Extract validation errors from WTForms if available
    details = {}
    if hasattr(error, 'data') and 'errors' in error.data:
        details = {'fields': error.data['errors']}
    
    api_error = ValidationError("Validation error", details=details)
    return handle_api_error(api_error)

def handle_rate_limit_exceeded(error):
    """
    Handler for 429 Too Many Requests errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = RateLimitError("Rate limit exceeded")
    return handle_api_error(api_error)

def handle_server_error(error):
    """
    Handler for 500 Internal Server Error errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    # Log the full stack trace
    logger.error(f"Server error: {str(error)}", exc_info=True)
    
    # Create a more detailed error in development
    is_development = current_app.config.get('ENV') == 'development'
    
    details = None
    if is_development:
        details = {
            'traceback': traceback.format_exc(),
            'error_type': error.__class__.__name__
        }
    
    api_error = ServiceError("Internal server error", details=details)
    return handle_api_error(api_error)

def handle_exception(error):
    """
    Catch-all handler for uncaught exceptions.
    
    Args:
        error: Exception instance
        
    Returns:
        JSON response with error details
    """
    # Log the full stack trace
    logger.error(f"Uncaught exception: {str(error)}", exc_info=True)
    
    # Create a more detailed error in development
    is_development = current_app.config.get('ENV') == 'development'
    
    details = None
    if is_development:
        details = {
            'traceback': traceback.format_exc(),
            'error_type': error.__class__.__name__
        }
    
    message = str(error) if is_development else "An unexpected error occurred"
    
    api_error = ServiceError(message, details=details)
    return handle_api_error(api_error) 
```


### FILE: backend\flask-service\src\core\health.py
```
"""
Health check module for service health monitoring and diagnostics.
Provides comprehensive health checks for all service dependencies.
"""

import logging
import time
import os
import socket
import platform
import psutil
from datetime import datetime
from flask import Blueprint, jsonify, current_app

from .config import get_config

logger = logging.getLogger(__name__)

# Create health blueprint
health_bp = Blueprint('health', __name__)

@health_bp.route('/health', methods=['GET'])
def health_check():
    """
    Comprehensive health check endpoint for the service.
    Checks database, Redis, auth service, and system resources.
    """
    start_time = time.time()
    health_data = {
        "service": "Meeting API Service",
        "timestamp": datetime.utcnow().isoformat(),
        "uptime": _get_uptime(),
        "status": "checking",
        "checks": {},
        "system": _get_system_info()
    }
    
    # Perform all health checks
    try:
        # Check database
        db_status = _check_database()
        health_data["checks"]["database"] = db_status
        
        # Check Redis
        redis_status = _check_redis()
        health_data["checks"]["redis"] = redis_status
        
        # Check Auth Service connection
        auth_status = _check_auth_service()
        health_data["checks"]["auth_service"] = auth_status
        
        # Determine overall status (healthy only if all checks pass)
        critical_services = [db_status, redis_status]
        if all(service.get('status') == 'healthy' for service in critical_services):
            health_data["status"] = "healthy"
        else:
            health_data["status"] = "unhealthy"
            
    except Exception as e:
        logger.error(f"Error performing health check: {str(e)}")
        health_data["status"] = "error"
        health_data["error"] = str(e)
    
    # Add response time
    health_data["response_time_ms"] = round((time.time() - start_time) * 1000, 2)
    
    # Determine response status code
    status_code = 200 if health_data["status"] == "healthy" else 503
    
    return jsonify(health_data), status_code


def _check_database():
    """
    Check database connectivity and health
    """
    from flask_sqlalchemy import SQLAlchemy
    
    try:
        start_time = time.time()
        db = SQLAlchemy(current_app)
        
        # Execute a simple query to verify connection
        result = db.session.execute("SELECT 1").fetchone()
        response_time = round((time.time() - start_time) * 1000, 2)
        
        if result and result[0] == 1:
            return {
                "status": "healthy",
                "response_time_ms": response_time,
                "details": {
                    "connection_string": _mask_connection_string(current_app.config.get('SQLALCHEMY_DATABASE_URI', 'unknown'))
                }
            }
        else:
            return {
                "status": "unhealthy",
                "response_time_ms": response_time,
                "error": "Database query did not return expected result"
            }
    except Exception as e:
        logger.error(f"Database health check failed: {str(e)}")
        return {
            "status": "unhealthy",
            "error": str(e)
        }


def _check_redis():
    """
    Check Redis connectivity and health
    """
    from redis import Redis
    
    try:
        start_time = time.time()
        redis_url = current_app.config.get('REDIS_URL')
        redis_client = Redis.from_url(redis_url)
        
        # Ping Redis to verify connection
        if redis_client.ping():
            # Get Redis info
            info = redis_client.info()
            response_time = round((time.time() - start_time) * 1000, 2)
            
            return {
                "status": "healthy",
                "response_time_ms": response_time,
                "details": {
                    "redis_version": info.get('redis_version', 'unknown'),
                    "connected_clients": info.get('connected_clients', 'unknown'),
                    "used_memory_human": info.get('used_memory_human', 'unknown')
                }
            }
        else:
            return {
                "status": "unhealthy",
                "error": "Redis ping failed"
            }
    except Exception as e:
        logger.error(f"Redis health check failed: {str(e)}")
        return {
            "status": "unhealthy",
            "error": str(e)
        }


def _check_auth_service():
    """
    Check Auth Service connectivity
    """
    import requests
    
    try:
        start_time = time.time()
        auth_url = current_app.config.get('AUTH_SERVICE_URL')
        health_url = f"{auth_url}/health"
        
        # Set a short timeout for the request
        timeout = current_app.config.get('HEALTH_TIMEOUT', 3)
        
        # Make request to auth service health endpoint
        response = requests.get(health_url, timeout=timeout)
        response_time = round((time.time() - start_time) * 1000, 2)
        
        if response.status_code == 200:
            try:
                auth_data = response.json()
                return {
                    "status": "healthy",
                    "response_time_ms": response_time,
                    "details": {
                        "auth_service_status": auth_data.get('status', 'unknown'),
                        "auth_service_version": auth_data.get('version', 'unknown')
                    }
                }
            except:
                return {
                    "status": "degraded",
                    "response_time_ms": response_time,
                    "error": "Invalid JSON response from auth service"
                }
        else:
            return {
                "status": "unhealthy",
                "response_time_ms": response_time,
                "error": f"Auth service returned status code {response.status_code}"
            }
    except requests.Timeout:
        return {
            "status": "unhealthy",
            "error": "Auth service connection timeout"
        }
    except requests.ConnectionError:
        return {
            "status": "unhealthy",
            "error": "Could not connect to auth service"
        }
    except Exception as e:
        logger.error(f"Auth service health check failed: {str(e)}")
        return {
            "status": "unhealthy",
            "error": str(e)
        }


def _get_system_info():
    """
    Get system information for diagnostics
    """
    try:
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        return {
            "hostname": socket.gethostname(),
            "platform": platform.platform(),
            "python_version": platform.python_version(),
            "cpu_count": os.cpu_count(),
            "memory": {
                "total_gb": round(memory.total / (1024**3), 2),
                "available_gb": round(memory.available / (1024**3), 2),
                "used_percent": memory.percent
            },
            "disk": {
                "total_gb": round(disk.total / (1024**3), 2),
                "free_gb": round(disk.free / (1024**3), 2),
                "used_percent": disk.percent
            },
            "load_avg": _get_load_avg()
        }
    except Exception as e:
        logger.error(f"Error getting system info: {str(e)}")
        return {"error": "Could not retrieve system information"}


def _get_load_avg():
    """
    Get system load average, with Windows compatibility
    """
    try:
        if hasattr(os, 'getloadavg'):
            # Unix systems
            load1, load5, load15 = os.getloadavg()
            return {"1min": round(load1, 2), "5min": round(load5, 2), "15min": round(load15, 2)}
        else:
            # Windows systems
            return {"cpu_percent": psutil.cpu_percent(interval=0.1)}
    except:
        return {"error": "Could not retrieve load average"}


def _get_uptime():
    """
    Get service uptime
    """
    try:
        # Get process start time
        p = psutil.Process(os.getpid())
        start_time = datetime.fromtimestamp(p.create_time())
        uptime = datetime.now() - start_time
        
        # Format uptime as days, hours, minutes, seconds
        days, remainder = divmod(uptime.total_seconds(), 86400)
        hours, remainder = divmod(remainder, 3600)
        minutes, seconds = divmod(remainder, 60)
        
        return {
            "days": int(days),
            "hours": int(hours),
            "minutes": int(minutes),
            "seconds": int(seconds),
            "total_seconds": int(uptime.total_seconds())
        }
    except Exception as e:
        logger.error(f"Error getting uptime: {str(e)}")
        return {"error": "Could not determine uptime"}


def _mask_connection_string(conn_string):
    """
    Mask sensitive information in database connection string
    """
    if not conn_string or '://' not in conn_string:
        return 'invalid-connection-string'
    
    try:
        # Split connection string into parts
        protocol_part, rest = conn_string.split('://')
        
        # Mask username and password if present
        if '@' in rest:
            auth_part, host_part = rest.split('@')
            
            # Replace password with asterisks if present
            if ':' in auth_part:
                username, password = auth_part.split(':')
                masked_auth = f"{username}:***"
            else:
                masked_auth = auth_part
                
            return f"{protocol_part}://{masked_auth}@{host_part}"
        else:
            # No auth part
            return conn_string
    except:
        # If parsing fails, return a generic masked string
        return f"{conn_string.split('://')[0]}://***" 
```


### FILE: backend\flask-service\src\models\__init__.py
```
from .. import db
from .user import User
from .meeting import Meeting
from .meeting_participant import MeetingParticipant
from .meeting_co_host import MeetingCoHost
from .meeting_audit_log import MeetingAuditLog

__all__ = ['db', 'User', 'Meeting', 'MeetingParticipant', 'MeetingCoHost', 'MeetingAuditLog'] 
```


### FILE: backend\flask-service\src\models\meeting.py
```
from datetime import datetime, UTC
from .. import db
from ..schemas.meeting import MeetingCreate, MeetingUpdate, MeetingResponse

class Meeting(db.Model):
    __tablename__ = 'meetings'
    
    id = db.Column(db.Integer, primary_key=True)
    title = db.Column(db.String(200), nullable=False)
    description = db.Column(db.Text)
    start_time = db.Column(db.DateTime, nullable=False)
    end_time = db.Column(db.DateTime, nullable=False)
    created_by = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=False)
    created_at = db.Column(db.DateTime, nullable=False, default=lambda: datetime.now(UTC))
    updated_at = db.Column(db.DateTime, nullable=False, default=lambda: datetime.now(UTC), onupdate=lambda: datetime.now(UTC))
    ended_at = db.Column(db.DateTime, nullable=True)
    
    # New fields
    meeting_type = db.Column(db.String(20), nullable=False, default='regular')  # regular, recurring, private
    max_participants = db.Column(db.Integer, nullable=True)
    requires_approval = db.Column(db.Boolean, nullable=False, default=False)
    is_recorded = db.Column(db.Boolean, nullable=False, default=False)
    recording_url = db.Column(db.String(500), nullable=True)
    recurring_pattern = db.Column(db.String(50), nullable=True)  # daily, weekly, monthly, custom
    parent_meeting_id = db.Column(db.Integer, db.ForeignKey('meetings.id'), nullable=True)  # For recurring meetings

    # Relationships
    creator = db.relationship('User', backref=db.backref('created_meetings', lazy=True))
    participants = db.relationship('MeetingParticipant', backref='meeting', lazy=True, cascade='all, delete-orphan')
    co_hosts = db.relationship('MeetingCoHost', backref='meeting', lazy=True, cascade='all, delete-orphan')
    child_meetings = db.relationship('Meeting', backref=db.backref('parent_meeting', remote_side=[id]))

    def __init__(self, title, description, start_time, end_time, created_by, meeting_type='regular', 
                 max_participants=None, requires_approval=False, is_recorded=False):
        self.title = title
        self.description = description
        self.start_time = start_time
        self.end_time = end_time
        self.created_by = created_by
        self.meeting_type = meeting_type
        self.max_participants = max_participants
        self.requires_approval = requires_approval
        self.is_recorded = is_recorded

    def to_dict(self):
        return {
            'id': self.id,
            'title': self.title,
            'description': self.description,
            'start_time': self.start_time.isoformat(),
            'end_time': self.end_time.isoformat(),
            'created_by': self.created_by,
            'created_at': self.created_at.isoformat(),
            'updated_at': self.updated_at.isoformat(),
            'ended_at': self.ended_at.isoformat() if self.ended_at else None,
            'meeting_type': self.meeting_type,
            'max_participants': self.max_participants,
            'requires_approval': self.requires_approval,
            'is_recorded': self.is_recorded,
            'recording_url': self.recording_url,
            'recurring_pattern': self.recurring_pattern,
            'parent_meeting_id': self.parent_meeting_id
        }

    @classmethod
    def from_schema(cls, meeting_create: MeetingCreate, created_by: int):
        """Create a new meeting from a MeetingCreate schema"""
        return cls(
            title=meeting_create.title,
            description=meeting_create.description,
            start_time=meeting_create.start_time,
            end_time=meeting_create.end_time,
            created_by=created_by,
            meeting_type=meeting_create.meeting_type,
            max_participants=meeting_create.max_participants,
            requires_approval=meeting_create.requires_approval,
            is_recorded=meeting_create.is_recorded,
            recurring_pattern=meeting_create.recurring_pattern,
            parent_meeting_id=meeting_create.parent_meeting_id
        )

    def update_from_schema(self, meeting_update: MeetingUpdate):
        """Update meeting from a MeetingUpdate schema"""
        for field, value in meeting_update.model_dump(exclude_unset=True).items():
            setattr(self, field, value)

    def to_schema(self) -> MeetingResponse:
        """Convert meeting model to MeetingResponse schema"""
        response_data = {
            'id': self.id,
            'title': self.title,
            'description': self.description,
            'start_time': self.start_time,
            'end_time': self.end_time,
            'created_by': self.created_by,
            'created_at': self.created_at,
            'updated_at': self.updated_at,
            'ended_at': self.ended_at,
            'meeting_type': self.meeting_type,
            'max_participants': self.max_participants,
            'requires_approval': self.requires_approval,
            'is_recorded': self.is_recorded,
            'recording_url': self.recording_url,
            'recurring_pattern': self.recurring_pattern,
            'parent_meeting_id': self.parent_meeting_id,
            'participant_count': len(self.participants),
            'co_hosts': [co_host.user_id for co_host in self.co_hosts]
        }
        return MeetingResponse.model_validate(response_data) 
```


### FILE: backend\flask-service\src\models\meeting_audit_log.py
```
from datetime import datetime, UTC
from .. import db

class MeetingAuditLog(db.Model):
    __tablename__ = 'meeting_audit_logs'
    
    id = db.Column(db.Integer, primary_key=True)
    meeting_id = db.Column(db.Integer, db.ForeignKey('meetings.id'), nullable=False)
    user_id = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=False)
    action = db.Column(db.String(50), nullable=False)  # created, joined, left, ended, etc.
    details = db.Column(db.JSON, nullable=True)
    created_at = db.Column(db.DateTime, nullable=False, default=lambda: datetime.now(UTC))
    
    # Relationships
    meeting = db.relationship('Meeting', backref=db.backref('audit_logs', lazy=True))
    user = db.relationship('User', backref=db.backref('meeting_actions', lazy=True))
    
    def __init__(self, meeting_id, user_id, action, details=None):
        self.meeting_id = meeting_id
        self.user_id = user_id
        self.action = action
        self.details = details
        
    def to_dict(self):
        return {
            'id': self.id,
            'meeting_id': self.meeting_id,
            'user_id': self.user_id,
            'action': self.action,
            'details': self.details,
            'created_at': self.created_at.isoformat()
        } 
```


### FILE: backend\flask-service\src\models\meeting_co_host.py
```
from datetime import datetime, UTC
from .. import db

class MeetingCoHost(db.Model):
    __tablename__ = 'meeting_co_hosts'
    
    id = db.Column(db.Integer, primary_key=True)
    meeting_id = db.Column(db.Integer, db.ForeignKey('meetings.id'), nullable=False)
    user_id = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=False)
    created_at = db.Column(db.DateTime, nullable=False, default=lambda: datetime.now(UTC))
    updated_at = db.Column(db.DateTime, nullable=False, default=lambda: datetime.now(UTC), onupdate=lambda: datetime.now(UTC))
    
    # Relationships
    user = db.relationship('User', backref=db.backref('co_hosted_meetings', lazy=True))
    
    def __init__(self, meeting_id, user_id):
        self.meeting_id = meeting_id
        self.user_id = user_id
        
    def to_dict(self):
        return {
            'id': self.id,
            'meeting_id': self.meeting_id,
            'user_id': self.user_id,
            'created_at': self.created_at.isoformat(),
            'updated_at': self.updated_at.isoformat()
        } 
```


### FILE: backend\flask-service\src\models\meeting_participant.py
```
from datetime import datetime, UTC
from .. import db
from ..schemas.participant import ParticipantCreate, ParticipantUpdate, ParticipantResponse

class MeetingParticipant(db.Model):
    __tablename__ = 'meeting_participants'
    
    id = db.Column(db.Integer, primary_key=True)
    meeting_id = db.Column(db.Integer, db.ForeignKey('meetings.id'), nullable=False)
    user_id = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=False)
    status = db.Column(db.String(20), nullable=False, default='pending')  # pending, approved, declined, banned
    role = db.Column(db.String(20), nullable=False, default='attendee')  # attendee, presenter, moderator
    joined_at = db.Column(db.DateTime, nullable=True)
    left_at = db.Column(db.DateTime, nullable=True)
    is_banned = db.Column(db.Boolean, nullable=False, default=False)
    created_at = db.Column(db.DateTime, nullable=False, default=lambda: datetime.now(UTC))
    updated_at = db.Column(db.DateTime, nullable=False, default=lambda: datetime.now(UTC), onupdate=lambda: datetime.now(UTC))
    
    # Additional fields for participation tracking
    total_time = db.Column(db.Integer, nullable=True)  # Total time spent in meeting in seconds
    connection_quality = db.Column(db.Float, nullable=True)  # Average connection quality
    participation_score = db.Column(db.Float, nullable=True)  # Engagement score
    feedback = db.Column(db.Text, nullable=True)  # Participant feedback
    
    # Relationships
    user = db.relationship('User', backref=db.backref('meeting_participations', lazy=True))
    
    @classmethod
    def from_schema(cls, participant_create: ParticipantCreate):
        """Create a new participant from a ParticipantCreate schema"""
        return cls(
            meeting_id=participant_create.meeting_id,
            user_id=participant_create.user_id,
            status=participant_create.status,
            role=participant_create.role
        )

    def update_from_schema(self, participant_update: ParticipantUpdate):
        """Update participant from a ParticipantUpdate schema"""
        for field, value in participant_update.model_dump(exclude_unset=True).items():
            setattr(self, field, value)

    def to_schema(self) -> ParticipantResponse:
        """Convert participant model to ParticipantResponse schema"""
        response_data = {
            'id': self.id,
            'meeting_id': self.meeting_id,
            'user_id': self.user_id,
            'status': self.status,
            'role': self.role,
            'joined_at': self.joined_at,
            'left_at': self.left_at,
            'is_banned': self.is_banned,
            'created_at': self.created_at,
            'updated_at': self.updated_at,
            'total_time': self.total_time,
            'connection_quality': self.connection_quality,
            'participation_score': self.participation_score,
            'feedback': self.feedback,
            'user_name': self.user.name if self.user else None,
            'user_email': self.user.email if self.user else None
        }
        return ParticipantResponse.model_validate(response_data)

    def record_join(self, connection_quality: float = None):
        """Record participant joining the meeting"""
        self.joined_at = datetime.now(UTC)
        self.connection_quality = connection_quality
        db.session.commit()

    def record_leave(self, total_time: int, participation_score: float, feedback: str = None):
        """Record participant leaving the meeting"""
        self.left_at = datetime.now(UTC)
        self.total_time = total_time
        self.participation_score = participation_score
        self.feedback = feedback
        db.session.commit()

    def __init__(self, meeting_id, user_id, status='pending', role='attendee'):
        self.meeting_id = meeting_id
        self.user_id = user_id
        self.status = status
        self.role = role
        
    def to_dict(self):
        return {
            'id': self.id,
            'meeting_id': self.meeting_id,
            'user_id': self.user_id,
            'status': self.status,
            'role': self.role,
            'joined_at': self.joined_at.isoformat() if self.joined_at else None,
            'left_at': self.left_at.isoformat() if self.left_at else None,
            'is_banned': self.is_banned,
            'created_at': self.created_at.isoformat(),
            'updated_at': self.updated_at.isoformat(),
            'total_time': self.total_time,
            'connection_quality': self.connection_quality,
            'participation_score': self.participation_score,
            'feedback': self.feedback
        } 
```


### FILE: backend\flask-service\src\models\user.py
```
from datetime import datetime, UTC
from .. import db

class User(db.Model):
    """Simplified user model that mirrors essential user data from auth service"""
    __tablename__ = 'users'

    id = db.Column(db.Integer, primary_key=True)
    email = db.Column(db.String(120), unique=True, nullable=False, index=True)
    name = db.Column(db.String(100), nullable=False)
    is_active = db.Column(db.Boolean, nullable=False, default=True)
    is_email_verified = db.Column(db.Boolean, nullable=False, default=False)
    last_login_at = db.Column(db.DateTime, nullable=True)
    created_at = db.Column(db.DateTime, nullable=False, default=lambda: datetime.now(UTC))
    updated_at = db.Column(db.DateTime, nullable=False, default=lambda: datetime.now(UTC), onupdate=lambda: datetime.now(UTC))

    # Relationships
    hosted_meetings = db.relationship('Meeting', back_populates='host')

    def to_dict(self):
        return {
            'id': self.id,
            'email': self.email,
            'name': self.name,
            'is_active': self.is_active,
            'is_email_verified': self.is_email_verified,
            'last_login_at': self.last_login_at.isoformat() if self.last_login_at else None,
            'created_at': self.created_at.isoformat(),
            'updated_at': self.updated_at.isoformat()
        } 
```


### FILE: backend\flask-service\src\routes\__init__.py
```
from .auth import auth_bp
from .meetings import meetings_bp 
```


### FILE: backend\flask-service\src\routes\auth.py
```
from flask import Blueprint, request, jsonify
from werkzeug.security import generate_password_hash
import jwt
import datetime
from datetime import UTC
import os
import re
from sqlalchemy.exc import IntegrityError

from ..models import db, User

auth_bp = Blueprint('auth', __name__)

def validate_email(email):
    if not email or len(email) > 120:
        return False
    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    return re.match(pattern, email) is not None

def validate_password(password):
    if not password or len(password) > 72:  # bcrypt max length is 72 bytes
        return False
    # At least 8 chars, 1 uppercase, 1 lowercase, 1 number, 1 special char
    if len(password) < 8:
        return False
    if not re.search(r'[A-Z]', password):
        return False
    if not re.search(r'[a-z]', password):
        return False
    if not re.search(r'[0-9]', password):
        return False
    if not re.search(r'[!@#$%^&*(),.?":{}|<>]', password):
        return False
    return True

def validate_name(name):
    if not name or len(name) > 100:
        return False
    # Allow letters, numbers, spaces, dots, and hyphens
    return bool(re.match(r'^[a-zA-Z0-9\s.-]{3,100}$', name))

def get_failed_login_attempts(email):
    # You should implement rate limiting using Redis or similar
    # This is a placeholder
    return 0

def is_ip_blocked(ip):
    # You should implement IP blocking using Redis or similar
    # This is a placeholder
    return False

@auth_bp.route('/register', methods=['POST'])
def register():
    try:
        # Check IP blocking first
        if is_ip_blocked(request.remote_addr):
            return jsonify({'error': 'Too many requests', 'code': 'ip_blocked'}), 429

        data = request.get_json()
        
        if not data:
            return jsonify({'error': 'No data provided'}), 400
            
        if not all(k in data for k in ['email', 'name', 'password']):
            return jsonify({'error': 'Missing required fields'}), 400
            
        # Sanitize inputs
        email = data['email'].strip().lower()
        name = data['name'].strip()
        password = data['password']
            
        # Enhanced validations
        if not validate_email(email):
            return jsonify({
                'error': 'Invalid email format or length',
                'requirements': 'Valid email format and maximum 120 characters'
            }), 400
            
        if not validate_password(password):
            return jsonify({
                'error': 'Password does not meet requirements',
                'requirements': 'At least 8 characters, 1 uppercase, 1 lowercase, 1 number, 1 special character'
            }), 400
            
        if not validate_name(name):
            return jsonify({
                'error': 'Invalid name format or length',
                'requirements': 'Between 3-100 characters, letters, numbers, spaces, dots, and hyphens only'
            }), 400
            
        # Check for existing user with case-insensitive email
        if User.query.filter(User.email.ilike(email)).first():
            return jsonify({'error': 'Email already registered'}), 400
            
        # Check for existing user with case-insensitive name
        if User.query.filter(User.name.ilike(name)).first():
            return jsonify({'error': 'Name already taken'}), 400
        
        user = User(
            email=email,
            name=name,
            password=password
        )
        
        try:
            db.session.add(user)
            db.session.commit()
        except IntegrityError:
            db.session.rollback()
            return jsonify({'error': 'Database constraint violation'}), 400
        
        # Generate JWT token with limited expiry
        token_expiry = int(os.getenv('JWT_EXPIRY_DAYS', '1'))
        token = jwt.encode({
            'user_id': user.id,
            'email': user.email,
            'exp': datetime.datetime.now(UTC) + datetime.timedelta(days=token_expiry),
            'iat': datetime.datetime.now(UTC),
            'type': 'access'
        }, os.getenv('JWT_SECRET_KEY'), algorithm='HS256')
        
        return jsonify({
            'message': 'User registered successfully',
            'token': token,
            'user': user.to_dict()
        }), 201
        
    except Exception as e:
        db.session.rollback()
        return jsonify({'error': 'Server error occurred during registration'}), 500

@auth_bp.route('/login', methods=['POST'])
def login():
    try:
        # Check IP blocking first
        if is_ip_blocked(request.remote_addr):
            return jsonify({'error': 'Too many requests', 'code': 'ip_blocked'}), 429

        data = request.get_json()
        
        if not data:
            return jsonify({'error': 'No data provided'}), 400
        
        if not all(k in data for k in ['email', 'password']):
            return jsonify({'error': 'Missing required fields'}), 400
        
        email = data['email'].strip().lower()
        
        # Check failed login attempts
        attempts = get_failed_login_attempts(email)
        if attempts >= 5:  # Lock after 5 failed attempts
            return jsonify({
                'error': 'Account temporarily locked',
                'code': 'account_locked',
                'retry_after': '15 minutes'
            }), 429
        
        user = User.query.filter(User.email.ilike(email)).first()
        
        if not user or not user.check_password(data['password']):
            # Increment failed attempts counter (implement in Redis)
            return jsonify({
                'error': 'Invalid credentials',
                'remaining_attempts': 5 - (attempts + 1)
            }), 401
        
        # Reset failed attempts counter on successful login
        
        # Generate JWT token with all necessary claims
        token_expiry = int(os.getenv('JWT_EXPIRY_DAYS', '1'))
        token = jwt.encode({
            'user_id': user.id,
            'email': user.email,
            'exp': datetime.datetime.now(UTC) + datetime.timedelta(days=token_expiry),
            'iat': datetime.datetime.now(UTC),
            'type': 'access'
        }, os.getenv('JWT_SECRET_KEY'), algorithm='HS256')
        
        return jsonify({
            'token': token,
            'user': user.to_dict()
        }), 200
        
    except Exception as e:
        return jsonify({'error': 'Server error occurred during login'}), 500

@auth_bp.route('/verify-token', methods=['POST'])
def verify_token():
    try:
        token = request.headers.get('Authorization')
        
        if not token or not token.startswith('Bearer '):
            return jsonify({'error': 'Invalid token format', 'code': 'invalid_token_format'}), 401
            
        token = token.split('Bearer ')[1]
        
        try:
            data = jwt.decode(token, os.getenv('JWT_SECRET_KEY'), algorithms=['HS256'])
            user = User.query.get(data['user_id'])
            
            if not user:
                return jsonify({'error': 'User not found', 'code': 'user_not_found'}), 401
                
            return jsonify({
                'valid': True,
                'user': user.to_dict()
            })
            
        except jwt.ExpiredSignatureError:
            return jsonify({'error': 'Token has expired', 'code': 'token_expired'}), 401
        except jwt.InvalidTokenError:
            return jsonify({'error': 'Invalid token', 'code': 'token_invalid'}), 401
            
    except Exception as e:
        return jsonify({'error': 'Server error occurred during token verification', 'code': 'verification_error'}), 500 
```


### FILE: backend\flask-service\src\routes\auth_integration.py
```
from flask import Blueprint, request, jsonify, current_app
from functools import wraps
from ..utils.auth_integration import AuthIntegration
from shared.middleware.auth import service_auth_required
from shared.middleware.validation import validate_schema
from shared.schemas.base import ErrorResponse, SuccessResponse
from shared.database import transaction_context
import logging

logger = logging.getLogger(__name__)
bp = Blueprint('auth_integration', __name__)

def require_service_key(f):
    @wraps(f)
    def decorated(*args, **kwargs):
        service_key = request.headers.get('X-Service-Key')
        if not service_key or service_key != current_app.config['AUTH_SERVICE_KEY']:
            return jsonify({'error': 'Invalid service key'}), 403
        return f(*args, **kwargs)
    return decorated

@bp.route('/auth/validate-token', methods=['POST'])
@service_auth_required
def validate_token():
    """Validate JWT token"""
    try:
        data = request.get_json()
        token = data.get('token')
        if not token:
            return jsonify(ErrorResponse(
                error="Validation Error",
                message="Token is required"
            ).model_dump()), 400

        auth_integration = AuthIntegration()
        payload = auth_integration.validate_token(token)
        
        if payload:
            return jsonify(SuccessResponse(data=payload).model_dump())
        return jsonify(ErrorResponse(
            error="Authentication Error",
            message="Invalid token"
        ).model_dump()), 401
    except Exception as e:
        logger.error(f"Error validating token: {str(e)}")
        return jsonify(ErrorResponse(
            error="Internal Server Error",
            message="Failed to validate token"
        ).model_dump()), 500

@bp.route('/auth/sync-session', methods=['POST'])
@service_auth_required
def sync_session():
    """Synchronize session data from auth service"""
    try:
        data = request.get_json()
        auth_integration = AuthIntegration()
        
        with transaction_context() as session:
            if auth_integration.sync_user_session(data):
                return jsonify(SuccessResponse(
                    message="Session synchronized successfully"
                ).model_dump())
            
            return jsonify(ErrorResponse(
                error="Sync Error",
                message="Failed to sync session"
            ).model_dump()), 400
            
    except Exception as e:
        logger.error(f"Error syncing session: {str(e)}")
        return jsonify(ErrorResponse(
            error="Internal Server Error",
            message="Failed to process sync request"
        ).model_dump()), 500

@bp.route('/auth/sync-user', methods=['POST'])
@service_auth_required
def sync_user():
    """Synchronize user data from auth service"""
    try:
        data = request.get_json()
        auth_integration = AuthIntegration()
        
        with transaction_context() as session:
            if auth_integration.sync_user_data(data):
                return jsonify(SuccessResponse(
                    message="User data synchronized successfully"
                ).model_dump())
            return jsonify(ErrorResponse(
                error="Sync Error",
                message="Failed to sync user data"
            ).model_dump()), 400
    except Exception as e:
        logger.error(f"Error syncing user data: {str(e)}")
        return jsonify(ErrorResponse(
            error="Internal Server Error",
            message="Failed to sync user data"
        ).model_dump()), 500

@bp.route('/auth/revoke-user-sessions', methods=['POST'])
@service_auth_required
def revoke_sessions():
    """Handle session revocation from auth service"""
    try:
        data = request.get_json()
        user_id = data.get('user_id')
        reason = data.get('reason')
        
        if not user_id:
            return jsonify(ErrorResponse(
                error="Validation Error",
                message="User ID is required"
            ).model_dump()), 400

        auth_integration = AuthIntegration()
        with transaction_context() as session:
            if auth_integration.revoke_user_sessions(user_id, reason):
                return jsonify(SuccessResponse(
                    message="User sessions revoked successfully"
                ).model_dump())
            return jsonify(ErrorResponse(
                error="Revocation Error",
                message="Failed to revoke sessions"
            ).model_dump()), 400
    except Exception as e:
        logger.error(f"Error revoking sessions: {str(e)}")
        return jsonify(ErrorResponse(
            error="Internal Server Error",
            message="Failed to revoke sessions"
        ).model_dump()), 500 
```


### FILE: backend\flask-service\src\routes\health.py
```
from flask import Blueprint, jsonify, current_app
import requests
import time
import os
import sys
from datetime import datetime, timezone
import logging
import platform
from sqlalchemy import text
from sqlalchemy.exc import SQLAlchemyError

# Handle import based on whether we're using the application db or directly importing
try:
    from ..database import db
except ImportError:
    try:
        from shared.database import db
    except ImportError:
        db = None
        logging.error("Failed to import database module")

logger = logging.getLogger(__name__)
health_bp = Blueprint('health', __name__)

@health_bp.route('/health', methods=['GET'])
def health_check():
    """Basic health check endpoint that provides essential system information"""
    health_info = {
        'status': 'healthy',
        'service': 'backend',
        'timestamp': datetime.now(timezone.utc).isoformat(),
        'environment': os.environ.get('FLASK_ENV', 'unknown'),
        'system_info': {
            'python_version': sys.version,
            'platform': platform.platform(),
            'node': platform.node()
        }
    }
    
    # Basic database check
    try:
        if db is not None:
            db.session.execute(text('SELECT 1'))
        else:
            health_info['status'] = 'degraded'
            health_info['message'] = 'Database module not available'
    except Exception as e:
        health_info['status'] = 'unhealthy'
        health_info['error'] = str(e)
    
    return jsonify(health_info)

@health_bp.route('/health/detailed', methods=['GET'])
def detailed_health_check():
    """Detailed health check that verifies all dependencies"""
    start_time = time.time()
    health_status = {
        'service': 'backend',
        'timestamp': datetime.now(timezone.utc).isoformat(),
        'dependencies': {},
        'status': 'healthy'  # Will be updated if any dependency is unhealthy
    }
    
    # Check database
    try:
        db.session.execute(text('SELECT 1'))
        health_status['dependencies']['database'] = {
            'status': 'healthy',
            'type': 'postgres'
        }
    except Exception as e:
        logger.error(f"Database health check failed: {str(e)}")
        health_status['dependencies']['database'] = {
            'status': 'unhealthy',
            'error': str(e),
            'type': 'postgres'
        }
        health_status['status'] = 'unhealthy'
    
    # Check Redis
    try:
        redis_client = current_app.extensions.get('redis')
        if redis_client:
            redis_client.ping()
            health_status['dependencies']['redis'] = {
                'status': 'healthy'
            }
        else:
            health_status['dependencies']['redis'] = {
                'status': 'unavailable',
                'error': 'Redis client not initialized'
            }
            health_status['status'] = 'degraded'
    except Exception as e:
        logger.error(f"Redis health check failed: {str(e)}")
        health_status['dependencies']['redis'] = {
            'status': 'unhealthy',
            'error': str(e)
        }
        health_status['status'] = 'unhealthy'
    
    # Check auth service
    try:
        auth_service_url = current_app.config.get('AUTH_SERVICE_URL')
        response = requests.get(
            f"{auth_service_url}/health", 
            timeout=5
        )
        if response.status_code == 200:
            health_status['dependencies']['auth_service'] = {
                'status': 'healthy',
                'url': auth_service_url
            }
        else:
            health_status['dependencies']['auth_service'] = {
                'status': 'unhealthy',
                'error': f"Unexpected status code: {response.status_code}",
                'url': auth_service_url
            }
            health_status['status'] = 'unhealthy'
    except requests.RequestException as e:
        logger.error(f"Auth service health check failed: {str(e)}")
        health_status['dependencies']['auth_service'] = {
            'status': 'unhealthy',
            'error': str(e),
            'url': current_app.config.get('AUTH_SERVICE_URL')
        }
        health_status['status'] = 'unhealthy'
    
    # Check token validation
    try:
        # Try a basic token validation with a dummy token (should fail but connection should work)
        auth_service_url = current_app.config.get('AUTH_SERVICE_URL')
        service_key = current_app.config.get('SERVICE_KEY')
        
        response = requests.post(
            f"{auth_service_url}/api/auth/validate-token",
            json={"token": "dummy_test_token"},
            headers={"X-Service-Key": service_key},
            timeout=5
        )
        
        if response.status_code in [401, 400]:  # Expected for invalid token
            health_status['dependencies']['token_validation'] = {
                'status': 'healthy',
                'message': 'Token validation endpoint accessible'
            }
        else:
            health_status['dependencies']['token_validation'] = {
                'status': 'degraded',
                'error': f"Unexpected status code: {response.status_code}",
                'message': 'Token validation endpoint is accessible but not working as expected'
            }
            if health_status['status'] == 'healthy':
                health_status['status'] = 'degraded'
    except requests.RequestException as e:
        logger.error(f"Token validation health check failed: {str(e)}")
        health_status['dependencies']['token_validation'] = {
            'status': 'unhealthy',
            'error': str(e)
        }
        health_status['status'] = 'unhealthy'
    
    # Add response time
    health_status['response_time_ms'] = round((time.time() - start_time) * 1000, 2)
    
    # Return appropriate status code based on health
    status_code = 200
    if health_status['status'] == 'degraded':
        status_code = 200  # Still operational but with issues
    elif health_status['status'] == 'unhealthy':
        status_code = 503  # Service unavailable
        
    return jsonify(health_status), status_code 
```


### FILE: backend\flask-service\src\routes\meetings.py
```
from flask import Blueprint, request, jsonify, current_app
from sqlalchemy.exc import SQLAlchemyError
from datetime import datetime, timezone, UTC
import bleach
import json
import time
from shared.middleware.auth import token_required
from shared.middleware.error_handler import error_handler, APIError
from shared.middleware.validation import validate_schema
from shared.schemas.base import ErrorResponse, SuccessResponse
from ..schemas.meeting import MeetingCreate, MeetingResponse, MeetingUpdate
from ..models import db, User, Meeting, MeetingParticipant, MeetingCoHost, MeetingAuditLog
from ..utils.auth_integration import enhanced_token_required

meetings_bp = Blueprint('meetings', __name__)

def get_cache_client():
    """Get Redis client from app extensions"""
    return current_app.extensions.get('redis')

def get_cached_meetings(cache_key):
    """Get meetings from cache if available"""
    redis_client = get_cache_client()
    if not redis_client:
        return None
        
    cached = redis_client.get(cache_key)
    if cached:
        try:
            return json.loads(cached)
        except Exception as e:
            current_app.logger.error(f"Error parsing cached meetings: {e}")
    return None

def cache_meetings(cache_key, meetings, expiry=300):
    """Cache meetings in Redis"""
    redis_client = get_cache_client()
    if not redis_client:
        return
        
    try:
        redis_client.setex(cache_key, expiry, json.dumps(meetings))
    except Exception as e:
        current_app.logger.error(f"Error caching meetings: {e}")

@meetings_bp.route('/create', methods=['POST'])
@enhanced_token_required
@error_handler
def create_meeting(current_user):
    """Create a new meeting."""
    data = request.get_json()
    
    if not data:
        raise APIError('No data provided', 400)
        
    required_fields = ['title', 'description', 'start_time', 'end_time']
    if not all(field in data for field in required_fields):
        raise APIError('Missing required fields', 400, 
                       {'required': required_fields})
        
    # Validate title and description
    title = bleach.clean(data['title'].strip())
    description = bleach.clean(data['description'].strip())
    
    if not title:
        raise APIError('Meeting title cannot be empty', 400)
        
    if len(title) > 200:
        raise APIError('Meeting title too long (max 200 characters)', 400)
        
    if len(description) > 2000:
        raise APIError('Meeting description too long (max 2000 characters)', 400)

    try:
        start_time = datetime.fromisoformat(data['start_time'].replace('Z', '+00:00'))
        end_time = datetime.fromisoformat(data['end_time'].replace('Z', '+00:00'))
        
        if not start_time.tzinfo or not end_time.tzinfo:
            raise APIError('Timezone information is required', 400)
            
    except ValueError:
        raise APIError('Invalid datetime format. Please use ISO format', 400)

    current_time = datetime.now(UTC)
    
    # Enhanced time validations
    if start_time < current_time:
        raise APIError('Meeting cannot start in the past', 400)
        
    if start_time >= end_time:
        raise APIError('Start time must be before end time', 400)
        
    # Validate reasonable time ranges
    duration = end_time - start_time
    if duration.total_seconds() < 300:  # 5 minutes minimum
        raise APIError('Meeting must be at least 5 minutes long', 400)
        
    if duration.total_seconds() > 86400:  # 24 hours maximum
        raise APIError('Meeting cannot be longer than 24 hours', 400)
        
    # Check if start time is too far in the future
    if (start_time - current_time).days > 365:
        raise APIError('Cannot schedule meetings more than 1 year in advance', 400)
        
    # Validate meeting type and settings
    meeting_type = data.get('meeting_type', 'regular')
    if meeting_type not in ['regular', 'recurring', 'private']:
        raise APIError('Invalid meeting type', 400, {'valid_types': ['regular', 'recurring', 'private']})
        
    max_participants = data.get('max_participants')
    if max_participants is not None:
        if not isinstance(max_participants, int) or max_participants <= 0:
            raise APIError('Invalid maximum participants value', 400)
            
    requires_approval = data.get('requires_approval', False)
    is_recorded = data.get('is_recorded', False)
    
    # Handle recurring meeting pattern
    recurring_pattern = None
    if meeting_type == 'recurring':
        recurring_pattern = data.get('recurring_pattern')
        if not recurring_pattern or recurring_pattern not in ['daily', 'weekly', 'monthly', 'custom']:
            raise APIError('Invalid recurring pattern for recurring meeting', 400, 
                           {'valid_patterns': ['daily', 'weekly', 'monthly', 'custom']})
    
    # Check for overlapping meetings for the user
    user_meetings = Meeting.query.filter(
        Meeting.created_by == current_user.id,
        Meeting.ended_at.is_(None),
        Meeting.end_time > start_time,
        Meeting.start_time < end_time
    ).first()
    
    if user_meetings:
        raise APIError('You have another meeting scheduled during this time', 400)
        
    # Check total number of active meetings for user
    active_meetings_count = Meeting.query.filter(
        Meeting.created_by == current_user.id,
        Meeting.ended_at.is_(None)
    ).count()
    
    if active_meetings_count >= 50:
        raise APIError('You have reached the maximum limit of active meetings', 400)
    
    # Create the meeting
    meeting = Meeting(
        title=title,
        description=description,
        start_time=start_time,
        end_time=end_time,
        created_by=current_user.id,
        meeting_type=meeting_type,
        max_participants=max_participants,
        requires_approval=requires_approval,
        is_recorded=is_recorded
    )
    
    if recurring_pattern:
        meeting.recurring_pattern = recurring_pattern
        
    db.session.add(meeting)
    
    # Add co-hosts if specified
    co_host_ids = data.get('co_hosts', [])
    for co_host_id in co_host_ids:
        if co_host_id != current_user.id:
            co_host = MeetingCoHost(meeting_id=meeting.id, user_id=co_host_id)
            db.session.add(co_host)
            
    # Log the creation
    audit_log = MeetingAuditLog(
        meeting_id=meeting.id,
        user_id=current_user.id,
        action='created',
        details={
            'meeting_type': meeting_type,
            'requires_approval': requires_approval,
            'is_recorded': is_recorded,
            'recurring_pattern': recurring_pattern
        }
    )
    db.session.add(audit_log)
    
    # Invalidate cache for this user's meetings
    redis_client = get_cache_client()
    if redis_client:
        cache_key = f"meetings:user:{current_user.id}"
        redis_client.delete(cache_key)
    
    db.session.commit()
    
    response = MeetingResponse.from_orm(meeting)
    return jsonify(response.model_dump()), 201

@meetings_bp.route('/join/<int:id>', methods=['GET'])
@enhanced_token_required
def join_meeting(current_user, id):
    try:
        if id <= 0:
            return jsonify({'error': 'Invalid meeting ID'}), 400
            
        meeting = Meeting.query.get(id)
        
        if not meeting:
            return jsonify({'error': 'Meeting not found'}), 404
            
        # Check if meeting has ended
        if meeting.ended_at:
            return jsonify({'error': 'Meeting has already ended'}), 400

        # Check if meeting hasn't started yet
        current_time = datetime.now(UTC)
        if current_time < meeting.start_time:
            time_until_start = (meeting.start_time - current_time).total_seconds()
            if time_until_start > 300:  # More than 5 minutes before start
                return jsonify({
                    'error': 'Meeting has not started yet',
                    'starts_in_minutes': round(time_until_start / 60)
                }), 400

        # Check if meeting has exceeded its end time
        if current_time > meeting.end_time:
            return jsonify({'error': 'Meeting has exceeded its scheduled end time'}), 400

        # Check maximum participants limit
        current_participants = MeetingParticipant.query.filter_by(
            meeting_id=meeting.id,
            left_at=None
        ).count()
        if meeting.max_participants and current_participants >= meeting.max_participants:
            return jsonify({'error': 'Meeting has reached maximum participants'}), 400

        # Check if user is banned
        participant = MeetingParticipant.query.filter_by(
            meeting_id=meeting.id,
            user_id=current_user.id
        ).first()
        
        if participant and participant.is_banned:
            return jsonify({'error': 'You have been banned from this meeting'}), 403

        # Check concurrent meetings
        active_participation = MeetingParticipant.query.join(Meeting).filter(
            MeetingParticipant.user_id == current_user.id,
            Meeting.ended_at.is_(None),
            Meeting.id != meeting.id,
            MeetingParticipant.left_at.is_(None)
        ).first()
        
        if active_participation:
            return jsonify({'error': 'You are already in another active meeting'}), 400

        # Determine participant role
        participant_role = 'attendee'
        if meeting.created_by == current_user.id:
            participant_role = 'host'
        elif MeetingCoHost.query.filter_by(meeting_id=meeting.id, user_id=current_user.id).first():
            participant_role = 'co-host'

        # Handle participant joining
        if meeting.created_by != current_user.id:
            if not participant:
                participant = MeetingParticipant(
                    meeting_id=meeting.id,
                    user_id=current_user.id,
                    status='pending' if meeting.requires_approval else 'approved',
                    role=participant_role,
                    joined_at=current_time if not meeting.requires_approval else None
                )
                db.session.add(participant)
            else:
                # Update rejoin time if they previously left
                participant.joined_at = current_time if not meeting.requires_approval else None
                participant.left_at = None
                participant.role = participant_role
                
            db.session.commit()

            # If waiting room is enabled
            if meeting.requires_approval and participant.status == 'pending':
                return jsonify({
                    'message': 'Waiting for host approval',
                    'status': 'waiting'
                }), 202

        # Log the join attempt
        audit_log = MeetingAuditLog(
            meeting_id=meeting.id,
            user_id=current_user.id,
            action='joined',
            details={
                'role': participant_role,
                'status': participant.status if participant else 'host'
            }
        )
        db.session.add(audit_log)
        db.session.commit()

        # Return meeting details with participant info
        meeting_dict = meeting.to_dict()
        meeting_dict.update({
            'is_creator': meeting.created_by == current_user.id,
            'is_co_host': participant_role == 'co-host',
            'role': participant_role,
            'participant_count': current_participants,
            'time_remaining_minutes': round((meeting.end_time - current_time).total_seconds() / 60)
        })
        return jsonify(meeting_dict), 200
        
    except Exception as e:
        db.session.rollback()
        return jsonify({'error': 'Server error occurred while joining meeting'}), 500

@meetings_bp.route('/list', methods=['GET'])
@enhanced_token_required
@error_handler
def list_meetings(current_user):
    """Get list of meetings for the current user with caching."""
    # Get query parameters for filtering
    active_only = request.args.get('active_only', type=lambda v: v.lower() == 'true', default=True)
    force_refresh = request.args.get('refresh', type=lambda v: v.lower() == 'true', default=False)
    
    # Generate cache key based on user and filters
    cache_key = f"meetings:user:{current_user.id}:active:{active_only}"
    
    # Try to get from cache if not forcing refresh
    if not force_refresh:
        cached_meetings = get_cached_meetings(cache_key)
        if cached_meetings is not None:
            return jsonify(cached_meetings)
    
    # Track performance
    start_time = time.time()
    
    # First, get meetings where user is creator
    creator_meetings = Meeting.query.filter(Meeting.created_by == current_user.id)
    if active_only:
        creator_meetings = creator_meetings.filter(Meeting.ended_at.is_(None))
    creator_meetings = creator_meetings.all()

    # Then, get meetings where user is participant
    participant_meetings = Meeting.query.join(MeetingParticipant).filter(
        MeetingParticipant.user_id == current_user.id
    )
    if active_only:
        participant_meetings = participant_meetings.filter(Meeting.ended_at.is_(None))
    participant_meetings = participant_meetings.all()

    # Combine and sort meetings
    all_meetings = sorted(
        set(creator_meetings + participant_meetings),
        key=lambda m: m.start_time,
        reverse=True
    )
    
    # Convert to response format
    response_meetings = [MeetingResponse.from_orm(meeting).model_dump() for meeting in all_meetings]
    
    # Calculate query time for optimization metrics
    query_time = time.time() - start_time
    
    # Cache the results (only if query is slow enough to warrant caching)
    if query_time > 0.1:  # Only cache if query takes more than 100ms
        cache_meetings(cache_key, response_meetings)
    
    # Log performance metrics
    current_app.logger.debug(f"Meeting list query took {query_time:.3f}s for user {current_user.id}")
    
    return jsonify(response_meetings)

@meetings_bp.route('/<int:id>', methods=['GET'])
@enhanced_token_required
@error_handler
def get_meeting(current_user, id):
    """Get a specific meeting by ID."""
    meeting = Meeting.query.get(id)
    
    if not meeting:
        raise APIError('Meeting not found', 404)
        
    # Check if user has access to the meeting
    if meeting.created_by != current_user.id and current_user.id not in [p.user_id for p in meeting.participants]:
        raise APIError('Access denied', 403)
        
    response = MeetingResponse.from_orm(meeting)
    return jsonify(response.model_dump())

@meetings_bp.route('/<int:id>', methods=['DELETE'])
@enhanced_token_required
@error_handler
def delete_meeting(current_user, id):
    """Delete/cancel a meeting."""
    meeting = Meeting.query.get(id)
    
    if not meeting:
        raise APIError('Meeting not found', 404)
        
    # Only the creator can delete a meeting
    if meeting.created_by != current_user.id:
        raise APIError('You do not have permission to delete this meeting', 403)
        
    # If meeting has started, mark as ended instead of deleting
    current_time = datetime.now(UTC)
    if meeting.start_time <= current_time:
        meeting.ended_at = current_time
        
        # Log early termination
        audit_log = MeetingAuditLog(
            meeting_id=meeting.id,
            user_id=current_user.id,
            action='ended_early',
            details={"ended_at": current_time.isoformat()}
        )
    else:
        # Log cancellation
        audit_log = MeetingAuditLog(
            meeting_id=meeting.id,
            user_id=current_user.id,
            action='cancelled',
            details={"cancelled_at": current_time.isoformat()}
        )
        
        # Mark as cancelled
        meeting.is_cancelled = True
        meeting.cancelled_at = current_time
        
    db.session.add(audit_log)
    
    # Invalidate cache for this user's meetings and other participants
    redis_client = get_cache_client()
    if redis_client:
        # Invalidate creator's cache
        redis_client.delete(f"meetings:user:{meeting.created_by}")
        redis_client.delete(f"meetings:user:{meeting.created_by}:active:true")
        redis_client.delete(f"meetings:user:{meeting.created_by}:active:false")
        
        # Invalidate participant caches
        for participant in meeting.participants:
            redis_client.delete(f"meetings:user:{participant.user_id}")
            redis_client.delete(f"meetings:user:{participant.user_id}:active:true")
            redis_client.delete(f"meetings:user:{participant.user_id}:active:false")
    
    db.session.commit()
    
    return jsonify(SuccessResponse(
        message="Meeting cancelled successfully" if meeting.is_cancelled else "Meeting ended successfully"
    ).model_dump())

@meetings_bp.route('/stats', methods=['GET'])
@enhanced_token_required
@error_handler
def get_meeting_stats(current_user):
    """Get meeting statistics for the current user."""
    # Try to get from cache first
    cache_key = f"meeting_stats:user:{current_user.id}"
    cached_stats = get_cached_meetings(cache_key)
    if cached_stats is not None:
        return jsonify(cached_stats)
        
    # Calculate stats
    current_time = datetime.now(UTC)
    
    # Active meetings where user is creator
    active_hosted = Meeting.query.filter(
        Meeting.created_by == current_user.id,
        Meeting.ended_at.is_(None),
        Meeting.is_cancelled == False
    ).count()
    
    # Upcoming meetings where user is creator
    upcoming_hosted = Meeting.query.filter(
        Meeting.created_by == current_user.id,
        Meeting.start_time > current_time,
        Meeting.is_cancelled == False
    ).count()
    
    # Active meetings where user is participant
    active_participating = db.session.query(Meeting).join(MeetingParticipant).filter(
        MeetingParticipant.user_id == current_user.id,
        Meeting.ended_at.is_(None),
        Meeting.is_cancelled == False
    ).count()
    
    # Upcoming meetings where user is participant
    upcoming_participating = db.session.query(Meeting).join(MeetingParticipant).filter(
        MeetingParticipant.user_id == current_user.id,
        Meeting.start_time > current_time,
        Meeting.is_cancelled == False
    ).count()
    
    # All past meetings as host
    past_hosted = Meeting.query.filter(
        Meeting.created_by == current_user.id,
        Meeting.ended_at.isnot(None)
    ).count()
    
    # All past meetings as participant
    past_participating = db.session.query(Meeting).join(MeetingParticipant).filter(
        MeetingParticipant.user_id == current_user.id,
        Meeting.ended_at.isnot(None)
    ).count()
    
    # Calculate total meeting hours
    total_hours_query = db.session.query(
        db.func.sum(db.func.extract('epoch', Meeting.end_time - Meeting.start_time) / 3600)
    ).filter(
        Meeting.created_by == current_user.id,
        Meeting.ended_at.isnot(None)
    ).scalar()
    
    total_meeting_hours = round(float(total_hours_query or 0), 1)
    
    stats = {
        "active_hosted": active_hosted,
        "upcoming_hosted": upcoming_hosted,
        "active_participating": active_participating,
        "upcoming_participating": upcoming_participating,
        "past_hosted": past_hosted,
        "past_participating": past_participating,
        "total_meeting_hours": total_meeting_hours,
        "total_meetings": past_hosted + active_hosted
    }
    
    # Cache for 10 minutes
    cache_meetings(cache_key, stats, 600)
    
    return jsonify(stats) 
```


### FILE: backend\flask-service\src\schemas\audit_log.py
```
from datetime import datetime
from typing import Optional, Any, Literal
from pydantic import BaseModel, Field
from .base import BaseSchema

class AuditLogBase(BaseSchema):
    meeting_id: int
    user_id: Optional[int] = None
    action: Literal[
        'meeting_created',
        'meeting_updated',
        'meeting_started',
        'meeting_ended',
        'participant_joined',
        'participant_left',
        'participant_approved',
        'participant_declined',
        'participant_banned',
        'co_host_added',
        'co_host_removed',
        'recording_started',
        'recording_stopped',
        'chat_disabled',
        'chat_enabled',
        'screen_share_started',
        'screen_share_stopped'
    ]
    details: Optional[dict[str, Any]] = None
    ip_address: Optional[str] = Field(None, max_length=45)

class AuditLogCreate(BaseModel):
    meeting_id: int
    user_id: Optional[int] = None
    action: Literal[
        'meeting_created',
        'meeting_updated',
        'meeting_started',
        'meeting_ended',
        'participant_joined',
        'participant_left',
        'participant_approved',
        'participant_declined',
        'participant_banned',
        'co_host_added',
        'co_host_removed',
        'recording_started',
        'recording_stopped',
        'chat_disabled',
        'chat_enabled',
        'screen_share_started',
        'screen_share_stopped'
    ]
    details: Optional[dict[str, Any]] = None
    ip_address: Optional[str] = Field(None, max_length=45)

class AuditLogResponse(AuditLogBase):
    user_name: Optional[str] = None
    meeting_title: Optional[str] = None 
```


### FILE: backend\flask-service\src\schemas\base.py
```
"""
This module re-exports the shared schema base classes to maintain
backward compatibility with code that imports from here.
"""

from shared.schemas.base import BaseSchema as SharedBaseSchema
from shared.schemas.base import ErrorResponse, SuccessResponse

# For backward compatibility, provide a marshmallow-based BaseSchema
from marshmallow import Schema, fields, EXCLUDE

class BaseSchema(Schema):
    """Base schema class with common configuration."""
    
    class Meta:
        unknown = EXCLUDE
        ordered = True

    id = fields.Integer(dump_only=True)
    created_at = fields.DateTime(dump_only=True)
    updated_at = fields.DateTime(dump_only=True)

    def __init__(self, *args, **kwargs):
        """Initialize schema with strict validation by default."""
        kwargs['strict'] = kwargs.get('strict', True)
        super().__init__(*args, **kwargs) 
```


### FILE: backend\flask-service\src\schemas\co_host.py
```
from datetime import datetime
from typing import Optional, List
from pydantic import BaseModel
from .base import BaseSchema

class CoHostBase(BaseSchema):
    meeting_id: int
    user_id: int
    can_manage_participants: bool = True
    can_edit_meeting: bool = False
    can_end_meeting: bool = False

class CoHostCreate(BaseModel):
    meeting_id: int
    user_id: int
    can_manage_participants: bool = True
    can_edit_meeting: bool = False
    can_end_meeting: bool = False

class CoHostUpdate(BaseModel):
    can_manage_participants: Optional[bool] = None
    can_edit_meeting: Optional[bool] = None
    can_end_meeting: Optional[bool] = None

class CoHostResponse(CoHostBase):
    user_name: Optional[str] = None
    user_email: Optional[str] = None

class CoHostBulkCreate(BaseModel):
    meeting_id: int
    co_hosts: List[int]  # List of user IDs
    can_manage_participants: bool = True
    can_edit_meeting: bool = False
    can_end_meeting: bool = False 
```


### FILE: backend\flask-service\src\schemas\meeting.py
```
from datetime import datetime
from typing import Optional, List, Literal
from pydantic import BaseModel, Field, validator
from .base import BaseSchema

class MeetingBase(BaseSchema):
    title: str = Field(..., min_length=1, max_length=200)
    description: Optional[str] = None
    start_time: datetime
    end_time: datetime
    meeting_type: Literal['regular', 'recurring', 'private'] = 'regular'
    max_participants: Optional[int] = Field(None, gt=0)
    requires_approval: bool = False
    is_recorded: bool = False
    recording_url: Optional[str] = None
    recurring_pattern: Optional[Literal['daily', 'weekly', 'monthly', 'custom']] = None
    parent_meeting_id: Optional[int] = None
    ended_at: Optional[datetime] = None

    @validator('end_time')
    def end_time_must_be_after_start_time(cls, v, values):
        if 'start_time' in values and v <= values['start_time']:
            raise ValueError('end_time must be after start_time')
        return v

class MeetingCreate(BaseModel):
    title: str = Field(..., min_length=1, max_length=200)
    description: Optional[str] = None
    start_time: datetime
    end_time: datetime
    meeting_type: Literal['regular', 'recurring', 'private'] = 'regular'
    max_participants: Optional[int] = Field(None, gt=0)
    requires_approval: bool = False
    is_recorded: bool = False
    recurring_pattern: Optional[Literal['daily', 'weekly', 'monthly', 'custom']] = None
    parent_meeting_id: Optional[int] = None

    @validator('end_time')
    def end_time_must_be_after_start_time(cls, v, values):
        if 'start_time' in values and v <= values['start_time']:
            raise ValueError('end_time must be after start_time')
        return v

class MeetingUpdate(BaseModel):
    title: Optional[str] = Field(None, min_length=1, max_length=200)
    description: Optional[str] = None
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    max_participants: Optional[int] = Field(None, gt=0)
    requires_approval: Optional[bool] = None
    is_recorded: Optional[bool] = None
    recording_url: Optional[str] = None

    @validator('end_time')
    def end_time_must_be_after_start_time(cls, v, values):
        if v and 'start_time' in values and values['start_time'] and v <= values['start_time']:
            raise ValueError('end_time must be after start_time')
        return v

class MeetingResponse(MeetingBase):
    id: int
    created_by: int
    participant_count: Optional[int] = None
    co_hosts: Optional[List[int]] = None 
```


### FILE: backend\flask-service\src\schemas\participant.py
```
from datetime import datetime
from typing import Optional, Literal
from pydantic import BaseModel, Field, validator, confloat
from .base import BaseSchema

class ParticipantBase(BaseSchema):
    meeting_id: int
    user_id: int
    status: Literal['pending', 'approved', 'declined', 'banned'] = 'pending'
    role: Literal['attendee', 'presenter', 'moderator'] = 'attendee'
    joined_at: Optional[datetime] = None
    left_at: Optional[datetime] = None
    is_banned: bool = False
    total_time: Optional[int] = Field(None, ge=0)  # in seconds
    connection_quality: Optional[confloat(ge=0, le=1)] = None
    participation_score: Optional[confloat(ge=0, le=1)] = None
    feedback: Optional[str] = None

class ParticipantCreate(BaseModel):
    meeting_id: int
    user_id: int
    status: Literal['pending', 'approved', 'declined', 'banned'] = 'pending'
    role: Literal['attendee', 'presenter', 'moderator'] = 'attendee'

class ParticipantUpdate(BaseModel):
    status: Optional[Literal['pending', 'approved', 'declined', 'banned']] = None
    role: Optional[Literal['attendee', 'presenter', 'moderator']] = None
    is_banned: Optional[bool] = None
    feedback: Optional[str] = None

class ParticipantJoin(BaseModel):
    meeting_id: int
    user_id: int
    connection_quality: Optional[confloat(ge=0, le=1)] = None

    @validator('connection_quality')
    def validate_connection_quality(cls, v):
        if v is not None and (v < 0 or v > 1):
            raise ValueError('Connection quality must be between 0 and 1')
        return v

class ParticipantLeave(BaseModel):
    meeting_id: int
    user_id: int
    total_time: int = Field(..., ge=0)
    participation_score: confloat(ge=0, le=1)
    feedback: Optional[str] = None

class ParticipantResponse(ParticipantBase):
    user_name: Optional[str] = None
    user_email: Optional[str] = None 
```


### FILE: backend\flask-service\src\tasks\__init__.py
```
"""
Background tasks for the application.
This package contains modules for scheduled tasks like:
- Data cleanup
- System metrics collection
- Cache maintenance
""" 
```


### FILE: backend\flask-service\src\tasks\cleanup.py
```
import logging
from datetime import datetime, timedelta, timezone
from flask import current_app
from sqlalchemy import text
from ..database import db
from ..models.meeting import Meeting
from ..models.meeting_audit_log import MeetingAuditLog

logger = logging.getLogger(__name__)

def cleanup_expired_meetings():
    """
    Cleanup meetings that have ended but not marked as ended.
    Also cleans up stale meeting resources.
    """
    try:
        logger.info("Starting cleanup of expired meetings")
        start_time = datetime.now(timezone.utc)
        
        with current_app.app_context():
            # Find meetings that have passed their end time but not marked as ended
            current_time = datetime.now(timezone.utc)
            cutoff_time = current_time - timedelta(minutes=30)  # Give 30 minute grace period
            
            # Find meetings to mark as ended
            expired_meetings = Meeting.query.filter(
                Meeting.end_time < cutoff_time,
                Meeting.ended_at.is_(None),
                Meeting.is_cancelled == False
            ).all()
            
            if expired_meetings:
                logger.info(f"Found {len(expired_meetings)} expired meetings to cleanup")
                
                for meeting in expired_meetings:
                    meeting.ended_at = meeting.end_time  # Use the scheduled end time
                    
                    # Log the auto-end
                    audit_log = MeetingAuditLog(
                        meeting_id=meeting.id,
                        user_id=meeting.created_by,
                        action='auto_ended',
                        details={
                            'reason': 'Meeting ended automatically after scheduled end time',
                            'ended_at': meeting.end_time.isoformat(),
                            'cleanup_time': current_time.isoformat()
                        }
                    )
                    db.session.add(audit_log)
                
                db.session.commit()
                logger.info(f"Successfully marked {len(expired_meetings)} meetings as ended")
                
                # Invalidate caches for affected users
                redis_client = current_app.extensions.get('redis')
                if redis_client:
                    for meeting in expired_meetings:
                        redis_client.delete(f"meetings:user:{meeting.created_by}")
                        redis_client.delete(f"meetings:user:{meeting.created_by}:active:true")
                        redis_client.delete(f"meetings:user:{meeting.created_by}:active:false")
            else:
                logger.info("No expired meetings to cleanup")
            
            # Archive old meetings (older than 6 months)
            archive_cutoff = current_time - timedelta(days=180)
            meetings_to_archive = Meeting.query.filter(
                Meeting.ended_at < archive_cutoff,
                Meeting.is_archived == False
            ).all()
            
            if meetings_to_archive:
                logger.info(f"Found {len(meetings_to_archive)} old meetings to archive")
                
                for meeting in meetings_to_archive:
                    meeting.is_archived = True
                    meeting.archived_at = current_time
                    
                    # Log the archiving
                    audit_log = MeetingAuditLog(
                        meeting_id=meeting.id,
                        user_id=meeting.created_by,
                        action='archived',
                        details={
                            'reason': 'Meeting archived automatically after 6 months',
                            'archived_at': current_time.isoformat()
                        }
                    )
                    db.session.add(audit_log)
                
                db.session.commit()
                logger.info(f"Successfully archived {len(meetings_to_archive)} meetings")
            else:
                logger.info("No old meetings to archive")
            
            # Calculate duration for monitoring
            duration = (datetime.now(timezone.utc) - start_time).total_seconds()
            logger.info(f"Meeting cleanup completed in {duration:.2f} seconds")
            
            # Store metrics in Redis
            try:
                redis_client = current_app.extensions.get('redis')
                if redis_client:
                    metrics = {
                        'expired_meetings': len(expired_meetings),
                        'archived_meetings': len(meetings_to_archive),
                        'duration_seconds': duration,
                        'timestamp': current_time.isoformat()
                    }
                    redis_client.hmset('metrics:last_meeting_cleanup', metrics)
                    redis_client.expire('metrics:last_meeting_cleanup', 86400)  # 24 hours
            except Exception as e:
                logger.error(f"Failed to store cleanup metrics: {str(e)}")
                
            return {
                'expired_meetings': len(expired_meetings),
                'archived_meetings': len(meetings_to_archive),
                'duration_seconds': duration
            }
    
    except Exception as e:
        logger.error(f"Error during meeting cleanup: {str(e)}")
        if 'db' in locals() and db.session:
            db.session.rollback()
        return {'error': str(e)} 
```


### FILE: backend\flask-service\src\tasks\metrics.py
```
import logging
import json
import os
import platform
import time
from datetime import datetime, timezone
from sqlalchemy import text
from flask import current_app
from ..database import db
from ..models.meeting import Meeting

logger = logging.getLogger(__name__)

def update_system_metrics():
    """
    Collect and store system metrics for monitoring
    """
    try:
        logger.info("Starting metrics collection")
        start_time = time.time()
        
        with current_app.app_context():
            metrics = {}
            
            # DB metrics
            db_metrics = collect_database_metrics()
            if db_metrics:
                metrics.update(db_metrics)
            
            # Application metrics
            app_metrics = collect_application_metrics()
            if app_metrics:
                metrics.update(app_metrics)
            
            # System metrics
            sys_metrics = collect_system_metrics()
            if sys_metrics:
                metrics.update(sys_metrics)
            
            # Store metrics in Redis
            redis_client = current_app.extensions.get('redis')
            if redis_client:
                # Add timestamp
                metrics['timestamp'] = datetime.now(timezone.utc).isoformat()
                metrics['collection_duration_ms'] = int((time.time() - start_time) * 1000)
                
                # Store latest metrics
                for key, value in metrics.items():
                    redis_client.hset('metrics:system:latest', key, _serialize_value(value))
                
                # Set expiry for latest metrics
                redis_client.expire('metrics:system:latest', 86400)  # 24 hours
                
                # Store historical data points for time-series metrics
                store_time_series_metrics(redis_client, metrics)
                
                logger.info(f"Metrics collection completed in {(time.time() - start_time):.2f} seconds")
                return metrics
            else:
                logger.warning("Redis client not available, metrics not stored")
                return metrics
    
    except Exception as e:
        logger.error(f"Error during metrics collection: {str(e)}")
        return {'error': str(e)}

def _serialize_value(value):
    """Serialize value for Redis storage"""
    if isinstance(value, (dict, list)):
        return json.dumps(value)
    return str(value)

def collect_database_metrics():
    """Collect database metrics"""
    try:
        metrics = {}
        
        # Count active meetings
        active_meetings = Meeting.query.filter(
            Meeting.ended_at.is_(None),
            Meeting.is_cancelled == False
        ).count()
        metrics['active_meetings'] = active_meetings
        
        # Count total meetings
        total_meetings = Meeting.query.count()
        metrics['total_meetings'] = total_meetings
        
        # Count today's meetings
        today = datetime.now(timezone.utc).replace(hour=0, minute=0, second=0, microsecond=0)
        todays_meetings = Meeting.query.filter(
            Meeting.start_time >= today
        ).count()
        metrics['todays_meetings'] = todays_meetings
        
        # Get database size (PostgreSQL)
        try:
            db_name = current_app.config.get('SQLALCHEMY_DATABASE_URI').split('/')[-1]
            query = text("""
                SELECT pg_database_size(:db_name) as db_size
            """)
            result = db.session.execute(query, {'db_name': db_name}).first()
            if result:
                metrics['database_size_bytes'] = result.db_size
        except Exception as e:
            logger.warning(f"Could not get database size: {e}")
        
        # Get table statistics
        try:
            query = text("""
                SELECT 
                    relname as table_name,
                    n_live_tup as row_count
                FROM 
                    pg_stat_user_tables
                ORDER BY 
                    n_live_tup DESC
            """)
            results = db.session.execute(query).fetchall()
            table_stats = {r.table_name: r.row_count for r in results}
            metrics['table_row_counts'] = table_stats
        except Exception as e:
            logger.warning(f"Could not get table statistics: {e}")
        
        return metrics
    except Exception as e:
        logger.error(f"Error collecting database metrics: {e}")
        return {}

def collect_application_metrics():
    """Collect application metrics"""
    try:
        metrics = {}
        
        # Application version/build info
        metrics['app_version'] = os.environ.get('APP_VERSION', 'unknown')
        metrics['flask_env'] = current_app.config.get('FLASK_ENV', 'unknown')
        
        # Cache hit ratio if available
        redis_client = current_app.extensions.get('redis')
        if redis_client:
            try:
                # Get cache statistics from Redis INFO
                info = redis_client.info()
                metrics['redis_hit_ratio'] = (info['keyspace_hits'] / (info['keyspace_hits'] + info['keyspace_misses'] + 0.001)) * 100
                metrics['redis_used_memory'] = info['used_memory']
                metrics['redis_connected_clients'] = info['connected_clients']
            except Exception as e:
                logger.warning(f"Could not get Redis stats: {e}")
        
        return metrics
    except Exception as e:
        logger.error(f"Error collecting application metrics: {e}")
        return {}

def collect_system_metrics():
    """Collect system metrics"""
    try:
        metrics = {}
        
        # System information
        metrics['python_version'] = platform.python_version()
        metrics['os_name'] = platform.system()
        metrics['os_version'] = platform.version()
        
        # Process information
        metrics['process_id'] = os.getpid()
        
        # Memory usage
        try:
            import psutil
            process = psutil.Process(os.getpid())
            
            # Memory usage for this process
            memory_info = process.memory_info()
            metrics['process_memory_rss'] = memory_info.rss
            metrics['process_memory_vms'] = memory_info.vms
            
            # CPU usage
            metrics['process_cpu_percent'] = process.cpu_percent(interval=0.1)
            metrics['system_cpu_percent'] = psutil.cpu_percent(interval=0.1)
            
            # System memory
            system_memory = psutil.virtual_memory()
            metrics['system_memory_available'] = system_memory.available
            metrics['system_memory_total'] = system_memory.total
            metrics['system_memory_percent'] = system_memory.percent
            
            # Disk usage
            disk_usage = psutil.disk_usage('/')
            metrics['disk_usage_percent'] = disk_usage.percent
            metrics['disk_free'] = disk_usage.free
        except ImportError:
            logger.warning("psutil not available, skipping detailed system metrics")
        
        return metrics
    except Exception as e:
        logger.error(f"Error collecting system metrics: {e}")
        return {}

def store_time_series_metrics(redis_client, metrics):
    """Store time-series metrics for historical analysis"""
    try:
        timestamp = int(time.time())
        
        # Define which metrics to track historically
        time_series_metrics = [
            'active_meetings',
            'process_memory_rss',
            'system_cpu_percent',
            'system_memory_percent',
            'redis_hit_ratio'
        ]
        
        # For each metric, store a data point
        for metric_name in time_series_metrics:
            if metric_name in metrics:
                # Store as a sorted set with timestamp as score
                # This allows efficient time range queries
                redis_client.zadd(
                    f'metrics:timeseries:{metric_name}',
                    {f"{timestamp}:{metrics[metric_name]}": timestamp}
                )
                
                # Trim to last 1000 points to avoid unlimited growth
                redis_client.zremrangebyrank(
                    f'metrics:timeseries:{metric_name}',
                    0, -1001
                )
    except Exception as e:
        logger.error(f"Error storing time-series metrics: {e}") 
```


### FILE: backend\flask-service\src\utils\auth_integration.py
```
from typing import Optional, Dict, Any, Tuple
from flask import current_app, request, g
from shared.database import db, transaction_context
from shared.middleware.auth import jwt_required
from shared.schemas.base import ErrorResponse
from ..models.user import User
import jwt
import logging
import requests
import json
from datetime import datetime, timedelta
from functools import wraps

logger = logging.getLogger(__name__)

class AuthIntegration:
    def __init__(self):
        self.jwt_secret = current_app.config['JWT_SECRET_KEY']
        self.algorithm = 'HS256'
        self.auth_service_url = current_app.config.get('AUTH_SERVICE_URL', 'http://auth-service:5001')
        self.service_key = current_app.config.get('SERVICE_KEY')
        self.token_cache = {}  # Simple in-memory cache for token validation results
        self.token_cache_expiry = {}  # Expiry times for cache entries
        self.cache_ttl = 300  # 5 minutes cache TTL

    def validate_token(self, token: str) -> Optional[Dict[str, Any]]:
        """Validate JWT token and return payload if valid"""
        try:
            # Check cache first to avoid repeated decoding
            if token in self.token_cache:
                # Check if cache entry is still valid
                if datetime.now().timestamp() < self.token_cache_expiry.get(token, 0):
                    return self.token_cache[token]
                else:
                    # Remove expired entry
                    self.token_cache.pop(token, None)
                    self.token_cache_expiry.pop(token, None)
            
            # First try local validation
            try:
                payload = jwt.decode(token, self.jwt_secret, algorithms=[self.algorithm])
                
                # Check if the user exists in our database
                user = User.query.get(payload.get('user_id'))
                if not user:
                    logger.warning(f"User {payload.get('user_id')} not found in database during token validation")
                    return self._verify_with_auth_service(token)
                
                # Cache the successful result
                self.token_cache[token] = payload
                self.token_cache_expiry[token] = datetime.now().timestamp() + self.cache_ttl
                return payload
            except jwt.InvalidTokenError as e:
                # If local validation fails, verify with auth service
                logger.info(f"Local token validation failed: {str(e)}, trying auth service")
                return self._verify_with_auth_service(token)
        except Exception as e:
            logger.error(f"Token validation error: {str(e)}")
            return None

    def _verify_with_auth_service(self, token: str) -> Optional[Dict[str, Any]]:
        """Verify token with auth service"""
        try:
            headers = {'X-Service-Key': self.service_key}
            response = requests.post(
                f"{self.auth_service_url}/api/auth/validate-token",
                json={"token": token},
                headers=headers,
                timeout=5
            )
            
            if response.status_code == 200:
                payload = response.json().get('data', {})
                
                # Cache the successful result
                self.token_cache[token] = payload
                self.token_cache_expiry[token] = datetime.now().timestamp() + self.cache_ttl
                return payload
            else:
                logger.warning(f"Auth service rejected token: {response.status_code}, {response.text}")
                return None
        except requests.RequestException as e:
            logger.error(f"Error connecting to auth service: {str(e)}")
            # Fall back to local validation as a last resort
            try:
                return jwt.decode(token, self.jwt_secret, algorithms=[self.algorithm])
            except:
                return None

    def get_user_from_token(self, token: str) -> Tuple[Optional[User], Optional[str]]:
        """
        Get user from token and handle error messages
        Returns (user, error_message)
        """
        try:
            payload = self.validate_token(token)
            if not payload:
                return None, "Invalid or expired token"
            
            user_id = payload.get('user_id')
            if not user_id:
                return None, "Token missing user ID"
            
            user = User.query.get(user_id)
            if not user:
                return None, "User not found"
            
            if not user.is_active:
                return None, "Account is inactive"
            
            return user, None
        except Exception as e:
            logger.error(f"Error getting user from token: {str(e)}")
            return None, f"Authentication error: {str(e)}"

    def sync_user_session(self, data: Dict[str, Any]) -> bool:
        """
        Synchronize user session data from auth service
        """
        try:
            with transaction_context() as session:
                user_id = data.get('user_id')
                if not user_id:
                    return True  # Skip for cleanup notifications
                
                user = User.query.get(user_id)
                if not user:
                    logger.warning(f"User {user_id} not found during session sync")
                    return False

                # Update user's session state
                session_data = data.get('session_data', {})
                user.last_login_at = datetime.fromisoformat(session_data.get('expires_at')) if session_data.get('expires_at') else None
                user.is_active = session_data.get('is_active', True)
                
                # Clear any cached tokens for this user
                self._clear_user_token_cache(user_id)
                
                return True
                
        except Exception as e:
            logger.error(f"Error syncing user session: {str(e)}")
            return False
            
    def _clear_user_token_cache(self, user_id: int) -> None:
        """Clear cached tokens for a specific user"""
        try:
            # Find all tokens in cache that belong to this user
            tokens_to_remove = []
            for token, payload in self.token_cache.items():
                if payload.get('user_id') == user_id:
                    tokens_to_remove.append(token)
            
            # Remove tokens from cache
            for token in tokens_to_remove:
                self.token_cache.pop(token, None)
                self.token_cache_expiry.pop(token, None)
                
            logger.debug(f"Cleared {len(tokens_to_remove)} cached tokens for user {user_id}")
        except Exception as e:
            logger.error(f"Error clearing user token cache: {str(e)}")
            
    def cleanup_token_cache(self) -> int:
        """
        Clean up expired token cache entries
        Returns number of entries removed
        """
        try:
            now = datetime.now().timestamp()
            tokens_to_remove = [
                token for token, expiry in self.token_cache_expiry.items()
                if expiry < now
            ]
            
            for token in tokens_to_remove:
                self.token_cache.pop(token, None)
                self.token_cache_expiry.pop(token, None)
                
            return len(tokens_to_remove)
        except Exception as e:
            logger.error(f"Error cleaning up token cache: {str(e)}")
            return 0

def enhanced_token_required(f):
    """
    Enhanced decorator to require JWT token for route access
    Uses AuthIntegration for validation with caching and auth service fallback
    """
    @wraps(f)
    def decorated(*args, **kwargs):
        auth_header = request.headers.get('Authorization', '')
        
        if not auth_header or not auth_header.startswith('Bearer '):
            return ErrorResponse(
                error="Authentication Error",
                message="Missing or invalid Authorization header"
            ).to_response(401)
        
        token = auth_header.split(' ')[1]
        
        # Get auth integration instance
        auth_integration = AuthIntegration()
        
        # Try to get user from token
        user, error = auth_integration.get_user_from_token(token)
        if not user:
            return ErrorResponse(
                error="Authentication Error",
                message=error or "Invalid token"
            ).to_response(401)
        
        # Store in flask g object for route access
        g.current_user = user
        g.current_token = token
        
        return f(user, *args, **kwargs)
    
    return decorated

    def sync_user_data(self, data: Dict[str, Any]) -> bool:
        """
        Synchronize user data from auth service
        """
        try:
            with transaction_context() as session:
                user_id = data.get('id')
                if not user_id:
                    return False

                user = User.query.get(user_id)
                if not user:
                    # Create user if doesn't exist
                    user = User(
                        id=user_id,
                        email=data['email'],
                        name=f"{data.get('first_name', '')} {data.get('last_name', '')}".strip(),
                        is_active=data['is_active'],
                        is_email_verified=data['is_email_verified']
                    )
                    session.add(user)
                else:
                    # Update existing user
                    user.email = data['email']
                    user.name = f"{data.get('first_name', '')} {data.get('last_name', '')}".strip()
                    user.is_active = data['is_active']
                    user.is_email_verified = data['is_email_verified']

                return True
        except Exception as e:
            logger.error(f"Error syncing user data: {str(e)}")
            return False

    def revoke_user_sessions(self, user_id: int, reason: str = None) -> bool:
        """
        Handle session revocation from auth service
        """
        try:
            with transaction_context() as session:
                user = User.query.get(user_id)
                if user:
                    user.last_login_at = None
                return True
        except Exception as e:
            logger.error(f"Error revoking user sessions: {str(e)}")
            return False

    def get_current_user(self) -> Optional[User]:
        """Get current authenticated user"""
        try:
            token = request.headers.get('Authorization', '').split(' ')[1]
            payload = self.validate_token(token)
            if not payload:
                return None
                
            return User.query.get(payload.get('user_id'))
            
        except Exception as e:
            logger.error(f"Error getting current user: {str(e)}")
            return None 
```


### FILE: backend\flask-service\src\utils\data_seeder.py
```
from shared.utils.data_seeder import DataSeeder

# Re-export the shared DataSeeder
__all__ = ['DataSeeder'] 
```


### FILE: backend\flask-service\src\utils\database.py
```
from shared.database import transaction_context
from shared.utils.database import with_transaction, DatabaseManager
from shared.middleware.validation import validate_schema
from flask import current_app
from sqlalchemy.exc import SQLAlchemyError
import logging

logger = logging.getLogger(__name__)

# Re-export shared database utilities
__all__ = ['transaction_context', 'with_transaction', 'DatabaseManager']

# Initialize database manager
db_manager = None

def get_db_manager():
    """Get or create database manager instance"""
    global db_manager
    if db_manager is None:
        from shared.database import db
        db_manager = DatabaseManager(db)
    return db_manager

def safe_commit():
    """Safely commit database changes"""
    return get_db_manager().safe_commit()

def safe_add(obj, auto_commit=True):
    """Safely add an object to the database"""
    return get_db_manager().safe_add(obj, auto_commit)

def safe_delete(obj, auto_commit=True):
    """Safely delete an object from the database"""
    return get_db_manager().safe_delete(obj, auto_commit)

def safe_bulk_add(objects, auto_commit=True):
    """Safely add multiple objects to the database"""
    return get_db_manager().safe_bulk_add(objects, auto_commit)

def safe_bulk_delete(objects, auto_commit=True):
    """Safely delete multiple objects from the database"""
    return get_db_manager().safe_bulk_delete(objects, auto_commit) 
```


### FILE: backend\flask-service\src\utils\logger.py
```
import logging
import logging.handlers
import os
from typing import Optional
from pathlib import Path

def setup_logging(
    app_name: str,
    log_level: Optional[str] = None,
    log_format: Optional[str] = None,
    log_file: Optional[str] = None
) -> logging.Logger:
    """
    Configure logging for the application
    
    Args:
        app_name: Name of the application
        log_level: Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
        log_format: Log message format
        log_file: Path to log file
    """
    # Get configuration from environment or use defaults
    level = getattr(logging, (log_level or os.getenv('LOG_LEVEL', 'INFO')).upper())
    fmt = log_format or os.getenv('LOG_FORMAT', '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    log_path = log_file or os.getenv('LOG_FILE')

    # Create logger
    logger = logging.getLogger(app_name)
    logger.setLevel(level)

    # Create formatters and handlers
    formatter = logging.Formatter(fmt)
    
    # Console handler
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

    # File handler (if log path is specified)
    if log_path:
        # Ensure log directory exists
        log_dir = os.path.dirname(log_path)
        if log_dir:
            Path(log_dir).mkdir(parents=True, exist_ok=True)

        # Create rotating file handler
        file_handler = logging.handlers.RotatingFileHandler(
            log_path,
            maxBytes=10485760,  # 10MB
            backupCount=5
        )
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)

    # Prevent propagation to root logger
    logger.propagate = False

    logger.info(f"Logging configured for {app_name} at level {level}")
    return logger 
```


### FILE: backend\flask-service\src\utils\metrics.py
```
from prometheus_client import Counter, Histogram, Gauge, start_http_server
from functools import wraps
import time
from typing import Optional
from flask import request, Flask
import os
import threading
import logging

logger = logging.getLogger(__name__)

# Define metrics
http_requests_total = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

http_request_duration_seconds = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration in seconds',
    ['method', 'endpoint']
)

db_connections_current = Gauge(
    'db_connections_current',
    'Current number of database connections'
)

redis_connections_current = Gauge(
    'redis_connections_current',
    'Current number of Redis connections'
)

class MetricsManager:
    def __init__(self, app: Optional[Flask] = None):
        self.app = app
        if app is not None:
            self.init_app(app)

    def init_app(self, app: Flask):
        """Initialize metrics with Flask app"""
        self.app = app
        
        if os.getenv('ENABLE_METRICS', 'false').lower() == 'true':
            # Start metrics server in a separate thread
            metrics_port = int(os.getenv('METRICS_PORT', 9090))
            threading.Thread(
                target=start_http_server,
                args=(metrics_port,),
                daemon=True
            ).start()
            logger.info(f"Metrics server started on port {metrics_port}")

            # Register metrics middleware
            app.before_request(self._before_request)
            app.after_request(self._after_request)

    def _before_request(self):
        """Store start time for request duration calculation"""
        request._prometheus_metrics_start_time = time.time()

    def _after_request(self, response):
        """Record request duration and update metrics"""
        if hasattr(request, '_prometheus_metrics_start_time'):
            duration = time.time() - request._prometheus_metrics_start_time
            endpoint = request.endpoint or 'unknown'
            
            # Record request duration
            http_request_duration_seconds.labels(
                method=request.method,
                endpoint=endpoint
            ).observe(duration)
            
            # Count total requests
            http_requests_total.labels(
                method=request.method,
                endpoint=endpoint,
                status=response.status_code
            ).inc()
            
        return response

def track_db_connections(f):
    """Decorator to track database connections"""
    @wraps(f)
    def wrapped(*args, **kwargs):
        db_connections_current.inc()
        try:
            return f(*args, **kwargs)
        finally:
            db_connections_current.dec()
    return wrapped

def track_redis_connections(f):
    """Decorator to track Redis connections"""
    @wraps(f)
    def wrapped(*args, **kwargs):
        redis_connections_current.inc()
        try:
            return f(*args, **kwargs)
        finally:
            redis_connections_current.dec()
    return wrapped 
```


### FILE: backend\flask-service\src\utils\migrations_manager.py
```
import os
import sys
import logging
from flask import Flask
from flask_migrate import Migrate, upgrade, downgrade, current
from sqlalchemy import text
from sqlalchemy.exc import OperationalError
import time
from datetime import datetime
from shared.utils.migrations_manager import MigrationsManager as SharedMigrationsManager

logger = logging.getLogger(__name__)

class MigrationsManager(SharedMigrationsManager):
    def __init__(self, app: Flask, db, max_retries=5, retry_interval=5):
        self.app = app
        self.db = db
        self.migrate = Migrate(app, db)
        self.max_retries = max_retries
        self.retry_interval = retry_interval
        self.migration_history = []

    def wait_for_db(self):
        """Wait for database to be ready"""
        logger.info("Waiting for database...")
        for attempt in range(self.max_retries):
            try:
                with self.app.app_context():
                    self.db.session.execute(text('SELECT 1'))
                logger.info("Database is ready!")
                return True
            except OperationalError as e:
                if attempt == self.max_retries - 1:
                    logger.error(f"Database connection failed after {self.max_retries} attempts: {e}")
                    return False
                logger.warning(f"Database not ready (attempt {attempt + 1}/{self.max_retries}), waiting...")
                time.sleep(self.retry_interval)

    def backup_database(self):
        """Create a database backup before migrations"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_file = f"backup_{timestamp}.sql"
            backup_path = os.path.join(self.app.config['BACKUP_DIR'], backup_file)
            
            # Ensure backup directory exists
            os.makedirs(self.app.config['BACKUP_DIR'], exist_ok=True)
            
            # Create backup using pg_dump
            os.system(f"pg_dump {self.app.config['SQLALCHEMY_DATABASE_URI']} > {backup_path}")
            logger.info(f"Database backup created: {backup_file}")
            return backup_path
        except Exception as e:
            logger.error(f"Failed to create database backup: {e}")
            return None

    def restore_database(self, backup_path):
        """Restore database from backup"""
        try:
            os.system(f"psql {self.app.config['SQLALCHEMY_DATABASE_URI']} < {backup_path}")
            logger.info("Database restored from backup")
            return True
        except Exception as e:
            logger.error(f"Failed to restore database: {e}")
            return False

    def run_migrations(self):
        """Run database migrations with safety checks"""
        try:
            with self.app.app_context():
                # Get current migration version
                current_version = current(self.app)
                logger.info(f"Current migration version: {current_version}")

                # Create backup before migrations
                backup_path = self.backup_database()
                if not backup_path:
                    logger.error("Failed to create backup, aborting migrations")
                    return False

                # Run migrations
                logger.info("Starting database migrations...")
                upgrade()
                
                # Verify migrations
                if not self.verify_migrations():
                    logger.error("Migration verification failed, initiating rollback...")
                    if self.restore_database(backup_path):
                        logger.info("Successfully rolled back to previous state")
                    else:
                        logger.error("Failed to rollback, manual intervention required")
                    return False

                logger.info("Database migrations completed successfully!")
                return True
        except Exception as e:
            logger.error(f"Error running migrations: {e}")
            return False

    def verify_migrations(self):
        """Verify all migrations have been applied correctly"""
        try:
            with self.app.app_context():
                # Check if all tables exist
                for table in self.db.metadata.tables:
                    if not self.db.engine.dialect.has_table(self.db.engine, table):
                        logger.error(f"Table {table} does not exist!")
                        return False

                # Verify table constraints
                for table_name in self.db.metadata.tables:
                    result = self.db.session.execute(
                        text(f"SELECT conname FROM pg_constraint WHERE conrelid = '{table_name}'::regclass")
                    ).fetchall()
                    if not result:
                        logger.warning(f"No constraints found for table {table_name}")

                logger.info("All database tables and constraints verified!")
                return True
        except Exception as e:
            logger.error(f"Error verifying migrations: {e}")
            return False

    def check_migration_status(self):
        """Check and log migration status"""
        try:
            with self.app.app_context():
                current_version = current(self.app)
                logger.info(f"Current migration version: {current_version}")
                
                # Get all migration versions
                migrations_dir = os.path.join(os.path.dirname(self.app.root_path), 'migrations', 'versions')
                available_migrations = [f for f in os.listdir(migrations_dir) if f.endswith('.py')]
                
                logger.info(f"Available migrations: {len(available_migrations)}")
                return True
        except Exception as e:
            logger.error(f"Error checking migration status: {e}")
            return False

    def initialize_database(self):
        """Initialize database with migrations and verify integrity"""
        if not self.wait_for_db():
            logger.error("Could not connect to database")
            sys.exit(1)

        if not self.check_migration_status():
            logger.error("Failed to check migration status")
            sys.exit(1)

        if not self.run_migrations():
            logger.error("Failed to run migrations")
            sys.exit(1)

        logger.info("Database initialization completed successfully!")

# Re-export the shared MigrationsManager
__all__ = ['MigrationsManager'] 
```


### FILE: backend\flask-service\src\utils\responses.py
```
from flask import jsonify
from typing import Any, Dict, Optional, Tuple, Union

def api_response(
    data: Optional[Dict[str, Any]] = None,
    message: Optional[str] = None,
    error: Optional[str] = None,
    code: Optional[str] = None,
    status_code: int = 200
) -> Tuple[Dict[str, Any], int]:
    """
    Create a standardized API response.
    
    Args:
        data: Optional dictionary of response data
        message: Optional success message
        error: Optional error message
        code: Optional error code
        status_code: HTTP status code (default: 200)
    
    Returns:
        Tuple of (response_dict, status_code)
    """
    response = {}
    
    if data is not None:
        response.update(data)
    
    if message is not None:
        response['message'] = message
        
    if error is not None:
        response['error'] = error
        
    if code is not None:
        response['code'] = code
        
    return jsonify(response), status_code

def error_response(
    error: str,
    code: str,
    status_code: int = 400
) -> Tuple[Dict[str, Any], int]:
    """
    Create a standardized error response.
    
    Args:
        error: Error message
        code: Error code
        status_code: HTTP status code (default: 400)
    
    Returns:
        Tuple of (response_dict, status_code)
    """
    return api_response(error=error, code=code, status_code=status_code)

def success_response(
    data: Optional[Dict[str, Any]] = None,
    message: Optional[str] = None,
    status_code: int = 200
) -> Tuple[Dict[str, Any], int]:
    """
    Create a standardized success response.
    
    Args:
        data: Optional dictionary of response data
        message: Optional success message
        status_code: HTTP status code (default: 200)
    
    Returns:
        Tuple of (response_dict, status_code)
    """
    return api_response(data=data, message=message, status_code=status_code) 
```


### FILE: backend\flask-service\src\utils\socket_events.py
```
from flask_socketio import emit, join_room, leave_room
from functools import wraps
import jwt
import os

def socket_auth_required(f):
    @wraps(f)
    def decorated(data, *args, **kwargs):
        token = data.get('token')
        
        if not token:
            return emit('error', {'message': 'Token is missing'})
            
        try:
            token_data = jwt.decode(token, os.getenv('JWT_SECRET_KEY'), algorithms=['HS256'])
            data['user_id'] = token_data['user_id']
        except:
            return emit('error', {'message': 'Invalid token'})
            
        return f(data, *args, **kwargs)
        
    return decorated

def register_socket_events(socketio):
    @socketio.on('join')
    @socket_auth_required
    def handle_join(data):
        room = data.get('meeting_code')
        if room:
            join_room(room)
            emit('user_joined', {
                'user_id': data['user_id']
            }, room=room)

    @socketio.on('leave')
    @socket_auth_required
    def handle_leave(data):
        room = data.get('meeting_code')
        if room:
            leave_room(room)
            emit('user_left', {
                'user_id': data['user_id']
            }, room=room)

    @socketio.on('offer')
    @socket_auth_required
    def handle_offer(data):
        target_user = data.get('target_user')
        if target_user:
            emit('offer', {
                'sdp': data['sdp'],
                'user_id': data['user_id']
            }, room=target_user)

    @socketio.on('answer')
    @socket_auth_required
    def handle_answer(data):
        target_user = data.get('target_user')
        if target_user:
            emit('answer', {
                'sdp': data['sdp'],
                'user_id': data['user_id']
            }, room=target_user)

    @socketio.on('ice_candidate')
    @socket_auth_required
    def handle_ice_candidate(data):
        target_user = data.get('target_user')
        if target_user:
            emit('ice_candidate', {
                'candidate': data['candidate'],
                'user_id': data['user_id']
            }, room=target_user)

    @socketio.on('chat_message')
    @socket_auth_required
    def handle_chat_message(data):
        room = data.get('meeting_code')
        if room:
            emit('chat_message', {
                'user_id': data['user_id'],
                'message': data['message'],
                'timestamp': data['timestamp']
            }, room=room) 
```


### FILE: backend\node-service\.dockerignore
```
# Git
.git
.gitignore

# Node.js
node_modules/
npm-debug.log
yarn-debug.log
yarn-error.log
.npm/
.yarn/
*.tgz

# Docker
Dockerfile*
docker-compose*
.dockerignore

# IDE
.idea/
.vscode/
*.swp
*.swo

# Logs
logs/
*.log

# Data
data/ 
```


### FILE: backend\node-service\.env.example
```
# Server Configuration
PORT=3001
HOST=0.0.0.0
NODE_ENV=development

# CORS Configuration
CORS_ORIGINS=http://localhost:3000,http://localhost:8080

# Redis Configuration
REDIS_URL=redis://localhost:6379

# JWT Configuration
JWT_SECRET=your-secret-key-here
JWT_EXPIRES_IN=24h

# WebRTC Configuration
STUN_SERVERS=stun:stun.l.google.com:19302,stun:stun1.l.google.com:19302
TURN_SERVERS=turn:your-turn-server:3478
TURN_USERNAME=your-turn-username
TURN_CREDENTIAL=your-turn-password

# Metrics Configuration
ENABLE_METRICS=true

# Logging Configuration
LOG_LEVEL=info
LOG_FORMAT=json

# File Sharing Configuration
MAX_FILE_SIZE=10485760
ALLOWED_FILE_TYPES=image/*,application/pdf,application/msword,application/vnd.openxmlformats-officedocument.wordprocessingml.document,text/plain

# Room Configuration
MAX_ROOM_PARTICIPANTS=12
ROOM_TIMEOUT=1800000 
```


### FILE: backend\node-service\Dockerfile
```
FROM node:18-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    curl \
    jq \
    && rm -rf /var/lib/apt/lists/*

# Copy package files
COPY package*.json ./

# Install all dependencies from package.json
RUN npm install && \
    npm cache clean --force

# Create directories
RUN mkdir -p /app/logs /app/src

# Copy source code separately to avoid permission issues
COPY src/ /app/src/
COPY *.js /app/

# Create healthcheck script that tests Redis connection
RUN echo '#!/bin/sh\n\
\n\
# Test HTTP endpoint\n\
RESPONSE=$(curl -s http://localhost:3001/health)\n\
if [ $? -ne 0 ]; then\n\
  echo "Healthcheck failed: Could not connect to service"\n\
  exit 1\n\
fi\n\
\n\
# Extract status from response\n\
STATUS=$(echo $RESPONSE | jq -r .status 2>/dev/null)\n\
\n\
# Handle "degraded" status as healthy to allow container time to fully connect\n\
if [ "$STATUS" = "degraded" ]; then\n\
  echo "Service is degraded but operational..."\n\
  exit 0\n\
fi\n\
\n\
# Require "healthy" status for fully operational service\n\
if [ "$STATUS" != "healthy" ]; then\n\
  echo "Healthcheck failed: Service returned status $STATUS"\n\
  exit 1\n\
fi\n\
\n\
exit 0\n\
' > /healthcheck.sh && \
chmod +x /healthcheck.sh

# Set environment
ENV NODE_ENV=production
ENV PORT=3001

# Expose port
EXPOSE 3001

# Health check with more lenient parameters
HEALTHCHECK --interval=30s --timeout=30s --start-period=30s --retries=3 \
    CMD /healthcheck.sh

# Start the application with error handling
CMD ["node", "src/server.js"] 
```


### FILE: backend\node-service\package-lock.json
```
{
  "name": "meeting-app-websocket",
  "version": "1.0.0",
  "lockfileVersion": 3,
  "requires": true,
  "packages": {
    "": {
      "name": "meeting-app-websocket",
      "version": "1.0.0",
      "dependencies": {
        "compression": "^1.7.4",
        "cors": "^2.8.5",
        "dotenv": "^16.3.1",
        "express": "^4.18.2",
        "helmet": "^7.0.0",
        "ioredis": "^5.3.2",
        "jsonwebtoken": "^9.0.2",
        "morgan": "^1.10.0",
        "prom-client": "^14.2.0",
        "socket.io": "^4.7.2",
        "winston": "^3.10.0"
      },
      "devDependencies": {
        "jest": "^29.6.4",
        "nodemon": "^3.0.1"
      }
    },
    "node_modules/@ampproject/remapping": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/@ampproject/remapping/-/remapping-2.3.0.tgz",
      "integrity": "sha512-30iZtAPgz+LTIYoeivqYo853f02jBYSd5uGnGpkFV0M3xOt9aN73erkgYAmZU43x4VfqcnLxW9Kpg3R5LC4YYw==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@jridgewell/gen-mapping": "^0.3.5",
        "@jridgewell/trace-mapping": "^0.3.24"
      },
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@babel/code-frame": {
      "version": "7.26.2",
      "resolved": "https://registry.npmjs.org/@babel/code-frame/-/code-frame-7.26.2.tgz",
      "integrity": "sha512-RJlIHRueQgwWitWgF8OdFYGZX328Ax5BCemNGlqHfplnRT9ESi8JkFlvaVYbS+UubVY6dpv87Fs2u5M29iNFVQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-validator-identifier": "^7.25.9",
        "js-tokens": "^4.0.0",
        "picocolors": "^1.0.0"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/compat-data": {
      "version": "7.26.8",
      "resolved": "https://registry.npmjs.org/@babel/compat-data/-/compat-data-7.26.8.tgz",
      "integrity": "sha512-oH5UPLMWR3L2wEFLnFJ1TZXqHufiTKAiLfqw5zkhS4dKXLJ10yVztfil/twG8EDTA4F/tvVNw9nOl4ZMslB8rQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/core": {
      "version": "7.26.9",
      "resolved": "https://registry.npmjs.org/@babel/core/-/core-7.26.9.tgz",
      "integrity": "sha512-lWBYIrF7qK5+GjY5Uy+/hEgp8OJWOD/rpy74GplYRhEauvbHDeFB8t5hPOZxCZ0Oxf4Cc36tK51/l3ymJysrKw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@ampproject/remapping": "^2.2.0",
        "@babel/code-frame": "^7.26.2",
        "@babel/generator": "^7.26.9",
        "@babel/helper-compilation-targets": "^7.26.5",
        "@babel/helper-module-transforms": "^7.26.0",
        "@babel/helpers": "^7.26.9",
        "@babel/parser": "^7.26.9",
        "@babel/template": "^7.26.9",
        "@babel/traverse": "^7.26.9",
        "@babel/types": "^7.26.9",
        "convert-source-map": "^2.0.0",
        "debug": "^4.1.0",
        "gensync": "^1.0.0-beta.2",
        "json5": "^2.2.3",
        "semver": "^6.3.1"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/babel"
      }
    },
    "node_modules/@babel/core/node_modules/debug": {
      "version": "4.4.0",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.4.0.tgz",
      "integrity": "sha512-6WTZ/IxCY/T6BALoZHaE4ctp9xm+Z5kY/pzYaCHRFeyVhojxlrm+46y68HA6hr0TcwEssoxNiDEUJQjfPZ/RYA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/@babel/core/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@babel/generator": {
      "version": "7.26.9",
      "resolved": "https://registry.npmjs.org/@babel/generator/-/generator-7.26.9.tgz",
      "integrity": "sha512-kEWdzjOAUMW4hAyrzJ0ZaTOu9OmpyDIQicIh0zg0EEcEkYXZb2TjtBhnHi2ViX7PKwZqF4xwqfAm299/QMP3lg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/parser": "^7.26.9",
        "@babel/types": "^7.26.9",
        "@jridgewell/gen-mapping": "^0.3.5",
        "@jridgewell/trace-mapping": "^0.3.25",
        "jsesc": "^3.0.2"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-compilation-targets": {
      "version": "7.26.5",
      "resolved": "https://registry.npmjs.org/@babel/helper-compilation-targets/-/helper-compilation-targets-7.26.5.tgz",
      "integrity": "sha512-IXuyn5EkouFJscIDuFF5EsiSolseme1s0CZB+QxVugqJLYmKdxI1VfIBOst0SUu4rnk2Z7kqTwmoO1lp3HIfnA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/compat-data": "^7.26.5",
        "@babel/helper-validator-option": "^7.25.9",
        "browserslist": "^4.24.0",
        "lru-cache": "^5.1.1",
        "semver": "^6.3.1"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-module-imports": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/helper-module-imports/-/helper-module-imports-7.25.9.tgz",
      "integrity": "sha512-tnUA4RsrmflIM6W6RFTLFSXITtl0wKjgpnLgXyowocVPrbYrLUXSBXDgTs8BlbmIzIdlBySRQjINYs2BAkiLtw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/traverse": "^7.25.9",
        "@babel/types": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-module-transforms": {
      "version": "7.26.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-module-transforms/-/helper-module-transforms-7.26.0.tgz",
      "integrity": "sha512-xO+xu6B5K2czEnQye6BHA7DolFFmS3LB7stHZFaOLb1pAwO1HWLS8fXA+eh0A2yIvltPVmx3eNNDBJA2SLHXFw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-module-imports": "^7.25.9",
        "@babel/helper-validator-identifier": "^7.25.9",
        "@babel/traverse": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/@babel/helper-plugin-utils": {
      "version": "7.26.5",
      "resolved": "https://registry.npmjs.org/@babel/helper-plugin-utils/-/helper-plugin-utils-7.26.5.tgz",
      "integrity": "sha512-RS+jZcRdZdRFzMyr+wcsaqOmld1/EqTghfaBGQQd/WnRdzdlvSZ//kF7U8VQTxf1ynZ4cjUcYgjVGx13ewNPMg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-string-parser": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/helper-string-parser/-/helper-string-parser-7.25.9.tgz",
      "integrity": "sha512-4A/SCr/2KLd5jrtOMFzaKjVtAei3+2r/NChoBNoZ3EyP/+GlhoaEGoWOZUmFmoITP7zOJyHIMm+DYRd8o3PvHA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-validator-identifier": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/helper-validator-identifier/-/helper-validator-identifier-7.25.9.tgz",
      "integrity": "sha512-Ed61U6XJc3CVRfkERJWDz4dJwKe7iLmmJsbOGu9wSloNSFttHV0I8g6UAgb7qnK5ly5bGLPd4oXZlxCdANBOWQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-validator-option": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/helper-validator-option/-/helper-validator-option-7.25.9.tgz",
      "integrity": "sha512-e/zv1co8pp55dNdEcCynfj9X7nyUKUXoUEwfXqaZt0omVOmDe9oOTdKStH4GmAw6zxMFs50ZayuMfHDKlO7Tfw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helpers": {
      "version": "7.26.9",
      "resolved": "https://registry.npmjs.org/@babel/helpers/-/helpers-7.26.9.tgz",
      "integrity": "sha512-Mz/4+y8udxBKdmzt/UjPACs4G3j5SshJJEFFKxlCGPydG4JAHXxjWjAwjd09tf6oINvl1VfMJo+nB7H2YKQ0dA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/template": "^7.26.9",
        "@babel/types": "^7.26.9"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/parser": {
      "version": "7.26.9",
      "resolved": "https://registry.npmjs.org/@babel/parser/-/parser-7.26.9.tgz",
      "integrity": "sha512-81NWa1njQblgZbQHxWHpxxCzNsa3ZwvFqpUg7P+NNUU6f3UU2jBEg4OlF/J6rl8+PQGh1q6/zWScd001YwcA5A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/types": "^7.26.9"
      },
      "bin": {
        "parser": "bin/babel-parser.js"
      },
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@babel/plugin-syntax-async-generators": {
      "version": "7.8.4",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-async-generators/-/plugin-syntax-async-generators-7.8.4.tgz",
      "integrity": "sha512-tycmZxkGfZaxhMRbXlPXuVFpdWlXpir2W4AMhSJgRKzk/eDlIXOhb2LHWoLpDF7TEHylV5zNhykX6KAgHJmTNw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.8.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-bigint": {
      "version": "7.8.3",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-bigint/-/plugin-syntax-bigint-7.8.3.tgz",
      "integrity": "sha512-wnTnFlG+YxQm3vDxpGE57Pj0srRU4sHE/mDkt1qv2YJJSeUAec2ma4WLUnUPeKjyrfntVwe/N6dCXpU+zL3Npg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.8.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-class-properties": {
      "version": "7.12.13",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-class-properties/-/plugin-syntax-class-properties-7.12.13.tgz",
      "integrity": "sha512-fm4idjKla0YahUNgFNLCB0qySdsoPiZP3iQE3rky0mBUtMZ23yDJ9SJdg6dXTSDnulOVqiF3Hgr9nbXvXTQZYA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.12.13"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-class-static-block": {
      "version": "7.14.5",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-class-static-block/-/plugin-syntax-class-static-block-7.14.5.tgz",
      "integrity": "sha512-b+YyPmr6ldyNnM6sqYeMWE+bgJcJpO6yS4QD7ymxgH34GBPNDM/THBh8iunyvKIZztiwLH4CJZ0RxTk9emgpjw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.14.5"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-import-attributes": {
      "version": "7.26.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-import-attributes/-/plugin-syntax-import-attributes-7.26.0.tgz",
      "integrity": "sha512-e2dttdsJ1ZTpi3B9UYGLw41hifAubg19AtCu/2I/F1QNVclOBr1dYpTdmdyZ84Xiz43BS/tCUkMAZNLv12Pi+A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-import-meta": {
      "version": "7.10.4",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-import-meta/-/plugin-syntax-import-meta-7.10.4.tgz",
      "integrity": "sha512-Yqfm+XDx0+Prh3VSeEQCPU81yC+JWZ2pDPFSS4ZdpfZhp4MkFMaDC1UqseovEKwSUpnIL7+vK+Clp7bfh0iD7g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.10.4"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-json-strings": {
      "version": "7.8.3",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-json-strings/-/plugin-syntax-json-strings-7.8.3.tgz",
      "integrity": "sha512-lY6kdGpWHvjoe2vk4WrAapEuBR69EMxZl+RoGRhrFGNYVK8mOPAW8VfbT/ZgrFbXlDNiiaxQnAtgVCZ6jv30EA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.8.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-jsx": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-jsx/-/plugin-syntax-jsx-7.25.9.tgz",
      "integrity": "sha512-ld6oezHQMZsZfp6pWtbjaNDF2tiiCYYDqQszHt5VV437lewP9aSi2Of99CK0D0XB21k7FLgnLcmQKyKzynfeAA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-logical-assignment-operators": {
      "version": "7.10.4",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-logical-assignment-operators/-/plugin-syntax-logical-assignment-operators-7.10.4.tgz",
      "integrity": "sha512-d8waShlpFDinQ5MtvGU9xDAOzKH47+FFoney2baFIoMr952hKOLp1HR7VszoZvOsV/4+RRszNY7D17ba0te0ig==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.10.4"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-nullish-coalescing-operator": {
      "version": "7.8.3",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-nullish-coalescing-operator/-/plugin-syntax-nullish-coalescing-operator-7.8.3.tgz",
      "integrity": "sha512-aSff4zPII1u2QD7y+F8oDsz19ew4IGEJg9SVW+bqwpwtfFleiQDMdzA/R+UlWDzfnHFCxxleFT0PMIrR36XLNQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.8.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-numeric-separator": {
      "version": "7.10.4",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-numeric-separator/-/plugin-syntax-numeric-separator-7.10.4.tgz",
      "integrity": "sha512-9H6YdfkcK/uOnY/K7/aA2xpzaAgkQn37yzWUMRK7OaPOqOpGS1+n0H5hxT9AUw9EsSjPW8SVyMJwYRtWs3X3ug==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.10.4"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-object-rest-spread": {
      "version": "7.8.3",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-object-rest-spread/-/plugin-syntax-object-rest-spread-7.8.3.tgz",
      "integrity": "sha512-XoqMijGZb9y3y2XskN+P1wUGiVwWZ5JmoDRwx5+3GmEplNyVM2s2Dg8ILFQm8rWM48orGy5YpI5Bl8U1y7ydlA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.8.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-optional-catch-binding": {
      "version": "7.8.3",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-optional-catch-binding/-/plugin-syntax-optional-catch-binding-7.8.3.tgz",
      "integrity": "sha512-6VPD0Pc1lpTqw0aKoeRTMiB+kWhAoT24PA+ksWSBrFtl5SIRVpZlwN3NNPQjehA2E/91FV3RjLWoVTglWcSV3Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.8.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-optional-chaining": {
      "version": "7.8.3",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-optional-chaining/-/plugin-syntax-optional-chaining-7.8.3.tgz",
      "integrity": "sha512-KoK9ErH1MBlCPxV0VANkXW2/dw4vlbGDrFgz8bmUsBGYkFRcbRwMh6cIJubdPrkxRwuGdtCk0v/wPTKbQgBjkg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.8.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-private-property-in-object": {
      "version": "7.14.5",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-private-property-in-object/-/plugin-syntax-private-property-in-object-7.14.5.tgz",
      "integrity": "sha512-0wVnp9dxJ72ZUJDV27ZfbSj6iHLoytYZmh3rFcxNnvsJF3ktkzLDZPy/mA17HGsaQT3/DQsWYX1f1QGWkCoVUg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.14.5"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-top-level-await": {
      "version": "7.14.5",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-top-level-await/-/plugin-syntax-top-level-await-7.14.5.tgz",
      "integrity": "sha512-hx++upLv5U1rgYfwe1xBQUhRmU41NEvpUvrp8jkrSCdvGSnM5/qdRMtylJ6PG5OFkBaHkbTAKTnd3/YyESRHFw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.14.5"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-typescript": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-typescript/-/plugin-syntax-typescript-7.25.9.tgz",
      "integrity": "sha512-hjMgRy5hb8uJJjUcdWunWVcoi9bGpJp8p5Ol1229PoN6aytsLwNMgmdftO23wnCLMfVmTwZDWMPNq/D1SY60JQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/template": {
      "version": "7.26.9",
      "resolved": "https://registry.npmjs.org/@babel/template/-/template-7.26.9.tgz",
      "integrity": "sha512-qyRplbeIpNZhmzOysF/wFMuP9sctmh2cFzRAZOn1YapxBsE1i9bJIY586R/WBLfLcmcBlM8ROBiQURnnNy+zfA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/code-frame": "^7.26.2",
        "@babel/parser": "^7.26.9",
        "@babel/types": "^7.26.9"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/traverse": {
      "version": "7.26.9",
      "resolved": "https://registry.npmjs.org/@babel/traverse/-/traverse-7.26.9.tgz",
      "integrity": "sha512-ZYW7L+pL8ahU5fXmNbPF+iZFHCv5scFak7MZ9bwaRPLUhHh7QQEMjZUg0HevihoqCM5iSYHN61EyCoZvqC+bxg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/code-frame": "^7.26.2",
        "@babel/generator": "^7.26.9",
        "@babel/parser": "^7.26.9",
        "@babel/template": "^7.26.9",
        "@babel/types": "^7.26.9",
        "debug": "^4.3.1",
        "globals": "^11.1.0"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/traverse/node_modules/debug": {
      "version": "4.4.0",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.4.0.tgz",
      "integrity": "sha512-6WTZ/IxCY/T6BALoZHaE4ctp9xm+Z5kY/pzYaCHRFeyVhojxlrm+46y68HA6hr0TcwEssoxNiDEUJQjfPZ/RYA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/@babel/traverse/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@babel/types": {
      "version": "7.26.9",
      "resolved": "https://registry.npmjs.org/@babel/types/-/types-7.26.9.tgz",
      "integrity": "sha512-Y3IR1cRnOxOCDvMmNiym7XpXQ93iGDDPHx+Zj+NM+rg0fBaShfQLkg+hKPaZCEvg5N/LeCo4+Rj/i3FuJsIQaw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-string-parser": "^7.25.9",
        "@babel/helper-validator-identifier": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@bcoe/v8-coverage": {
      "version": "0.2.3",
      "resolved": "https://registry.npmjs.org/@bcoe/v8-coverage/-/v8-coverage-0.2.3.tgz",
      "integrity": "sha512-0hYQ8SB4Db5zvZB4axdMHGwEaQjkZzFjQiN9LVYvIFB2nSUHW9tYpxWriPrWDASIxiaXax83REcLxuSdnGPZtw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@colors/colors": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/@colors/colors/-/colors-1.6.0.tgz",
      "integrity": "sha512-Ir+AOibqzrIsL6ajt3Rz3LskB7OiMVHqltZmspbW/TJuTVuyOMirVqAkjfY6JISiLHgyNqicAC8AyHHGzNd/dA==",
      "license": "MIT",
      "engines": {
        "node": ">=0.1.90"
      }
    },
    "node_modules/@dabh/diagnostics": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/@dabh/diagnostics/-/diagnostics-2.0.3.tgz",
      "integrity": "sha512-hrlQOIi7hAfzsMqlGSFyVucrx38O+j6wiGOf//H2ecvIEqYN4ADBSS2iLMh5UFyDunCNniUIPk/q3riFv45xRA==",
      "license": "MIT",
      "dependencies": {
        "colorspace": "1.1.x",
        "enabled": "2.0.x",
        "kuler": "^2.0.0"
      }
    },
    "node_modules/@ioredis/commands": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/@ioredis/commands/-/commands-1.2.0.tgz",
      "integrity": "sha512-Sx1pU8EM64o2BrqNpEO1CNLtKQwyhuXuqyfH7oGKCk+1a33d2r5saW8zNwm3j6BTExtjrv2BxTgzzkMwts6vGg==",
      "license": "MIT"
    },
    "node_modules/@istanbuljs/load-nyc-config": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@istanbuljs/load-nyc-config/-/load-nyc-config-1.1.0.tgz",
      "integrity": "sha512-VjeHSlIzpv/NyD3N0YuHfXOPDIixcA1q2ZV98wsMqcYlPmv2n3Yb2lYP9XMElnaFVXg5A7YLTeLu6V84uQDjmQ==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "camelcase": "^5.3.1",
        "find-up": "^4.1.0",
        "get-package-type": "^0.1.0",
        "js-yaml": "^3.13.1",
        "resolve-from": "^5.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/@istanbuljs/schema": {
      "version": "0.1.3",
      "resolved": "https://registry.npmjs.org/@istanbuljs/schema/-/schema-0.1.3.tgz",
      "integrity": "sha512-ZXRY4jNvVgSVQ8DL3LTcakaAtXwTVUxE81hslsyD2AtoXW/wVob10HkOJ1X/pAlcI7D+2YoZKg5do8G/w6RYgA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/@jest/console": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/console/-/console-29.7.0.tgz",
      "integrity": "sha512-5Ni4CU7XHQi32IJ398EEP4RrB8eV09sXP2ROqD4bksHrnTree52PsxvX8tpL8LvTZ3pFzXyPbNQReSN41CAhOg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "chalk": "^4.0.0",
        "jest-message-util": "^29.7.0",
        "jest-util": "^29.7.0",
        "slash": "^3.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/core": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/core/-/core-29.7.0.tgz",
      "integrity": "sha512-n7aeXWKMnGtDA48y8TLWJPJmLmmZ642Ceo78cYWEpiD7FzDgmNDV/GCVRorPABdXLJZ/9wzzgZAlHjXjxDHGsg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/console": "^29.7.0",
        "@jest/reporters": "^29.7.0",
        "@jest/test-result": "^29.7.0",
        "@jest/transform": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "ansi-escapes": "^4.2.1",
        "chalk": "^4.0.0",
        "ci-info": "^3.2.0",
        "exit": "^0.1.2",
        "graceful-fs": "^4.2.9",
        "jest-changed-files": "^29.7.0",
        "jest-config": "^29.7.0",
        "jest-haste-map": "^29.7.0",
        "jest-message-util": "^29.7.0",
        "jest-regex-util": "^29.6.3",
        "jest-resolve": "^29.7.0",
        "jest-resolve-dependencies": "^29.7.0",
        "jest-runner": "^29.7.0",
        "jest-runtime": "^29.7.0",
        "jest-snapshot": "^29.7.0",
        "jest-util": "^29.7.0",
        "jest-validate": "^29.7.0",
        "jest-watcher": "^29.7.0",
        "micromatch": "^4.0.4",
        "pretty-format": "^29.7.0",
        "slash": "^3.0.0",
        "strip-ansi": "^6.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "node-notifier": "^8.0.1 || ^9.0.0 || ^10.0.0"
      },
      "peerDependenciesMeta": {
        "node-notifier": {
          "optional": true
        }
      }
    },
    "node_modules/@jest/environment": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/environment/-/environment-29.7.0.tgz",
      "integrity": "sha512-aQIfHDq33ExsN4jP1NWGXhxgQ/wixs60gDiKO+XVMd8Mn0NWPWgc34ZQDTb2jKaUWQ7MuwoitXAsN2XVXNMpAw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/fake-timers": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "jest-mock": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/expect": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/expect/-/expect-29.7.0.tgz",
      "integrity": "sha512-8uMeAMycttpva3P1lBHB8VciS9V0XAr3GymPpipdyQXbBcuhkLQOSe8E/p92RyAdToS6ZD1tFkX+CkhoECE0dQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "expect": "^29.7.0",
        "jest-snapshot": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/expect-utils": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/expect-utils/-/expect-utils-29.7.0.tgz",
      "integrity": "sha512-GlsNBWiFQFCVi9QVSx7f5AgMeLxe9YCCs5PuP2O2LdjDAA8Jh9eX7lA1Jq/xdXw3Wb3hyvlFNfZIfcRetSzYcA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "jest-get-type": "^29.6.3"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/fake-timers": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/fake-timers/-/fake-timers-29.7.0.tgz",
      "integrity": "sha512-q4DH1Ha4TTFPdxLsqDXK1d3+ioSL7yL5oCMJZgDYm6i+6CygW5E5xVr/D1HdsGxjt1ZWSfUAs9OxSB/BNelWrQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "@sinonjs/fake-timers": "^10.0.2",
        "@types/node": "*",
        "jest-message-util": "^29.7.0",
        "jest-mock": "^29.7.0",
        "jest-util": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/globals": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/globals/-/globals-29.7.0.tgz",
      "integrity": "sha512-mpiz3dutLbkW2MNFubUGUEVLkTGiqW6yLVTA+JbP6fI6J5iL9Y0Nlg8k95pcF8ctKwCS7WVxteBs29hhfAotzQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/environment": "^29.7.0",
        "@jest/expect": "^29.7.0",
        "@jest/types": "^29.6.3",
        "jest-mock": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/reporters": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/reporters/-/reporters-29.7.0.tgz",
      "integrity": "sha512-DApq0KJbJOEzAFYjHADNNxAE3KbhxQB1y5Kplb5Waqw6zVbuWatSnMjE5gs8FUgEPmNsnZA3NCWl9NG0ia04Pg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@bcoe/v8-coverage": "^0.2.3",
        "@jest/console": "^29.7.0",
        "@jest/test-result": "^29.7.0",
        "@jest/transform": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@jridgewell/trace-mapping": "^0.3.18",
        "@types/node": "*",
        "chalk": "^4.0.0",
        "collect-v8-coverage": "^1.0.0",
        "exit": "^0.1.2",
        "glob": "^7.1.3",
        "graceful-fs": "^4.2.9",
        "istanbul-lib-coverage": "^3.0.0",
        "istanbul-lib-instrument": "^6.0.0",
        "istanbul-lib-report": "^3.0.0",
        "istanbul-lib-source-maps": "^4.0.0",
        "istanbul-reports": "^3.1.3",
        "jest-message-util": "^29.7.0",
        "jest-util": "^29.7.0",
        "jest-worker": "^29.7.0",
        "slash": "^3.0.0",
        "string-length": "^4.0.1",
        "strip-ansi": "^6.0.0",
        "v8-to-istanbul": "^9.0.1"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "node-notifier": "^8.0.1 || ^9.0.0 || ^10.0.0"
      },
      "peerDependenciesMeta": {
        "node-notifier": {
          "optional": true
        }
      }
    },
    "node_modules/@jest/schemas": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/@jest/schemas/-/schemas-29.6.3.tgz",
      "integrity": "sha512-mo5j5X+jIZmJQveBKeS/clAueipV7KgiX1vMgCxam1RNYiqE1w62n0/tJJnHtjW8ZHcQco5gY85jA3mi0L+nSA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@sinclair/typebox": "^0.27.8"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/source-map": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/@jest/source-map/-/source-map-29.6.3.tgz",
      "integrity": "sha512-MHjT95QuipcPrpLM+8JMSzFx6eHp5Bm+4XeFDJlwsvVBjmKNiIAvasGK2fxz2WbGRlnvqehFbh07MMa7n3YJnw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/trace-mapping": "^0.3.18",
        "callsites": "^3.0.0",
        "graceful-fs": "^4.2.9"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/test-result": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/test-result/-/test-result-29.7.0.tgz",
      "integrity": "sha512-Fdx+tv6x1zlkJPcWXmMDAG2HBnaR9XPSd5aDWQVsfrZmLVT3lU1cwyxLgRmXR9yrq4NBoEm9BMsfgFzTQAbJYA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/console": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/istanbul-lib-coverage": "^2.0.0",
        "collect-v8-coverage": "^1.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/test-sequencer": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/test-sequencer/-/test-sequencer-29.7.0.tgz",
      "integrity": "sha512-GQwJ5WZVrKnOJuiYiAF52UNUJXgTZx1NHjFSEB0qEMmSZKAkdMoIzw/Cj6x6NF4AvV23AUqDpFzQkN/eYCYTxw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/test-result": "^29.7.0",
        "graceful-fs": "^4.2.9",
        "jest-haste-map": "^29.7.0",
        "slash": "^3.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/transform": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/transform/-/transform-29.7.0.tgz",
      "integrity": "sha512-ok/BTPFzFKVMwO5eOHRrvnBVHdRy9IrsrW1GpMaQ9MCnilNLXQKmAX8s1YXDFaai9xJpac2ySzV0YeRRECr2Vw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/core": "^7.11.6",
        "@jest/types": "^29.6.3",
        "@jridgewell/trace-mapping": "^0.3.18",
        "babel-plugin-istanbul": "^6.1.1",
        "chalk": "^4.0.0",
        "convert-source-map": "^2.0.0",
        "fast-json-stable-stringify": "^2.1.0",
        "graceful-fs": "^4.2.9",
        "jest-haste-map": "^29.7.0",
        "jest-regex-util": "^29.6.3",
        "jest-util": "^29.7.0",
        "micromatch": "^4.0.4",
        "pirates": "^4.0.4",
        "slash": "^3.0.0",
        "write-file-atomic": "^4.0.2"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/types": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/@jest/types/-/types-29.6.3.tgz",
      "integrity": "sha512-u3UPsIilWKOM3F9CXtrG8LEJmNxwoCQC/XVj4IKYXvvpx7QIi/Kg1LI5uDmDpKlac62NUtX7eLjRh+jVZcLOzw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/schemas": "^29.6.3",
        "@types/istanbul-lib-coverage": "^2.0.0",
        "@types/istanbul-reports": "^3.0.0",
        "@types/node": "*",
        "@types/yargs": "^17.0.8",
        "chalk": "^4.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jridgewell/gen-mapping": {
      "version": "0.3.8",
      "resolved": "https://registry.npmjs.org/@jridgewell/gen-mapping/-/gen-mapping-0.3.8.tgz",
      "integrity": "sha512-imAbBGkb+ebQyxKgzv5Hu2nmROxoDOXHh80evxdoXNOrvAnVx7zimzc1Oo5h9RlfV4vPXaE2iM5pOFbvOCClWA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/set-array": "^1.2.1",
        "@jridgewell/sourcemap-codec": "^1.4.10",
        "@jridgewell/trace-mapping": "^0.3.24"
      },
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/resolve-uri": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/@jridgewell/resolve-uri/-/resolve-uri-3.1.2.tgz",
      "integrity": "sha512-bRISgCIjP20/tbWSPWMEi54QVPRZExkuD9lJL+UIxUKtwVJA8wW1Trb1jMs1RFXo1CBTNZ/5hpC9QvmKWdopKw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/set-array": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/@jridgewell/set-array/-/set-array-1.2.1.tgz",
      "integrity": "sha512-R8gLRTZeyp03ymzP/6Lil/28tGeGEzhx1q2k703KGWRAI1VdvPIXdG70VJc2pAMw3NA6JKL5hhFu1sJX0Mnn/A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/sourcemap-codec": {
      "version": "1.5.0",
      "resolved": "https://registry.npmjs.org/@jridgewell/sourcemap-codec/-/sourcemap-codec-1.5.0.tgz",
      "integrity": "sha512-gv3ZRaISU3fjPAgNsriBRqGWQL6quFx04YMPW/zD8XMLsU32mhCCbfbO6KZFLjvYpCZ8zyDEgqsgf+PwPaM7GQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@jridgewell/trace-mapping": {
      "version": "0.3.25",
      "resolved": "https://registry.npmjs.org/@jridgewell/trace-mapping/-/trace-mapping-0.3.25.tgz",
      "integrity": "sha512-vNk6aEwybGtawWmy/PzwnGDOjCkLWSD2wqvjGGAgOAwCGWySYXfYoxt00IJkTF+8Lb57DwOb3Aa0o9CApepiYQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/resolve-uri": "^3.1.0",
        "@jridgewell/sourcemap-codec": "^1.4.14"
      }
    },
    "node_modules/@sinclair/typebox": {
      "version": "0.27.8",
      "resolved": "https://registry.npmjs.org/@sinclair/typebox/-/typebox-0.27.8.tgz",
      "integrity": "sha512-+Fj43pSMwJs4KRrH/938Uf+uAELIgVBmQzg/q1YG10djyfA3TnrU8N8XzqCh/okZdszqBQTZf96idMfE5lnwTA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@sinonjs/commons": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/@sinonjs/commons/-/commons-3.0.1.tgz",
      "integrity": "sha512-K3mCHKQ9sVh8o1C9cxkwxaOmXoAMlDxC1mYyHrjqOWEcBjYr76t96zL2zlj5dUGZ3HSw240X1qgH3Mjf1yJWpQ==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "type-detect": "4.0.8"
      }
    },
    "node_modules/@sinonjs/fake-timers": {
      "version": "10.3.0",
      "resolved": "https://registry.npmjs.org/@sinonjs/fake-timers/-/fake-timers-10.3.0.tgz",
      "integrity": "sha512-V4BG07kuYSUkTCSBHG8G8TNhM+F19jXFWnQtzj+we8DrkpSBCee9Z3Ms8yiGer/dlmhe35/Xdgyo3/0rQKg7YA==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "@sinonjs/commons": "^3.0.0"
      }
    },
    "node_modules/@socket.io/component-emitter": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/@socket.io/component-emitter/-/component-emitter-3.1.2.tgz",
      "integrity": "sha512-9BCxFwvbGg/RsZK9tjXd8s4UcwR0MWeFQ1XEKIQVVvAGJyINdrqKMcTRyLoK8Rse1GjzLV9cwjWV1olXRWEXVA==",
      "license": "MIT"
    },
    "node_modules/@types/babel__core": {
      "version": "7.20.5",
      "resolved": "https://registry.npmjs.org/@types/babel__core/-/babel__core-7.20.5.tgz",
      "integrity": "sha512-qoQprZvz5wQFJwMDqeseRXWv3rqMvhgpbXFfVyWhbx9X47POIA6i/+dXefEmZKoAgOaTdaIgNSMqMIU61yRyzA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/parser": "^7.20.7",
        "@babel/types": "^7.20.7",
        "@types/babel__generator": "*",
        "@types/babel__template": "*",
        "@types/babel__traverse": "*"
      }
    },
    "node_modules/@types/babel__generator": {
      "version": "7.6.8",
      "resolved": "https://registry.npmjs.org/@types/babel__generator/-/babel__generator-7.6.8.tgz",
      "integrity": "sha512-ASsj+tpEDsEiFr1arWrlN6V3mdfjRMZt6LtK/Vp/kreFLnr5QH5+DhvD5nINYZXzwJvXeGq+05iUXcAzVrqWtw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/types": "^7.0.0"
      }
    },
    "node_modules/@types/babel__template": {
      "version": "7.4.4",
      "resolved": "https://registry.npmjs.org/@types/babel__template/-/babel__template-7.4.4.tgz",
      "integrity": "sha512-h/NUaSyG5EyxBIp8YRxo4RMe2/qQgvyowRwVMzhYhBCONbW8PUsg4lkFMrhgZhUe5z3L3MiLDuvyJ/CaPa2A8A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/parser": "^7.1.0",
        "@babel/types": "^7.0.0"
      }
    },
    "node_modules/@types/babel__traverse": {
      "version": "7.20.6",
      "resolved": "https://registry.npmjs.org/@types/babel__traverse/-/babel__traverse-7.20.6.tgz",
      "integrity": "sha512-r1bzfrm0tomOI8g1SzvCaQHo6Lcv6zu0EA+W2kHrt8dyrHQxGzBBL4kdkzIS+jBMV+EYcMAEAqXqYaLJq5rOZg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/types": "^7.20.7"
      }
    },
    "node_modules/@types/cors": {
      "version": "2.8.17",
      "resolved": "https://registry.npmjs.org/@types/cors/-/cors-2.8.17.tgz",
      "integrity": "sha512-8CGDvrBj1zgo2qE+oS3pOCyYNqCPryMWY2bGfwA0dcfopWGgxs+78df0Rs3rc9THP4JkOhLsAa+15VdpAqkcUA==",
      "license": "MIT",
      "dependencies": {
        "@types/node": "*"
      }
    },
    "node_modules/@types/graceful-fs": {
      "version": "4.1.9",
      "resolved": "https://registry.npmjs.org/@types/graceful-fs/-/graceful-fs-4.1.9.tgz",
      "integrity": "sha512-olP3sd1qOEe5dXTSaFvQG+02VdRXcdytWLAZsAq1PecU8uqQAhkrnbli7DagjtXKW/Bl7YJbUsa8MPcuc8LHEQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/node": "*"
      }
    },
    "node_modules/@types/istanbul-lib-coverage": {
      "version": "2.0.6",
      "resolved": "https://registry.npmjs.org/@types/istanbul-lib-coverage/-/istanbul-lib-coverage-2.0.6.tgz",
      "integrity": "sha512-2QF/t/auWm0lsy8XtKVPG19v3sSOQlJe/YHZgfjb/KBBHOGSV+J2q/S671rcq9uTBrLAXmZpqJiaQbMT+zNU1w==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@types/istanbul-lib-report": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/@types/istanbul-lib-report/-/istanbul-lib-report-3.0.3.tgz",
      "integrity": "sha512-NQn7AHQnk/RSLOxrBbGyJM/aVQ+pjj5HCgasFxc0K/KhoATfQ/47AyUl15I2yBUpihjmas+a+VJBOqecrFH+uA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/istanbul-lib-coverage": "*"
      }
    },
    "node_modules/@types/istanbul-reports": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/@types/istanbul-reports/-/istanbul-reports-3.0.4.tgz",
      "integrity": "sha512-pk2B1NWalF9toCRu6gjBzR69syFjP4Od8WRAX+0mmf9lAjCRicLOWc+ZrxZHx/0XRjotgkF9t6iaMJ+aXcOdZQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/istanbul-lib-report": "*"
      }
    },
    "node_modules/@types/node": {
      "version": "22.13.10",
      "resolved": "https://registry.npmjs.org/@types/node/-/node-22.13.10.tgz",
      "integrity": "sha512-I6LPUvlRH+O6VRUqYOcMudhaIdUVWfsjnZavnsraHvpBwaEyMN29ry+0UVJhImYL16xsscu0aske3yA+uPOWfw==",
      "license": "MIT",
      "dependencies": {
        "undici-types": "~6.20.0"
      }
    },
    "node_modules/@types/stack-utils": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/@types/stack-utils/-/stack-utils-2.0.3.tgz",
      "integrity": "sha512-9aEbYZ3TbYMznPdcdr3SmIrLXwC/AKZXQeCf9Pgao5CKb8CyHuEX5jzWPTkvregvhRJHcpRO6BFoGW9ycaOkYw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@types/triple-beam": {
      "version": "1.3.5",
      "resolved": "https://registry.npmjs.org/@types/triple-beam/-/triple-beam-1.3.5.tgz",
      "integrity": "sha512-6WaYesThRMCl19iryMYP7/x2OVgCtbIVflDGFpWnb9irXI3UjYE4AzmYuiUKY1AJstGijoY+MgUszMgRxIYTYw==",
      "license": "MIT"
    },
    "node_modules/@types/yargs": {
      "version": "17.0.33",
      "resolved": "https://registry.npmjs.org/@types/yargs/-/yargs-17.0.33.tgz",
      "integrity": "sha512-WpxBCKWPLr4xSsHgz511rFJAM+wS28w2zEO1QDNY5zM/S8ok70NNfztH0xwhqKyaK0OHCbN98LDAZuy1ctxDkA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/yargs-parser": "*"
      }
    },
    "node_modules/@types/yargs-parser": {
      "version": "21.0.3",
      "resolved": "https://registry.npmjs.org/@types/yargs-parser/-/yargs-parser-21.0.3.tgz",
      "integrity": "sha512-I4q9QU9MQv4oEOz4tAHJtNz1cwuLxn2F3xcc2iV5WdqLPpUnj30aUuxt1mAxYTG+oe8CZMV/+6rU4S4gRDzqtQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/accepts": {
      "version": "1.3.8",
      "resolved": "https://registry.npmjs.org/accepts/-/accepts-1.3.8.tgz",
      "integrity": "sha512-PYAthTa2m2VKxuvSD3DPC/Gy+U+sOA1LAuT8mkmRuvw+NACSaeXEQ+NHcVF7rONl6qcaxV3Uuemwawk+7+SJLw==",
      "license": "MIT",
      "dependencies": {
        "mime-types": "~2.1.34",
        "negotiator": "0.6.3"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/accepts/node_modules/negotiator": {
      "version": "0.6.3",
      "resolved": "https://registry.npmjs.org/negotiator/-/negotiator-0.6.3.tgz",
      "integrity": "sha512-+EUsqGPLsM+j/zdChZjsnX51g4XrHFOIXwfnCVPGlQk/k5giakcKsuxCObBRu6DSm9opw/O6slWbJdghQM4bBg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/ansi-escapes": {
      "version": "4.3.2",
      "resolved": "https://registry.npmjs.org/ansi-escapes/-/ansi-escapes-4.3.2.tgz",
      "integrity": "sha512-gKXj5ALrKWQLsYG9jlTRmR/xKluxHV+Z9QEwNIgCfM1/uwPMCuzVVnh5mwTd+OuBZcwSIMbqssNWRm1lE51QaQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "type-fest": "^0.21.3"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/ansi-regex": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-5.0.1.tgz",
      "integrity": "sha512-quJQXlTSUGL2LH9SUXo8VwsY4soanhgo6LNSm84E1LBcE8s3O0wpdiRzyR9z/ZZJMlMWv37qOOb9pdJlMUEKFQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/ansi-styles": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-4.3.0.tgz",
      "integrity": "sha512-zbB9rCJAT1rbjiVDb2hqKFHNYLxgtk8NURxZ3IZwD3F6NtxbXZQCnnSi1Lkx+IDohdPlFp222wVALIheZJQSEg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "color-convert": "^2.0.1"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/anymatch": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/anymatch/-/anymatch-3.1.3.tgz",
      "integrity": "sha512-KMReFUr0B4t+D+OBkjR3KYqvocp2XaSzO55UcB6mgQMd3KbcE+mWTyvVV7D/zsdEbNnV6acZUutkiHQXvTr1Rw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "normalize-path": "^3.0.0",
        "picomatch": "^2.0.4"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/argparse": {
      "version": "1.0.10",
      "resolved": "https://registry.npmjs.org/argparse/-/argparse-1.0.10.tgz",
      "integrity": "sha512-o5Roy6tNG4SL/FOkCAN6RzjiakZS25RLYFrcMttJqbdd8BWrnA+fGz57iN5Pb06pvBGvl5gQ0B48dJlslXvoTg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "sprintf-js": "~1.0.2"
      }
    },
    "node_modules/array-flatten": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/array-flatten/-/array-flatten-1.1.1.tgz",
      "integrity": "sha512-PCVAQswWemu6UdxsDFFX/+gVeYqKAod3D3UVm91jHwynguOwAvYPhx8nNlM++NqRcK6CxxpUafjmhIdKiHibqg==",
      "license": "MIT"
    },
    "node_modules/async": {
      "version": "3.2.6",
      "resolved": "https://registry.npmjs.org/async/-/async-3.2.6.tgz",
      "integrity": "sha512-htCUDlxyyCLMgaM3xXg0C0LW2xqfuQ6p05pCEIsXuyQ+a1koYKTuBMzRNwmybfLgvJDMd0r1LTn4+E0Ti6C2AA==",
      "license": "MIT"
    },
    "node_modules/babel-jest": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/babel-jest/-/babel-jest-29.7.0.tgz",
      "integrity": "sha512-BrvGY3xZSwEcCzKvKsCi2GgHqDqsYkOP4/by5xCgIwGXQxIEh+8ew3gmrE1y7XRR6LHZIj6yLYnUi/mm2KXKBg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/transform": "^29.7.0",
        "@types/babel__core": "^7.1.14",
        "babel-plugin-istanbul": "^6.1.1",
        "babel-preset-jest": "^29.6.3",
        "chalk": "^4.0.0",
        "graceful-fs": "^4.2.9",
        "slash": "^3.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.8.0"
      }
    },
    "node_modules/babel-plugin-istanbul": {
      "version": "6.1.1",
      "resolved": "https://registry.npmjs.org/babel-plugin-istanbul/-/babel-plugin-istanbul-6.1.1.tgz",
      "integrity": "sha512-Y1IQok9821cC9onCx5otgFfRm7Lm+I+wwxOx738M/WLPZ9Q42m4IG5W0FNX8WLL2gYMZo3JkuXIH2DOpWM+qwA==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@istanbuljs/load-nyc-config": "^1.0.0",
        "@istanbuljs/schema": "^0.1.2",
        "istanbul-lib-instrument": "^5.0.4",
        "test-exclude": "^6.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/babel-plugin-istanbul/node_modules/istanbul-lib-instrument": {
      "version": "5.2.1",
      "resolved": "https://registry.npmjs.org/istanbul-lib-instrument/-/istanbul-lib-instrument-5.2.1.tgz",
      "integrity": "sha512-pzqtp31nLv/XFOzXGuvhCb8qhjmTVo5vjVk19XE4CRlSWz0KoeJ3bw9XsA7nOp9YBf4qHjwBxkDzKcME/J29Yg==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "@babel/core": "^7.12.3",
        "@babel/parser": "^7.14.7",
        "@istanbuljs/schema": "^0.1.2",
        "istanbul-lib-coverage": "^3.2.0",
        "semver": "^6.3.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/babel-plugin-jest-hoist": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/babel-plugin-jest-hoist/-/babel-plugin-jest-hoist-29.6.3.tgz",
      "integrity": "sha512-ESAc/RJvGTFEzRwOTT4+lNDk/GNHMkKbNzsvT0qKRfDyyYTskxB5rnU2njIDYVxXCBHHEI1c0YwHob3WaYujOg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/template": "^7.3.3",
        "@babel/types": "^7.3.3",
        "@types/babel__core": "^7.1.14",
        "@types/babel__traverse": "^7.0.6"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/babel-preset-current-node-syntax": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/babel-preset-current-node-syntax/-/babel-preset-current-node-syntax-1.1.0.tgz",
      "integrity": "sha512-ldYss8SbBlWva1bs28q78Ju5Zq1F+8BrqBZZ0VFhLBvhh6lCpC2o3gDJi/5DRLs9FgYZCnmPYIVFU4lRXCkyUw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/plugin-syntax-async-generators": "^7.8.4",
        "@babel/plugin-syntax-bigint": "^7.8.3",
        "@babel/plugin-syntax-class-properties": "^7.12.13",
        "@babel/plugin-syntax-class-static-block": "^7.14.5",
        "@babel/plugin-syntax-import-attributes": "^7.24.7",
        "@babel/plugin-syntax-import-meta": "^7.10.4",
        "@babel/plugin-syntax-json-strings": "^7.8.3",
        "@babel/plugin-syntax-logical-assignment-operators": "^7.10.4",
        "@babel/plugin-syntax-nullish-coalescing-operator": "^7.8.3",
        "@babel/plugin-syntax-numeric-separator": "^7.10.4",
        "@babel/plugin-syntax-object-rest-spread": "^7.8.3",
        "@babel/plugin-syntax-optional-catch-binding": "^7.8.3",
        "@babel/plugin-syntax-optional-chaining": "^7.8.3",
        "@babel/plugin-syntax-private-property-in-object": "^7.14.5",
        "@babel/plugin-syntax-top-level-await": "^7.14.5"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/babel-preset-jest": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/babel-preset-jest/-/babel-preset-jest-29.6.3.tgz",
      "integrity": "sha512-0B3bhxR6snWXJZtR/RliHTDPRgn1sNHOR0yVtq/IiQFyuOVjFS+wuio/R4gSNkyYmKmJB4wGZv2NZanmKmTnNA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "babel-plugin-jest-hoist": "^29.6.3",
        "babel-preset-current-node-syntax": "^1.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/balanced-match": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/balanced-match/-/balanced-match-1.0.2.tgz",
      "integrity": "sha512-3oSeUO0TMV67hN1AmbXsK4yaqU7tjiHlbxRDZOpH0KW9+CeX4bRAaX0Anxt0tx2MrpRpWwQaPwIlISEJhYU5Pw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/base64id": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/base64id/-/base64id-2.0.0.tgz",
      "integrity": "sha512-lGe34o6EHj9y3Kts9R4ZYs/Gr+6N7MCaMlIFA3F1R2O5/m7K06AxfSeO5530PEERE6/WyEg3lsuyw4GHlPZHog==",
      "license": "MIT",
      "engines": {
        "node": "^4.5.0 || >= 5.9"
      }
    },
    "node_modules/basic-auth": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/basic-auth/-/basic-auth-2.0.1.tgz",
      "integrity": "sha512-NF+epuEdnUYVlGuhaxbbq+dvJttwLnGY+YixlXlME5KpQ5W3CnXA5cVTneY3SPbPDRkcjMbifrwmFYcClgOZeg==",
      "license": "MIT",
      "dependencies": {
        "safe-buffer": "5.1.2"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/basic-auth/node_modules/safe-buffer": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/safe-buffer/-/safe-buffer-5.1.2.tgz",
      "integrity": "sha512-Gd2UZBJDkXlY7GbJxfsE8/nvKkUEU1G38c1siN6QP6a9PT9MmHB8GnpscSmMJSoF8LOIrt8ud/wPtojys4G6+g==",
      "license": "MIT"
    },
    "node_modules/binary-extensions": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/binary-extensions/-/binary-extensions-2.3.0.tgz",
      "integrity": "sha512-Ceh+7ox5qe7LJuLHoY0feh3pHuUDHAcRUeyL2VYghZwfpkNIy/+8Ocg0a3UuSoYzavmylwuLWQOf3hl0jjMMIw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/bintrees": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/bintrees/-/bintrees-1.0.2.tgz",
      "integrity": "sha512-VOMgTMwjAaUG580SXn3LacVgjurrbMme7ZZNYGSSV7mmtY6QQRh0Eg3pwIcntQ77DErK1L0NxkbetjcoXzVwKw==",
      "license": "MIT"
    },
    "node_modules/body-parser": {
      "version": "1.20.3",
      "resolved": "https://registry.npmjs.org/body-parser/-/body-parser-1.20.3.tgz",
      "integrity": "sha512-7rAxByjUMqQ3/bHJy7D6OGXvx/MMc4IqBn/X0fcM1QUcAItpZrBEYhWGem+tzXH90c+G01ypMcYJBO9Y30203g==",
      "license": "MIT",
      "dependencies": {
        "bytes": "3.1.2",
        "content-type": "~1.0.5",
        "debug": "2.6.9",
        "depd": "2.0.0",
        "destroy": "1.2.0",
        "http-errors": "2.0.0",
        "iconv-lite": "0.4.24",
        "on-finished": "2.4.1",
        "qs": "6.13.0",
        "raw-body": "2.5.2",
        "type-is": "~1.6.18",
        "unpipe": "1.0.0"
      },
      "engines": {
        "node": ">= 0.8",
        "npm": "1.2.8000 || >= 1.4.16"
      }
    },
    "node_modules/brace-expansion": {
      "version": "1.1.11",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.11.tgz",
      "integrity": "sha512-iCuPHDFgrHX7H2vEI/5xpz07zSHB00TpugqhmYtVmMO6518mCuRMoOYFldEBl0g187ufozdaHgWKcYFb61qGiA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "node_modules/braces": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/braces/-/braces-3.0.3.tgz",
      "integrity": "sha512-yQbXgO/OSZVD2IsiLlro+7Hf6Q18EJrKSEsdoMzKePKXct3gvD8oLcOQdIzGupr5Fj+EDe8gO/lxc1BzfMpxvA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fill-range": "^7.1.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/browserslist": {
      "version": "4.24.4",
      "resolved": "https://registry.npmjs.org/browserslist/-/browserslist-4.24.4.tgz",
      "integrity": "sha512-KDi1Ny1gSePi1vm0q4oxSF8b4DR44GF4BbmS2YdhPLOEqd8pDviZOGH/GsmRwoWJ2+5Lr085X7naowMwKHDG1A==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/browserslist"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "caniuse-lite": "^1.0.30001688",
        "electron-to-chromium": "^1.5.73",
        "node-releases": "^2.0.19",
        "update-browserslist-db": "^1.1.1"
      },
      "bin": {
        "browserslist": "cli.js"
      },
      "engines": {
        "node": "^6 || ^7 || ^8 || ^9 || ^10 || ^11 || ^12 || >=13.7"
      }
    },
    "node_modules/bser": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/bser/-/bser-2.1.1.tgz",
      "integrity": "sha512-gQxTNE/GAfIIrmHLUE3oJyp5FO6HRBfhjnw4/wMmA63ZGDJnWBmgY/lyQBpnDUkGmAhbSe39tx2d/iTOAfglwQ==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "node-int64": "^0.4.0"
      }
    },
    "node_modules/buffer-equal-constant-time": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/buffer-equal-constant-time/-/buffer-equal-constant-time-1.0.1.tgz",
      "integrity": "sha512-zRpUiDwd/xk6ADqPMATG8vc9VPrkck7T07OIx0gnjmJAnHnTVXNQG3vfvWNuiZIkwu9KrKdA1iJKfsfTVxE6NA==",
      "license": "BSD-3-Clause"
    },
    "node_modules/buffer-from": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/buffer-from/-/buffer-from-1.1.2.tgz",
      "integrity": "sha512-E+XQCRwSbaaiChtv6k6Dwgc+bx+Bs6vuKJHHl5kox/BaKbhiXzqQOwK4cO22yElGp2OCmjwVhT3HmxgyPGnJfQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/bytes": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/bytes/-/bytes-3.1.2.tgz",
      "integrity": "sha512-/Nf7TyzTx6S3yRJObOAV7956r8cr2+Oj8AC5dt8wSP3BQAoeX58NoHyCU8P8zGkNXStjTSi6fzO6F0pBdcYbEg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/call-bind-apply-helpers": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/call-bind-apply-helpers/-/call-bind-apply-helpers-1.0.2.tgz",
      "integrity": "sha512-Sp1ablJ0ivDkSzjcaJdxEunN5/XvksFJ2sMBFfq6x0ryhQV/2b/KwFe21cMpmHtPOSij8K99/wSfoEuTObmuMQ==",
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/call-bound": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/call-bound/-/call-bound-1.0.4.tgz",
      "integrity": "sha512-+ys997U96po4Kx/ABpBCqhA9EuxJaQWDQg7295H4hBphv3IZg0boBKuwYpt4YXp6MZ5AmZQnU/tyMTlRpaSejg==",
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.2",
        "get-intrinsic": "^1.3.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/callsites": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/callsites/-/callsites-3.1.0.tgz",
      "integrity": "sha512-P8BjAsXvZS+VIDUI11hHCQEv74YT67YUi5JJFNWIqL235sBmjX4+qx9Muvls5ivyNENctx46xQLQ3aTuE7ssaQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/camelcase": {
      "version": "5.3.1",
      "resolved": "https://registry.npmjs.org/camelcase/-/camelcase-5.3.1.tgz",
      "integrity": "sha512-L28STB170nwWS63UjtlEOE3dldQApaJXZkOI1uMFfzf3rRuPegHaHesyee+YxQ+W6SvRDQV6UrdOdRiR153wJg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/caniuse-lite": {
      "version": "1.0.30001702",
      "resolved": "https://registry.npmjs.org/caniuse-lite/-/caniuse-lite-1.0.30001702.tgz",
      "integrity": "sha512-LoPe/D7zioC0REI5W73PeR1e1MLCipRGq/VkovJnd6Df+QVqT+vT33OXCp8QUd7kA7RZrHWxb1B36OQKI/0gOA==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/caniuse-lite"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "CC-BY-4.0"
    },
    "node_modules/chalk": {
      "version": "4.1.2",
      "resolved": "https://registry.npmjs.org/chalk/-/chalk-4.1.2.tgz",
      "integrity": "sha512-oKnbhFyRIXpUuez8iBMmyEa4nbj4IOQyuhc/wy9kY7/WVPcwIO9VA668Pu8RkO7+0G76SLROeyw9CpQ061i4mA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^4.1.0",
        "supports-color": "^7.1.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/chalk?sponsor=1"
      }
    },
    "node_modules/char-regex": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/char-regex/-/char-regex-1.0.2.tgz",
      "integrity": "sha512-kWWXztvZ5SBQV+eRgKFeh8q5sLuZY2+8WUIzlxWVTg+oGwY14qylx1KbKzHd8P6ZYkAg0xyIDU9JMHhyJMZ1jw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/chokidar": {
      "version": "3.6.0",
      "resolved": "https://registry.npmjs.org/chokidar/-/chokidar-3.6.0.tgz",
      "integrity": "sha512-7VT13fmjotKpGipCW9JEQAusEPE+Ei8nl6/g4FBAmIm0GOOLMua9NDDo/DWp0ZAxCr3cPq5ZpBqmPAQgDda2Pw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "anymatch": "~3.1.2",
        "braces": "~3.0.2",
        "glob-parent": "~5.1.2",
        "is-binary-path": "~2.1.0",
        "is-glob": "~4.0.1",
        "normalize-path": "~3.0.0",
        "readdirp": "~3.6.0"
      },
      "engines": {
        "node": ">= 8.10.0"
      },
      "funding": {
        "url": "https://paulmillr.com/funding/"
      },
      "optionalDependencies": {
        "fsevents": "~2.3.2"
      }
    },
    "node_modules/ci-info": {
      "version": "3.9.0",
      "resolved": "https://registry.npmjs.org/ci-info/-/ci-info-3.9.0.tgz",
      "integrity": "sha512-NIxF55hv4nSqQswkAeiOi1r83xy8JldOFDTWiug55KBu9Jnblncd2U6ViHmYgHf01TPZS77NJBhBMKdWj9HQMQ==",
      "dev": true,
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/sibiraj-s"
        }
      ],
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/cjs-module-lexer": {
      "version": "1.4.3",
      "resolved": "https://registry.npmjs.org/cjs-module-lexer/-/cjs-module-lexer-1.4.3.tgz",
      "integrity": "sha512-9z8TZaGM1pfswYeXrUpzPrkx8UnWYdhJclsiYMm6x/w5+nN+8Tf/LnAgfLGQCm59qAOxU8WwHEq2vNwF6i4j+Q==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/cliui": {
      "version": "8.0.1",
      "resolved": "https://registry.npmjs.org/cliui/-/cliui-8.0.1.tgz",
      "integrity": "sha512-BSeNnyus75C4//NQ9gQt1/csTXyo/8Sb+afLAkzAptFuMsod9HFokGNudZpi/oQV73hnVK+sR+5PVRMd+Dr7YQ==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "string-width": "^4.2.0",
        "strip-ansi": "^6.0.1",
        "wrap-ansi": "^7.0.0"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/cluster-key-slot": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/cluster-key-slot/-/cluster-key-slot-1.1.2.tgz",
      "integrity": "sha512-RMr0FhtfXemyinomL4hrWcYJxmX6deFdCxpJzhDttxgO1+bcCnkk+9drydLVDmAMG7NE6aN/fl4F7ucU/90gAA==",
      "license": "Apache-2.0",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/co": {
      "version": "4.6.0",
      "resolved": "https://registry.npmjs.org/co/-/co-4.6.0.tgz",
      "integrity": "sha512-QVb0dM5HvG+uaxitm8wONl7jltx8dqhfU33DcqtOZcLSVIKSDDLDi7+0LbAKiyI8hD9u42m2YxXSkMGWThaecQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "iojs": ">= 1.0.0",
        "node": ">= 0.12.0"
      }
    },
    "node_modules/collect-v8-coverage": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/collect-v8-coverage/-/collect-v8-coverage-1.0.2.tgz",
      "integrity": "sha512-lHl4d5/ONEbLlJvaJNtsF/Lz+WvB07u2ycqTYbdrq7UypDXailES4valYb2eWiJFxZlVmpGekfqoxQhzyFdT4Q==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/color": {
      "version": "3.2.1",
      "resolved": "https://registry.npmjs.org/color/-/color-3.2.1.tgz",
      "integrity": "sha512-aBl7dZI9ENN6fUGC7mWpMTPNHmWUSNan9tuWN6ahh5ZLNk9baLJOnSMlrQkHcrfFgz2/RigjUVAjdx36VcemKA==",
      "license": "MIT",
      "dependencies": {
        "color-convert": "^1.9.3",
        "color-string": "^1.6.0"
      }
    },
    "node_modules/color-convert": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/color-convert/-/color-convert-2.0.1.tgz",
      "integrity": "sha512-RRECPsj7iu/xb5oKYcsFHSppFNnsj/52OVTRKb4zP5onXwVF3zVmmToNcOfGC+CRDpfK/U584fMg38ZHCaElKQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "color-name": "~1.1.4"
      },
      "engines": {
        "node": ">=7.0.0"
      }
    },
    "node_modules/color-name": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/color-name/-/color-name-1.1.4.tgz",
      "integrity": "sha512-dOy+3AuW3a2wNbZHIuMZpTcgjGuLU/uBL/ubcZF9OXbDo8ff4O8yVp5Bf0efS8uEoYo5q4Fx7dY9OgQGXgAsQA==",
      "license": "MIT"
    },
    "node_modules/color-string": {
      "version": "1.9.1",
      "resolved": "https://registry.npmjs.org/color-string/-/color-string-1.9.1.tgz",
      "integrity": "sha512-shrVawQFojnZv6xM40anx4CkoDP+fZsw/ZerEMsW/pyzsRbElpsL/DBVW7q3ExxwusdNXI3lXpuhEZkzs8p5Eg==",
      "license": "MIT",
      "dependencies": {
        "color-name": "^1.0.0",
        "simple-swizzle": "^0.2.2"
      }
    },
    "node_modules/color/node_modules/color-convert": {
      "version": "1.9.3",
      "resolved": "https://registry.npmjs.org/color-convert/-/color-convert-1.9.3.tgz",
      "integrity": "sha512-QfAUtd+vFdAtFQcC8CCyYt1fYWxSqAiK2cSD6zDB8N3cpsEBAvRxp9zOGg6G/SHHJYAT88/az/IuDGALsNVbGg==",
      "license": "MIT",
      "dependencies": {
        "color-name": "1.1.3"
      }
    },
    "node_modules/color/node_modules/color-name": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/color-name/-/color-name-1.1.3.tgz",
      "integrity": "sha512-72fSenhMw2HZMTVHeCA9KCmpEIbzWiQsjN+BHcBbS9vr1mtt+vJjPdksIBNUmKAW8TFUDPJK5SUU3QhE9NEXDw==",
      "license": "MIT"
    },
    "node_modules/colorspace": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/colorspace/-/colorspace-1.1.4.tgz",
      "integrity": "sha512-BgvKJiuVu1igBUF2kEjRCZXol6wiiGbY5ipL/oVPwm0BL9sIpMIzM8IK7vwuxIIzOXMV3Ey5w+vxhm0rR/TN8w==",
      "license": "MIT",
      "dependencies": {
        "color": "^3.1.3",
        "text-hex": "1.0.x"
      }
    },
    "node_modules/compressible": {
      "version": "2.0.18",
      "resolved": "https://registry.npmjs.org/compressible/-/compressible-2.0.18.tgz",
      "integrity": "sha512-AF3r7P5dWxL8MxyITRMlORQNaOA2IkAFaTr4k7BUumjPtRpGDTZpl0Pb1XCO6JeDCBdp126Cgs9sMxqSjgYyRg==",
      "license": "MIT",
      "dependencies": {
        "mime-db": ">= 1.43.0 < 2"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/compression": {
      "version": "1.8.0",
      "resolved": "https://registry.npmjs.org/compression/-/compression-1.8.0.tgz",
      "integrity": "sha512-k6WLKfunuqCYD3t6AsuPGvQWaKwuLLh2/xHNcX4qE+vIfDNXpSqnrhwA7O53R7WVQUnt8dVAIW+YHr7xTgOgGA==",
      "license": "MIT",
      "dependencies": {
        "bytes": "3.1.2",
        "compressible": "~2.0.18",
        "debug": "2.6.9",
        "negotiator": "~0.6.4",
        "on-headers": "~1.0.2",
        "safe-buffer": "5.2.1",
        "vary": "~1.1.2"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/concat-map": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/concat-map/-/concat-map-0.0.1.tgz",
      "integrity": "sha512-/Srv4dswyQNBfohGpz9o6Yb3Gz3SrUDqBH5rTuhGR7ahtlbYKnVxw2bCFMRljaA7EXHaXZ8wsHdodFvbkhKmqg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/content-disposition": {
      "version": "0.5.4",
      "resolved": "https://registry.npmjs.org/content-disposition/-/content-disposition-0.5.4.tgz",
      "integrity": "sha512-FveZTNuGw04cxlAiWbzi6zTAL/lhehaWbTtgluJh4/E95DqMwTmha3KZN1aAWA8cFIhHzMZUvLevkw5Rqk+tSQ==",
      "license": "MIT",
      "dependencies": {
        "safe-buffer": "5.2.1"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/content-type": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/content-type/-/content-type-1.0.5.tgz",
      "integrity": "sha512-nTjqfcBFEipKdXCv4YDQWCfmcLZKm81ldF0pAopTvyrFGVbcR6P/VAAd5G7N+0tTr8QqiU0tFadD6FK4NtJwOA==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/convert-source-map": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/convert-source-map/-/convert-source-map-2.0.0.tgz",
      "integrity": "sha512-Kvp459HrV2FEJ1CAsi1Ku+MY3kasH19TFykTz2xWmMeq6bk2NU3XXvfJ+Q61m0xktWwt+1HSYf3JZsTms3aRJg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/cookie": {
      "version": "0.7.1",
      "resolved": "https://registry.npmjs.org/cookie/-/cookie-0.7.1.tgz",
      "integrity": "sha512-6DnInpx7SJ2AK3+CTUE/ZM0vWTUboZCegxhC2xiIydHR9jNuTAASBrfEpHhiGOZw/nX51bHt6YQl8jsGo4y/0w==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/cookie-signature": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/cookie-signature/-/cookie-signature-1.0.6.tgz",
      "integrity": "sha512-QADzlaHc8icV8I7vbaJXJwod9HWYp8uCqf1xa4OfNu1T7JVxQIrUgOWtHdNDtPiywmFbiS12VjotIXLrKM3orQ==",
      "license": "MIT"
    },
    "node_modules/cors": {
      "version": "2.8.5",
      "resolved": "https://registry.npmjs.org/cors/-/cors-2.8.5.tgz",
      "integrity": "sha512-KIHbLJqu73RGr/hnbrO9uBeixNGuvSQjul/jdFvS/KFSIH1hWVd1ng7zOHx+YrEfInLG7q4n6GHQ9cDtxv/P6g==",
      "license": "MIT",
      "dependencies": {
        "object-assign": "^4",
        "vary": "^1"
      },
      "engines": {
        "node": ">= 0.10"
      }
    },
    "node_modules/create-jest": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/create-jest/-/create-jest-29.7.0.tgz",
      "integrity": "sha512-Adz2bdH0Vq3F53KEMJOoftQFutWCukm6J24wbPWRO4k1kMY7gS7ds/uoJkNuV8wDCtWWnuwGcJwpWcih+zEW1Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "chalk": "^4.0.0",
        "exit": "^0.1.2",
        "graceful-fs": "^4.2.9",
        "jest-config": "^29.7.0",
        "jest-util": "^29.7.0",
        "prompts": "^2.0.1"
      },
      "bin": {
        "create-jest": "bin/create-jest.js"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/cross-spawn": {
      "version": "7.0.6",
      "resolved": "https://registry.npmjs.org/cross-spawn/-/cross-spawn-7.0.6.tgz",
      "integrity": "sha512-uV2QOWP2nWzsy2aMp8aRibhi9dlzF5Hgh5SHaB9OiTGEyDTiJJyx0uy51QXdyWbtAHNua4XJzUKca3OzKUd3vA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "path-key": "^3.1.0",
        "shebang-command": "^2.0.0",
        "which": "^2.0.1"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/debug": {
      "version": "2.6.9",
      "resolved": "https://registry.npmjs.org/debug/-/debug-2.6.9.tgz",
      "integrity": "sha512-bC7ElrdJaJnPbAP+1EotYvqZsb3ecl5wi6Bfi6BJTUcNowp6cvspg0jXznRTKDjm/E7AdgFBVeAPVMNcKGsHMA==",
      "license": "MIT",
      "dependencies": {
        "ms": "2.0.0"
      }
    },
    "node_modules/dedent": {
      "version": "1.5.3",
      "resolved": "https://registry.npmjs.org/dedent/-/dedent-1.5.3.tgz",
      "integrity": "sha512-NHQtfOOW68WD8lgypbLA5oT+Bt0xXJhiYvoR6SmmNXZfpzOGXwdKWmcwG8N7PwVVWV3eF/68nmD9BaJSsTBhyQ==",
      "dev": true,
      "license": "MIT",
      "peerDependencies": {
        "babel-plugin-macros": "^3.1.0"
      },
      "peerDependenciesMeta": {
        "babel-plugin-macros": {
          "optional": true
        }
      }
    },
    "node_modules/deepmerge": {
      "version": "4.3.1",
      "resolved": "https://registry.npmjs.org/deepmerge/-/deepmerge-4.3.1.tgz",
      "integrity": "sha512-3sUqbMEc77XqpdNO7FRyRog+eW3ph+GYCbj+rK+uYyRMuwsVy0rMiVtPn+QJlKFvWP/1PYpapqYn0Me2knFn+A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/denque": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/denque/-/denque-2.1.0.tgz",
      "integrity": "sha512-HVQE3AAb/pxF8fQAoiqpvg9i3evqug3hoiwakOyZAwJm+6vZehbkYXZ0l4JxS+I3QxM97v5aaRNhj8v5oBhekw==",
      "license": "Apache-2.0",
      "engines": {
        "node": ">=0.10"
      }
    },
    "node_modules/depd": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/depd/-/depd-2.0.0.tgz",
      "integrity": "sha512-g7nH6P6dyDioJogAAGprGpCtVImJhpPk/roCzdb3fIh61/s/nPsfR6onyMwkCAR/OlC3yBC0lESvUoQEAssIrw==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/destroy": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/destroy/-/destroy-1.2.0.tgz",
      "integrity": "sha512-2sJGJTaXIIaR1w4iJSNoN0hnMY7Gpc/n8D4qSCJw8QqFWXf7cuAgnEHxBpweaVcPevC2l3KpjYCx3NypQQgaJg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.8",
        "npm": "1.2.8000 || >= 1.4.16"
      }
    },
    "node_modules/detect-newline": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/detect-newline/-/detect-newline-3.1.0.tgz",
      "integrity": "sha512-TLz+x/vEXm/Y7P7wn1EJFNLxYpUD4TgMosxY6fAVJUnJMbupHBOncxyWUG9OpTaH9EBD7uFI5LfEgmMOc54DsA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/diff-sequences": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/diff-sequences/-/diff-sequences-29.6.3.tgz",
      "integrity": "sha512-EjePK1srD3P08o2j4f0ExnylqRs5B9tJjcp9t1krH2qRi8CCdsYfwe9JgSLurFBWwq4uOlipzfk5fHNvwFKr8Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/dotenv": {
      "version": "16.4.7",
      "resolved": "https://registry.npmjs.org/dotenv/-/dotenv-16.4.7.tgz",
      "integrity": "sha512-47qPchRCykZC03FhkYAhrvwU4xDBFIj1QPqaarj6mdM/hgUzfPHcpkHJOn3mJAufFeeAxAzeGsr5X0M4k6fLZQ==",
      "license": "BSD-2-Clause",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://dotenvx.com"
      }
    },
    "node_modules/dunder-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/dunder-proto/-/dunder-proto-1.0.1.tgz",
      "integrity": "sha512-KIN/nDJBQRcXw0MLVhZE9iQHmG68qAVIBg9CqmUYjmQIhgij9U5MFvrqkUL5FbtyyzZuOeOt0zdeRe4UY7ct+A==",
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.1",
        "es-errors": "^1.3.0",
        "gopd": "^1.2.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/ecdsa-sig-formatter": {
      "version": "1.0.11",
      "resolved": "https://registry.npmjs.org/ecdsa-sig-formatter/-/ecdsa-sig-formatter-1.0.11.tgz",
      "integrity": "sha512-nagl3RYrbNv6kQkeJIpt6NJZy8twLB/2vtz6yN9Z4vRKHN4/QZJIEbqohALSgwKdnksuY3k5Addp5lg8sVoVcQ==",
      "license": "Apache-2.0",
      "dependencies": {
        "safe-buffer": "^5.0.1"
      }
    },
    "node_modules/ee-first": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/ee-first/-/ee-first-1.1.1.tgz",
      "integrity": "sha512-WMwm9LhRUo+WUaRN+vRuETqG89IgZphVSNkdFgeb6sS/E4OrDIN7t48CAewSHXc6C8lefD8KKfr5vY61brQlow==",
      "license": "MIT"
    },
    "node_modules/electron-to-chromium": {
      "version": "1.5.113",
      "resolved": "https://registry.npmjs.org/electron-to-chromium/-/electron-to-chromium-1.5.113.tgz",
      "integrity": "sha512-wjT2O4hX+wdWPJ76gWSkMhcHAV2PTMX+QetUCPYEdCIe+cxmgzzSSiGRCKW8nuh4mwKZlpv0xvoW7OF2X+wmHg==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/emittery": {
      "version": "0.13.1",
      "resolved": "https://registry.npmjs.org/emittery/-/emittery-0.13.1.tgz",
      "integrity": "sha512-DeWwawk6r5yR9jFgnDKYt4sLS0LmHJJi3ZOnb5/JdbYwj3nW+FxQnHIjhBKz8YLC7oRNPVM9NQ47I3CVx34eqQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sindresorhus/emittery?sponsor=1"
      }
    },
    "node_modules/emoji-regex": {
      "version": "8.0.0",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz",
      "integrity": "sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/enabled": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/enabled/-/enabled-2.0.0.tgz",
      "integrity": "sha512-AKrN98kuwOzMIdAizXGI86UFBoo26CL21UM763y1h/GMSJ4/OHU9k2YlsmBpyScFo/wbLzWQJBMCW4+IO3/+OQ==",
      "license": "MIT"
    },
    "node_modules/encodeurl": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/encodeurl/-/encodeurl-2.0.0.tgz",
      "integrity": "sha512-Q0n9HRi4m6JuGIV1eFlmvJB7ZEVxu93IrMyiMsGC0lrMJMWzRgx6WGquyfQgZVb31vhGgXnfmPNNXmxnOkRBrg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/engine.io": {
      "version": "6.6.4",
      "resolved": "https://registry.npmjs.org/engine.io/-/engine.io-6.6.4.tgz",
      "integrity": "sha512-ZCkIjSYNDyGn0R6ewHDtXgns/Zre/NT6Agvq1/WobF7JXgFff4SeDroKiCO3fNJreU9YG429Sc81o4w5ok/W5g==",
      "license": "MIT",
      "dependencies": {
        "@types/cors": "^2.8.12",
        "@types/node": ">=10.0.0",
        "accepts": "~1.3.4",
        "base64id": "2.0.0",
        "cookie": "~0.7.2",
        "cors": "~2.8.5",
        "debug": "~4.3.1",
        "engine.io-parser": "~5.2.1",
        "ws": "~8.17.1"
      },
      "engines": {
        "node": ">=10.2.0"
      }
    },
    "node_modules/engine.io-parser": {
      "version": "5.2.3",
      "resolved": "https://registry.npmjs.org/engine.io-parser/-/engine.io-parser-5.2.3.tgz",
      "integrity": "sha512-HqD3yTBfnBxIrbnM1DoD6Pcq8NECnh8d4As1Qgh0z5Gg3jRRIqijury0CL3ghu/edArpUYiYqQiDUQBIs4np3Q==",
      "license": "MIT",
      "engines": {
        "node": ">=10.0.0"
      }
    },
    "node_modules/engine.io/node_modules/cookie": {
      "version": "0.7.2",
      "resolved": "https://registry.npmjs.org/cookie/-/cookie-0.7.2.tgz",
      "integrity": "sha512-yki5XnKuf750l50uGTllt6kKILY4nQ1eNIQatoXEByZ5dWgnKqbnqmTrBE5B4N7lrMJKQ2ytWMiTO2o0v6Ew/w==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/engine.io/node_modules/debug": {
      "version": "4.3.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.3.7.tgz",
      "integrity": "sha512-Er2nc/H7RrMXZBFCEim6TCmMk02Z8vLC2Rbi1KEBggpo0fS6l0S1nnapwmIi3yW/+GOJap1Krg4w0Hg80oCqgQ==",
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/engine.io/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "license": "MIT"
    },
    "node_modules/error-ex": {
      "version": "1.3.2",
      "resolved": "https://registry.npmjs.org/error-ex/-/error-ex-1.3.2.tgz",
      "integrity": "sha512-7dFHNmqeFSEt2ZBsCriorKnn3Z2pj+fd9kmI6QoWw4//DL+icEBfc0U7qJCisqrTsKTjw4fNFy2pW9OqStD84g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-arrayish": "^0.2.1"
      }
    },
    "node_modules/es-define-property": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/es-define-property/-/es-define-property-1.0.1.tgz",
      "integrity": "sha512-e3nRfgfUZ4rNGL232gUgX06QNyyez04KdjFrF+LTRoOXmrOgFKDg4BCdsjW8EnT69eqdYGmRpJwiPVYNrCaW3g==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-errors": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/es-errors/-/es-errors-1.3.0.tgz",
      "integrity": "sha512-Zf5H2Kxt2xjTvbJvP2ZWLEICxA6j+hAmMzIlypy4xcBg1vKVnx89Wy0GbS+kf5cwCVFFzdCFh2XSCFNULS6csw==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-object-atoms": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/es-object-atoms/-/es-object-atoms-1.1.1.tgz",
      "integrity": "sha512-FGgH2h8zKNim9ljj7dankFPcICIK9Cp5bm+c2gQSYePhpaG5+esrLODihIorn+Pe6FGJzWhXQotPv73jTaldXA==",
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/escalade": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/escalade/-/escalade-3.2.0.tgz",
      "integrity": "sha512-WUj2qlxaQtO4g6Pq5c29GTcWGDyd8itL8zTlipgECz3JesAiiOKotd8JU6otB3PACgG6xkJUyVhboMS+bje/jA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/escape-html": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/escape-html/-/escape-html-1.0.3.tgz",
      "integrity": "sha512-NiSupZ4OeuGwr68lGIeym/ksIZMJodUGOSCZ/FSnTxcrekbvqrgdUxlJOMpijaKZVjAJrWrGs/6Jy8OMuyj9ow==",
      "license": "MIT"
    },
    "node_modules/escape-string-regexp": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/escape-string-regexp/-/escape-string-regexp-2.0.0.tgz",
      "integrity": "sha512-UpzcLCXolUWcNu5HtVMHYdXJjArjsF9C0aNnquZYY4uW/Vu0miy5YoWvbV345HauVvcAUnpRuhMMcqTcGOY2+w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/esprima": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/esprima/-/esprima-4.0.1.tgz",
      "integrity": "sha512-eGuFFw7Upda+g4p+QHvnW0RyTX/SVeJBDM/gCtMARO0cLuT2HcEKnTPvhjV6aGeqrCB/sbNop0Kszm0jsaWU4A==",
      "dev": true,
      "license": "BSD-2-Clause",
      "bin": {
        "esparse": "bin/esparse.js",
        "esvalidate": "bin/esvalidate.js"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/etag": {
      "version": "1.8.1",
      "resolved": "https://registry.npmjs.org/etag/-/etag-1.8.1.tgz",
      "integrity": "sha512-aIL5Fx7mawVa300al2BnEE4iNvo1qETxLrPI/o05L7z6go7fCw1J6EQmbK4FmJ2AS7kgVF/KEZWufBfdClMcPg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/execa": {
      "version": "5.1.1",
      "resolved": "https://registry.npmjs.org/execa/-/execa-5.1.1.tgz",
      "integrity": "sha512-8uSpZZocAZRBAPIEINJj3Lo9HyGitllczc27Eh5YYojjMFMn8yHMDMaUHE2Jqfq05D/wucwI4JGURyXt1vchyg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "cross-spawn": "^7.0.3",
        "get-stream": "^6.0.0",
        "human-signals": "^2.1.0",
        "is-stream": "^2.0.0",
        "merge-stream": "^2.0.0",
        "npm-run-path": "^4.0.1",
        "onetime": "^5.1.2",
        "signal-exit": "^3.0.3",
        "strip-final-newline": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sindresorhus/execa?sponsor=1"
      }
    },
    "node_modules/exit": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/exit/-/exit-0.1.2.tgz",
      "integrity": "sha512-Zk/eNKV2zbjpKzrsQ+n1G6poVbErQxJ0LBOJXaKZ1EViLzH+hrLu9cdXI4zw9dBQJslwBEpbQ2P1oS7nDxs6jQ==",
      "dev": true,
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/expect": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/expect/-/expect-29.7.0.tgz",
      "integrity": "sha512-2Zks0hf1VLFYI1kbh0I5jP3KHHyCHpkfyHBzsSXRFgl/Bg9mWYfMW8oD+PdMPlEwy5HNsR9JutYy6pMeOh61nw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/expect-utils": "^29.7.0",
        "jest-get-type": "^29.6.3",
        "jest-matcher-utils": "^29.7.0",
        "jest-message-util": "^29.7.0",
        "jest-util": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/express": {
      "version": "4.21.2",
      "resolved": "https://registry.npmjs.org/express/-/express-4.21.2.tgz",
      "integrity": "sha512-28HqgMZAmih1Czt9ny7qr6ek2qddF4FclbMzwhCREB6OFfH+rXAnuNCwo1/wFvrtbgsQDb4kSbX9de9lFbrXnA==",
      "license": "MIT",
      "dependencies": {
        "accepts": "~1.3.8",
        "array-flatten": "1.1.1",
        "body-parser": "1.20.3",
        "content-disposition": "0.5.4",
        "content-type": "~1.0.4",
        "cookie": "0.7.1",
        "cookie-signature": "1.0.6",
        "debug": "2.6.9",
        "depd": "2.0.0",
        "encodeurl": "~2.0.0",
        "escape-html": "~1.0.3",
        "etag": "~1.8.1",
        "finalhandler": "1.3.1",
        "fresh": "0.5.2",
        "http-errors": "2.0.0",
        "merge-descriptors": "1.0.3",
        "methods": "~1.1.2",
        "on-finished": "2.4.1",
        "parseurl": "~1.3.3",
        "path-to-regexp": "0.1.12",
        "proxy-addr": "~2.0.7",
        "qs": "6.13.0",
        "range-parser": "~1.2.1",
        "safe-buffer": "5.2.1",
        "send": "0.19.0",
        "serve-static": "1.16.2",
        "setprototypeof": "1.2.0",
        "statuses": "2.0.1",
        "type-is": "~1.6.18",
        "utils-merge": "1.0.1",
        "vary": "~1.1.2"
      },
      "engines": {
        "node": ">= 0.10.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/express"
      }
    },
    "node_modules/fast-json-stable-stringify": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/fast-json-stable-stringify/-/fast-json-stable-stringify-2.1.0.tgz",
      "integrity": "sha512-lhd/wF+Lk98HZoTCtlVraHtfh5XYijIjalXck7saUtuanSDyLMxnHhSXEDJqHxD7msR8D0uCmqlkwjCV8xvwHw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fb-watchman": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/fb-watchman/-/fb-watchman-2.0.2.tgz",
      "integrity": "sha512-p5161BqbuCaSnB8jIbzQHOlpgsPmK5rJVDfDKO91Axs5NC1uu3HRQm6wt9cd9/+GtQQIO53JdGXXoyDpTAsgYA==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "bser": "2.1.1"
      }
    },
    "node_modules/fecha": {
      "version": "4.2.3",
      "resolved": "https://registry.npmjs.org/fecha/-/fecha-4.2.3.tgz",
      "integrity": "sha512-OP2IUU6HeYKJi3i0z4A19kHMQoLVs4Hc+DPqqxI2h/DPZHTm/vjsfC6P0b4jCMy14XizLBqvndQ+UilD7707Jw==",
      "license": "MIT"
    },
    "node_modules/fill-range": {
      "version": "7.1.1",
      "resolved": "https://registry.npmjs.org/fill-range/-/fill-range-7.1.1.tgz",
      "integrity": "sha512-YsGpe3WHLK8ZYi4tWDg2Jy3ebRz2rXowDxnld4bkQB00cc/1Zw9AWnC0i9ztDJitivtQvaI9KaLyKrc+hBW0yg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "to-regex-range": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/finalhandler": {
      "version": "1.3.1",
      "resolved": "https://registry.npmjs.org/finalhandler/-/finalhandler-1.3.1.tgz",
      "integrity": "sha512-6BN9trH7bp3qvnrRyzsBz+g3lZxTNZTbVO2EV1CS0WIcDbawYVdYvGflME/9QP0h0pYlCDBCTjYa9nZzMDpyxQ==",
      "license": "MIT",
      "dependencies": {
        "debug": "2.6.9",
        "encodeurl": "~2.0.0",
        "escape-html": "~1.0.3",
        "on-finished": "2.4.1",
        "parseurl": "~1.3.3",
        "statuses": "2.0.1",
        "unpipe": "~1.0.0"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/find-up": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/find-up/-/find-up-4.1.0.tgz",
      "integrity": "sha512-PpOwAdQ/YlXQ2vj8a3h8IipDuYRi3wceVQQGYWxNINccq40Anw7BlsEXCMbt1Zt+OLA6Fq9suIpIWD0OsnISlw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "locate-path": "^5.0.0",
        "path-exists": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/fn.name": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/fn.name/-/fn.name-1.1.0.tgz",
      "integrity": "sha512-GRnmB5gPyJpAhTQdSZTSp9uaPSvl09KoYcMQtsB9rQoOmzs9dH6ffeccH+Z+cv6P68Hu5bC6JjRh4Ah/mHSNRw==",
      "license": "MIT"
    },
    "node_modules/forwarded": {
      "version": "0.2.0",
      "resolved": "https://registry.npmjs.org/forwarded/-/forwarded-0.2.0.tgz",
      "integrity": "sha512-buRG0fpBtRHSTCOASe6hD258tEubFoRLb4ZNA6NxMVHNw2gOcwHo9wyablzMzOA5z9xA9L1KNjk/Nt6MT9aYow==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/fresh": {
      "version": "0.5.2",
      "resolved": "https://registry.npmjs.org/fresh/-/fresh-0.5.2.tgz",
      "integrity": "sha512-zJ2mQYM18rEFOudeV4GShTGIQ7RbzA7ozbU9I/XBpm7kqgMywgmylMwXHxZJmkVoYkna9d2pVXVXPdYTP9ej8Q==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/fs.realpath": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/fs.realpath/-/fs.realpath-1.0.0.tgz",
      "integrity": "sha512-OO0pH2lK6a0hZnAdau5ItzHPI6pUlvI7jMVnxUQRtw4owF2wk8lOSabtGDCTP4Ggrg2MbGnWO9X8K1t4+fGMDw==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/fsevents": {
      "version": "2.3.3",
      "resolved": "https://registry.npmjs.org/fsevents/-/fsevents-2.3.3.tgz",
      "integrity": "sha512-5xoDfX+fL7faATnagmWPpbFtwh/R77WmMMqqHGS65C3vvB0YHrgF+B1YmZ3441tMj5n63k0212XNoJwzlhffQw==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": "^8.16.0 || ^10.6.0 || >=11.0.0"
      }
    },
    "node_modules/function-bind": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/function-bind/-/function-bind-1.1.2.tgz",
      "integrity": "sha512-7XHNxH7qX9xG5mIwxkhumTox/MIRNcOgDrxWsMt2pAr23WHp6MrRlN7FBSFpCpr+oVO0F744iUgR82nJMfG2SA==",
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/gensync": {
      "version": "1.0.0-beta.2",
      "resolved": "https://registry.npmjs.org/gensync/-/gensync-1.0.0-beta.2.tgz",
      "integrity": "sha512-3hN7NaskYvMDLQY55gnW3NQ+mesEAepTqlg+VEbj7zzqEMBVNhzcGYYeqFo/TlYz6eQiFcp1HcsCZO+nGgS8zg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/get-caller-file": {
      "version": "2.0.5",
      "resolved": "https://registry.npmjs.org/get-caller-file/-/get-caller-file-2.0.5.tgz",
      "integrity": "sha512-DyFP3BM/3YHTQOCUL/w0OZHR0lpKeGrxotcHWcqNEdnltqFwXVfhEBQ94eIo34AfQpo0rGki4cyIiftY06h2Fg==",
      "dev": true,
      "license": "ISC",
      "engines": {
        "node": "6.* || 8.* || >= 10.*"
      }
    },
    "node_modules/get-intrinsic": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/get-intrinsic/-/get-intrinsic-1.3.0.tgz",
      "integrity": "sha512-9fSjSaos/fRIVIp+xSJlE6lfwhES7LNtKaCBIamHsjr2na1BiABJPo0mOjjz8GJDURarmCPGqaiVg5mfjb98CQ==",
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.2",
        "es-define-property": "^1.0.1",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.1.1",
        "function-bind": "^1.1.2",
        "get-proto": "^1.0.1",
        "gopd": "^1.2.0",
        "has-symbols": "^1.1.0",
        "hasown": "^2.0.2",
        "math-intrinsics": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-package-type": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/get-package-type/-/get-package-type-0.1.0.tgz",
      "integrity": "sha512-pjzuKtY64GYfWizNAJ0fr9VqttZkNiK2iS430LtIHzjBEr6bX8Am2zm4sW4Ro5wjWW5cAlRL1qAMTcXbjNAO2Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8.0.0"
      }
    },
    "node_modules/get-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/get-proto/-/get-proto-1.0.1.tgz",
      "integrity": "sha512-sTSfBjoXBp89JvIKIefqw7U2CCebsc74kiY6awiGogKtoSGbgjYE/G/+l9sF3MWFPNc9IcoOC4ODfKHfxFmp0g==",
      "license": "MIT",
      "dependencies": {
        "dunder-proto": "^1.0.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/get-stream": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/get-stream/-/get-stream-6.0.1.tgz",
      "integrity": "sha512-ts6Wi+2j3jQjqi70w5AlN8DFnkSwC+MqmxEzdEALB2qXZYV3X/b1CTfgPLGJNMeAWxdPfU8FO1ms3NUfaHCPYg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/glob": {
      "version": "7.2.3",
      "resolved": "https://registry.npmjs.org/glob/-/glob-7.2.3.tgz",
      "integrity": "sha512-nFR0zLpU2YCaRxwoCJvL6UvCH2JFyFVIvwTLsIf21AuHlMskA1hhTdk+LlYJtOlYt9v6dvszD2BGRqBL+iQK9Q==",
      "deprecated": "Glob versions prior to v9 are no longer supported",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "fs.realpath": "^1.0.0",
        "inflight": "^1.0.4",
        "inherits": "2",
        "minimatch": "^3.1.1",
        "once": "^1.3.0",
        "path-is-absolute": "^1.0.0"
      },
      "engines": {
        "node": "*"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/glob-parent": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-5.1.2.tgz",
      "integrity": "sha512-AOIgSQCepiJYwP3ARnGx+5VnTu2HBYdzbGP45eLw1vr3zB3vZLeyed1sC9hnbcOc9/SrMyM5RPQrkGz4aS9Zow==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "is-glob": "^4.0.1"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/globals": {
      "version": "11.12.0",
      "resolved": "https://registry.npmjs.org/globals/-/globals-11.12.0.tgz",
      "integrity": "sha512-WOBp/EEGUiIsJSp7wcv/y6MO+lV9UoncWqxuFfm8eBwzWNgyfBd6Gz+IeKQ9jCmyhoH99g15M3T+QaVHFjizVA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/gopd": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/gopd/-/gopd-1.2.0.tgz",
      "integrity": "sha512-ZUKRh6/kUFoAiTAtTYPZJ3hw9wNxx+BIBOijnlG9PnrJsCcSjs1wyyD6vJpaYtgnzDrKYRSqf3OO6Rfa93xsRg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/graceful-fs": {
      "version": "4.2.11",
      "resolved": "https://registry.npmjs.org/graceful-fs/-/graceful-fs-4.2.11.tgz",
      "integrity": "sha512-RbJ5/jmFcNNCcDV5o9eTnBLJ/HszWV0P73bc+Ff4nS/rJj+YaS6IGyiOL0VoBYX+l1Wrl3k63h/KrH+nhJ0XvQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/has-flag": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/has-flag/-/has-flag-4.0.0.tgz",
      "integrity": "sha512-EykJT/Q1KjTWctppgIAgfSO0tKVuZUjhgMr17kqTumMl6Afv3EISleU7qZUzoXDFTAHTDC4NOoG/ZxU3EvlMPQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/has-symbols": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/has-symbols/-/has-symbols-1.1.0.tgz",
      "integrity": "sha512-1cDNdwJ2Jaohmb3sg4OmKaMBwuC48sYni5HUw2DvsC8LjGTLK9h+eb1X6RyuOHe4hT0ULCW68iomhjUoKUqlPQ==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/hasown": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/hasown/-/hasown-2.0.2.tgz",
      "integrity": "sha512-0hJU9SCPvmMzIBdZFqNPXWa6dqh7WdH0cII9y+CyS8rG3nL48Bclra9HmKhVVUHyPWNH5Y7xDwAB7bfgSjkUMQ==",
      "license": "MIT",
      "dependencies": {
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/helmet": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/helmet/-/helmet-7.2.0.tgz",
      "integrity": "sha512-ZRiwvN089JfMXokizgqEPXsl2Guk094yExfoDXR0cBYWxtBbaSww/w+vT4WEJsBW2iTUi1GgZ6swmoug3Oy4Xw==",
      "license": "MIT",
      "engines": {
        "node": ">=16.0.0"
      }
    },
    "node_modules/html-escaper": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/html-escaper/-/html-escaper-2.0.2.tgz",
      "integrity": "sha512-H2iMtd0I4Mt5eYiapRdIDjp+XzelXQ0tFE4JS7YFwFevXXMmOp9myNrUvCg0D6ws8iqkRPBfKHgbwig1SmlLfg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/http-errors": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/http-errors/-/http-errors-2.0.0.tgz",
      "integrity": "sha512-FtwrG/euBzaEjYeRqOgly7G0qviiXoJWnvEH2Z1plBdXgbyjv34pHTSb9zoeHMyDy33+DWy5Wt9Wo+TURtOYSQ==",
      "license": "MIT",
      "dependencies": {
        "depd": "2.0.0",
        "inherits": "2.0.4",
        "setprototypeof": "1.2.0",
        "statuses": "2.0.1",
        "toidentifier": "1.0.1"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/human-signals": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/human-signals/-/human-signals-2.1.0.tgz",
      "integrity": "sha512-B4FFZ6q/T2jhhksgkbEW3HBvWIfDW85snkQgawt07S7J5QXTk6BkNV+0yAeZrM5QpMAdYlocGoljn0sJ/WQkFw==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">=10.17.0"
      }
    },
    "node_modules/iconv-lite": {
      "version": "0.4.24",
      "resolved": "https://registry.npmjs.org/iconv-lite/-/iconv-lite-0.4.24.tgz",
      "integrity": "sha512-v3MXnZAcvnywkTUEZomIActle7RXXeedOR31wwl7VlyoXO4Qi9arvSenNQWne1TcRwhCL1HwLI21bEqdpj8/rA==",
      "license": "MIT",
      "dependencies": {
        "safer-buffer": ">= 2.1.2 < 3"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/ignore-by-default": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/ignore-by-default/-/ignore-by-default-1.0.1.tgz",
      "integrity": "sha512-Ius2VYcGNk7T90CppJqcIkS5ooHUZyIQK+ClZfMfMNFEF9VSE73Fq+906u/CWu92x4gzZMWOwfFYckPObzdEbA==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/import-local": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/import-local/-/import-local-3.2.0.tgz",
      "integrity": "sha512-2SPlun1JUPWoM6t3F0dw0FkCF/jWY8kttcY4f599GLTSjh2OCuuhdTkJQsEcZzBqbXZGKMK2OqW1oZsjtf/gQA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "pkg-dir": "^4.2.0",
        "resolve-cwd": "^3.0.0"
      },
      "bin": {
        "import-local-fixture": "fixtures/cli.js"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/imurmurhash": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/imurmurhash/-/imurmurhash-0.1.4.tgz",
      "integrity": "sha512-JmXMZ6wuvDmLiHEml9ykzqO6lwFbof0GG4IkcGaENdCRDDmMVnny7s5HsIgHCbaq0w2MyPhDqkhTUgS2LU2PHA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.8.19"
      }
    },
    "node_modules/inflight": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/inflight/-/inflight-1.0.6.tgz",
      "integrity": "sha512-k92I/b08q4wvFscXCLvqfsHCrjrF7yiXsQuIVvVE7N82W3+aqpzuUdBbfhWcy/FZR3/4IgflMgKLOsvPDrGCJA==",
      "deprecated": "This module is not supported, and leaks memory. Do not use it. Check out lru-cache if you want a good and tested way to coalesce async requests by a key value, which is much more comprehensive and powerful.",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "once": "^1.3.0",
        "wrappy": "1"
      }
    },
    "node_modules/inherits": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/inherits/-/inherits-2.0.4.tgz",
      "integrity": "sha512-k/vGaX4/Yla3WzyMCvTQOXYeIHvqOKtnqBduzTHpzpQZzAskKMhZ2K+EnBiSM9zGSoIFeMpXKxa4dYeZIQqewQ==",
      "license": "ISC"
    },
    "node_modules/ioredis": {
      "version": "5.6.0",
      "resolved": "https://registry.npmjs.org/ioredis/-/ioredis-5.6.0.tgz",
      "integrity": "sha512-tBZlIIWbndeWBWCXWZiqtOF/yxf6yZX3tAlTJ7nfo5jhd6dctNxF7QnYlZLZ1a0o0pDoen7CgZqO+zjNaFbJAg==",
      "license": "MIT",
      "dependencies": {
        "@ioredis/commands": "^1.1.1",
        "cluster-key-slot": "^1.1.0",
        "debug": "^4.3.4",
        "denque": "^2.1.0",
        "lodash.defaults": "^4.2.0",
        "lodash.isarguments": "^3.1.0",
        "redis-errors": "^1.2.0",
        "redis-parser": "^3.0.0",
        "standard-as-callback": "^2.1.0"
      },
      "engines": {
        "node": ">=12.22.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/ioredis"
      }
    },
    "node_modules/ioredis/node_modules/debug": {
      "version": "4.4.0",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.4.0.tgz",
      "integrity": "sha512-6WTZ/IxCY/T6BALoZHaE4ctp9xm+Z5kY/pzYaCHRFeyVhojxlrm+46y68HA6hr0TcwEssoxNiDEUJQjfPZ/RYA==",
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/ioredis/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "license": "MIT"
    },
    "node_modules/ipaddr.js": {
      "version": "1.9.1",
      "resolved": "https://registry.npmjs.org/ipaddr.js/-/ipaddr.js-1.9.1.tgz",
      "integrity": "sha512-0KI/607xoxSToH7GjN1FfSbLoU0+btTicjsQSWQlh/hZykN8KpmMf7uYwPW3R+akZ6R/w18ZlXSHBYXiYUPO3g==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.10"
      }
    },
    "node_modules/is-arrayish": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/is-arrayish/-/is-arrayish-0.2.1.tgz",
      "integrity": "sha512-zz06S8t0ozoDXMG+ube26zeCTNXcKIPJZJi8hBrF4idCLms4CG9QtK7qBl1boi5ODzFpjswb5JPmHCbMpjaYzg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/is-binary-path": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/is-binary-path/-/is-binary-path-2.1.0.tgz",
      "integrity": "sha512-ZMERYes6pDydyuGidse7OsHxtbI7WVeUEozgR/g7rd0xUimYNlvZRE/K2MgZTjWy725IfelLeVcEM97mmtRGXw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "binary-extensions": "^2.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-core-module": {
      "version": "2.16.1",
      "resolved": "https://registry.npmjs.org/is-core-module/-/is-core-module-2.16.1.tgz",
      "integrity": "sha512-UfoeMA6fIJ8wTYFEUjelnaGI67v6+N7qXJEvQuIGa99l4xsCruSYOVSQ0uPANn4dAzm8lkYPaKLrrijLq7x23w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-extglob": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/is-extglob/-/is-extglob-2.1.1.tgz",
      "integrity": "sha512-SbKbANkN603Vi4jEZv49LeVJMn4yGwsbzZworEoyEiutsN3nJYdbO36zfhGJ6QEDpOZIFkDtnq5JRxmvl3jsoQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/is-fullwidth-code-point": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/is-fullwidth-code-point/-/is-fullwidth-code-point-3.0.0.tgz",
      "integrity": "sha512-zymm5+u+sCsSWyD9qNaejV3DFvhCKclKdizYaJUuHA83RLjb7nSuGnddCHGv0hk+KY7BMAlsWeK4Ueg6EV6XQg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-generator-fn": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/is-generator-fn/-/is-generator-fn-2.1.0.tgz",
      "integrity": "sha512-cTIB4yPYL/Grw0EaSzASzg6bBy9gqCofvWN8okThAYIxKJZC+udlRAmGbM0XLeniEJSs8uEgHPGuHSe1XsOLSQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/is-glob": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/is-glob/-/is-glob-4.0.3.tgz",
      "integrity": "sha512-xelSayHH36ZgE7ZWhli7pW34hNbNl8Ojv5KVmkJD4hBdD3th8Tfk9vYasLM+mXWOZhFkgZfxhLSnrwRr4elSSg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-extglob": "^2.1.1"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/is-number": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/is-number/-/is-number-7.0.0.tgz",
      "integrity": "sha512-41Cifkg6e8TylSpdtTpeLVMqvSBEVzTttHvERD741+pnZ8ANv0004MRL43QKPDlK9cGvNp6NZWZUBlbGXYxxng==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.12.0"
      }
    },
    "node_modules/is-stream": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/is-stream/-/is-stream-2.0.1.tgz",
      "integrity": "sha512-hFoiJiTl63nn+kstHGBtewWSKnQLpyb155KHheA1l39uvtO9nWIop1p3udqPcUd/xbF1VLMO4n7OI6p7RbngDg==",
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/isexe": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/isexe/-/isexe-2.0.0.tgz",
      "integrity": "sha512-RHxMLp9lnKHGHRng9QFhRCMbYAcVpn69smSGcq3f36xjgVVWThj4qqLbTLlq7Ssj8B+fIQ1EuCEGI2lKsyQeIw==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/istanbul-lib-coverage": {
      "version": "3.2.2",
      "resolved": "https://registry.npmjs.org/istanbul-lib-coverage/-/istanbul-lib-coverage-3.2.2.tgz",
      "integrity": "sha512-O8dpsF+r0WV/8MNRKfnmrtCWhuKjxrq2w+jpzBL5UZKTi2LeVWnWOmWRxFlesJONmc+wLAGvKQZEOanko0LFTg==",
      "dev": true,
      "license": "BSD-3-Clause",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/istanbul-lib-instrument": {
      "version": "6.0.3",
      "resolved": "https://registry.npmjs.org/istanbul-lib-instrument/-/istanbul-lib-instrument-6.0.3.tgz",
      "integrity": "sha512-Vtgk7L/R2JHyyGW07spoFlB8/lpjiOLTjMdms6AFMraYt3BaJauod/NGrfnVG/y4Ix1JEuMRPDPEj2ua+zz1/Q==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "@babel/core": "^7.23.9",
        "@babel/parser": "^7.23.9",
        "@istanbuljs/schema": "^0.1.3",
        "istanbul-lib-coverage": "^3.2.0",
        "semver": "^7.5.4"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/istanbul-lib-instrument/node_modules/semver": {
      "version": "7.7.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-7.7.1.tgz",
      "integrity": "sha512-hlq8tAfn0m/61p4BVRcPzIGr6LKiMwo4VM6dGi6pt4qcRkmNzTcWq6eCEjEh+qXjkMDvPlOFFSGwQjoEa6gyMA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/istanbul-lib-report": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/istanbul-lib-report/-/istanbul-lib-report-3.0.1.tgz",
      "integrity": "sha512-GCfE1mtsHGOELCU8e/Z7YWzpmybrx/+dSTfLrvY8qRmaY6zXTKWn6WQIjaAFw069icm6GVMNkgu0NzI4iPZUNw==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "istanbul-lib-coverage": "^3.0.0",
        "make-dir": "^4.0.0",
        "supports-color": "^7.1.0"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/istanbul-lib-source-maps": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/istanbul-lib-source-maps/-/istanbul-lib-source-maps-4.0.1.tgz",
      "integrity": "sha512-n3s8EwkdFIJCG3BPKBYvskgXGoy88ARzvegkitk60NxRdwltLOTaH7CUiMRXvwYorl0Q712iEjcWB+fK/MrWVw==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "debug": "^4.1.1",
        "istanbul-lib-coverage": "^3.0.0",
        "source-map": "^0.6.1"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/istanbul-lib-source-maps/node_modules/debug": {
      "version": "4.4.0",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.4.0.tgz",
      "integrity": "sha512-6WTZ/IxCY/T6BALoZHaE4ctp9xm+Z5kY/pzYaCHRFeyVhojxlrm+46y68HA6hr0TcwEssoxNiDEUJQjfPZ/RYA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/istanbul-lib-source-maps/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/istanbul-reports": {
      "version": "3.1.7",
      "resolved": "https://registry.npmjs.org/istanbul-reports/-/istanbul-reports-3.1.7.tgz",
      "integrity": "sha512-BewmUXImeuRk2YY0PVbxgKAysvhRPUQE0h5QRM++nVWyubKGV0l8qQ5op8+B2DOmwSe63Jivj0BjkPQVf8fP5g==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "html-escaper": "^2.0.0",
        "istanbul-lib-report": "^3.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/jest": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest/-/jest-29.7.0.tgz",
      "integrity": "sha512-NIy3oAFp9shda19hy4HK0HRTWKtPJmGdnvywu01nOqNC2vZg+Z+fvJDxpMQA88eb2I9EcafcdjYgsDthnYTvGw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/core": "^29.7.0",
        "@jest/types": "^29.6.3",
        "import-local": "^3.0.2",
        "jest-cli": "^29.7.0"
      },
      "bin": {
        "jest": "bin/jest.js"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "node-notifier": "^8.0.1 || ^9.0.0 || ^10.0.0"
      },
      "peerDependenciesMeta": {
        "node-notifier": {
          "optional": true
        }
      }
    },
    "node_modules/jest-changed-files": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-changed-files/-/jest-changed-files-29.7.0.tgz",
      "integrity": "sha512-fEArFiwf1BpQ+4bXSprcDc3/x4HSzL4al2tozwVpDFpsxALjLYdyiIK4e5Vz66GQJIbXJ82+35PtysofptNX2w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "execa": "^5.0.0",
        "jest-util": "^29.7.0",
        "p-limit": "^3.1.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-circus": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-circus/-/jest-circus-29.7.0.tgz",
      "integrity": "sha512-3E1nCMgipcTkCocFwM90XXQab9bS+GMsjdpmPrlelaxwD93Ad8iVEjX/vvHPdLPnFf+L40u+5+iutRdA1N9myw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/environment": "^29.7.0",
        "@jest/expect": "^29.7.0",
        "@jest/test-result": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "chalk": "^4.0.0",
        "co": "^4.6.0",
        "dedent": "^1.0.0",
        "is-generator-fn": "^2.0.0",
        "jest-each": "^29.7.0",
        "jest-matcher-utils": "^29.7.0",
        "jest-message-util": "^29.7.0",
        "jest-runtime": "^29.7.0",
        "jest-snapshot": "^29.7.0",
        "jest-util": "^29.7.0",
        "p-limit": "^3.1.0",
        "pretty-format": "^29.7.0",
        "pure-rand": "^6.0.0",
        "slash": "^3.0.0",
        "stack-utils": "^2.0.3"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-cli": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-cli/-/jest-cli-29.7.0.tgz",
      "integrity": "sha512-OVVobw2IubN/GSYsxETi+gOe7Ka59EFMR/twOU3Jb2GnKKeMGJB5SGUUrEz3SFVmJASUdZUzy83sLNNQ2gZslg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/core": "^29.7.0",
        "@jest/test-result": "^29.7.0",
        "@jest/types": "^29.6.3",
        "chalk": "^4.0.0",
        "create-jest": "^29.7.0",
        "exit": "^0.1.2",
        "import-local": "^3.0.2",
        "jest-config": "^29.7.0",
        "jest-util": "^29.7.0",
        "jest-validate": "^29.7.0",
        "yargs": "^17.3.1"
      },
      "bin": {
        "jest": "bin/jest.js"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "node-notifier": "^8.0.1 || ^9.0.0 || ^10.0.0"
      },
      "peerDependenciesMeta": {
        "node-notifier": {
          "optional": true
        }
      }
    },
    "node_modules/jest-config": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-config/-/jest-config-29.7.0.tgz",
      "integrity": "sha512-uXbpfeQ7R6TZBqI3/TxCU4q4ttk3u0PJeC+E0zbfSoSjq6bJ7buBPxzQPL0ifrkY4DNu4JUdk0ImlBUYi840eQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/core": "^7.11.6",
        "@jest/test-sequencer": "^29.7.0",
        "@jest/types": "^29.6.3",
        "babel-jest": "^29.7.0",
        "chalk": "^4.0.0",
        "ci-info": "^3.2.0",
        "deepmerge": "^4.2.2",
        "glob": "^7.1.3",
        "graceful-fs": "^4.2.9",
        "jest-circus": "^29.7.0",
        "jest-environment-node": "^29.7.0",
        "jest-get-type": "^29.6.3",
        "jest-regex-util": "^29.6.3",
        "jest-resolve": "^29.7.0",
        "jest-runner": "^29.7.0",
        "jest-util": "^29.7.0",
        "jest-validate": "^29.7.0",
        "micromatch": "^4.0.4",
        "parse-json": "^5.2.0",
        "pretty-format": "^29.7.0",
        "slash": "^3.0.0",
        "strip-json-comments": "^3.1.1"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "@types/node": "*",
        "ts-node": ">=9.0.0"
      },
      "peerDependenciesMeta": {
        "@types/node": {
          "optional": true
        },
        "ts-node": {
          "optional": true
        }
      }
    },
    "node_modules/jest-diff": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-diff/-/jest-diff-29.7.0.tgz",
      "integrity": "sha512-LMIgiIrhigmPrs03JHpxUh2yISK3vLFPkAodPeo0+BuF7wA2FoQbkEg1u8gBYBThncu7e1oEDUfIXVuTqLRUjw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "chalk": "^4.0.0",
        "diff-sequences": "^29.6.3",
        "jest-get-type": "^29.6.3",
        "pretty-format": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-docblock": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-docblock/-/jest-docblock-29.7.0.tgz",
      "integrity": "sha512-q617Auw3A612guyaFgsbFeYpNP5t2aoUNLwBUbc/0kD1R4t9ixDbyFTHd1nok4epoVFpr7PmeWHrhvuV3XaJ4g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "detect-newline": "^3.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-each": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-each/-/jest-each-29.7.0.tgz",
      "integrity": "sha512-gns+Er14+ZrEoC5fhOfYCY1LOHHr0TI+rQUHZS8Ttw2l7gl+80eHc/gFf2Ktkw0+SIACDTeWvpFcv3B04VembQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "chalk": "^4.0.0",
        "jest-get-type": "^29.6.3",
        "jest-util": "^29.7.0",
        "pretty-format": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-environment-node": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-environment-node/-/jest-environment-node-29.7.0.tgz",
      "integrity": "sha512-DOSwCRqXirTOyheM+4d5YZOrWcdu0LNZ87ewUoywbcb2XR4wKgqiG8vNeYwhjFMbEkfju7wx2GYH0P2gevGvFw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/environment": "^29.7.0",
        "@jest/fake-timers": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "jest-mock": "^29.7.0",
        "jest-util": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-get-type": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/jest-get-type/-/jest-get-type-29.6.3.tgz",
      "integrity": "sha512-zrteXnqYxfQh7l5FHyL38jL39di8H8rHoecLH3JNxH3BwOrBsNeabdap5e0I23lD4HHI8W5VFBZqG4Eaq5LNcw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-haste-map": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-haste-map/-/jest-haste-map-29.7.0.tgz",
      "integrity": "sha512-fP8u2pyfqx0K1rGn1R9pyE0/KTn+G7PxktWidOBTqFPLYX0b9ksaMFkhK5vrS3DVun09pckLdlx90QthlW7AmA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "@types/graceful-fs": "^4.1.3",
        "@types/node": "*",
        "anymatch": "^3.0.3",
        "fb-watchman": "^2.0.0",
        "graceful-fs": "^4.2.9",
        "jest-regex-util": "^29.6.3",
        "jest-util": "^29.7.0",
        "jest-worker": "^29.7.0",
        "micromatch": "^4.0.4",
        "walker": "^1.0.8"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "optionalDependencies": {
        "fsevents": "^2.3.2"
      }
    },
    "node_modules/jest-leak-detector": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-leak-detector/-/jest-leak-detector-29.7.0.tgz",
      "integrity": "sha512-kYA8IJcSYtST2BY9I+SMC32nDpBT3J2NvWJx8+JCuCdl/CR1I4EKUJROiP8XtCcxqgTTBGJNdbB1A8XRKbTetw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "jest-get-type": "^29.6.3",
        "pretty-format": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-matcher-utils": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-matcher-utils/-/jest-matcher-utils-29.7.0.tgz",
      "integrity": "sha512-sBkD+Xi9DtcChsI3L3u0+N0opgPYnCRPtGcQYrgXmR+hmt/fYfWAL0xRXYU8eWOdfuLgBe0YCW3AFtnRLagq/g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "chalk": "^4.0.0",
        "jest-diff": "^29.7.0",
        "jest-get-type": "^29.6.3",
        "pretty-format": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-message-util": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-message-util/-/jest-message-util-29.7.0.tgz",
      "integrity": "sha512-GBEV4GRADeP+qtB2+6u61stea8mGcOT4mCtrYISZwfu9/ISHFJ/5zOMXYbpBE9RsS5+Gb63DW4FgmnKJ79Kf6w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/code-frame": "^7.12.13",
        "@jest/types": "^29.6.3",
        "@types/stack-utils": "^2.0.0",
        "chalk": "^4.0.0",
        "graceful-fs": "^4.2.9",
        "micromatch": "^4.0.4",
        "pretty-format": "^29.7.0",
        "slash": "^3.0.0",
        "stack-utils": "^2.0.3"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-mock": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-mock/-/jest-mock-29.7.0.tgz",
      "integrity": "sha512-ITOMZn+UkYS4ZFh83xYAOzWStloNzJFO2s8DWrE4lhtGD+AorgnbkiKERe4wQVBydIGPx059g6riW5Btp6Llnw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "jest-util": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-pnp-resolver": {
      "version": "1.2.3",
      "resolved": "https://registry.npmjs.org/jest-pnp-resolver/-/jest-pnp-resolver-1.2.3.tgz",
      "integrity": "sha512-+3NpwQEnRoIBtx4fyhblQDPgJI0H1IEIkX7ShLUjPGA7TtUTvI1oiKi3SR4oBR0hQhQR80l4WAe5RrXBwWMA8w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      },
      "peerDependencies": {
        "jest-resolve": "*"
      },
      "peerDependenciesMeta": {
        "jest-resolve": {
          "optional": true
        }
      }
    },
    "node_modules/jest-regex-util": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/jest-regex-util/-/jest-regex-util-29.6.3.tgz",
      "integrity": "sha512-KJJBsRCyyLNWCNBOvZyRDnAIfUiRJ8v+hOBQYGn8gDyF3UegwiP4gwRR3/SDa42g1YbVycTidUF3rKjyLFDWbg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-resolve": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-resolve/-/jest-resolve-29.7.0.tgz",
      "integrity": "sha512-IOVhZSrg+UvVAshDSDtHyFCCBUl/Q3AAJv8iZ6ZjnZ74xzvwuzLXid9IIIPgTnY62SJjfuupMKZsZQRsCvxEgA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "chalk": "^4.0.0",
        "graceful-fs": "^4.2.9",
        "jest-haste-map": "^29.7.0",
        "jest-pnp-resolver": "^1.2.2",
        "jest-util": "^29.7.0",
        "jest-validate": "^29.7.0",
        "resolve": "^1.20.0",
        "resolve.exports": "^2.0.0",
        "slash": "^3.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-resolve-dependencies": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-resolve-dependencies/-/jest-resolve-dependencies-29.7.0.tgz",
      "integrity": "sha512-un0zD/6qxJ+S0et7WxeI3H5XSe9lTBBR7bOHCHXkKR6luG5mwDDlIzVQ0V5cZCuoTgEdcdwzTghYkTWfubi+nA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "jest-regex-util": "^29.6.3",
        "jest-snapshot": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-runner": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-runner/-/jest-runner-29.7.0.tgz",
      "integrity": "sha512-fsc4N6cPCAahybGBfTRcq5wFR6fpLznMg47sY5aDpsoejOcVYFb07AHuSnR0liMcPTgBsA3ZJL6kFOjPdoNipQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/console": "^29.7.0",
        "@jest/environment": "^29.7.0",
        "@jest/test-result": "^29.7.0",
        "@jest/transform": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "chalk": "^4.0.0",
        "emittery": "^0.13.1",
        "graceful-fs": "^4.2.9",
        "jest-docblock": "^29.7.0",
        "jest-environment-node": "^29.7.0",
        "jest-haste-map": "^29.7.0",
        "jest-leak-detector": "^29.7.0",
        "jest-message-util": "^29.7.0",
        "jest-resolve": "^29.7.0",
        "jest-runtime": "^29.7.0",
        "jest-util": "^29.7.0",
        "jest-watcher": "^29.7.0",
        "jest-worker": "^29.7.0",
        "p-limit": "^3.1.0",
        "source-map-support": "0.5.13"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-runtime": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-runtime/-/jest-runtime-29.7.0.tgz",
      "integrity": "sha512-gUnLjgwdGqW7B4LvOIkbKs9WGbn+QLqRQQ9juC6HndeDiezIwhDP+mhMwHWCEcfQ5RUXa6OPnFF8BJh5xegwwQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/environment": "^29.7.0",
        "@jest/fake-timers": "^29.7.0",
        "@jest/globals": "^29.7.0",
        "@jest/source-map": "^29.6.3",
        "@jest/test-result": "^29.7.0",
        "@jest/transform": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "chalk": "^4.0.0",
        "cjs-module-lexer": "^1.0.0",
        "collect-v8-coverage": "^1.0.0",
        "glob": "^7.1.3",
        "graceful-fs": "^4.2.9",
        "jest-haste-map": "^29.7.0",
        "jest-message-util": "^29.7.0",
        "jest-mock": "^29.7.0",
        "jest-regex-util": "^29.6.3",
        "jest-resolve": "^29.7.0",
        "jest-snapshot": "^29.7.0",
        "jest-util": "^29.7.0",
        "slash": "^3.0.0",
        "strip-bom": "^4.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-snapshot": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-snapshot/-/jest-snapshot-29.7.0.tgz",
      "integrity": "sha512-Rm0BMWtxBcioHr1/OX5YCP8Uov4riHvKPknOGs804Zg9JGZgmIBkbtlxJC/7Z4msKYVbIJtfU+tKb8xlYNfdkw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/core": "^7.11.6",
        "@babel/generator": "^7.7.2",
        "@babel/plugin-syntax-jsx": "^7.7.2",
        "@babel/plugin-syntax-typescript": "^7.7.2",
        "@babel/types": "^7.3.3",
        "@jest/expect-utils": "^29.7.0",
        "@jest/transform": "^29.7.0",
        "@jest/types": "^29.6.3",
        "babel-preset-current-node-syntax": "^1.0.0",
        "chalk": "^4.0.0",
        "expect": "^29.7.0",
        "graceful-fs": "^4.2.9",
        "jest-diff": "^29.7.0",
        "jest-get-type": "^29.6.3",
        "jest-matcher-utils": "^29.7.0",
        "jest-message-util": "^29.7.0",
        "jest-util": "^29.7.0",
        "natural-compare": "^1.4.0",
        "pretty-format": "^29.7.0",
        "semver": "^7.5.3"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-snapshot/node_modules/semver": {
      "version": "7.7.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-7.7.1.tgz",
      "integrity": "sha512-hlq8tAfn0m/61p4BVRcPzIGr6LKiMwo4VM6dGi6pt4qcRkmNzTcWq6eCEjEh+qXjkMDvPlOFFSGwQjoEa6gyMA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/jest-util": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-util/-/jest-util-29.7.0.tgz",
      "integrity": "sha512-z6EbKajIpqGKU56y5KBUgy1dt1ihhQJgWzUlZHArA/+X2ad7Cb5iF+AK1EWVL/Bo7Rz9uurpqw6SiBCefUbCGA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "chalk": "^4.0.0",
        "ci-info": "^3.2.0",
        "graceful-fs": "^4.2.9",
        "picomatch": "^2.2.3"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-validate": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-validate/-/jest-validate-29.7.0.tgz",
      "integrity": "sha512-ZB7wHqaRGVw/9hST/OuFUReG7M8vKeq0/J2egIGLdvjHCmYqGARhzXmtgi+gVeZ5uXFF219aOc3Ls2yLg27tkw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "camelcase": "^6.2.0",
        "chalk": "^4.0.0",
        "jest-get-type": "^29.6.3",
        "leven": "^3.1.0",
        "pretty-format": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-validate/node_modules/camelcase": {
      "version": "6.3.0",
      "resolved": "https://registry.npmjs.org/camelcase/-/camelcase-6.3.0.tgz",
      "integrity": "sha512-Gmy6FhYlCY7uOElZUSbxo2UCDH8owEk996gkbrpsgGtrJLM3J7jGxl9Ic7Qwwj4ivOE5AWZWRMecDdF7hqGjFA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/jest-watcher": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-watcher/-/jest-watcher-29.7.0.tgz",
      "integrity": "sha512-49Fg7WXkU3Vl2h6LbLtMQ/HyB6rXSIX7SqvBLQmssRBGN9I0PNvPmAmCWSOY6SOvrjhI/F7/bGAv9RtnsPA03g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/test-result": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "ansi-escapes": "^4.2.1",
        "chalk": "^4.0.0",
        "emittery": "^0.13.1",
        "jest-util": "^29.7.0",
        "string-length": "^4.0.1"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-worker": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-worker/-/jest-worker-29.7.0.tgz",
      "integrity": "sha512-eIz2msL/EzL9UFTFFx7jBTkeZfku0yUAyZZZmJ93H2TYEiroIx2PQjEXcwYtYl8zXCxb+PAmA2hLIt/6ZEkPHw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/node": "*",
        "jest-util": "^29.7.0",
        "merge-stream": "^2.0.0",
        "supports-color": "^8.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-worker/node_modules/supports-color": {
      "version": "8.1.1",
      "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-8.1.1.tgz",
      "integrity": "sha512-MpUEN2OodtUzxvKQl72cUF7RQ5EiHsGvSsVG0ia9c5RbWGL2CI4C7EpPS8UTBIplnlzZiNuV56w+FuNxy3ty2Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "has-flag": "^4.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/supports-color?sponsor=1"
      }
    },
    "node_modules/js-tokens": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/js-tokens/-/js-tokens-4.0.0.tgz",
      "integrity": "sha512-RdJUflcE3cUzKiMqQgsCu06FPu9UdIJO0beYbPhHN4k6apgJtifcoCtT9bcxOpYBtpD2kCM6Sbzg4CausW/PKQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/js-yaml": {
      "version": "3.14.1",
      "resolved": "https://registry.npmjs.org/js-yaml/-/js-yaml-3.14.1.tgz",
      "integrity": "sha512-okMH7OXXJ7YrN9Ok3/SXrnu4iX9yOk+25nqX4imS2npuvTYDmo/QEZoqwZkYaIDk3jVvBOTOIEgEhaLOynBS9g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "argparse": "^1.0.7",
        "esprima": "^4.0.0"
      },
      "bin": {
        "js-yaml": "bin/js-yaml.js"
      }
    },
    "node_modules/jsesc": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/jsesc/-/jsesc-3.1.0.tgz",
      "integrity": "sha512-/sM3dO2FOzXjKQhJuo0Q173wf2KOo8t4I8vHy6lF9poUp7bKT0/NHE8fPX23PwfhnykfqnC2xRxOnVw5XuGIaA==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "jsesc": "bin/jsesc"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/json-parse-even-better-errors": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/json-parse-even-better-errors/-/json-parse-even-better-errors-2.3.1.tgz",
      "integrity": "sha512-xyFwyhro/JEof6Ghe2iz2NcXoj2sloNsWr/XsERDK/oiPCfaNhl5ONfp+jQdAZRQQ0IJWNzH9zIZF7li91kh2w==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json5": {
      "version": "2.2.3",
      "resolved": "https://registry.npmjs.org/json5/-/json5-2.2.3.tgz",
      "integrity": "sha512-XmOWe7eyHYH14cLdVPoyg+GOH3rYX++KpzrylJwSW98t3Nk+U8XOl8FWKOgwtzdb8lXGf6zYwDUzeHMWfxasyg==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "json5": "lib/cli.js"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/jsonwebtoken": {
      "version": "9.0.2",
      "resolved": "https://registry.npmjs.org/jsonwebtoken/-/jsonwebtoken-9.0.2.tgz",
      "integrity": "sha512-PRp66vJ865SSqOlgqS8hujT5U4AOgMfhrwYIuIhfKaoSCZcirrmASQr8CX7cUg+RMih+hgznrjp99o+W4pJLHQ==",
      "license": "MIT",
      "dependencies": {
        "jws": "^3.2.2",
        "lodash.includes": "^4.3.0",
        "lodash.isboolean": "^3.0.3",
        "lodash.isinteger": "^4.0.4",
        "lodash.isnumber": "^3.0.3",
        "lodash.isplainobject": "^4.0.6",
        "lodash.isstring": "^4.0.1",
        "lodash.once": "^4.0.0",
        "ms": "^2.1.1",
        "semver": "^7.5.4"
      },
      "engines": {
        "node": ">=12",
        "npm": ">=6"
      }
    },
    "node_modules/jsonwebtoken/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "license": "MIT"
    },
    "node_modules/jsonwebtoken/node_modules/semver": {
      "version": "7.7.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-7.7.1.tgz",
      "integrity": "sha512-hlq8tAfn0m/61p4BVRcPzIGr6LKiMwo4VM6dGi6pt4qcRkmNzTcWq6eCEjEh+qXjkMDvPlOFFSGwQjoEa6gyMA==",
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/jwa": {
      "version": "1.4.1",
      "resolved": "https://registry.npmjs.org/jwa/-/jwa-1.4.1.tgz",
      "integrity": "sha512-qiLX/xhEEFKUAJ6FiBMbes3w9ATzyk5W7Hvzpa/SLYdxNtng+gcurvrI7TbACjIXlsJyr05/S1oUhZrc63evQA==",
      "license": "MIT",
      "dependencies": {
        "buffer-equal-constant-time": "1.0.1",
        "ecdsa-sig-formatter": "1.0.11",
        "safe-buffer": "^5.0.1"
      }
    },
    "node_modules/jws": {
      "version": "3.2.2",
      "resolved": "https://registry.npmjs.org/jws/-/jws-3.2.2.tgz",
      "integrity": "sha512-YHlZCB6lMTllWDtSPHz/ZXTsi8S00usEV6v1tjq8tOUZzw7DpSDWVXjXDre6ed1w/pd495ODpHZYSdkRTsa0HA==",
      "license": "MIT",
      "dependencies": {
        "jwa": "^1.4.1",
        "safe-buffer": "^5.0.1"
      }
    },
    "node_modules/kleur": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/kleur/-/kleur-3.0.3.tgz",
      "integrity": "sha512-eTIzlVOSUR+JxdDFepEYcBMtZ9Qqdef+rnzWdRZuMbOywu5tO2w2N7rqjoANZ5k9vywhL6Br1VRjUIgTQx4E8w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/kuler": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/kuler/-/kuler-2.0.0.tgz",
      "integrity": "sha512-Xq9nH7KlWZmXAtodXDDRE7vs6DU1gTU8zYDHDiWLSip45Egwq3plLHzPn27NgvzL2r1LMPC1vdqh98sQxtqj4A==",
      "license": "MIT"
    },
    "node_modules/leven": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/leven/-/leven-3.1.0.tgz",
      "integrity": "sha512-qsda+H8jTaUaN/x5vzW2rzc+8Rw4TAQ/4KjB46IwK5VH+IlVeeeje/EoZRpiXvIqjFgK84QffqPztGI3VBLG1A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/lines-and-columns": {
      "version": "1.2.4",
      "resolved": "https://registry.npmjs.org/lines-and-columns/-/lines-and-columns-1.2.4.tgz",
      "integrity": "sha512-7ylylesZQ/PV29jhEDl3Ufjo6ZX7gCqJr5F7PKrqc93v7fzSymt1BpwEU8nAUXs8qzzvqhbjhK5QZg6Mt/HkBg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/locate-path": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/locate-path/-/locate-path-5.0.0.tgz",
      "integrity": "sha512-t7hw9pI+WvuwNJXwk5zVHpyhIqzg2qTlklJOf0mVxGSbe3Fp2VieZcduNYjaLDoy6p9uGpQEGWG87WpMKlNq8g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-locate": "^4.1.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/lodash.defaults": {
      "version": "4.2.0",
      "resolved": "https://registry.npmjs.org/lodash.defaults/-/lodash.defaults-4.2.0.tgz",
      "integrity": "sha512-qjxPLHd3r5DnsdGacqOMU6pb/avJzdh9tFX2ymgoZE27BmjXrNy/y4LoaiTeAb+O3gL8AfpJGtqfX/ae2leYYQ==",
      "license": "MIT"
    },
    "node_modules/lodash.includes": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/lodash.includes/-/lodash.includes-4.3.0.tgz",
      "integrity": "sha512-W3Bx6mdkRTGtlJISOvVD/lbqjTlPPUDTMnlXZFnVwi9NKJ6tiAk6LVdlhZMm17VZisqhKcgzpO5Wz91PCt5b0w==",
      "license": "MIT"
    },
    "node_modules/lodash.isarguments": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/lodash.isarguments/-/lodash.isarguments-3.1.0.tgz",
      "integrity": "sha512-chi4NHZlZqZD18a0imDHnZPrDeBbTtVN7GXMwuGdRH9qotxAjYs3aVLKc7zNOG9eddR5Ksd8rvFEBc9SsggPpg==",
      "license": "MIT"
    },
    "node_modules/lodash.isboolean": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/lodash.isboolean/-/lodash.isboolean-3.0.3.tgz",
      "integrity": "sha512-Bz5mupy2SVbPHURB98VAcw+aHh4vRV5IPNhILUCsOzRmsTmSQ17jIuqopAentWoehktxGd9e/hbIXq980/1QJg==",
      "license": "MIT"
    },
    "node_modules/lodash.isinteger": {
      "version": "4.0.4",
      "resolved": "https://registry.npmjs.org/lodash.isinteger/-/lodash.isinteger-4.0.4.tgz",
      "integrity": "sha512-DBwtEWN2caHQ9/imiNeEA5ys1JoRtRfY3d7V9wkqtbycnAmTvRRmbHKDV4a0EYc678/dia0jrte4tjYwVBaZUA==",
      "license": "MIT"
    },
    "node_modules/lodash.isnumber": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/lodash.isnumber/-/lodash.isnumber-3.0.3.tgz",
      "integrity": "sha512-QYqzpfwO3/CWf3XP+Z+tkQsfaLL/EnUlXWVkIk5FUPc4sBdTehEqZONuyRt2P67PXAk+NXmTBcc97zw9t1FQrw==",
      "license": "MIT"
    },
    "node_modules/lodash.isplainobject": {
      "version": "4.0.6",
      "resolved": "https://registry.npmjs.org/lodash.isplainobject/-/lodash.isplainobject-4.0.6.tgz",
      "integrity": "sha512-oSXzaWypCMHkPC3NvBEaPHf0KsA5mvPrOPgQWDsbg8n7orZ290M0BmC/jgRZ4vcJ6DTAhjrsSYgdsW/F+MFOBA==",
      "license": "MIT"
    },
    "node_modules/lodash.isstring": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/lodash.isstring/-/lodash.isstring-4.0.1.tgz",
      "integrity": "sha512-0wJxfxH1wgO3GrbuP+dTTk7op+6L41QCXbGINEmD+ny/G/eCqGzxyCsh7159S+mgDDcoarnBw6PC1PS5+wUGgw==",
      "license": "MIT"
    },
    "node_modules/lodash.once": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/lodash.once/-/lodash.once-4.1.1.tgz",
      "integrity": "sha512-Sb487aTOCr9drQVL8pIxOzVhafOjZN9UU54hiN8PU3uAiSV7lx1yYNpbNmex2PK6dSJoNTSJUUswT651yww3Mg==",
      "license": "MIT"
    },
    "node_modules/logform": {
      "version": "2.7.0",
      "resolved": "https://registry.npmjs.org/logform/-/logform-2.7.0.tgz",
      "integrity": "sha512-TFYA4jnP7PVbmlBIfhlSe+WKxs9dklXMTEGcBCIvLhE/Tn3H6Gk1norupVW7m5Cnd4bLcr08AytbyV/xj7f/kQ==",
      "license": "MIT",
      "dependencies": {
        "@colors/colors": "1.6.0",
        "@types/triple-beam": "^1.3.2",
        "fecha": "^4.2.0",
        "ms": "^2.1.1",
        "safe-stable-stringify": "^2.3.1",
        "triple-beam": "^1.3.0"
      },
      "engines": {
        "node": ">= 12.0.0"
      }
    },
    "node_modules/logform/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "license": "MIT"
    },
    "node_modules/lru-cache": {
      "version": "5.1.1",
      "resolved": "https://registry.npmjs.org/lru-cache/-/lru-cache-5.1.1.tgz",
      "integrity": "sha512-KpNARQA3Iwv+jTA0utUVVbrh+Jlrr1Fv0e56GGzAFOXN7dk/FviaDW8LHmK52DlcH4WP2n6gI8vN1aesBFgo9w==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "yallist": "^3.0.2"
      }
    },
    "node_modules/make-dir": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/make-dir/-/make-dir-4.0.0.tgz",
      "integrity": "sha512-hXdUTZYIVOt1Ex//jAQi+wTZZpUpwBj/0QsOzqegb3rGMMeJiSEu5xLHnYfBrRV4RH2+OCSOO95Is/7x1WJ4bw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "semver": "^7.5.3"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/make-dir/node_modules/semver": {
      "version": "7.7.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-7.7.1.tgz",
      "integrity": "sha512-hlq8tAfn0m/61p4BVRcPzIGr6LKiMwo4VM6dGi6pt4qcRkmNzTcWq6eCEjEh+qXjkMDvPlOFFSGwQjoEa6gyMA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/makeerror": {
      "version": "1.0.12",
      "resolved": "https://registry.npmjs.org/makeerror/-/makeerror-1.0.12.tgz",
      "integrity": "sha512-JmqCvUhmt43madlpFzG4BQzG2Z3m6tvQDNKdClZnO3VbIudJYmxsT0FNJMeiB2+JTSlTQTSbU8QdesVmwJcmLg==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "tmpl": "1.0.5"
      }
    },
    "node_modules/math-intrinsics": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/math-intrinsics/-/math-intrinsics-1.1.0.tgz",
      "integrity": "sha512-/IXtbwEk5HTPyEwyKX6hGkYXxM9nbj64B+ilVJnC/R6B0pH5G4V3b0pVbL7DBj4tkhBAppbQUlf6F6Xl9LHu1g==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/media-typer": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/media-typer/-/media-typer-0.3.0.tgz",
      "integrity": "sha512-dq+qelQ9akHpcOl/gUVRTxVIOkAJ1wR3QAvb4RsVjS8oVoFjDGTc679wJYmUmknUF5HwMLOgb5O+a3KxfWapPQ==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/merge-descriptors": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/merge-descriptors/-/merge-descriptors-1.0.3.tgz",
      "integrity": "sha512-gaNvAS7TZ897/rVaZ0nMtAyxNyi/pdbjbAwUpFQpN70GqnVfOiXpeUUMKRBmzXaSQ8DdTX4/0ms62r2K+hE6mQ==",
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/merge-stream": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/merge-stream/-/merge-stream-2.0.0.tgz",
      "integrity": "sha512-abv/qOcuPfk3URPfDzmZU1LKmuw8kT+0nIHvKrKgFrwifol/doWcdA4ZqsWQ8ENrFKkd67Mfpo/LovbIUsbt3w==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/methods": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/methods/-/methods-1.1.2.tgz",
      "integrity": "sha512-iclAHeNqNm68zFtnZ0e+1L2yUIdvzNoauKU4WBA3VvH/vPFieF7qfRlwUZU+DA9P9bPXIS90ulxoUoCH23sV2w==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/micromatch": {
      "version": "4.0.8",
      "resolved": "https://registry.npmjs.org/micromatch/-/micromatch-4.0.8.tgz",
      "integrity": "sha512-PXwfBhYu0hBCPw8Dn0E+WDYb7af3dSLVWKi3HGv84IdF4TyFoC0ysxFd0Goxw7nSv4T/PzEJQxsYsEiFCKo2BA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "braces": "^3.0.3",
        "picomatch": "^2.3.1"
      },
      "engines": {
        "node": ">=8.6"
      }
    },
    "node_modules/mime": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/mime/-/mime-1.6.0.tgz",
      "integrity": "sha512-x0Vn8spI+wuJ1O6S7gnbaQg8Pxh4NNHb7KSINmEWKiPE4RKOplvijn+NkmYmmRgP68mc70j2EbeTFRsrswaQeg==",
      "license": "MIT",
      "bin": {
        "mime": "cli.js"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/mime-db": {
      "version": "1.53.0",
      "resolved": "https://registry.npmjs.org/mime-db/-/mime-db-1.53.0.tgz",
      "integrity": "sha512-oHlN/w+3MQ3rba9rqFr6V/ypF10LSkdwUysQL7GkXoTgIWeV+tcXGA852TBxH+gsh8UWoyhR1hKcoMJTuWflpg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/mime-types": {
      "version": "2.1.35",
      "resolved": "https://registry.npmjs.org/mime-types/-/mime-types-2.1.35.tgz",
      "integrity": "sha512-ZDY+bPm5zTTF+YpCrAU9nK0UgICYPT0QtT1NZWFv4s++TNkcgVaT0g6+4R2uI4MjQjzysHB1zxuWL50hzaeXiw==",
      "license": "MIT",
      "dependencies": {
        "mime-db": "1.52.0"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/mime-types/node_modules/mime-db": {
      "version": "1.52.0",
      "resolved": "https://registry.npmjs.org/mime-db/-/mime-db-1.52.0.tgz",
      "integrity": "sha512-sPU4uV7dYlvtWJxwwxHD0PuihVNiE7TyAbQ5SWxDCB9mUYvOgroQOwYQQOKPJ8CIbE+1ETVlOoK1UC2nU3gYvg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/mimic-fn": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/mimic-fn/-/mimic-fn-2.1.0.tgz",
      "integrity": "sha512-OqbOk5oEQeAZ8WXWydlu9HJjz9WVdEIvamMCcXmuqUYjTknH/sqsWvhQ3vgwKFRR1HpjvNBKQ37nbJgYzGqGcg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/minimatch": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz",
      "integrity": "sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^1.1.7"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/morgan": {
      "version": "1.10.0",
      "resolved": "https://registry.npmjs.org/morgan/-/morgan-1.10.0.tgz",
      "integrity": "sha512-AbegBVI4sh6El+1gNwvD5YIck7nSA36weD7xvIxG4in80j/UoK8AEGaWnnz8v1GxonMCltmlNs5ZKbGvl9b1XQ==",
      "license": "MIT",
      "dependencies": {
        "basic-auth": "~2.0.1",
        "debug": "2.6.9",
        "depd": "~2.0.0",
        "on-finished": "~2.3.0",
        "on-headers": "~1.0.2"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/morgan/node_modules/on-finished": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/on-finished/-/on-finished-2.3.0.tgz",
      "integrity": "sha512-ikqdkGAAyf/X/gPhXGvfgAytDZtDbr+bkNUJ0N9h5MI/dmdgCs3l6hoHrcUv41sRKew3jIwrp4qQDXiK99Utww==",
      "license": "MIT",
      "dependencies": {
        "ee-first": "1.1.1"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/ms": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.0.0.tgz",
      "integrity": "sha512-Tpp60P6IUJDTuOq/5Z8cdskzJujfwqfOTkrwIwj7IRISpnkJnT6SyJ4PCPnGMoFjC9ddhal5KVIYtAt97ix05A==",
      "license": "MIT"
    },
    "node_modules/natural-compare": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/natural-compare/-/natural-compare-1.4.0.tgz",
      "integrity": "sha512-OWND8ei3VtNC9h7V60qff3SVobHr996CTwgxubgyQYEpg290h9J0buyECNNJexkFm5sOajh5G116RYA1c8ZMSw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/negotiator": {
      "version": "0.6.4",
      "resolved": "https://registry.npmjs.org/negotiator/-/negotiator-0.6.4.tgz",
      "integrity": "sha512-myRT3DiWPHqho5PrJaIRyaMv2kgYf0mUVgBNOYMuCH5Ki1yEiQaf/ZJuQ62nvpc44wL5WDbTX7yGJi1Neevw8w==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/node-int64": {
      "version": "0.4.0",
      "resolved": "https://registry.npmjs.org/node-int64/-/node-int64-0.4.0.tgz",
      "integrity": "sha512-O5lz91xSOeoXP6DulyHfllpq+Eg00MWitZIbtPfoSEvqIHdl5gfcY6hYzDWnj0qD5tz52PI08u9qUvSVeUBeHw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/node-releases": {
      "version": "2.0.19",
      "resolved": "https://registry.npmjs.org/node-releases/-/node-releases-2.0.19.tgz",
      "integrity": "sha512-xxOWJsBKtzAq7DY0J+DTzuz58K8e7sJbdgwkbMWQe8UYB6ekmsQ45q0M/tJDsGaZmbC+l7n57UV8Hl5tHxO9uw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/nodemon": {
      "version": "3.1.9",
      "resolved": "https://registry.npmjs.org/nodemon/-/nodemon-3.1.9.tgz",
      "integrity": "sha512-hdr1oIb2p6ZSxu3PB2JWWYS7ZQ0qvaZsc3hK8DR8f02kRzc8rjYmxAIvdz+aYC+8F2IjNaB7HMcSDg8nQpJxyg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "chokidar": "^3.5.2",
        "debug": "^4",
        "ignore-by-default": "^1.0.1",
        "minimatch": "^3.1.2",
        "pstree.remy": "^1.1.8",
        "semver": "^7.5.3",
        "simple-update-notifier": "^2.0.0",
        "supports-color": "^5.5.0",
        "touch": "^3.1.0",
        "undefsafe": "^2.0.5"
      },
      "bin": {
        "nodemon": "bin/nodemon.js"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/nodemon"
      }
    },
    "node_modules/nodemon/node_modules/debug": {
      "version": "4.4.0",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.4.0.tgz",
      "integrity": "sha512-6WTZ/IxCY/T6BALoZHaE4ctp9xm+Z5kY/pzYaCHRFeyVhojxlrm+46y68HA6hr0TcwEssoxNiDEUJQjfPZ/RYA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/nodemon/node_modules/has-flag": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/has-flag/-/has-flag-3.0.0.tgz",
      "integrity": "sha512-sKJf1+ceQBr4SMkvQnBDNDtf4TXpVhVGateu0t918bl30FnbE2m4vNLX+VWe/dpjlb+HugGYzW7uQXH98HPEYw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/nodemon/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/nodemon/node_modules/semver": {
      "version": "7.7.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-7.7.1.tgz",
      "integrity": "sha512-hlq8tAfn0m/61p4BVRcPzIGr6LKiMwo4VM6dGi6pt4qcRkmNzTcWq6eCEjEh+qXjkMDvPlOFFSGwQjoEa6gyMA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/nodemon/node_modules/supports-color": {
      "version": "5.5.0",
      "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-5.5.0.tgz",
      "integrity": "sha512-QjVjwdXIt408MIiAqCX4oUKsgU2EqAGzs2Ppkm4aQYbjm+ZEWEcW4SfFNTr4uMNZma0ey4f5lgLrkB0aX0QMow==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "has-flag": "^3.0.0"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/normalize-path": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/normalize-path/-/normalize-path-3.0.0.tgz",
      "integrity": "sha512-6eZs5Ls3WtCisHWp9S2GUy8dqkpGi4BVSz3GaqiE6ezub0512ESztXUwUB6C6IKbQkY2Pnb/mD4WYojCRwcwLA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/npm-run-path": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/npm-run-path/-/npm-run-path-4.0.1.tgz",
      "integrity": "sha512-S48WzZW777zhNIrn7gxOlISNAqi9ZC/uQFnRdbeIHhZhCA6UqpkOT8T1G7BvfdgP4Er8gF4sUbaS0i7QvIfCWw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "path-key": "^3.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/object-assign": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/object-assign/-/object-assign-4.1.1.tgz",
      "integrity": "sha512-rJgTQnkUnH1sFw8yT6VSU3zD3sWmu6sZhIseY8VX+GRu3P6F7Fu+JNDoXfklElbLJSnc3FUQHVe4cU5hj+BcUg==",
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/object-inspect": {
      "version": "1.13.4",
      "resolved": "https://registry.npmjs.org/object-inspect/-/object-inspect-1.13.4.tgz",
      "integrity": "sha512-W67iLl4J2EXEGTbfeHCffrjDfitvLANg0UlX3wFUUSTx92KXRFegMHUVgSqE+wvhAbi4WqjGg9czysTV2Epbew==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/on-finished": {
      "version": "2.4.1",
      "resolved": "https://registry.npmjs.org/on-finished/-/on-finished-2.4.1.tgz",
      "integrity": "sha512-oVlzkg3ENAhCk2zdv7IJwd/QUD4z2RxRwpkcGY8psCVcCYZNq4wYnVWALHM+brtuJjePWiYF/ClmuDr8Ch5+kg==",
      "license": "MIT",
      "dependencies": {
        "ee-first": "1.1.1"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/on-headers": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/on-headers/-/on-headers-1.0.2.tgz",
      "integrity": "sha512-pZAE+FJLoyITytdqK0U5s+FIpjN0JP3OzFi/u8Rx+EV5/W+JTWGXG8xFzevE7AjBfDqHv/8vL8qQsIhHnqRkrA==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/once": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/once/-/once-1.4.0.tgz",
      "integrity": "sha512-lNaJgI+2Q5URQBkccEKHTQOPaXdUxnZZElQTZY0MFUAuaEqe1E+Nyvgdz/aIyNi6Z9MzO5dv1H8n58/GELp3+w==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "wrappy": "1"
      }
    },
    "node_modules/one-time": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/one-time/-/one-time-1.0.0.tgz",
      "integrity": "sha512-5DXOiRKwuSEcQ/l0kGCF6Q3jcADFv5tSmRaJck/OqkVFcOzutB134KRSfF0xDrL39MNnqxbHBbUUcjZIhTgb2g==",
      "license": "MIT",
      "dependencies": {
        "fn.name": "1.x.x"
      }
    },
    "node_modules/onetime": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/onetime/-/onetime-5.1.2.tgz",
      "integrity": "sha512-kbpaSSGJTWdAY5KPVeMOKXSrPtr8C8C7wodJbcsd51jRnmD+GZu8Y0VoU6Dm5Z4vWr0Ig/1NKuWRKf7j5aaYSg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "mimic-fn": "^2.1.0"
      },
      "engines": {
        "node": ">=6"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/p-limit": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-3.1.0.tgz",
      "integrity": "sha512-TYOanM3wGwNGsZN2cVTYPArw454xnXj5qmWF1bEoAc4+cU/ol7GVh7odevjp1FNHduHc3KZMcFduxU5Xc6uJRQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "yocto-queue": "^0.1.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/p-locate": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/p-locate/-/p-locate-4.1.0.tgz",
      "integrity": "sha512-R79ZZ/0wAxKGu3oYMlz8jy/kbhsNrS7SKZ7PxEHBgJ5+F2mtFW2fK2cOtBh1cHYkQsbzFV7I+EoRKe6Yt0oK7A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-limit": "^2.2.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/p-locate/node_modules/p-limit": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-2.3.0.tgz",
      "integrity": "sha512-//88mFWSJx8lxCzwdAABTJL2MyWB12+eIY7MDL2SqLmAkeKU9qxRvWuSyTjm3FUmpBEMuFfckAIqEaVGUDxb6w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-try": "^2.0.0"
      },
      "engines": {
        "node": ">=6"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/p-try": {
      "version": "2.2.0",
      "resolved": "https://registry.npmjs.org/p-try/-/p-try-2.2.0.tgz",
      "integrity": "sha512-R4nPAVTAU0B9D35/Gk3uJf/7XYbQcyohSKdvAxIRSNghFl4e71hVoGnBNQz9cWaXxO2I10KTC+3jMdvvoKw6dQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/parse-json": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/parse-json/-/parse-json-5.2.0.tgz",
      "integrity": "sha512-ayCKvm/phCGxOkYRSCM82iDwct8/EonSEgCSxWxD7ve6jHggsFl4fZVQBPRNgQoKiuV/odhFrGzQXZwbifC8Rg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/code-frame": "^7.0.0",
        "error-ex": "^1.3.1",
        "json-parse-even-better-errors": "^2.3.0",
        "lines-and-columns": "^1.1.6"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/parseurl": {
      "version": "1.3.3",
      "resolved": "https://registry.npmjs.org/parseurl/-/parseurl-1.3.3.tgz",
      "integrity": "sha512-CiyeOxFT/JZyN5m0z9PfXw4SCBJ6Sygz1Dpl0wqjlhDEGGBP1GnsUVEL0p63hoG1fcj3fHynXi9NYO4nWOL+qQ==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/path-exists": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/path-exists/-/path-exists-4.0.0.tgz",
      "integrity": "sha512-ak9Qy5Q7jYb2Wwcey5Fpvg2KoAc/ZIhLSLOSBmRmygPsGwkVVt0fZa0qrtMz+m6tJTAHfZQ8FnmB4MG4LWy7/w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/path-is-absolute": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/path-is-absolute/-/path-is-absolute-1.0.1.tgz",
      "integrity": "sha512-AVbw3UJ2e9bq64vSaS9Am0fje1Pa8pbGqTTsmXfaIiMpnr5DlDhfJOuLj9Sf95ZPVDAUerDfEk88MPmPe7UCQg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/path-key": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/path-key/-/path-key-3.1.1.tgz",
      "integrity": "sha512-ojmeN0qd+y0jszEtoY48r0Peq5dwMEkIlCOu6Q5f41lfkswXuKtYrhgoTpLnyIcHm24Uhqx+5Tqm2InSwLhE6Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/path-parse": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/path-parse/-/path-parse-1.0.7.tgz",
      "integrity": "sha512-LDJzPVEEEPR+y48z93A0Ed0yXb8pAByGWo/k5YYdYgpY2/2EsOsksJrq7lOHxryrVOn1ejG6oAp8ahvOIQD8sw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/path-to-regexp": {
      "version": "0.1.12",
      "resolved": "https://registry.npmjs.org/path-to-regexp/-/path-to-regexp-0.1.12.tgz",
      "integrity": "sha512-RA1GjUVMnvYFxuqovrEqZoxxW5NUZqbwKtYz/Tt7nXerk0LbLblQmrsgdeOxV5SFHf0UDggjS/bSeOZwt1pmEQ==",
      "license": "MIT"
    },
    "node_modules/picocolors": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/picocolors/-/picocolors-1.1.1.tgz",
      "integrity": "sha512-xceH2snhtb5M9liqDsmEw56le376mTZkEX/jEb/RxNFyegNul7eNslCXP9FDj/Lcu0X8KEyMceP2ntpaHrDEVA==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/picomatch": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/picomatch/-/picomatch-2.3.1.tgz",
      "integrity": "sha512-JU3teHTNjmE2VCGFzuY8EXzCDVwEqB2a8fsIvwaStHhAWJEeVd1o1QD80CU6+ZdEXXSLbSsuLwJjkCBWqRQUVA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8.6"
      },
      "funding": {
        "url": "https://github.com/sponsors/jonschlinkert"
      }
    },
    "node_modules/pirates": {
      "version": "4.0.6",
      "resolved": "https://registry.npmjs.org/pirates/-/pirates-4.0.6.tgz",
      "integrity": "sha512-saLsH7WeYYPiD25LDuLRRY/i+6HaPYr6G1OUlN39otzkSTxKnubR9RTxS3/Kk50s1g2JTgFwWQDQyplC5/SHZg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/pkg-dir": {
      "version": "4.2.0",
      "resolved": "https://registry.npmjs.org/pkg-dir/-/pkg-dir-4.2.0.tgz",
      "integrity": "sha512-HRDzbaKjC+AOWVXxAU/x54COGeIv9eb+6CkDSQoNTt4XyWoIJvuPsXizxu/Fr23EiekbtZwmh1IcIG/l/a10GQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "find-up": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/pretty-format": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/pretty-format/-/pretty-format-29.7.0.tgz",
      "integrity": "sha512-Pdlw/oPxN+aXdmM9R00JVC9WVFoCLTKJvDVLgmJ+qAffBMxsV85l/Lu7sNx4zSzPyoL2euImuEwHhOXdEgNFZQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/schemas": "^29.6.3",
        "ansi-styles": "^5.0.0",
        "react-is": "^18.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/pretty-format/node_modules/ansi-styles": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-5.2.0.tgz",
      "integrity": "sha512-Cxwpt2SfTzTtXcfOlzGEee8O+c+MmUgGrNiBcXnuWxuFJHe6a5Hz7qwhwe5OgaSYI0IJvkLqWX1ASG+cJOkEiA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/prom-client": {
      "version": "14.2.0",
      "resolved": "https://registry.npmjs.org/prom-client/-/prom-client-14.2.0.tgz",
      "integrity": "sha512-sF308EhTenb/pDRPakm+WgiN+VdM/T1RaHj1x+MvAuT8UiQP8JmOEbxVqtkbfR4LrvOg5n7ic01kRBDGXjYikA==",
      "license": "Apache-2.0",
      "dependencies": {
        "tdigest": "^0.1.1"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/prompts": {
      "version": "2.4.2",
      "resolved": "https://registry.npmjs.org/prompts/-/prompts-2.4.2.tgz",
      "integrity": "sha512-NxNv/kLguCA7p3jE8oL2aEBsrJWgAakBpgmgK6lpPWV+WuOmY6r2/zbAVnP+T8bQlA0nzHXSJSJW0Hq7ylaD2Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "kleur": "^3.0.3",
        "sisteransi": "^1.0.5"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/proxy-addr": {
      "version": "2.0.7",
      "resolved": "https://registry.npmjs.org/proxy-addr/-/proxy-addr-2.0.7.tgz",
      "integrity": "sha512-llQsMLSUDUPT44jdrU/O37qlnifitDP+ZwrmmZcoSKyLKvtZxpyV0n2/bD/N4tBAAZ/gJEdZU7KMraoK1+XYAg==",
      "license": "MIT",
      "dependencies": {
        "forwarded": "0.2.0",
        "ipaddr.js": "1.9.1"
      },
      "engines": {
        "node": ">= 0.10"
      }
    },
    "node_modules/pstree.remy": {
      "version": "1.1.8",
      "resolved": "https://registry.npmjs.org/pstree.remy/-/pstree.remy-1.1.8.tgz",
      "integrity": "sha512-77DZwxQmxKnu3aR542U+X8FypNzbfJ+C5XQDk3uWjWxn6151aIMGthWYRXTqT1E5oJvg+ljaa2OJi+VfvCOQ8w==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/pure-rand": {
      "version": "6.1.0",
      "resolved": "https://registry.npmjs.org/pure-rand/-/pure-rand-6.1.0.tgz",
      "integrity": "sha512-bVWawvoZoBYpp6yIoQtQXHZjmz35RSVHnUOTefl8Vcjr8snTPY1wnpSPMWekcFwbxI6gtmT7rSYPFvz71ldiOA==",
      "dev": true,
      "funding": [
        {
          "type": "individual",
          "url": "https://github.com/sponsors/dubzzz"
        },
        {
          "type": "opencollective",
          "url": "https://opencollective.com/fast-check"
        }
      ],
      "license": "MIT"
    },
    "node_modules/qs": {
      "version": "6.13.0",
      "resolved": "https://registry.npmjs.org/qs/-/qs-6.13.0.tgz",
      "integrity": "sha512-+38qI9SOr8tfZ4QmJNplMUxqjbe7LKvvZgWdExBOmd+egZTtjLB67Gu0HRX3u/XOq7UU2Nx6nsjvS16Z9uwfpg==",
      "license": "BSD-3-Clause",
      "dependencies": {
        "side-channel": "^1.0.6"
      },
      "engines": {
        "node": ">=0.6"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/range-parser": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/range-parser/-/range-parser-1.2.1.tgz",
      "integrity": "sha512-Hrgsx+orqoygnmhFbKaHE6c296J+HTAQXoxEF6gNupROmmGJRoyzfG3ccAveqCBrwr/2yxQ5BVd/GTl5agOwSg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/raw-body": {
      "version": "2.5.2",
      "resolved": "https://registry.npmjs.org/raw-body/-/raw-body-2.5.2.tgz",
      "integrity": "sha512-8zGqypfENjCIqGhgXToC8aB2r7YrBX+AQAfIPs/Mlk+BtPTztOvTS01NRW/3Eh60J+a48lt8qsCzirQ6loCVfA==",
      "license": "MIT",
      "dependencies": {
        "bytes": "3.1.2",
        "http-errors": "2.0.0",
        "iconv-lite": "0.4.24",
        "unpipe": "1.0.0"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/react-is": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-18.3.1.tgz",
      "integrity": "sha512-/LLMVyas0ljjAtoYiPqYiL8VWXzUUdThrmU5+n20DZv+a+ClRoevUzw5JxU+Ieh5/c87ytoTBV9G1FiKfNJdmg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/readable-stream": {
      "version": "3.6.2",
      "resolved": "https://registry.npmjs.org/readable-stream/-/readable-stream-3.6.2.tgz",
      "integrity": "sha512-9u/sniCrY3D5WdsERHzHE4G2YCXqoG5FTHUiCC4SIbr6XcLZBY05ya9EKjYek9O5xOAwjGq+1JdGBAS7Q9ScoA==",
      "license": "MIT",
      "dependencies": {
        "inherits": "^2.0.3",
        "string_decoder": "^1.1.1",
        "util-deprecate": "^1.0.1"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/readdirp": {
      "version": "3.6.0",
      "resolved": "https://registry.npmjs.org/readdirp/-/readdirp-3.6.0.tgz",
      "integrity": "sha512-hOS089on8RduqdbhvQ5Z37A0ESjsqz6qnRcffsMU3495FuTdqSm+7bhJ29JvIOsBDEEnan5DPu9t3To9VRlMzA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "picomatch": "^2.2.1"
      },
      "engines": {
        "node": ">=8.10.0"
      }
    },
    "node_modules/redis-errors": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/redis-errors/-/redis-errors-1.2.0.tgz",
      "integrity": "sha512-1qny3OExCf0UvUV/5wpYKf2YwPcOqXzkwKKSmKHiE6ZMQs5heeE/c8eXK+PNllPvmjgAbfnsbpkGZWy8cBpn9w==",
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/redis-parser": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/redis-parser/-/redis-parser-3.0.0.tgz",
      "integrity": "sha512-DJnGAeenTdpMEH6uAJRK/uiyEIH9WVsUmoLwzudwGJUwZPp80PDBWPHXSAGNPwNvIXAbe7MSUB1zQFugFml66A==",
      "license": "MIT",
      "dependencies": {
        "redis-errors": "^1.0.0"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/require-directory": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/require-directory/-/require-directory-2.1.1.tgz",
      "integrity": "sha512-fGxEI7+wsG9xrvdjsrlmL22OMTTiHRwAMroiEeMgq8gzoLC/PQr7RsRDSTLUg/bZAZtF+TVIkHc6/4RIKrui+Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/resolve": {
      "version": "1.22.10",
      "resolved": "https://registry.npmjs.org/resolve/-/resolve-1.22.10.tgz",
      "integrity": "sha512-NPRy+/ncIMeDlTAsuqwKIiferiawhefFJtkNSW0qZJEqMEb+qBt/77B/jGeeek+F0uOeN05CDa6HXbbIgtVX4w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-core-module": "^2.16.0",
        "path-parse": "^1.0.7",
        "supports-preserve-symlinks-flag": "^1.0.0"
      },
      "bin": {
        "resolve": "bin/resolve"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/resolve-cwd": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/resolve-cwd/-/resolve-cwd-3.0.0.tgz",
      "integrity": "sha512-OrZaX2Mb+rJCpH/6CpSqt9xFVpN++x01XnN2ie9g6P5/3xelLAkXWVADpdz1IHD/KFfEXyE6V0U01OQ3UO2rEg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "resolve-from": "^5.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/resolve-from": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/resolve-from/-/resolve-from-5.0.0.tgz",
      "integrity": "sha512-qYg9KP24dD5qka9J47d0aVky0N+b4fTU89LN9iDnjB5waksiC49rvMB0PrUJQGoTmH50XPiqOvAjDfaijGxYZw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/resolve.exports": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/resolve.exports/-/resolve.exports-2.0.3.tgz",
      "integrity": "sha512-OcXjMsGdhL4XnbShKpAcSqPMzQoYkYyhbEaeSko47MjRP9NfEQMhZkXL1DoFlt9LWQn4YttrdnV6X2OiyzBi+A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/safe-buffer": {
      "version": "5.2.1",
      "resolved": "https://registry.npmjs.org/safe-buffer/-/safe-buffer-5.2.1.tgz",
      "integrity": "sha512-rp3So07KcdmmKbGvgaNxQSJr7bGVSVk5S9Eq1F+ppbRo70+YeaDxkw5Dd8NPN+GD6bjnYm2VuPuCXmpuYvmCXQ==",
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ],
      "license": "MIT"
    },
    "node_modules/safe-stable-stringify": {
      "version": "2.5.0",
      "resolved": "https://registry.npmjs.org/safe-stable-stringify/-/safe-stable-stringify-2.5.0.tgz",
      "integrity": "sha512-b3rppTKm9T+PsVCBEOUR46GWI7fdOs00VKZ1+9c1EWDaDMvjQc6tUwuFyIprgGgTcWoVHSKrU8H31ZHA2e0RHA==",
      "license": "MIT",
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/safer-buffer": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/safer-buffer/-/safer-buffer-2.1.2.tgz",
      "integrity": "sha512-YZo3K82SD7Riyi0E1EQPojLz7kpepnSQI9IyPbHHg1XXXevb5dJI7tpyN2ADxGcQbHG7vcyRHk0cbwqcQriUtg==",
      "license": "MIT"
    },
    "node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/send": {
      "version": "0.19.0",
      "resolved": "https://registry.npmjs.org/send/-/send-0.19.0.tgz",
      "integrity": "sha512-dW41u5VfLXu8SJh5bwRmyYUbAoSB3c9uQh6L8h/KtsFREPWpbX1lrljJo186Jc4nmci/sGUZ9a0a0J2zgfq2hw==",
      "license": "MIT",
      "dependencies": {
        "debug": "2.6.9",
        "depd": "2.0.0",
        "destroy": "1.2.0",
        "encodeurl": "~1.0.2",
        "escape-html": "~1.0.3",
        "etag": "~1.8.1",
        "fresh": "0.5.2",
        "http-errors": "2.0.0",
        "mime": "1.6.0",
        "ms": "2.1.3",
        "on-finished": "2.4.1",
        "range-parser": "~1.2.1",
        "statuses": "2.0.1"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/send/node_modules/encodeurl": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/encodeurl/-/encodeurl-1.0.2.tgz",
      "integrity": "sha512-TPJXq8JqFaVYm2CWmPvnP2Iyo4ZSM7/QKcSmuMLDObfpH5fi7RUGmd/rTDf+rut/saiDiQEeVTNgAmJEdAOx0w==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/send/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "license": "MIT"
    },
    "node_modules/serve-static": {
      "version": "1.16.2",
      "resolved": "https://registry.npmjs.org/serve-static/-/serve-static-1.16.2.tgz",
      "integrity": "sha512-VqpjJZKadQB/PEbEwvFdO43Ax5dFBZ2UECszz8bQ7pi7wt//PWe1P6MN7eCnjsatYtBT6EuiClbjSWP2WrIoTw==",
      "license": "MIT",
      "dependencies": {
        "encodeurl": "~2.0.0",
        "escape-html": "~1.0.3",
        "parseurl": "~1.3.3",
        "send": "0.19.0"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/setprototypeof": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/setprototypeof/-/setprototypeof-1.2.0.tgz",
      "integrity": "sha512-E5LDX7Wrp85Kil5bhZv46j8jOeboKq5JMmYM3gVGdGH8xFpPWXUMsNrlODCrkoxMEeNi/XZIwuRvY4XNwYMJpw==",
      "license": "ISC"
    },
    "node_modules/shebang-command": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/shebang-command/-/shebang-command-2.0.0.tgz",
      "integrity": "sha512-kHxr2zZpYtdmrN1qDjrrX/Z1rR1kG8Dx+gkpK1G4eXmvXswmcE1hTWBWYUzlraYw1/yZp6YuDY77YtvbN0dmDA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "shebang-regex": "^3.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/shebang-regex": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/shebang-regex/-/shebang-regex-3.0.0.tgz",
      "integrity": "sha512-7++dFhtcx3353uBaq8DDR4NuxBetBzC7ZQOhmTQInHEd6bSrXdiEyzCvG07Z44UYdLShWUyXt5M/yhz8ekcb1A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/side-channel": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/side-channel/-/side-channel-1.1.0.tgz",
      "integrity": "sha512-ZX99e6tRweoUXqR+VBrslhda51Nh5MTQwou5tnUDgbtyM0dBgmhEDtWGP/xbKn6hqfPRHujUNwz5fy/wbbhnpw==",
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "object-inspect": "^1.13.3",
        "side-channel-list": "^1.0.0",
        "side-channel-map": "^1.0.1",
        "side-channel-weakmap": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/side-channel-list": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/side-channel-list/-/side-channel-list-1.0.0.tgz",
      "integrity": "sha512-FCLHtRD/gnpCiCHEiJLOwdmFP+wzCmDEkc9y7NsYxeF4u7Btsn1ZuwgwJGxImImHicJArLP4R0yX4c2KCrMrTA==",
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "object-inspect": "^1.13.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/side-channel-map": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/side-channel-map/-/side-channel-map-1.0.1.tgz",
      "integrity": "sha512-VCjCNfgMsby3tTdo02nbjtM/ewra6jPHmpThenkTYh8pG9ucZ/1P8So4u4FGBek/BjpOVsDCMoLA/iuBKIFXRA==",
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.5",
        "object-inspect": "^1.13.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/side-channel-weakmap": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/side-channel-weakmap/-/side-channel-weakmap-1.0.2.tgz",
      "integrity": "sha512-WPS/HvHQTYnHisLo9McqBHOJk2FkHO/tlpvldyrnem4aeQp4hai3gythswg6p01oSoTl58rcpiFAjF2br2Ak2A==",
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.5",
        "object-inspect": "^1.13.3",
        "side-channel-map": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/signal-exit": {
      "version": "3.0.7",
      "resolved": "https://registry.npmjs.org/signal-exit/-/signal-exit-3.0.7.tgz",
      "integrity": "sha512-wnD2ZE+l+SPC/uoS0vXeE9L1+0wuaMqKlfz9AMUo38JsyLSBWSFcHR1Rri62LZc12vLr1gb3jl7iwQhgwpAbGQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/simple-swizzle": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/simple-swizzle/-/simple-swizzle-0.2.2.tgz",
      "integrity": "sha512-JA//kQgZtbuY83m+xT+tXJkmJncGMTFT+C+g2h2R9uxkYIrE2yy9sgmcLhCnw57/WSD+Eh3J97FPEDFnbXnDUg==",
      "license": "MIT",
      "dependencies": {
        "is-arrayish": "^0.3.1"
      }
    },
    "node_modules/simple-swizzle/node_modules/is-arrayish": {
      "version": "0.3.2",
      "resolved": "https://registry.npmjs.org/is-arrayish/-/is-arrayish-0.3.2.tgz",
      "integrity": "sha512-eVRqCvVlZbuw3GrM63ovNSNAeA1K16kaR/LRY/92w0zxQ5/1YzwblUX652i4Xs9RwAGjW9d9y6X88t8OaAJfWQ==",
      "license": "MIT"
    },
    "node_modules/simple-update-notifier": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/simple-update-notifier/-/simple-update-notifier-2.0.0.tgz",
      "integrity": "sha512-a2B9Y0KlNXl9u/vsW6sTIu9vGEpfKu2wRV6l1H3XEas/0gUIzGzBoP/IouTcUQbm9JWZLH3COxyn03TYlFax6w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "semver": "^7.5.3"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/simple-update-notifier/node_modules/semver": {
      "version": "7.7.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-7.7.1.tgz",
      "integrity": "sha512-hlq8tAfn0m/61p4BVRcPzIGr6LKiMwo4VM6dGi6pt4qcRkmNzTcWq6eCEjEh+qXjkMDvPlOFFSGwQjoEa6gyMA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/sisteransi": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/sisteransi/-/sisteransi-1.0.5.tgz",
      "integrity": "sha512-bLGGlR1QxBcynn2d5YmDX4MGjlZvy2MRBDRNHLJ8VI6l6+9FUiyTFNJ0IveOSP0bcXgVDPRcfGqA0pjaqUpfVg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/slash": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/slash/-/slash-3.0.0.tgz",
      "integrity": "sha512-g9Q1haeby36OSStwb4ntCGGGaKsaVSjQ68fBxoQcutl5fS1vuY18H3wSt3jFyFtrkx+Kz0V1G85A4MyAdDMi2Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/socket.io": {
      "version": "4.8.1",
      "resolved": "https://registry.npmjs.org/socket.io/-/socket.io-4.8.1.tgz",
      "integrity": "sha512-oZ7iUCxph8WYRHHcjBEc9unw3adt5CmSNlppj/5Q4k2RIrhl8Z5yY2Xr4j9zj0+wzVZ0bxmYoGSzKJnRl6A4yg==",
      "license": "MIT",
      "dependencies": {
        "accepts": "~1.3.4",
        "base64id": "~2.0.0",
        "cors": "~2.8.5",
        "debug": "~4.3.2",
        "engine.io": "~6.6.0",
        "socket.io-adapter": "~2.5.2",
        "socket.io-parser": "~4.2.4"
      },
      "engines": {
        "node": ">=10.2.0"
      }
    },
    "node_modules/socket.io-adapter": {
      "version": "2.5.5",
      "resolved": "https://registry.npmjs.org/socket.io-adapter/-/socket.io-adapter-2.5.5.tgz",
      "integrity": "sha512-eLDQas5dzPgOWCk9GuuJC2lBqItuhKI4uxGgo9aIV7MYbk2h9Q6uULEh8WBzThoI7l+qU9Ast9fVUmkqPP9wYg==",
      "license": "MIT",
      "dependencies": {
        "debug": "~4.3.4",
        "ws": "~8.17.1"
      }
    },
    "node_modules/socket.io-adapter/node_modules/debug": {
      "version": "4.3.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.3.7.tgz",
      "integrity": "sha512-Er2nc/H7RrMXZBFCEim6TCmMk02Z8vLC2Rbi1KEBggpo0fS6l0S1nnapwmIi3yW/+GOJap1Krg4w0Hg80oCqgQ==",
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/socket.io-adapter/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "license": "MIT"
    },
    "node_modules/socket.io-parser": {
      "version": "4.2.4",
      "resolved": "https://registry.npmjs.org/socket.io-parser/-/socket.io-parser-4.2.4.tgz",
      "integrity": "sha512-/GbIKmo8ioc+NIWIhwdecY0ge+qVBSMdgxGygevmdHj24bsfgtCmcUUcQ5ZzcylGFHsN3k4HB4Cgkl96KVnuew==",
      "license": "MIT",
      "dependencies": {
        "@socket.io/component-emitter": "~3.1.0",
        "debug": "~4.3.1"
      },
      "engines": {
        "node": ">=10.0.0"
      }
    },
    "node_modules/socket.io-parser/node_modules/debug": {
      "version": "4.3.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.3.7.tgz",
      "integrity": "sha512-Er2nc/H7RrMXZBFCEim6TCmMk02Z8vLC2Rbi1KEBggpo0fS6l0S1nnapwmIi3yW/+GOJap1Krg4w0Hg80oCqgQ==",
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/socket.io-parser/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "license": "MIT"
    },
    "node_modules/socket.io/node_modules/debug": {
      "version": "4.3.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.3.7.tgz",
      "integrity": "sha512-Er2nc/H7RrMXZBFCEim6TCmMk02Z8vLC2Rbi1KEBggpo0fS6l0S1nnapwmIi3yW/+GOJap1Krg4w0Hg80oCqgQ==",
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/socket.io/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "license": "MIT"
    },
    "node_modules/source-map": {
      "version": "0.6.1",
      "resolved": "https://registry.npmjs.org/source-map/-/source-map-0.6.1.tgz",
      "integrity": "sha512-UjgapumWlbMhkBgzT7Ykc5YXUT46F0iKu8SGXq0bcwP5dz/h0Plj6enJqjz1Zbq2l5WaqYnrVbwWOWMyF3F47g==",
      "dev": true,
      "license": "BSD-3-Clause",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/source-map-support": {
      "version": "0.5.13",
      "resolved": "https://registry.npmjs.org/source-map-support/-/source-map-support-0.5.13.tgz",
      "integrity": "sha512-SHSKFHadjVA5oR4PPqhtAVdcBWwRYVd6g6cAXnIbRiIwc2EhPrTuKUBdSLvlEKyIP3GCf89fltvcZiP9MMFA1w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "buffer-from": "^1.0.0",
        "source-map": "^0.6.0"
      }
    },
    "node_modules/sprintf-js": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/sprintf-js/-/sprintf-js-1.0.3.tgz",
      "integrity": "sha512-D9cPgkvLlV3t3IzL0D0YLvGA9Ahk4PcvVwUbN0dSGr1aP0Nrt4AEnTUbuGvquEC0mA64Gqt1fzirlRs5ibXx8g==",
      "dev": true,
      "license": "BSD-3-Clause"
    },
    "node_modules/stack-trace": {
      "version": "0.0.10",
      "resolved": "https://registry.npmjs.org/stack-trace/-/stack-trace-0.0.10.tgz",
      "integrity": "sha512-KGzahc7puUKkzyMt+IqAep+TVNbKP+k2Lmwhub39m1AsTSkaDutx56aDCo+HLDzf/D26BIHTJWNiTG1KAJiQCg==",
      "license": "MIT",
      "engines": {
        "node": "*"
      }
    },
    "node_modules/stack-utils": {
      "version": "2.0.6",
      "resolved": "https://registry.npmjs.org/stack-utils/-/stack-utils-2.0.6.tgz",
      "integrity": "sha512-XlkWvfIm6RmsWtNJx+uqtKLS8eqFbxUg0ZzLXqY0caEy9l7hruX8IpiDnjsLavoBgqCCR71TqWO8MaXYheJ3RQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "escape-string-regexp": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/standard-as-callback": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/standard-as-callback/-/standard-as-callback-2.1.0.tgz",
      "integrity": "sha512-qoRRSyROncaz1z0mvYqIE4lCd9p2R90i6GxW3uZv5ucSu8tU7B5HXUP1gG8pVZsYNVaXjk8ClXHPttLyxAL48A==",
      "license": "MIT"
    },
    "node_modules/statuses": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/statuses/-/statuses-2.0.1.tgz",
      "integrity": "sha512-RwNA9Z/7PrK06rYLIzFMlaF+l73iwpzsqRIFgbMLbTcLD6cOao82TaWefPXQvB2fOC4AjuYSEndS7N/mTCbkdQ==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/string_decoder": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/string_decoder/-/string_decoder-1.3.0.tgz",
      "integrity": "sha512-hkRX8U1WjJFd8LsDJ2yQ/wWWxaopEsABU1XfkM8A+j0+85JAGppt16cr1Whg6KIbb4okU6Mql6BOj+uup/wKeA==",
      "license": "MIT",
      "dependencies": {
        "safe-buffer": "~5.2.0"
      }
    },
    "node_modules/string-length": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/string-length/-/string-length-4.0.2.tgz",
      "integrity": "sha512-+l6rNN5fYHNhZZy41RXsYptCjA2Igmq4EG7kZAYFQI1E1VTXarr6ZPXBg6eq7Y6eK4FEhY6AJlyuFIb/v/S0VQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "char-regex": "^1.0.2",
        "strip-ansi": "^6.0.0"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/string-width": {
      "version": "4.2.3",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz",
      "integrity": "sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "emoji-regex": "^8.0.0",
        "is-fullwidth-code-point": "^3.0.0",
        "strip-ansi": "^6.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/strip-ansi": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz",
      "integrity": "sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/strip-bom": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/strip-bom/-/strip-bom-4.0.0.tgz",
      "integrity": "sha512-3xurFv5tEgii33Zi8Jtp55wEIILR9eh34FAW00PZf+JnSsTmV/ioewSgQl97JHvgjoRGwPShsWm+IdrxB35d0w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/strip-final-newline": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/strip-final-newline/-/strip-final-newline-2.0.0.tgz",
      "integrity": "sha512-BrpvfNAE3dcvq7ll3xVumzjKjZQ5tI1sEUIKr3Uoks0XUl45St3FlatVqef9prk4jRDzhW6WZg+3bk93y6pLjA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/strip-json-comments": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/strip-json-comments/-/strip-json-comments-3.1.1.tgz",
      "integrity": "sha512-6fPc+R4ihwqP6N/aIv2f1gMH8lOVtWQHoqC4yK6oSDVVocumAsfCqjkXnqiYMhmMwS/mEHLp7Vehlt3ql6lEig==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/supports-color": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-7.2.0.tgz",
      "integrity": "sha512-qpCAvRl9stuOHveKsn7HncJRvv501qIacKzQlO/+Lwxc9+0q2wLyv4Dfvt80/DPn2pqOBsJdDiogXGR9+OvwRw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "has-flag": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/supports-preserve-symlinks-flag": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/supports-preserve-symlinks-flag/-/supports-preserve-symlinks-flag-1.0.0.tgz",
      "integrity": "sha512-ot0WnXS9fgdkgIcePe6RHNk1WA8+muPa6cSjeR3V8K27q9BB1rTE3R1p7Hv0z1ZyAc8s6Vvv8DIyWf681MAt0w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/tdigest": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/tdigest/-/tdigest-0.1.2.tgz",
      "integrity": "sha512-+G0LLgjjo9BZX2MfdvPfH+MKLCrxlXSYec5DaPYP1fe6Iyhf0/fSmJ0bFiZ1F8BT6cGXl2LpltQptzjXKWEkKA==",
      "license": "MIT",
      "dependencies": {
        "bintrees": "1.0.2"
      }
    },
    "node_modules/test-exclude": {
      "version": "6.0.0",
      "resolved": "https://registry.npmjs.org/test-exclude/-/test-exclude-6.0.0.tgz",
      "integrity": "sha512-cAGWPIyOHU6zlmg88jwm7VRyXnMN7iV68OGAbYDk/Mh/xC/pzVPlQtY6ngoIH/5/tciuhGfvESU8GrHrcxD56w==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "@istanbuljs/schema": "^0.1.2",
        "glob": "^7.1.4",
        "minimatch": "^3.0.4"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/text-hex": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/text-hex/-/text-hex-1.0.0.tgz",
      "integrity": "sha512-uuVGNWzgJ4yhRaNSiubPY7OjISw4sw4E5Uv0wbjp+OzcbmVU/rsT8ujgcXJhn9ypzsgr5vlzpPqP+MBBKcGvbg==",
      "license": "MIT"
    },
    "node_modules/tmpl": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/tmpl/-/tmpl-1.0.5.tgz",
      "integrity": "sha512-3f0uOEAQwIqGuWW2MVzYg8fV/QNnc/IpuJNG837rLuczAaLVHslWHZQj4IGiEl5Hs3kkbhwL9Ab7Hrsmuj+Smw==",
      "dev": true,
      "license": "BSD-3-Clause"
    },
    "node_modules/to-regex-range": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/to-regex-range/-/to-regex-range-5.0.1.tgz",
      "integrity": "sha512-65P7iz6X5yEr1cwcgvQxbbIw7Uk3gOy5dIdtZ4rDveLqhrdJP+Li/Hx6tyK0NEb+2GCyneCMJiGqrADCSNk8sQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-number": "^7.0.0"
      },
      "engines": {
        "node": ">=8.0"
      }
    },
    "node_modules/toidentifier": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/toidentifier/-/toidentifier-1.0.1.tgz",
      "integrity": "sha512-o5sSPKEkg/DIQNmH43V0/uerLrpzVedkUh8tGNvaeXpfpuwjKenlSox/2O/BTlZUtEe+JG7s5YhEz608PlAHRA==",
      "license": "MIT",
      "engines": {
        "node": ">=0.6"
      }
    },
    "node_modules/touch": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/touch/-/touch-3.1.1.tgz",
      "integrity": "sha512-r0eojU4bI8MnHr8c5bNo7lJDdI2qXlWWJk6a9EAFG7vbhTjElYhBVS3/miuE0uOuoLdb8Mc/rVfsmm6eo5o9GA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "nodetouch": "bin/nodetouch.js"
      }
    },
    "node_modules/triple-beam": {
      "version": "1.4.1",
      "resolved": "https://registry.npmjs.org/triple-beam/-/triple-beam-1.4.1.tgz",
      "integrity": "sha512-aZbgViZrg1QNcG+LULa7nhZpJTZSLm/mXnHXnbAbjmN5aSa0y7V+wvv6+4WaBtpISJzThKy+PIPxc1Nq1EJ9mg==",
      "license": "MIT",
      "engines": {
        "node": ">= 14.0.0"
      }
    },
    "node_modules/type-detect": {
      "version": "4.0.8",
      "resolved": "https://registry.npmjs.org/type-detect/-/type-detect-4.0.8.tgz",
      "integrity": "sha512-0fr/mIH1dlO+x7TlcMy+bIDqKPsw/70tVyeHW787goQjhmqaZe10uwLujubK9q9Lg6Fiho1KUKDYz0Z7k7g5/g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/type-fest": {
      "version": "0.21.3",
      "resolved": "https://registry.npmjs.org/type-fest/-/type-fest-0.21.3.tgz",
      "integrity": "sha512-t0rzBq87m3fVcduHDUFhKmyyX+9eo6WQjZvf51Ea/M0Q7+T374Jp1aUiyUl0GKxp8M/OETVHSDvmkyPgvX+X2w==",
      "dev": true,
      "license": "(MIT OR CC0-1.0)",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/type-is": {
      "version": "1.6.18",
      "resolved": "https://registry.npmjs.org/type-is/-/type-is-1.6.18.tgz",
      "integrity": "sha512-TkRKr9sUTxEH8MdfuCSP7VizJyzRNMjj2J2do2Jr3Kym598JVdEksuzPQCnlFPW4ky9Q+iA+ma9BGm06XQBy8g==",
      "license": "MIT",
      "dependencies": {
        "media-typer": "0.3.0",
        "mime-types": "~2.1.24"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/undefsafe": {
      "version": "2.0.5",
      "resolved": "https://registry.npmjs.org/undefsafe/-/undefsafe-2.0.5.tgz",
      "integrity": "sha512-WxONCrssBM8TSPRqN5EmsjVrsv4A8X12J4ArBiiayv3DyyG3ZlIg6yysuuSYdZsVz3TKcTg2fd//Ujd4CHV1iA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/undici-types": {
      "version": "6.20.0",
      "resolved": "https://registry.npmjs.org/undici-types/-/undici-types-6.20.0.tgz",
      "integrity": "sha512-Ny6QZ2Nju20vw1SRHe3d9jVu6gJ+4e3+MMpqu7pqE5HT6WsTSlce++GQmK5UXS8mzV8DSYHrQH+Xrf2jVcuKNg==",
      "license": "MIT"
    },
    "node_modules/unpipe": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/unpipe/-/unpipe-1.0.0.tgz",
      "integrity": "sha512-pjy2bYhSsufwWlKwPc+l3cN7+wuJlK6uz0YdJEOlQDbl6jo/YlPi4mb8agUkVC8BF7V8NuzeyPNqRksA3hztKQ==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/update-browserslist-db": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/update-browserslist-db/-/update-browserslist-db-1.1.3.tgz",
      "integrity": "sha512-UxhIZQ+QInVdunkDAaiazvvT/+fXL5Osr0JZlJulepYu6Jd7qJtDZjlur0emRlT71EN3ScPoE7gvsuIKKNavKw==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/browserslist"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "escalade": "^3.2.0",
        "picocolors": "^1.1.1"
      },
      "bin": {
        "update-browserslist-db": "cli.js"
      },
      "peerDependencies": {
        "browserslist": ">= 4.21.0"
      }
    },
    "node_modules/util-deprecate": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/util-deprecate/-/util-deprecate-1.0.2.tgz",
      "integrity": "sha512-EPD5q1uXyFxJpCrLnCc1nHnq3gOa6DZBocAIiI2TaSCA7VCJ1UJDMagCzIkXNsUYfD1daK//LTEQ8xiIbrHtcw==",
      "license": "MIT"
    },
    "node_modules/utils-merge": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/utils-merge/-/utils-merge-1.0.1.tgz",
      "integrity": "sha512-pMZTvIkT1d+TFGvDOqodOclx0QWkkgi6Tdoa8gC8ffGAAqz9pzPTZWAybbsHHoED/ztMtkv/VoYTYyShUn81hA==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4.0"
      }
    },
    "node_modules/v8-to-istanbul": {
      "version": "9.3.0",
      "resolved": "https://registry.npmjs.org/v8-to-istanbul/-/v8-to-istanbul-9.3.0.tgz",
      "integrity": "sha512-kiGUalWN+rgBJ/1OHZsBtU4rXZOfj/7rKQxULKlIzwzQSvMJUUNgPwJEEh7gU6xEVxC0ahoOBvN2YI8GH6FNgA==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "@jridgewell/trace-mapping": "^0.3.12",
        "@types/istanbul-lib-coverage": "^2.0.1",
        "convert-source-map": "^2.0.0"
      },
      "engines": {
        "node": ">=10.12.0"
      }
    },
    "node_modules/vary": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/vary/-/vary-1.1.2.tgz",
      "integrity": "sha512-BNGbWLfd0eUPabhkXUVm0j8uuvREyTh5ovRa/dyow/BqAbZJyC+5fU+IzQOzmAKzYqYRAISoRhdQr3eIZ/PXqg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/walker": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/walker/-/walker-1.0.8.tgz",
      "integrity": "sha512-ts/8E8l5b7kY0vlWLewOkDXMmPdLcVV4GmOQLyxuSswIJsweeFZtAsMF7k1Nszz+TYBQrlYRmzOnr398y1JemQ==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "makeerror": "1.0.12"
      }
    },
    "node_modules/which": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/which/-/which-2.0.2.tgz",
      "integrity": "sha512-BLI3Tl1TW3Pvl70l3yq3Y64i+awpwXqsGBYWkkqMtnbXgrMD+yj7rhW0kuEDxzJaYXGjEW5ogapKNMEKNMjibA==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "isexe": "^2.0.0"
      },
      "bin": {
        "node-which": "bin/node-which"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/winston": {
      "version": "3.17.0",
      "resolved": "https://registry.npmjs.org/winston/-/winston-3.17.0.tgz",
      "integrity": "sha512-DLiFIXYC5fMPxaRg832S6F5mJYvePtmO5G9v9IgUFPhXm9/GkXarH/TUrBAVzhTCzAj9anE/+GjrgXp/54nOgw==",
      "license": "MIT",
      "dependencies": {
        "@colors/colors": "^1.6.0",
        "@dabh/diagnostics": "^2.0.2",
        "async": "^3.2.3",
        "is-stream": "^2.0.0",
        "logform": "^2.7.0",
        "one-time": "^1.0.0",
        "readable-stream": "^3.4.0",
        "safe-stable-stringify": "^2.3.1",
        "stack-trace": "0.0.x",
        "triple-beam": "^1.3.0",
        "winston-transport": "^4.9.0"
      },
      "engines": {
        "node": ">= 12.0.0"
      }
    },
    "node_modules/winston-transport": {
      "version": "4.9.0",
      "resolved": "https://registry.npmjs.org/winston-transport/-/winston-transport-4.9.0.tgz",
      "integrity": "sha512-8drMJ4rkgaPo1Me4zD/3WLfI/zPdA9o2IipKODunnGDcuqbHwjsbB79ylv04LCGGzU0xQ6vTznOMpQGaLhhm6A==",
      "license": "MIT",
      "dependencies": {
        "logform": "^2.7.0",
        "readable-stream": "^3.6.2",
        "triple-beam": "^1.3.0"
      },
      "engines": {
        "node": ">= 12.0.0"
      }
    },
    "node_modules/wrap-ansi": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-7.0.0.tgz",
      "integrity": "sha512-YVGIj2kamLSTxw6NsZjoBxfSwsn0ycdesmc4p+Q21c5zPuZ1pl+NfxVdxPtdHvmNVOQ6XSYG4AUtyt/Fi7D16Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^4.0.0",
        "string-width": "^4.1.0",
        "strip-ansi": "^6.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/wrap-ansi?sponsor=1"
      }
    },
    "node_modules/wrappy": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/wrappy/-/wrappy-1.0.2.tgz",
      "integrity": "sha512-l4Sp/DRseor9wL6EvV2+TuQn63dMkPjZ/sp9XkghTEbV9KlPS1xUsZ3u7/IQO4wxtcFB4bgpQPRcR3QCvezPcQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/write-file-atomic": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/write-file-atomic/-/write-file-atomic-4.0.2.tgz",
      "integrity": "sha512-7KxauUdBmSdWnmpaGFg+ppNjKF8uNLry8LyzjauQDOVONfFLNKrKvQOxZ/VuTIcS/gge/YNahf5RIIQWTSarlg==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "imurmurhash": "^0.1.4",
        "signal-exit": "^3.0.7"
      },
      "engines": {
        "node": "^12.13.0 || ^14.15.0 || >=16.0.0"
      }
    },
    "node_modules/ws": {
      "version": "8.17.1",
      "resolved": "https://registry.npmjs.org/ws/-/ws-8.17.1.tgz",
      "integrity": "sha512-6XQFvXTkbfUOZOKKILFG1PDK2NDQs4azKQl26T0YS5CxqWLgXajbPZ+h4gZekJyRqFU8pvnbAbbs/3TgRPy+GQ==",
      "license": "MIT",
      "engines": {
        "node": ">=10.0.0"
      },
      "peerDependencies": {
        "bufferutil": "^4.0.1",
        "utf-8-validate": ">=5.0.2"
      },
      "peerDependenciesMeta": {
        "bufferutil": {
          "optional": true
        },
        "utf-8-validate": {
          "optional": true
        }
      }
    },
    "node_modules/y18n": {
      "version": "5.0.8",
      "resolved": "https://registry.npmjs.org/y18n/-/y18n-5.0.8.tgz",
      "integrity": "sha512-0pfFzegeDWJHJIAmTLRP2DwHjdF5s7jo9tuztdQxAhINCdvS+3nGINqPd00AphqJR/0LhANUS6/+7SCb98YOfA==",
      "dev": true,
      "license": "ISC",
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/yallist": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/yallist/-/yallist-3.1.1.tgz",
      "integrity": "sha512-a4UGQaWPH59mOXUYnAG2ewncQS4i4F43Tv3JoAM+s2VDAmS9NsK8GpDMLrCHPksFT7h3K6TOoUNn2pb7RoXx4g==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/yargs": {
      "version": "17.7.2",
      "resolved": "https://registry.npmjs.org/yargs/-/yargs-17.7.2.tgz",
      "integrity": "sha512-7dSzzRQ++CKnNI/krKnYRV7JKKPUXMEh61soaHKg9mrWEhzFWhFnxPxGl+69cD1Ou63C13NUPCnmIcrvqCuM6w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "cliui": "^8.0.1",
        "escalade": "^3.1.1",
        "get-caller-file": "^2.0.5",
        "require-directory": "^2.1.1",
        "string-width": "^4.2.3",
        "y18n": "^5.0.5",
        "yargs-parser": "^21.1.1"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/yargs-parser": {
      "version": "21.1.1",
      "resolved": "https://registry.npmjs.org/yargs-parser/-/yargs-parser-21.1.1.tgz",
      "integrity": "sha512-tVpsJW7DdjecAiFpbIB1e3qxIQsE6NoPc5/eTdrbbIC4h0LVsWhnoa3g+m2HclBIujHzsxZ4VJVA+GUuc2/LBw==",
      "dev": true,
      "license": "ISC",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/yocto-queue": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/yocto-queue/-/yocto-queue-0.1.0.tgz",
      "integrity": "sha512-rVksvsnNCdJ/ohGc6xgPwyN8eheCxsiLM8mxuE/t/mOVqJewPuO1miLpTHQiRgTKCLexL4MeAFVagts7HmNZ2Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    }
  }
}

```


### FILE: backend\node-service\package.json
```
{
  "name": "meeting-app-websocket",
  "version": "1.0.0",
  "description": "WebSocket service for the meeting application",
  "main": "src/server.js",
  "scripts": {
    "start": "node src/server.js",
    "dev": "nodemon src/server.js",
    "test": "jest"
  },
  "dependencies": {
    "compression": "^1.7.4",
    "cors": "^2.8.5",
    "dotenv": "^16.3.1",
    "express": "^4.18.2",
    "helmet": "^7.0.0",
    "ioredis": "^5.3.2",
    "jsonwebtoken": "^9.0.2",
    "morgan": "^1.10.0",
    "prom-client": "^14.2.0",
    "socket.io": "^4.7.2",
    "winston": "^3.10.0"
  },
  "devDependencies": {
    "jest": "^29.6.4",
    "nodemon": "^3.0.1"
  }
}

```


### FILE: backend\node-service\src\config.js
```
require('dotenv').config();

const config = {
  // Server configuration
  port: process.env.PORT || 3001,
  host: process.env.HOST || '0.0.0.0',

  // CORS configuration
  cors: {
    origin: process.env.CORS_ORIGIN || 'http://localhost:3000',
    methods: ['GET', 'POST'],
    credentials: true
  },

  // Redis configuration
  redis: {
    url: process.env.REDIS_URL || 'redis://redis:6379',
    options: {
      retryStrategy: (times) => {
        const delay = Math.min(times * 50, 2000);
        return delay;
      },
      maxRetriesPerRequest: 3
    }
  },

  // JWT configuration
  jwt: {
    secret: process.env.JWT_SECRET || 'your-secret-key',
    expiresIn: process.env.JWT_EXPIRES_IN || '24h'
  },

  // WebRTC configuration
  webrtc: {
    iceServers: [
      {
        urls: process.env.STUN_SERVERS?.split(',') || [
          'stun:stun.l.google.com:19302',
          'stun:stun1.l.google.com:19302'
        ]
      },
      {
        urls: process.env.TURN_SERVERS?.split(',') || [],
        username: process.env.TURN_USERNAME,
        credential: process.env.TURN_CREDENTIAL
      }
    ].filter(server => server.urls.length > 0)
  },

  // Metrics configuration
  metrics: {
    enabled: process.env.ENABLE_METRICS === 'true',
    prefix: 'meeting_app_',
    defaultLabels: {
      app: 'meeting-app',
      env: process.env.NODE_ENV || 'development'
    }
  },

  // Logging configuration
  logging: {
    level: process.env.LOG_LEVEL || 'info',
    format: process.env.LOG_FORMAT || 'json'
  },

  // File sharing configuration
  fileSharing: {
    maxSize: parseInt(process.env.MAX_FILE_SIZE) || 10 * 1024 * 1024, // 10MB
    allowedTypes: process.env.ALLOWED_FILE_TYPES?.split(',') || [
      'image/*',
      'application/pdf',
      'application/msword',
      'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
      'text/plain'
    ]
  },

  // Room configuration
  room: {
    maxParticipants: parseInt(process.env.MAX_ROOM_PARTICIPANTS) || 12,
    timeout: parseInt(process.env.ROOM_TIMEOUT) || 30 * 60 * 1000 // 30 minutes
  }
};

module.exports = config; 
```


### FILE: backend\node-service\src\server.js
```
// Initialize environment variables from .env file
try {
  require('dotenv').config();
} catch (error) {
  console.log('Error loading dotenv, using process.env variables:', error.message);
}

const express = require('express');
const http = require('http');
const socketIo = require('socket.io');
const cors = require('cors');
const Redis = require('ioredis');
const morgan = require('morgan');
const winston = require('winston');
const helmet = require('helmet');
const compression = require('compression');
const jwt = require('jsonwebtoken');
const WebRTCSignaling = require('./services/webrtc');
const ChatService = require('./services/chat');
const WhiteboardService = require('./services/whiteboard');
const config = require('./config');

// Setup logger
const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [
    new winston.transports.Console(),
    new winston.transports.File({ filename: 'logs/error.log', level: 'error' }),
    new winston.transports.File({ filename: 'logs/combined.log' })
  ]
});

// Initialize Express app
const app = express();
const server = http.createServer(app);

// Set port
const PORT = process.env.PORT || 3001;

// Middleware
app.use(cors());
app.use(helmet());
app.use(compression());
app.use(express.json());
app.use(morgan('dev'));

// Redis client
let redisClient;
let redisReconnectAttempts = 0;
const MAX_RECONNECT_ATTEMPTS = 10;

function connectRedis() {
  try {
    const redisUrl = process.env.REDIS_URL || 'redis://:dev-redis-123@redis:6379/0';
    logger.info(`Connecting to Redis at ${redisUrl.replace(/:[^:]*@/, ':****@')}`);
    
    redisClient = new Redis(redisUrl, {
      retryStrategy: (times) => {
        redisReconnectAttempts = times;
        if (times > MAX_RECONNECT_ATTEMPTS) {
          logger.error(`Redis connection failed after ${times} attempts. Giving up.`);
          return null; // stop retrying
        }
        const delay = Math.min(times * 1000, 5000);
        logger.info(`Redis reconnecting... attempt ${times}. Retrying in ${delay}ms`);
        return delay;
      }
    });

    redisClient.on('connect', () => {
      logger.info('Redis connection established');
      redisReconnectAttempts = 0;
    });

    redisClient.on('error', (err) => {
      logger.error(`Redis error: ${err.message}`);
    });

    return redisClient;
  } catch (error) {
    logger.error(`Redis connection error: ${error.message}`);
    return null;
  }
}

// Initialize Redis connection
connectRedis();

// Socket.io setup
const io = socketIo(server, {
  cors: {
    origin: '*',
    methods: ['GET', 'POST']
  }
});

// Initialize services
const webrtcService = new WebRTCSignaling(io);
const chatService = new ChatService(io);
const whiteboardService = new WhiteboardService(io);

// Health check endpoint
app.get('/health', (req, res) => {
  const healthInfo = {
    status: 'healthy',
    service: 'websocket',
    timestamp: new Date().toISOString(),
    environment: process.env.NODE_ENV || 'development',
    system_info: {
      node_version: process.version,
      platform: process.platform,
      arch: process.arch,
      hostname: require('os').hostname()
    },
    dependencies: {}
  };

  // Check Redis connectivity
  if (redisClient) {
    redisClient.ping()
      .then(() => {
        healthInfo.dependencies.redis = {
          status: 'connected',
          reconnect_attempts: redisReconnectAttempts
        };
        res.status(200).json(healthInfo);
      })
      .catch((err) => {
        healthInfo.status = 'degraded';
        healthInfo.dependencies.redis = {
          status: 'disconnected',
          error: err.message,
          reconnect_attempts: redisReconnectAttempts
        };
        res.status(200).json(healthInfo);
      });
  } else {
    healthInfo.status = 'degraded';
    healthInfo.dependencies.redis = {
      status: 'not_initialized'
    };
    res.status(200).json(healthInfo);
  }
});

// Socket.io event handlers
io.on('connection', (socket) => {
  logger.info(`User connected: ${socket.id}`);

  socket.on('join-meeting', (meetingId) => {
    socket.join(meetingId);
    logger.info(`User ${socket.id} joined meeting ${meetingId}`);
  });

  socket.on('leave-meeting', (meetingId) => {
    socket.leave(meetingId);
    logger.info(`User ${socket.id} left meeting ${meetingId}`);
  });

  socket.on('message', (data) => {
    io.to(data.meetingId).emit('message', data);
    logger.info(`Message sent in meeting ${data.meetingId} by ${socket.id}`);
  });

  socket.on('disconnect', () => {
    logger.info(`User disconnected: ${socket.id}`);
  });
});

// Start server
server.listen(PORT, () => {
  logger.info(`WebSocket service running on port ${PORT}`);
});

// Handle graceful shutdown
process.on('SIGTERM', () => {
  logger.info('SIGTERM signal received: closing HTTP server');
  server.close(() => {
    logger.info('HTTP server closed');
    if (redisClient) {
      redisClient.quit();
    }
    process.exit(0);
  });
}); 
```


### FILE: backend\node-service\src\services\chat.js
```
const { logger } = require('../utils/logger');
const { metrics } = require('../utils/metrics');

class ChatService {
  constructor(io) {
    this.io = io;
    this.messageHistory = new Map(); // roomId -> array of messages
    this.MAX_HISTORY = 100; // Maximum number of messages to keep per room
    this.typingUsers = new Map(); // roomId -> Set of typing users
  }

  // Initialize a new room's chat
  initRoom(roomId) {
    if (!this.messageHistory.has(roomId)) {
      this.messageHistory.set(roomId, []);
    }
  }

  // Handle new message
  handleMessage(socket, data) {
    const { roomId, message } = data;
    logger.info(`New message in room ${roomId} from user ${socket.id}`);
    
    this.io.to(roomId).emit('chat-message', {
      userId: socket.id,
      message,
      timestamp: Date.now()
    });
  }

  // Handle file sharing
  handleFileShare(socket, data) {
    const { roomId, fileInfo } = data;
    logger.info(`File shared in room ${roomId} by user ${socket.id}`);
    
    this.io.to(roomId).emit('file-shared', {
      userId: socket.id,
      fileInfo,
      timestamp: Date.now()
    });
  }

  // Get chat history
  getChatHistory(roomId) {
    return this.messageHistory.get(roomId) || [];
  }

  // Handle user typing status
  handleTyping(socket, data) {
    const { roomId, isTyping } = data;
    
    if (!this.typingUsers.has(roomId)) {
      this.typingUsers.set(roomId, new Set());
    }

    const roomTyping = this.typingUsers.get(roomId);
    if (isTyping) {
      roomTyping.add(socket.id);
    } else {
      roomTyping.delete(socket.id);
    }

    socket.to(roomId).emit('typing-update', {
      userId: socket.id,
      isTyping
    });
  }

  // Clean up room when it's empty
  cleanupRoom(roomId) {
    this.messageHistory.delete(roomId);
  }

  // Handle message reaction
  handleReaction(socket, data) {
    const { roomId, messageId, reaction } = data;
    
    this.io.to(roomId).emit('message-reaction', {
      userId: socket.id,
      messageId,
      reaction,
      timestamp: Date.now()
    });
  }

  handleDisconnect(socket) {
    // Remove user from typing lists in all rooms
    this.typingUsers.forEach((users, roomId) => {
      if (users.has(socket.id)) {
        users.delete(socket.id);
        if (users.size === 0) {
          this.typingUsers.delete(roomId);
        }
        // Notify room that user stopped typing
        socket.to(roomId).emit('typing-update', {
          userId: socket.id,
          isTyping: false
        });
      }
    });
  }
}

module.exports = ChatService; 
```


### FILE: backend\node-service\src\services\webrtc.js
```
const { logger } = require('../utils/logger');
const { metrics } = require('../utils/metrics');

class WebRTCSignaling {
  constructor(io) {
    this.io = io;
    this.rooms = new Map(); // roomId -> Set of socket IDs
  }

  handleJoin(socket, roomId) {
    logger.info(`User ${socket.id} joining room ${roomId}`);
    socket.join(roomId);
    
    if (!this.rooms.has(roomId)) {
      this.rooms.set(roomId, new Set());
    }
    this.rooms.get(roomId).add(socket.id);

    // Notify others in the room
    socket.to(roomId).emit('user-joined', { userId: socket.id });

    // Send list of existing peers to the new participant
    const peers = Array.from(this.rooms.get(roomId)).filter(id => id !== socket.id);
    socket.emit('room_users', {
      peers: peers.map(peerId => ({
        peerId,
        userId: this.io.sockets.sockets.get(peerId)?.userId,
        username: this.io.sockets.sockets.get(peerId)?.user?.username
      }))
    });

    logger.info(`User ${socket.userId} joined room ${roomId}`);
    metrics.activeRooms.set(this.rooms.size);
    metrics.usersPerRoom.set({ room: roomId }, this.rooms.get(roomId).size);
  }

  handleLeave(socket, roomId) {
    logger.info(`User ${socket.id} leaving room ${roomId}`);
    socket.leave(roomId);
    
    if (this.rooms.has(roomId)) {
      this.rooms.get(roomId).delete(socket.id);
      if (this.rooms.get(roomId).size === 0) {
        this.rooms.delete(roomId);
      }
    }

    // Notify others in the room
    socket.to(roomId).emit('user-left', { userId: socket.id });

    logger.info(`User ${socket.userId} left room ${roomId}`);
    metrics.activeRooms.set(this.rooms.size);
    metrics.usersPerRoom.set({ room: roomId }, this.rooms.get(roomId)?.size || 0);
  }

  handleOffer(socket, data) {
    const { targetId, offer } = data;
    logger.info(`Relaying offer from ${socket.id} to ${targetId}`);
    this.io.to(targetId).emit('offer', {
      userId: socket.id,
      offer
    });

    metrics.webrtcOffers.inc();
  }

  handleAnswer(socket, data) {
    const { targetId, answer } = data;
    logger.info(`Relaying answer from ${socket.id} to ${targetId}`);
    this.io.to(targetId).emit('answer', {
      userId: socket.id,
      answer
    });

    metrics.webrtcAnswers.inc();
  }

  handleIceCandidate(socket, data) {
    const { targetId, candidate } = data;
    logger.info(`Relaying ICE candidate from ${socket.id} to ${targetId}`);
    this.io.to(targetId).emit('ice-candidate', {
      userId: socket.id,
      candidate
    });

    metrics.iceCandidates.inc();
  }

  // Handle media stream events
  handleMediaStreamStart(socket, { roomId, type }) {
    socket.to(roomId).emit('media_stream_start', {
      userId: socket.userId,
      type // 'video', 'audio', or 'screen'
    });
  }

  handleMediaStreamStop(socket, { roomId, type }) {
    socket.to(roomId).emit('media_stream_stop', {
      userId: socket.userId,
      type
    });
  }

  // Handle connection state changes
  handleConnectionStateChange(socket, { roomId, state }) {
    socket.to(roomId).emit('peer_connection_state', {
      userId: socket.userId,
      state
    });
  }

  handleDisconnect(socket) {
    // Remove user from all rooms they were in
    this.rooms.forEach((users, roomId) => {
      if (users.has(socket.id)) {
        this.handleLeave(socket, roomId);
      }
    });
  }
}

module.exports = WebRTCSignaling; 
```


### FILE: backend\node-service\src\services\whiteboard.js
```
const { logger } = require('../utils/logger');
const { metrics } = require('../utils/metrics');

class WhiteboardService {
  constructor(io) {
    this.io = io;
    this.whiteboards = new Map();
  }

  handleDraw(socket, data) {
    const { roomId, path } = data;
    logger.info(`New drawing in room ${roomId} from user ${socket.id}`);
    
    if (!this.whiteboards.has(roomId)) {
      this.whiteboards.set(roomId, {
        paths: [],
        undoStack: [],
        redoStack: []
      });
    }

    const whiteboard = this.whiteboards.get(roomId);
    whiteboard.paths.push({
      userId: socket.id,
      path,
      timestamp: Date.now()
    });
    whiteboard.redoStack = []; // Clear redo stack on new draw

    this.io.to(roomId).emit('draw', {
      userId: socket.id,
      path
    });
  }

  handleClear(socket, data) {
    const { roomId } = data;
    logger.info(`Clearing whiteboard in room ${roomId}`);
    
    if (this.whiteboards.has(roomId)) {
      const whiteboard = this.whiteboards.get(roomId);
      whiteboard.undoStack.push([...whiteboard.paths]);
      whiteboard.paths = [];
      whiteboard.redoStack = [];
    }

    this.io.to(roomId).emit('clear', {
      userId: socket.id
    });
  }

  handleUndo(socket, data) {
    const { roomId } = data;
    
    if (this.whiteboards.has(roomId)) {
      const whiteboard = this.whiteboards.get(roomId);
      if (whiteboard.paths.length > 0) {
        const lastPath = whiteboard.paths.pop();
        whiteboard.undoStack.push(lastPath);
        
        this.io.to(roomId).emit('undo', {
          userId: socket.id,
          pathId: lastPath.timestamp
        });
      }
    }
  }

  handleRedo(socket, data) {
    const { roomId } = data;
    
    if (this.whiteboards.has(roomId)) {
      const whiteboard = this.whiteboards.get(roomId);
      if (whiteboard.undoStack.length > 0) {
        const pathToRedo = whiteboard.undoStack.pop();
        whiteboard.paths.push(pathToRedo);
        
        this.io.to(roomId).emit('redo', {
          userId: socket.id,
          path: pathToRedo.path
        });
      }
    }
  }

  handleDisconnect(socket) {
    // No cleanup needed for whiteboard data
    // Data persists until room is deleted
  }

  // Get current whiteboard state for a room
  getWhiteboardState(roomId) {
    return this.whiteboards.get(roomId) || { paths: [], undoStack: [], redoStack: [] };
  }
}

module.exports = WhiteboardService; 
```


### FILE: backend\node-service\src\utils\logger.js
```
const winston = require('winston');
const morgan = require('morgan');
const config = require('../config');

// Create Winston logger
const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [
    new winston.transports.Console(),
    new winston.transports.File({ 
      filename: 'logs/error.log', 
      level: 'error' 
    }),
    new winston.transports.File({ 
      filename: 'logs/combined.log' 
    })
  ]
});

// Create HTTP request logger middleware
const requestLogger = morgan('combined', {
  stream: {
    write: (message) => logger.http(message.trim())
  }
});

// Create WebSocket logger middleware
const wsLogger = (socket, next) => {
  const start = Date.now();
  const clientIp = socket.handshake.address;
  const query = socket.handshake.query;

  logger.info('WebSocket connection attempt', {
    clientIp,
    query,
    socketId: socket.id
  });

  // Log successful connection
  socket.on('connect', () => {
    logger.info('WebSocket connected', {
      clientIp,
      socketId: socket.id,
      connectionTime: Date.now() - start
    });
  });

  // Log disconnection
  socket.on('disconnect', (reason) => {
    logger.info('WebSocket disconnected', {
      clientIp,
      socketId: socket.id,
      reason,
      duration: Date.now() - start
    });
  });

  // Log errors
  socket.on('error', (error) => {
    logger.error('WebSocket error', {
      clientIp,
      socketId: socket.id,
      error: error.message,
      stack: error.stack
    });
  });

  next();
};

module.exports = {
  logger,
  requestLogger,
  wsLogger
}; 
```


### FILE: backend\node-service\src\utils\metrics.js
```
const promClient = require('prom-client');
const config = require('../config');

// Initialize metrics registry
const register = new promClient.Registry();

// Add default labels from config
register.setDefaultLabels(config.metrics.defaultLabels);

// Define metrics
const metrics = {
  // Connection metrics
  activeConnections: new promClient.Gauge({
    name: `${config.metrics.prefix}active_connections`,
    help: 'Number of active WebSocket connections',
    registers: [register]
  }),

  // Room metrics
  activeRooms: new promClient.Gauge({
    name: `${config.metrics.prefix}active_rooms`,
    help: 'Number of active meeting rooms',
    registers: [register]
  }),

  usersPerRoom: new promClient.Gauge({
    name: `${config.metrics.prefix}users_per_room`,
    help: 'Number of users in each room',
    labelNames: ['room'],
    registers: [register]
  }),

  // WebRTC metrics
  webrtcOffers: new promClient.Counter({
    name: `${config.metrics.prefix}webrtc_offers_total`,
    help: 'Total number of WebRTC offers sent',
    registers: [register]
  }),

  webrtcAnswers: new promClient.Counter({
    name: `${config.metrics.prefix}webrtc_answers_total`,
    help: 'Total number of WebRTC answers sent',
    registers: [register]
  }),

  iceCandidates: new promClient.Counter({
    name: `${config.metrics.prefix}ice_candidates_total`,
    help: 'Total number of ICE candidates exchanged',
    registers: [register]
  }),

  webrtcErrors: new promClient.Counter({
    name: `${config.metrics.prefix}webrtc_errors_total`,
    help: 'Total number of WebRTC errors',
    registers: [register]
  }),

  // Chat metrics
  chatMessages: new promClient.Counter({
    name: `${config.metrics.prefix}chat_messages_total`,
    help: 'Total number of chat messages sent',
    labelNames: ['type'],
    registers: [register]
  }),

  messageReactions: new promClient.Counter({
    name: `${config.metrics.prefix}message_reactions_total`,
    help: 'Total number of message reactions',
    registers: [register]
  }),

  // File sharing metrics
  fileShares: new promClient.Counter({
    name: `${config.metrics.prefix}file_shares_total`,
    help: 'Total number of files shared',
    registers: [register]
  }),

  fileShareBytes: new promClient.Counter({
    name: `${config.metrics.prefix}file_share_bytes_total`,
    help: 'Total bytes of shared files',
    registers: [register]
  }),

  // Whiteboard metrics
  whiteboardStrokes: new promClient.Counter({
    name: `${config.metrics.prefix}whiteboard_strokes_total`,
    help: 'Total number of whiteboard strokes',
    registers: [register]
  }),

  whiteboardClears: new promClient.Counter({
    name: `${config.metrics.prefix}whiteboard_clears_total`,
    help: 'Total number of whiteboard clears',
    registers: [register]
  }),

  whiteboardUndos: new promClient.Counter({
    name: `${config.metrics.prefix}whiteboard_undos_total`,
    help: 'Total number of whiteboard undos',
    registers: [register]
  }),

  whiteboardRedos: new promClient.Counter({
    name: `${config.metrics.prefix}whiteboard_redos_total`,
    help: 'Total number of whiteboard redos',
    registers: [register]
  })
};

// Create metrics middleware
const metricsMiddleware = async (req, res) => {
  try {
    res.set('Content-Type', register.contentType);
    res.end(await register.metrics());
  } catch (error) {
    res.status(500).end(error.message);
  }
};

module.exports = {
  metrics,
  metricsMiddleware,
  register
}; 
```


### FILE: backend\shared\__init__.py
```
"""
Shared modules package for backend services.
Provides consistent import mechanisms across different services.
"""

import os
import sys
import importlib
import logging

logger = logging.getLogger(__name__)

# Define potential module paths
POTENTIAL_PATHS = [
    '/app',
    '/app/shared',
    '/app/backend/shared',
    os.path.dirname(os.path.dirname(os.path.abspath(__file__))),  # Project root
    os.path.dirname(os.path.abspath(__file__)),  # Shared module directory
]

# Add paths to sys.path if not already present
for path in POTENTIAL_PATHS:
    if path not in sys.path and os.path.exists(path):
        sys.path.append(path)
        logger.debug(f"Added {path} to sys.path")

# Helper function to import a module with fallbacks
def import_module(module_name, package=None):
    """
    Import a module with fallbacks.
    
    Args:
        module_name: The name of the module to import
        package: The package to import from (optional)
        
    Returns:
        The imported module, or None if not found
    """
    # Try different import paths
    possible_imports = [
        module_name,  # Direct import
        f"shared.{module_name}",  # From shared package
        f"backend.shared.{module_name}",  # From backend.shared package
    ]
    
    if package:
        possible_imports.extend([
            f"{package}.{module_name}",
            f"shared.{package}.{module_name}",
            f"backend.shared.{package}.{module_name}",
        ])
    
    for import_path in possible_imports:
        try:
            return importlib.import_module(import_path)
        except ImportError:
            continue
    
    return None

# Import key shared modules with fallbacks
try:
    # Import logging module
    logging_module = import_module('logging')
    
    # Import middleware modules
    middleware_module = import_module('middleware')
    request_id_module = import_module('request_id', 'middleware')
    
    # Import database modules
    database_module = import_module('database')
    
    # Import utils modules
    utils_module = import_module('utils')
    http_module = import_module('http', 'utils')
    
    # Import config
    config_module = import_module('config')
    
    IMPORTS_SUCCESSFUL = True
except Exception as e:
    IMPORTS_SUCCESSFUL = False
    logger.error(f"Error importing shared modules: {e}")

# Define public exports
__all__ = [
    'import_module',
    'logging_module',
    'middleware_module',
    'request_id_module',
    'database_module',
    'utils_module',
    'http_module',
    'config_module',
] 
```


### FILE: backend\shared\config.py
```
"""
Standardized configuration module for backend services.
Provides consistent configuration across different services.
"""

import os
from pathlib import Path

class BaseConfig:
    """Base configuration settings shared across all environments"""
    # Environment settings
    DEBUG = False
    TESTING = False
    ENV = 'production'
    
    # Application settings
    API_PREFIX = "/api"
    
    # Security settings
    SECRET_KEY = os.environ.get("SECRET_KEY")
    JWT_SECRET_KEY = os.environ.get("JWT_SECRET_KEY")
    SERVICE_KEY = os.environ.get("SERVICE_KEY")
    JWT_ALGORITHM = "HS256"
    JWT_ACCESS_TOKEN_EXPIRES = 60 * 60  # 1 hour
    JWT_REFRESH_TOKEN_EXPIRES = 30 * 24 * 60 * 60  # 30 days
    BCRYPT_LOG_ROUNDS = 13
    
    # Database settings
    SQLALCHEMY_TRACK_MODIFICATIONS = False
    
    # Redis settings
    REDIS_URL = os.environ.get("REDIS_URL", "redis://localhost:6379/0")
    REDIS_TOKEN_BLACKLIST_DB = 1
    
    # CORS settings
    CORS_ORIGINS = os.environ.get("CORS_ORIGINS", "http://localhost:3000").split(",")
    CORS_METHODS = ["GET", "POST", "PUT", "DELETE", "OPTIONS"]
    CORS_HEADERS = ["Content-Type", "Authorization", "X-Service-Key", "X-Request-ID", "X-Correlation-ID"]
    
    # Logging settings
    LOG_LEVEL = "INFO"
    JSON_LOGS = os.environ.get("JSON_LOGS", "true").lower() == "true"
    LOG_TO_FILE = os.environ.get("LOG_TO_FILE", "false").lower() == "true"
    LOG_FILE = os.environ.get("LOG_FILE", "logs/app.log")
    
    # Service discovery settings
    SERVICE_DISCOVERY_PROVIDER = os.environ.get("SERVICE_DISCOVERY_PROVIDER", "env")
    
    # Secret management settings
    SECRET_MANAGER_TYPE = os.environ.get("SECRET_MANAGER_TYPE", "env")
    
    # File paths
    ROOT_DIR = Path("/app")
    LOG_DIR = ROOT_DIR / "logs"
    
    # Ensure directories exist
    LOG_DIR.mkdir(parents=True, exist_ok=True)
    
    # Service URLs
    AUTH_SERVICE_URL = os.environ.get("AUTH_SERVICE_URL", "http://auth-service:5001")
    BACKEND_SERVICE_URL = os.environ.get("BACKEND_SERVICE_URL", "http://backend:5000")
    WEBSOCKET_SERVICE_URL = os.environ.get("WEBSOCKET_SERVICE_URL", "http://websocket:3001")
    FRONTEND_URL = os.environ.get("FRONTEND_URL", "http://localhost:3000")


class DevelopmentConfig(BaseConfig):
    """Development environment specific configuration"""
    DEBUG = True
    ENV = 'development'
    LOG_LEVEL = "DEBUG"
    
    # More lenient security settings for development
    BCRYPT_LOG_ROUNDS = 4
    JWT_ACCESS_TOKEN_EXPIRES = 24 * 60 * 60  # 24 hours in development
    
    # Enable detailed error messages and SQL query logging
    SQLALCHEMY_ECHO = True
    
    # Development-specific settings
    PRESERVE_CONTEXT_ON_EXCEPTION = False
    
    # Extended CORS settings for development
    CORS_ORIGINS = os.environ.get("CORS_ORIGINS", 
                                "http://localhost:3000,http://127.0.0.1:3000").split(",")


class TestingConfig(BaseConfig):
    """Testing environment specific configuration"""
    TESTING = True
    DEBUG = True
    ENV = 'testing'
    
    # Use in-memory database for testing
    SQLALCHEMY_DATABASE_URI = "sqlite:///:memory:"
    
    # Disable CSRF protection for testing
    WTF_CSRF_ENABLED = False
    
    # Faster password hashing for tests
    BCRYPT_LOG_ROUNDS = 4
    
    # Shorter token expiration for testing
    JWT_ACCESS_TOKEN_EXPIRES = 300  # 5 minutes
    JWT_REFRESH_TOKEN_EXPIRES = 600  # 10 minutes
    
    # Mock external services
    REDIS_URL = "redis://localhost:6379/2"
    
    # Disable email sending in tests
    MAIL_SUPPRESS_SEND = True


class ProductionConfig(BaseConfig):
    """Production environment specific configuration"""
    LOG_LEVEL = "INFO"
    
    # Production security settings
    WTF_CSRF_SSL_STRICT = True
    PREFERRED_URL_SCHEME = 'https'
    
    # Set stricter CORS
    CORS_ORIGINS = os.environ.get("CORS_ORIGINS", "https://yourdomain.com").split(",")
    
    # Production database settings
    SQLALCHEMY_ENGINE_OPTIONS = {
        'pool_size': 10,
        'pool_recycle': 300,
        'pool_pre_ping': True,
        'max_overflow': 15
    }
    
    # Enhanced logging for production
    LOG_TO_FILE = True


class AuthServiceConfig(BaseConfig):
    """Auth service specific configuration"""
    APP_NAME = "Auth Service"
    SQLALCHEMY_DATABASE_URI = os.environ.get("AUTH_DATABASE_URL")
    OAUTH_PROVIDERS = {
        'google': {
            'client_id': os.environ.get("GOOGLE_CLIENT_ID"),
            'client_secret': os.environ.get("GOOGLE_CLIENT_SECRET")
        }
    }


class FlaskServiceConfig(BaseConfig):
    """Flask service specific configuration"""
    APP_NAME = "Meeting API Service"
    SQLALCHEMY_DATABASE_URI = os.environ.get("BACKEND_DATABASE_URL")


class WebsocketServiceConfig(BaseConfig):
    """Websocket service specific configuration"""
    APP_NAME = "Websocket Service"
    WEBSOCKET_PORT = int(os.environ.get("WEBSOCKET_PORT", 3001))


# Config dictionary mapping
config = {
    'development': DevelopmentConfig,
    'testing': TestingConfig,
    'production': ProductionConfig,
    'default': DevelopmentConfig,
    'auth': AuthServiceConfig,
    'flask': FlaskServiceConfig,
    'websocket': WebsocketServiceConfig,
}


def get_config(env_name=None):
    """
    Get configuration based on environment name.
    
    Args:
        env_name: Environment name ('development', 'testing', 'production')
        
    Returns:
        Configuration class
    """
    if not env_name:
        env_name = os.environ.get('FLASK_ENV', 'development')
    
    # Combine service-specific config with env-specific config
    service_type = os.environ.get('SERVICE_TYPE', 'default')
    base_config = config.get(env_name, config['default'])
    service_config = config.get(service_type, config['default'])
    
    # Create a new config class that inherits from both
    class CombinedConfig(service_config, base_config):
        pass
    
    return CombinedConfig 
```


### FILE: backend\shared\database.py
```
from contextlib import contextmanager
from sqlalchemy.exc import SQLAlchemyError
from flask_sqlalchemy import SQLAlchemy

db = SQLAlchemy()

@contextmanager
def transaction():
    """
    Context manager for database transactions.
    Automatically handles commit/rollback based on exceptions.
    
    Usage:
        with transaction():
            db.session.add(some_model)
            db.session.add(another_model)
    """
    try:
        yield
        db.session.commit()
    except SQLAlchemyError as e:
        db.session.rollback()
        raise e
    except Exception as e:
        db.session.rollback()
        raise e

# Alias for backward compatibility
transaction_context = transaction

def init_db(app):
    """Initialize the database with the app"""
    db.init_app(app)
    
    with app.app_context():
        db.create_all() 
```


### FILE: backend\shared\errors.py
```
"""
Standardized error handling for backend services.
Provides common error classes and utilities for consistent error responses.
"""

import logging
import traceback
from datetime import datetime
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)

# Try to import request ID functionality
try:
    from backend.shared.middleware.request_id import get_request_id
    HAS_REQUEST_ID = True
except ImportError:
    try:
        from shared.middleware.request_id import get_request_id
        HAS_REQUEST_ID = True
    except ImportError:
        HAS_REQUEST_ID = False

class APIError(Exception):
    """Base exception class for API errors with status code and message"""
    
    def __init__(self, message: str, status_code: int = 400, details: Optional[Dict[str, Any]] = None):
        """
        Initialize API error.
        
        Args:
            message: Error message
            status_code: HTTP status code
            details: Additional error details
        """
        self.message = message
        self.status_code = status_code
        self.details = details or {}
        self.timestamp = datetime.utcnow().isoformat() + 'Z'
        
        # Add request ID if available
        if HAS_REQUEST_ID:
            self.request_id = get_request_id()
        else:
            self.request_id = None
    
    def to_dict(self) -> Dict[str, Any]:
        """
        Convert exception to dictionary representation.
        
        Returns:
            Dictionary with error details
        """
        error_dict = {
            'error': True,
            'status_code': self.status_code,
            'message': self.message,
            'timestamp': self.timestamp
        }
        
        # Include request ID if available
        if hasattr(self, 'request_id') and self.request_id:
            error_dict['request_id'] = self.request_id
        
        # Include additional details if provided
        if self.details:
            error_dict['details'] = self.details
        
        return error_dict

# --- User and Authentication Errors ---

class ValidationError(APIError):
    """Exception for data validation errors"""
    
    def __init__(self, message: str = "Validation error", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=422, details=details)

class AuthenticationError(APIError):
    """Exception for authentication failures"""
    
    def __init__(self, message: str = "Authentication required", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=401, details=details)

class AuthorizationError(APIError):
    """Exception for authorization failures"""
    
    def __init__(self, message: str = "Not authorized", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=403, details=details)

class UserExistsError(APIError):
    """Exception for duplicate user registration"""
    
    def __init__(self, message: str = "User already exists", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=409, details=details)

class UserNotFoundError(APIError):
    """Exception for user not found"""
    
    def __init__(self, message: str = "User not found", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=404, details=details)

class TokenError(APIError):
    """Exception for token validation failures"""
    
    def __init__(self, message: str = "Invalid or expired token", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=401, details=details)

# --- Resource Errors ---

class ResourceNotFoundError(APIError):
    """Exception for resource not found"""
    
    def __init__(self, message: str = "Resource not found", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=404, details=details)

class ResourceExistsError(APIError):
    """Exception for duplicate resource"""
    
    def __init__(self, message: str = "Resource already exists", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=409, details=details)

# --- Service Errors ---

class ServiceError(APIError):
    """Exception for service failures"""
    
    def __init__(self, message: str = "Service error", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=500, details=details)

class ConfigurationError(APIError):
    """Exception for configuration errors"""
    
    def __init__(self, message: str = "Configuration error", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=500, details=details)

class DependencyError(APIError):
    """Exception for dependency failures"""
    
    def __init__(self, message: str = "Dependency error", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=503, details=details)

class RateLimitError(APIError):
    """Exception for rate limiting"""
    
    def __init__(self, message: str = "Rate limit exceeded", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=429, details=details)

class EmailError(APIError):
    """Exception for email sending failures"""
    
    def __init__(self, message: str = "Failed to send email", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=500, details=details)

# Export all error classes
__all__ = [
    'APIError',
    'ValidationError',
    'AuthenticationError',
    'AuthorizationError',
    'UserExistsError',
    'UserNotFoundError',
    'TokenError',
    'ResourceNotFoundError',
    'ResourceExistsError',
    'ServiceError',
    'ConfigurationError',
    'DependencyError',
    'RateLimitError',
    'EmailError',
] 
```


### FILE: backend\shared\discovery\README.md
```
# Service Discovery Module

This module provides a unified interface for service discovery across various backends. It allows services to locate and communicate with each other dynamically, without hardcoding service locations.

## Features

- **Multiple Backend Support**: Works with environment variables, static configuration, Consul, and Kubernetes.
- **Automatic Provider Detection**: Automatically detects the appropriate provider based on the environment.
- **Consistent Interface**: Provides a unified interface regardless of the underlying discovery mechanism.
- **Service Registration**: Supports registering and deregistering services (where applicable).
- **Caching**: Implements caching to improve performance.

## Usage

### Basic Usage

```python
from backend.shared.discovery import get_service_url

# Get the URL for a service
auth_url = get_service_url('auth')
backend_url = get_service_url('backend')

# Make a request to the service
import requests
response = requests.get(f"{auth_url}/health")
```

### Getting Detailed Service Information

```python
from backend.shared.discovery import get_service

# Get detailed information about a service
auth_service = get_service('auth')
print(f"Auth service is at {auth_service['url']} on port {auth_service['port']}")
```

### Getting All Services

```python
from backend.shared.discovery import get_services

# Get all available services
services = get_services()
for name, service in services.items():
    print(f"Service {name} is at {service.get('url')}")
```

### Registering a Service

```python
from backend.shared.discovery import register_service

# Register a service
register_service('my-service', {
    'address': 'localhost',
    'port': 8080,
    'tags': ['http', 'api'],
    'check': {
        'http': 'http://localhost:8080/health',
        'interval': '10s'
    }
})
```

### Deregistering a Service

```python
from backend.shared.discovery import deregister_service

# Deregister a service
deregister_service('my-service')
```

### Explicitly Setting the Provider

```python
from backend.shared.discovery import set_discovery_provider
from backend.shared.discovery.consul import ConsulServiceDiscovery

# Create a custom provider
provider = ConsulServiceDiscovery(host='consul.example.com', port=8500)

# Set it as the global provider
set_discovery_provider(provider)
```

## Supported Providers

### Environment Variables (`EnvServiceDiscovery`)

Uses environment variables to discover services. This is the simplest provider and serves as a fallback.

Environment variables should be in the format:
- `SERVICE_<NAME>_URL`: The full URL to the service
- `SERVICE_<NAME>_HOST`: The hostname of the service
- `SERVICE_<NAME>_PORT`: The port of the service

Example:
```
SERVICE_AUTH_URL=http://auth-service:5001
SERVICE_BACKEND_HOST=backend-service
SERVICE_BACKEND_PORT=5000
```

### Static Configuration (`StaticServiceDiscovery`)

Uses a static JSON or YAML configuration file to discover services. This is useful for development and testing environments, or when using Docker Compose.

Example configuration file:
```json
{
  "auth": {
    "url": "http://auth-service:5001",
    "address": "auth-service",
    "port": 5001
  },
  "backend": {
    "url": "http://backend-service:5000",
    "address": "backend-service",
    "port": 5000
  }
}
```

### Consul (`ConsulServiceDiscovery`)

Uses HashiCorp Consul for service discovery. This is a production-ready solution that supports health checks and dynamic service registration.

Requires the `python-consul` package to be installed.

### Kubernetes (`KubernetesServiceDiscovery`)

Uses the Kubernetes API for service discovery. This is ideal for applications running in a Kubernetes cluster.

Requires the `kubernetes` package to be installed.

## Configuration

The module can be configured using environment variables:

- `SERVICE_DISCOVERY_PROVIDER`: The provider to use (`env`, `static`, `consul`, or `kubernetes`).
- `SERVICE_DISCOVERY_CONFIG_FILE`: The path to the configuration file for the static provider.
- `CONSUL_HOST`, `CONSUL_PORT`, `CONSUL_TOKEN`: Configuration for the Consul provider.
- `KUBERNETES_NAMESPACE`: The namespace to use for Kubernetes service discovery.

## Development

### Adding a New Provider

To add a new provider:

1. Create a new file in the `discovery` directory (e.g., `myservice.py`).
2. Implement a class that inherits from `ServiceDiscovery` and implements all required methods.
3. Update the `__init__.py` file to import and register the new provider.

Example:

```python
from .base import ServiceDiscovery

class MyServiceDiscovery(ServiceDiscovery):
    def __init__(self, config_param=None):
        self.config_param = config_param
        
    def get_service_url(self, service_name, default=None):
        # Implementation
        
    def get_service(self, service_name, default=None):
        # Implementation
        
    def get_services(self):
        # Implementation
        
    def register_service(self, service_name, service_data):
        # Implementation
        
    def deregister_service(self, service_name):
        # Implementation
```

Then update `__init__.py`:

```python
try:
    from .myservice import MyServiceDiscovery
    HAS_MYSERVICE = True
except ImportError:
    HAS_MYSERVICE = False

def get_discovery_provider(provider_type=None):
    # ...
    elif provider_type == 'myservice' and HAS_MYSERVICE:
        return MyServiceDiscovery()
    # ...
``` 
```


### FILE: backend\shared\discovery\__init__.py
```
"""
Service discovery module for dynamically locating services.
Provides a unified interface for service discovery across different backends.
"""

import os
import logging

logger = logging.getLogger(__name__)

# Import strategies (with fallback mechanism)
try:
    from .consul import ConsulServiceDiscovery
    HAS_CONSUL = True
except ImportError:
    logger.debug("Consul module not available")
    HAS_CONSUL = False

try:
    from .kubernetes import KubernetesServiceDiscovery
    HAS_K8S = True
except ImportError:
    logger.debug("Kubernetes module not available")
    HAS_K8S = False

from .static import StaticServiceDiscovery
from .env import EnvServiceDiscovery


def get_discovery_provider(provider_type=None):
    """
    Factory method to get the appropriate service discovery provider.
    
    Args:
        provider_type: Type of service discovery to use (consul, kubernetes, env, static)
                       If None, will try to determine from environment.
                       
    Returns:
        An instance of the appropriate service discovery class.
    """
    # If not specified, determine from environment
    if not provider_type:
        provider_type = os.environ.get('SERVICE_DISCOVERY', 'env').lower()
    
    if provider_type == 'consul' and HAS_CONSUL:
        logger.info("Using Consul for service discovery")
        consul_host = os.environ.get('CONSUL_HOST', 'localhost')
        consul_port = int(os.environ.get('CONSUL_PORT', '8500'))
        return ConsulServiceDiscovery(host=consul_host, port=consul_port)
    
    elif provider_type == 'kubernetes' and HAS_K8S:
        logger.info("Using Kubernetes for service discovery")
        namespace = os.environ.get('K8S_NAMESPACE', 'default')
        return KubernetesServiceDiscovery(namespace=namespace)
    
    elif provider_type == 'static':
        logger.info("Using static configuration for service discovery")
        config_file = os.environ.get('SERVICE_CONFIG', '/app/config/services.json')
        return StaticServiceDiscovery(config_file=config_file)
    
    # Default to environment variables
    logger.info("Using environment variables for service discovery")
    return EnvServiceDiscovery()


# Global service discovery instance
_discovery_provider = None

def get_service_url(service_name, default=None):
    """
    Get the URL for a service by name.
    
    Args:
        service_name: The service name to look up
        default: Default URL if service not found
        
    Returns:
        The service URL, or default if not found
    """
    global _discovery_provider
    
    if _discovery_provider is None:
        _discovery_provider = get_discovery_provider()
        
    return _discovery_provider.get_service_url(service_name, default)


def get_service(service_name, default=None):
    """
    Get detailed information for a service by name.
    
    Args:
        service_name: The service name to look up
        default: Default value if service not found
        
    Returns:
        Dictionary with service details, or default if not found
    """
    global _discovery_provider
    
    if _discovery_provider is None:
        _discovery_provider = get_discovery_provider()
        
    return _discovery_provider.get_service(service_name, default)


def get_services():
    """
    Get all available services.
    
    Returns:
        Dictionary of service name to service details
    """
    global _discovery_provider
    
    if _discovery_provider is None:
        _discovery_provider = get_discovery_provider()
        
    return _discovery_provider.get_services()


def register_service(service_name, service_data):
    """
    Register a service with the discovery system.
    
    Args:
        service_name: The service name to register
        service_data: Service details (URL, health check, etc.)
        
    Returns:
        True if registration was successful, False otherwise
    """
    global _discovery_provider
    
    if _discovery_provider is None:
        _discovery_provider = get_discovery_provider()
        
    return _discovery_provider.register_service(service_name, service_data)


def deregister_service(service_name):
    """
    Deregister a service from the discovery system.
    
    Args:
        service_name: The service name to deregister
        
    Returns:
        True if deregistration was successful, False otherwise
    """
    global _discovery_provider
    
    if _discovery_provider is None:
        _discovery_provider = get_discovery_provider()
        
    return _discovery_provider.deregister_service(service_name)


def set_discovery_provider(provider):
    """
    Explicitly set the service discovery provider to use.
    
    Args:
        provider: An instance of a ServiceDiscovery class
    """
    global _discovery_provider
    _discovery_provider = provider
    logger.info(f"Service discovery provider explicitly set to {provider.__class__.__name__}") 
```


### FILE: backend\shared\discovery\base.py
```
"""
Base class for service discovery.
Defines the interface that all service discovery implementations must follow.
"""

from abc import ABC, abstractmethod


class ServiceDiscovery(ABC):
    """
    Abstract base class for service discovery.
    All service discovery implementations must extend this class.
    """
    
    @abstractmethod
    def get_service_url(self, service_name, default=None):
        """
        Get the URL for a service by name.
        
        Args:
            service_name: The service name to look up
            default: Default URL if service not found
            
        Returns:
            The service URL, or default if not found
        """
        pass
    
    @abstractmethod
    def get_service(self, service_name, default=None):
        """
        Get detailed information for a service by name.
        
        Args:
            service_name: The service name to look up
            default: Default value if service not found
            
        Returns:
            Dictionary with service details, or default if not found
        """
        pass
    
    @abstractmethod
    def get_services(self):
        """
        Get all available services.
        
        Returns:
            Dictionary of service name to service details
        """
        pass
    
    @abstractmethod
    def register_service(self, service_name, service_data):
        """
        Register a service with the discovery system.
        
        Args:
            service_name: The service name to register
            service_data: Service details (URL, health check, etc.)
            
        Returns:
            True if registration was successful, False otherwise
        """
        pass
    
    @abstractmethod
    def deregister_service(self, service_name):
        """
        Deregister a service from the discovery system.
        
        Args:
            service_name: The service name to deregister
            
        Returns:
            True if deregistration was successful, False otherwise
        """
        pass
    
    def _normalize_service_name(self, service_name):
        """
        Normalize a service name to match the discovery system's requirements.
        
        Args:
            service_name: The service name to normalize
            
        Returns:
            Normalized service name
        """
        # Default implementation just converts to lowercase and replaces spaces with hyphens
        # Subclasses can override this if needed
        return service_name.lower().replace(' ', '-').replace('_', '-') 
```


### FILE: backend\shared\discovery\consul.py
```
"""
Consul service discovery.
Retrieves service information from HashiCorp Consul.
"""

import os
import logging
from .base import ServiceDiscovery

try:
    import consul
    HAS_CONSUL = True
except ImportError:
    HAS_CONSUL = False

logger = logging.getLogger(__name__)

class ConsulServiceDiscovery(ServiceDiscovery):
    """
    Service discovery that retrieves service information from HashiCorp Consul.
    Requires the python-consul package to be installed.
    """
    
    def __init__(self, host='localhost', port=8500, token=None, scheme='http'):
        """
        Initialize Consul service discovery.
        
        Args:
            host: Consul host (default: 'localhost')
            port: Consul port (default: 8500)
            token: Consul ACL token (optional)
            scheme: HTTP scheme (default: 'http')
        """
        if not HAS_CONSUL:
            raise ImportError("python-consul package is required for ConsulServiceDiscovery")
        
        self.host = host
        self.port = port
        self.token = token
        self.scheme = scheme
        
        self.client = consul.Consul(
            host=self.host,
            port=self.port,
            token=self.token,
            scheme=self.scheme
        )
        
        logger.info(f"Initialized Consul service discovery at {self.scheme}://{self.host}:{self.port}")
    
    def get_service_url(self, service_name, default=None):
        """
        Get the URL for a service from Consul.
        
        Args:
            service_name: The service name to look up
            default: Default URL if service not found
            
        Returns:
            The service URL, or default if not found
        """
        try:
            normalized_name = self._normalize_service_name(service_name)
            
            # Get service from Consul
            _, services = self.client.catalog.service(normalized_name)
            
            if not services:
                logger.debug(f"Service {service_name} not found in Consul")
                return default
            
            # Get the first service instance
            service = services[0]
            
            # Construct URL
            service_address = service.get('ServiceAddress') or service.get('Address')
            service_port = service.get('ServicePort')
            
            if not service_address or not service_port:
                logger.warning(f"Service {service_name} found in Consul but has no address or port")
                return default
            
            # Check for protocol tag
            tags = service.get('ServiceTags', [])
            protocol = 'https' if 'https' in tags else 'http'
            
            url = f"{protocol}://{service_address}:{service_port}"
            logger.debug(f"Found service URL for {service_name} in Consul: {url}")
            return url
        except Exception as e:
            logger.error(f"Error getting service URL from Consul: {str(e)}")
            return default
    
    def get_service(self, service_name, default=None):
        """
        Get detailed information for a service from Consul.
        
        Args:
            service_name: The service name to look up
            default: Default value if service not found
            
        Returns:
            Dictionary with service details, or default if not found
        """
        try:
            normalized_name = self._normalize_service_name(service_name)
            
            # Get service from Consul
            _, services = self.client.catalog.service(normalized_name)
            
            if not services:
                logger.debug(f"Service {service_name} not found in Consul")
                return default
            
            # Get the first service instance
            consul_service = services[0]
            
            # Format service information
            service_info = {
                'name': normalized_name,
                'id': consul_service.get('ServiceID'),
                'address': consul_service.get('ServiceAddress') or consul_service.get('Address'),
                'port': consul_service.get('ServicePort'),
                'tags': consul_service.get('ServiceTags', []),
                'meta': consul_service.get('ServiceMeta', {}),
                'node': consul_service.get('Node'),
                'datacenter': consul_service.get('Datacenter')
            }
            
            # Check for protocol tag
            tags = consul_service.get('ServiceTags', [])
            protocol = 'https' if 'https' in tags else 'http'
            
            # Construct URL
            if service_info['address'] and service_info['port']:
                service_info['url'] = f"{protocol}://{service_info['address']}:{service_info['port']}"
            
            logger.debug(f"Found service {service_name} in Consul")
            return service_info
        except Exception as e:
            logger.error(f"Error getting service from Consul: {str(e)}")
            return default
    
    def get_services(self):
        """
        Get all available services from Consul.
        
        Returns:
            Dictionary of service name to service details
        """
        try:
            # Get all services from Consul
            _, consul_services = self.client.catalog.services()
            
            services = {}
            
            # Get details for each service
            for service_name in consul_services:
                service_info = self.get_service(service_name)
                if service_info:
                    normalized_name = self._normalize_service_name(service_name)
                    services[normalized_name] = service_info
            
            logger.debug(f"Found {len(services)} services in Consul")
            return services
        except Exception as e:
            logger.error(f"Error getting services from Consul: {str(e)}")
            return {}
    
    def register_service(self, service_name, service_data):
        """
        Register a service with Consul.
        
        Args:
            service_name: The service name to register
            service_data: Service details (address, port, tags, etc.)
            
        Returns:
            True if registration was successful, False otherwise
        """
        try:
            normalized_name = self._normalize_service_name(service_name)
            
            # Extract service information
            service_id = service_data.get('id', normalized_name)
            address = service_data.get('address', 'localhost')
            port = service_data.get('port', 80)
            tags = service_data.get('tags', [])
            
            # Extract health check information
            check = None
            if 'check' in service_data:
                check = service_data['check']
            elif 'url' in service_data:
                # Default HTTP check
                check = {
                    'http': service_data['url'] + '/health',
                    'interval': '10s',
                    'timeout': '5s'
                }
            
            # Register service
            result = self.client.agent.service.register(
                name=normalized_name,
                service_id=service_id,
                address=address,
                port=port,
                tags=tags,
                check=check
            )
            
            logger.info(f"Registered service {service_name} with Consul")
            return True
        except Exception as e:
            logger.error(f"Error registering service with Consul: {str(e)}")
            return False
    
    def deregister_service(self, service_name):
        """
        Deregister a service from Consul.
        
        Args:
            service_name: The service name to deregister
            
        Returns:
            True if deregistration was successful, False otherwise
        """
        try:
            normalized_name = self._normalize_service_name(service_name)
            
            # Get service ID (could be different from name)
            service_info = self.get_service(normalized_name)
            if not service_info:
                logger.warning(f"Service {service_name} not found in Consul")
                return False
            
            service_id = service_info.get('id', normalized_name)
            
            # Deregister service
            result = self.client.agent.service.deregister(service_id)
            
            logger.info(f"Deregistered service {service_name} from Consul")
            return True
        except Exception as e:
            logger.error(f"Error deregistering service from Consul: {str(e)}")
            return False 
```


### FILE: backend\shared\discovery\env.py
```
"""
Environment variable-based service discovery.
Retrieves service information from environment variables.
"""

import os
import logging
from .base import ServiceDiscovery

logger = logging.getLogger(__name__)

class EnvServiceDiscovery(ServiceDiscovery):
    """
    Service discovery that retrieves service information from environment variables.
    This is the simplest implementation and the default fallback.
    
    Environment variables should be in the format:
    - SERVICE_<NAME>_URL for the URL
    - SERVICE_<NAME>_HOST and SERVICE_<NAME>_PORT for host/port
    
    For example:
    - SERVICE_AUTH_URL=http://auth-service:5001
    - SERVICE_BACKEND_HOST=backend
    - SERVICE_BACKEND_PORT=5000
    """
    
    def __init__(self, prefix='SERVICE'):
        """
        Initialize environment variable service discovery.
        
        Args:
            prefix: Prefix for environment variables (default: 'SERVICE')
        """
        self.prefix = prefix
        self.services_cache = None
    
    def get_service_url(self, service_name, default=None):
        """
        Get the URL for a service from environment variables.
        
        Args:
            service_name: The service name to look up
            default: Default URL if service not found
            
        Returns:
            The service URL, or default if not found
        """
        # Normalize service name
        normalized_name = self._normalize_service_name(service_name)
        
        # Try direct URL environment variable first
        url_key = f"{self.prefix}_{normalized_name.upper()}_URL"
        url = os.environ.get(url_key)
        
        if url:
            logger.debug(f"Found service URL for {service_name} in environment variable {url_key}")
            return url
        
        # Try host/port combination
        host_key = f"{self.prefix}_{normalized_name.upper()}_HOST"
        port_key = f"{self.prefix}_{normalized_name.upper()}_PORT"
        
        host = os.environ.get(host_key)
        port = os.environ.get(port_key)
        
        if host and port:
            logger.debug(f"Found service host/port for {service_name} in environment variables {host_key}/{port_key}")
            protocol = 'https' if port == '443' else 'http'
            return f"{protocol}://{host}:{port}"
        
        # Try special case for common services
        if normalized_name == 'auth':
            if 'AUTH_SERVICE_URL' in os.environ:
                logger.debug(f"Using AUTH_SERVICE_URL for {service_name}")
                return os.environ['AUTH_SERVICE_URL']
        elif normalized_name == 'backend':
            if 'BACKEND_URL' in os.environ:
                logger.debug(f"Using BACKEND_URL for {service_name}")
                return os.environ['BACKEND_URL']
        elif normalized_name == 'websocket':
            if 'WEBSOCKET_URL' in os.environ:
                logger.debug(f"Using WEBSOCKET_URL for {service_name}")
                return os.environ['WEBSOCKET_URL']
        
        logger.debug(f"Service URL for {service_name} not found in environment variables")
        return default
    
    def get_service(self, service_name, default=None):
        """
        Get detailed information for a service from environment variables.
        
        Args:
            service_name: The service name to look up
            default: Default value if service not found
            
        Returns:
            Dictionary with service details, or default if not found
        """
        # Refresh services cache
        services = self.get_services()
        
        # Normalize service name
        normalized_name = self._normalize_service_name(service_name)
        
        # Return service details or default
        return services.get(normalized_name, default)
    
    def get_services(self):
        """
        Get all available services from environment variables.
        
        Returns:
            Dictionary of service name to service details
        """
        # Return cached result if available
        if self.services_cache is not None:
            return self.services_cache
        
        services = {}
        
        # Scan environment variables for service information
        for key, value in os.environ.items():
            if not key.startswith(f"{self.prefix}_"):
                continue
            
            # Extract service name from environment variable
            parts = key.split('_')
            if len(parts) < 3:
                continue
            
            # SERVICE_NAME_URL or SERVICE_NAME_HOST or SERVICE_NAME_PORT
            service_name = parts[1].lower()
            attribute = parts[2].lower()
            
            # Initialize service if not already in services
            if service_name not in services:
                services[service_name] = {'name': service_name}
            
            # Add attribute to service
            if attribute == 'url':
                services[service_name]['url'] = value
            elif attribute == 'host':
                services[service_name]['host'] = value
            elif attribute == 'port':
                services[service_name]['port'] = value
        
        # Add special case services
        special_cases = {
            'auth': 'AUTH_SERVICE_URL',
            'backend': 'BACKEND_URL',
            'websocket': 'WEBSOCKET_URL'
        }
        
        for name, env_var in special_cases.items():
            if env_var in os.environ and name not in services:
                services[name] = {
                    'name': name,
                    'url': os.environ[env_var]
                }
        
        # Derive URLs for services with host and port but no URL
        for name, service in services.items():
            if 'url' not in service and 'host' in service and 'port' in service:
                protocol = 'https' if service['port'] == '443' else 'http'
                service['url'] = f"{protocol}://{service['host']}:{service['port']}"
        
        # Cache for future use
        self.services_cache = services
        
        logger.debug(f"Found {len(services)} services in environment variables")
        return services
    
    def register_service(self, service_name, service_data):
        """
        Register a service with the environment variables.
        Note: This is a no-op for environment variables as they can't be modified at runtime.
        
        Args:
            service_name: The service name to register
            service_data: Service details (URL, health check, etc.)
            
        Returns:
            False (not supported)
        """
        logger.warning("Service registration not supported with environment variable discovery")
        return False
    
    def deregister_service(self, service_name):
        """
        Deregister a service from the environment variables.
        Note: This is a no-op for environment variables as they can't be modified at runtime.
        
        Args:
            service_name: The service name to deregister
            
        Returns:
            False (not supported)
        """
        logger.warning("Service deregistration not supported with environment variable discovery")
        return False 
```


### FILE: backend\shared\discovery\kubernetes.py
```
"""
Kubernetes service discovery.
Retrieves service information from the Kubernetes API.
"""

import os
import logging
from .base import ServiceDiscovery

try:
    from kubernetes import client, config
    HAS_K8S = True
except ImportError:
    HAS_K8S = False

logger = logging.getLogger(__name__)

class KubernetesServiceDiscovery(ServiceDiscovery):
    """
    Service discovery that retrieves service information from the Kubernetes API.
    Requires the kubernetes package to be installed.
    """
    
    def __init__(self, namespace=None, in_cluster=None):
        """
        Initialize Kubernetes service discovery.
        
        Args:
            namespace: Kubernetes namespace to search in (default: from env or 'default')
            in_cluster: Whether to use in-cluster config (default: auto-detect)
        """
        if not HAS_K8S:
            raise ImportError("kubernetes package is required for KubernetesServiceDiscovery")
        
        # Get namespace from environment or use default
        self.namespace = namespace or os.environ.get('KUBERNETES_NAMESPACE', 'default')
        
        # Auto-detect if we're running in a cluster
        if in_cluster is None:
            in_cluster = os.path.exists('/var/run/secrets/kubernetes.io/serviceaccount/token')
        
        self.in_cluster = in_cluster
        
        # Initialize Kubernetes client
        if self.in_cluster:
            config.load_incluster_config()
            logger.info("Using in-cluster Kubernetes configuration")
        else:
            config.load_kube_config()
            logger.info("Using local Kubernetes configuration")
        
        self.core_api = client.CoreV1Api()
        logger.info(f"Initialized Kubernetes service discovery in namespace {self.namespace}")
    
    def get_service_url(self, service_name, default=None):
        """
        Get the URL for a service from Kubernetes.
        
        Args:
            service_name: The service name to look up
            default: Default URL if service not found
            
        Returns:
            The service URL, or default if not found
        """
        try:
            normalized_name = self._normalize_service_name(service_name)
            
            # Get service from Kubernetes
            service = self.core_api.read_namespaced_service(
                name=normalized_name,
                namespace=self.namespace
            )
            
            if not service:
                logger.debug(f"Service {service_name} not found in Kubernetes")
                return default
            
            # Get cluster IP
            cluster_ip = service.spec.cluster_ip
            
            # Get port
            if not service.spec.ports:
                logger.warning(f"Service {service_name} has no ports")
                return default
            
            # Use the first port by default
            port = service.spec.ports[0].port
            
            # Check for protocol annotation
            annotations = service.metadata.annotations or {}
            protocol = annotations.get('protocol', 'http')
            
            url = f"{protocol}://{normalized_name}.{self.namespace}.svc.cluster.local:{port}"
            logger.debug(f"Found service URL for {service_name} in Kubernetes: {url}")
            return url
        except client.rest.ApiException as e:
            if e.status == 404:
                logger.debug(f"Service {service_name} not found in Kubernetes")
                return default
            logger.error(f"Kubernetes API error: {str(e)}")
            return default
        except Exception as e:
            logger.error(f"Error getting service URL from Kubernetes: {str(e)}")
            return default
    
    def get_service(self, service_name, default=None):
        """
        Get detailed information for a service from Kubernetes.
        
        Args:
            service_name: The service name to look up
            default: Default value if service not found
            
        Returns:
            Dictionary with service details, or default if not found
        """
        try:
            normalized_name = self._normalize_service_name(service_name)
            
            # Get service from Kubernetes
            service = self.core_api.read_namespaced_service(
                name=normalized_name,
                namespace=self.namespace
            )
            
            if not service:
                logger.debug(f"Service {service_name} not found in Kubernetes")
                return default
            
            # Get endpoints for this service
            endpoints = self.core_api.read_namespaced_endpoints(
                name=normalized_name,
                namespace=self.namespace
            )
            
            # Format service information
            service_info = {
                'name': normalized_name,
                'namespace': self.namespace,
                'cluster_ip': service.spec.cluster_ip,
                'external_ip': None,
                'port': None,
                'ports': [],
                'annotations': service.metadata.annotations or {},
                'labels': service.metadata.labels or {},
                'type': service.spec.type,
                'endpoints': []
            }
            
            # Get external IP if available
            if service.status.load_balancer and service.status.load_balancer.ingress:
                for ingress in service.status.load_balancer.ingress:
                    if ingress.ip:
                        service_info['external_ip'] = ingress.ip
                        break
                    elif ingress.hostname:
                        service_info['external_hostname'] = ingress.hostname
                        break
            
            # Get ports
            if service.spec.ports:
                for port in service.spec.ports:
                    port_info = {
                        'name': port.name,
                        'port': port.port,
                        'target_port': port.target_port,
                        'protocol': port.protocol
                    }
                    service_info['ports'].append(port_info)
                
                # Set default port to the first one
                service_info['port'] = service.spec.ports[0].port
            
            # Get endpoints
            if endpoints and endpoints.subsets:
                for subset in endpoints.subsets:
                    for address in subset.addresses:
                        for port in subset.ports:
                            endpoint = {
                                'ip': address.ip,
                                'hostname': address.hostname,
                                'node_name': getattr(address, 'node_name', None),
                                'port': port.port,
                                'protocol': port.protocol
                            }
                            service_info['endpoints'].append(endpoint)
            
            # Check for protocol annotation
            annotations = service.metadata.annotations or {}
            protocol = annotations.get('protocol', 'http')
            
            # Construct URL
            service_info['url'] = f"{protocol}://{normalized_name}.{self.namespace}.svc.cluster.local"
            if service_info['port']:
                service_info['url'] += f":{service_info['port']}"
            
            logger.debug(f"Found service {service_name} in Kubernetes")
            return service_info
        except client.rest.ApiException as e:
            if e.status == 404:
                logger.debug(f"Service {service_name} not found in Kubernetes")
                return default
            logger.error(f"Kubernetes API error: {str(e)}")
            return default
        except Exception as e:
            logger.error(f"Error getting service from Kubernetes: {str(e)}")
            return default
    
    def get_services(self):
        """
        Get all available services in the namespace from Kubernetes.
        
        Returns:
            Dictionary of service name to service details
        """
        try:
            # Get all services in namespace
            service_list = self.core_api.list_namespaced_service(namespace=self.namespace)
            
            if not service_list or not service_list.items:
                logger.debug(f"No services found in namespace {self.namespace}")
                return {}
            
            services = {}
            
            # Get details for each service
            for k8s_service in service_list.items:
                service_name = k8s_service.metadata.name
                service_info = self.get_service(service_name)
                if service_info:
                    normalized_name = self._normalize_service_name(service_name)
                    services[normalized_name] = service_info
            
            logger.debug(f"Found {len(services)} services in namespace {self.namespace}")
            return services
        except Exception as e:
            logger.error(f"Error getting services from Kubernetes: {str(e)}")
            return {}
    
    def register_service(self, service_name, service_data):
        """
        Register a service with Kubernetes.
        Note: This is not typically how Kubernetes services are created.
        Kubernetes services are usually defined via YAML manifests or Helm charts.
        
        Args:
            service_name: The service name to register
            service_data: Service details
            
        Returns:
            False - not supported
        """
        logger.warning("Service registration via API is not recommended in Kubernetes")
        logger.warning("Use kubectl apply, Helm, or another deployment tool instead")
        return False
    
    def deregister_service(self, service_name):
        """
        Deregister a service from Kubernetes.
        Note: This is not typically how Kubernetes services are removed.
        
        Args:
            service_name: The service name to deregister
            
        Returns:
            False - not supported
        """
        logger.warning("Service deregistration via API is not recommended in Kubernetes")
        logger.warning("Use kubectl delete, Helm, or another deployment tool instead")
        return False 
```


### FILE: backend\shared\discovery\static.py
```
"""
Static file-based service discovery.
Retrieves service information from a static JSON or YAML configuration file.
"""

import os
import json
import logging
from pathlib import Path
from .base import ServiceDiscovery

logger = logging.getLogger(__name__)

class StaticServiceDiscovery(ServiceDiscovery):
    """
    Service discovery that retrieves service information from a static configuration file.
    This is useful for development and testing environments, or when using Docker Compose.
    """
    
    def __init__(self, config_file='/app/config/services.json'):
        """
        Initialize static file service discovery.
        
        Args:
            config_file: Path to the configuration file (JSON or YAML)
        """
        self.config_file = Path(config_file)
        self.services = {}
        self.last_loaded = 0
        self._load_config()
    
    def get_service_url(self, service_name, default=None):
        """
        Get the URL for a service from the static configuration.
        
        Args:
            service_name: The service name to look up
            default: Default URL if service not found
            
        Returns:
            The service URL, or default if not found
        """
        self._maybe_reload()
        
        normalized_name = self._normalize_service_name(service_name)
        
        if normalized_name in self.services:
            service = self.services[normalized_name]
            
            # Return URL if available
            if 'url' in service:
                logger.debug(f"Found service URL for {service_name} in configuration")
                return service['url']
            
            # Construct URL from host and port if available
            if 'host' in service and 'port' in service:
                protocol = service.get('protocol', 'http')
                url = f"{protocol}://{service['host']}:{service['port']}"
                logger.debug(f"Constructed service URL for {service_name} from host/port")
                return url
        
        logger.debug(f"Service URL for {service_name} not found in configuration")
        return default
    
    def get_service(self, service_name, default=None):
        """
        Get detailed information for a service from the static configuration.
        
        Args:
            service_name: The service name to look up
            default: Default value if service not found
            
        Returns:
            Dictionary with service details, or default if not found
        """
        self._maybe_reload()
        
        normalized_name = self._normalize_service_name(service_name)
        return self.services.get(normalized_name, default)
    
    def get_services(self):
        """
        Get all available services from the static configuration.
        
        Returns:
            Dictionary of service name to service details
        """
        self._maybe_reload()
        return self.services
    
    def register_service(self, service_name, service_data):
        """
        Register a service in the static configuration.
        This updates the in-memory representation and writes to the configuration file.
        
        Args:
            service_name: The service name to register
            service_data: Service details (URL, health check, etc.)
            
        Returns:
            True if registration was successful, False otherwise
        """
        normalized_name = self._normalize_service_name(service_name)
        
        # Update in-memory representation
        self.services[normalized_name] = service_data
        
        # Write to file
        try:
            self._write_config()
            logger.info(f"Registered service {service_name} in configuration")
            return True
        except Exception as e:
            logger.error(f"Failed to register service {service_name}: {str(e)}")
            return False
    
    def deregister_service(self, service_name):
        """
        Deregister a service from the static configuration.
        This updates the in-memory representation and writes to the configuration file.
        
        Args:
            service_name: The service name to deregister
            
        Returns:
            True if deregistration was successful, False otherwise
        """
        normalized_name = self._normalize_service_name(service_name)
        
        # Check if service exists
        if normalized_name not in self.services:
            logger.warning(f"Service {service_name} not found in configuration")
            return False
        
        # Remove from in-memory representation
        del self.services[normalized_name]
        
        # Write to file
        try:
            self._write_config()
            logger.info(f"Deregistered service {service_name} from configuration")
            return True
        except Exception as e:
            logger.error(f"Failed to deregister service {service_name}: {str(e)}")
            return False
    
    def _load_config(self):
        """Load services from the configuration file."""
        if not self.config_file.exists():
            logger.warning(f"Configuration file {self.config_file} does not exist")
            return
        
        try:
            with open(self.config_file, 'r') as f:
                if self.config_file.suffix.lower() == '.json':
                    self.services = json.load(f)
                elif self.config_file.suffix.lower() in ['.yaml', '.yml']:
                    try:
                        import yaml
                        self.services = yaml.safe_load(f)
                    except ImportError:
                        logger.error("YAML support requires PyYAML. Please install it with pip install PyYAML")
                        raise
                else:
                    logger.error(f"Unsupported configuration file format: {self.config_file.suffix}")
                    return
            
            self.last_loaded = self.config_file.stat().st_mtime
            logger.info(f"Loaded {len(self.services)} services from {self.config_file}")
        except Exception as e:
            logger.error(f"Failed to load configuration file {self.config_file}: {str(e)}")
    
    def _write_config(self):
        """Write services to the configuration file."""
        try:
            # Create parent directories if they don't exist
            self.config_file.parent.mkdir(parents=True, exist_ok=True)
            
            with open(self.config_file, 'w') as f:
                if self.config_file.suffix.lower() == '.json':
                    json.dump(self.services, f, indent=2)
                elif self.config_file.suffix.lower() in ['.yaml', '.yml']:
                    try:
                        import yaml
                        yaml.dump(self.services, f)
                    except ImportError:
                        logger.error("YAML support requires PyYAML. Please install it with pip install PyYAML")
                        raise
                else:
                    logger.error(f"Unsupported configuration file format: {self.config_file.suffix}")
                    return
            
            self.last_loaded = self.config_file.stat().st_mtime
            logger.info(f"Wrote {len(self.services)} services to {self.config_file}")
        except Exception as e:
            logger.error(f"Failed to write configuration file {self.config_file}: {str(e)}")
            raise
    
    def _maybe_reload(self):
        """Reload the configuration file if it has been modified."""
        if not self.config_file.exists():
            return
        
        try:
            mtime = self.config_file.stat().st_mtime
            if mtime > self.last_loaded:
                logger.debug(f"Configuration file {self.config_file} has been modified, reloading")
                self._load_config()
        except Exception as e:
            logger.error(f"Failed to check configuration file modification time: {str(e)}") 
```


### FILE: backend\shared\logging\__init__.py
```
"""
Shared logging module for backend services.
Provides structured JSON logging and request ID tracking.
"""

from .config import (
    setup_logging,
    get_log_config,
    JSONFormatter,
    RequestIDLogFilter,
    configure_library_loggers
)

__all__ = [
    'setup_logging',
    'get_log_config',
    'JSONFormatter',
    'RequestIDLogFilter',
    'configure_library_loggers'
] 
```


### FILE: backend\shared\logging\config.py
```
"""
Standardized logging configuration for all backend services.
Supports structured JSON logging and request ID tracking.
"""

import os
import sys
import json
import logging
import logging.config
from datetime import datetime
from functools import partial

# Configure third-party library logging
def configure_library_loggers():
    """Configure third-party library loggers to reduce noise"""
    # Set higher log levels for noisy libraries
    logging.getLogger("werkzeug").setLevel(logging.WARNING)
    logging.getLogger("sqlalchemy.engine").setLevel(logging.WARNING)
    logging.getLogger("sqlalchemy.pool").setLevel(logging.WARNING)
    logging.getLogger("urllib3").setLevel(logging.WARNING)
    logging.getLogger("botocore").setLevel(logging.WARNING)
    logging.getLogger("boto3").setLevel(logging.WARNING)
    logging.getLogger("requests").setLevel(logging.WARNING)


class RequestIDLogFilter(logging.Filter):
    """Log filter that adds request and correlation IDs to log records."""
    
    def filter(self, record):
        """Add request_id and correlation_id fields to log records."""
        from flask import g, request, has_request_context
        
        # Default values
        record.request_id = "no_request_id"
        record.correlation_id = "no_correlation_id"
        record.user_id = "no_user"
        
        # Add request context if available
        if has_request_context():
            record.request_id = getattr(g, 'request_id', request.headers.get('X-Request-ID', 'no_request_id'))
            record.correlation_id = getattr(g, 'correlation_id', request.headers.get('X-Correlation-ID', 'no_correlation_id'))
            record.user_id = getattr(g, 'user_id', 'anonymous')
            
            # Add request path and method if available
            record.path = request.path
            record.method = request.method
        
        return True


class JSONFormatter(logging.Formatter):
    """
    JSON log formatter that outputs logs in a structured format.
    Includes service name, timestamp, level, message, and additional context.
    """
    
    def __init__(self, service_name=None):
        """
        Initialize the formatter with service name.
        
        Args:
            service_name: Optional service name to include in logs
        """
        super().__init__()
        self.service_name = service_name or os.environ.get('SERVICE_NAME', 'unknown')
    
    def format(self, record):
        """
        Format the log record as a JSON object.
        
        Args:
            record: The log record to format
            
        Returns:
            JSON formatted log string
        """
        log_data = {
            'timestamp': datetime.utcnow().isoformat(),
            'service': self.service_name,
            'level': record.levelname,
            'message': record.getMessage(),
            'logger': record.name,
            'module': record.module,
            'function': record.funcName,
            'line': record.lineno,
        }
        
        # Add request context if available
        if hasattr(record, 'request_id'):
            log_data['request_id'] = record.request_id
        
        if hasattr(record, 'correlation_id'):
            log_data['correlation_id'] = record.correlation_id
            
        if hasattr(record, 'user_id'):
            log_data['user_id'] = record.user_id
            
        if hasattr(record, 'path'):
            log_data['path'] = record.path
            
        if hasattr(record, 'method'):
            log_data['method'] = record.method
        
        # Add exception info if available
        if record.exc_info:
            log_data['exception'] = {
                'type': record.exc_info[0].__name__,
                'message': str(record.exc_info[1]),
                'traceback': self.formatException(record.exc_info)
            }
            
        # Add any extra attributes
        for key, value in record.__dict__.items():
            if key not in ['args', 'asctime', 'created', 'exc_info', 'exc_text', 
                           'filename', 'funcName', 'id', 'levelname', 'levelno', 
                           'lineno', 'module', 'msecs', 'message', 'msg', 'name', 
                           'pathname', 'process', 'processName', 'relativeCreated', 
                           'request_id', 'correlation_id', 'stack_info', 'thread', 
                           'threadName', 'user_id', 'path', 'method']:
                if not key.startswith('_'):
                    log_data[key] = value
        
        return json.dumps(log_data)


def get_log_config(service_name=None, log_level=None, json_logs=True, log_to_file=False, log_file=None):
    """
    Get logging configuration dictionary for a service.
    
    Args:
        service_name: Name of the service for log identification
        log_level: Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
        json_logs: Whether to use JSON formatting (default: True)
        log_to_file: Whether to log to a file (default: False)
        log_file: Path to the log file if log_to_file is True
        
    Returns:
        Logging configuration dictionary
    """
    # Default settings
    service_name = service_name or os.environ.get('SERVICE_NAME', 'service')
    log_level = log_level or os.environ.get('LOG_LEVEL', 'INFO')
    json_logs = json_logs if json_logs is not None else (os.environ.get('JSON_LOGS', 'true').lower() == 'true')
    log_to_file = log_to_file if log_to_file is not None else (os.environ.get('LOG_TO_FILE', 'false').lower() == 'true')
    log_file = log_file or os.environ.get('LOG_FILE', f'/app/logs/{service_name}.log')
    
    # Define formatters
    formatters = {
        'json': {
            '()': partial(JSONFormatter, service_name=service_name)
        },
        'standard': {
            'format': '%(asctime)s [%(levelname)s] %(name)s [%(request_id)s] [%(correlation_id)s] - %(message)s',
            'datefmt': '%Y-%m-%d %H:%M:%S'
        }
    }
    
    # Define handlers
    handlers = {
        'console': {
            'class': 'logging.StreamHandler',
            'level': log_level,
            'formatter': 'json' if json_logs else 'standard',
            'stream': 'ext://sys.stdout'
        }
    }
    
    # Add file handler if enabled
    if log_to_file:
        handlers['file'] = {
            'class': 'logging.handlers.RotatingFileHandler',
            'level': log_level,
            'formatter': 'json' if json_logs else 'standard',
            'filename': log_file,
            'maxBytes': 10485760,  # 10MB
            'backupCount': 5,
            'encoding': 'utf8'
        }
    
    # Define filters
    filters = {
        'request_id': {
            '()': RequestIDLogFilter
        }
    }
    
    # Create config dictionary
    log_config = {
        'version': 1,
        'disable_existing_loggers': False,
        'formatters': formatters,
        'filters': filters,
        'handlers': handlers,
        'loggers': {
            '': {  # Root logger
                'level': log_level,
                'handlers': ['console'] + (['file'] if log_to_file else []),
                'filters': ['request_id'],
                'propagate': False
            },
            service_name: {
                'level': log_level,
                'handlers': ['console'] + (['file'] if log_to_file else []),
                'filters': ['request_id'],
                'propagate': False
            },
            'werkzeug': {
                'level': 'WARNING',
                'handlers': ['console'] + (['file'] if log_to_file else []),
                'propagate': False
            },
            'sqlalchemy': {
                'level': 'WARNING',
                'handlers': ['console'] + (['file'] if log_to_file else []),
                'propagate': False
            }
        }
    }
    
    return log_config


def setup_logging(app=None, service_name=None, log_level=None, json_logs=True, log_to_file=False, log_file=None):
    """
    Set up logging for a Flask application or globally.
    
    Args:
        app: Optional Flask application instance
        service_name: Name of the service
        log_level: Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
        json_logs: Whether to use JSON formatting
        log_to_file: Whether to log to a file
        log_file: Path to the log file if log_to_file is True
    """
    # Configure third-party loggers
    configure_library_loggers()
    
    # Get service name from app if available and not explicitly provided
    if app and not service_name:
        service_name = app.config.get('APP_NAME', app.name)
    
    # Get log level from app if available and not explicitly provided
    if app and not log_level:
        log_level = app.config.get('LOG_LEVEL', 'INFO')
        
    # Get JSON logs setting from app if available
    if app and json_logs is None:
        json_logs = app.config.get('JSON_LOGS', True)
        
    # Get log to file setting from app if available
    if app and log_to_file is None:
        log_to_file = app.config.get('LOG_TO_FILE', False)
        
    # Get log file path from app if available and enabled
    if app and log_to_file and not log_file:
        log_file = app.config.get('LOG_FILE', f'/app/logs/{service_name}.log')
    
    # Get logging config
    log_config = get_log_config(
        service_name=service_name,
        log_level=log_level,
        json_logs=json_logs,
        log_to_file=log_to_file,
        log_file=log_file
    )
    
    # Configure logging
    logging.config.dictConfig(log_config)
    
    # Create a logger for this service
    logger = logging.getLogger(service_name)
    
    # Log startup message
    logger.info(f"Logging initialized for {service_name} at {log_level} level")
    
    return logger 
```


### FILE: backend\shared\middleware\__init__.py
```
"""
Shared middleware module for backend services.
Provides middleware for request ID tracking, logging, and more.
"""

from typing import List, Callable, Dict, Any, Optional, Type
import logging
import importlib

logger = logging.getLogger(__name__)

# Define middleware interface
class Middleware:
    """Base class for all middleware"""
    
    def __init__(self, app=None, **kwargs):
        """Initialize middleware with optional app"""
        self.app = app
        if app is not None:
            self.init_app(app, **kwargs)
    
    def init_app(self, app, **kwargs):
        """Initialize middleware with app"""
        raise NotImplementedError("Middleware must implement init_app")
        
    def process_request(self, request):
        """Process request before it reaches the view"""
        return None
        
    def process_response(self, request, response):
        """Process response after it leaves the view"""
        return response
        
    def __call__(self, environ, start_response):
        """WSGI middleware interface"""
        raise NotImplementedError("Middleware must implement __call__")


# Try to import specific middleware modules
# If not available, provide dummy implementations
try:
    from .request_id import RequestIdMiddleware
except ImportError:
    class RequestIdMiddleware(Middleware):
        """Dummy implementation of RequestIdMiddleware"""
        def init_app(self, app, **kwargs):
            logger.warning("Using dummy RequestIdMiddleware")
            
        def __call__(self, environ, start_response):
            return self.app(environ, start_response)


# Default middleware configuration
DEFAULT_MIDDLEWARE = {
    'request_id': {
        'class': RequestIdMiddleware,
        'kwargs': {
            'request_id_header': 'X-Request-ID',
            'correlation_id_header': 'X-Correlation-ID'
        }
    }
}


def register_middleware(app, middleware_list=None):
    """
    Register middleware with a Flask application.
    
    Args:
        app: Flask application
        middleware_list: List of middleware configurations or None for defaults
        
    Returns:
        Flask application with middleware registered
    """
    # Use default middleware if none specified
    if middleware_list is None:
        middleware_list = list(DEFAULT_MIDDLEWARE.values())
    
    # Add each middleware to the application
    for middleware_config in middleware_list:
        if isinstance(middleware_config, dict):
            middleware_class = middleware_config.get('class')
            kwargs = middleware_config.get('kwargs', {})
            
            if middleware_class:
                try:
                    middleware = middleware_class()
                    middleware.init_app(app, **kwargs)
                    logger.info(f"Registered middleware: {middleware_class.__name__}")
                except Exception as e:
                    logger.error(f"Failed to register middleware {middleware_class.__name__}: {str(e)}")
        elif isinstance(middleware_config, Middleware):
            # If middleware instance is provided directly
            try:
                middleware_config.init_app(app)
                logger.info(f"Registered middleware: {middleware_config.__class__.__name__}")
            except Exception as e:
                logger.error(f"Failed to register middleware {middleware_config.__class__.__name__}: {str(e)}")
    
    return app


# Import specific middleware to make them available at package level
__all__ = [
    'Middleware',
    'RequestIdMiddleware', 
    'register_middleware'
] 
```


### FILE: backend\shared\middleware\auth.py
```
from functools import wraps
from flask import request, jsonify, current_app, g
import jwt
from ..schemas.base import ErrorResponse
import logging

logger = logging.getLogger(__name__)

def jwt_required(f):
    """Decorator to require JWT token for route access"""
    @wraps(f)
    def decorated(*args, **kwargs):
        token = None
        if 'Authorization' in request.headers:
            token = request.headers['Authorization'].split(' ')[1]
        
        if not token:
            response = ErrorResponse(
                error="Authentication Error",
                message="Token is missing"
            )
            return jsonify(response.model_dump()), 401
        
        try:
            payload = jwt.decode(
                token, 
                current_app.config['JWT_SECRET_KEY'], 
                algorithms=['HS256']
            )
            g.current_user_id = payload['user_id']
            g.current_token = token
            
        except jwt.ExpiredSignatureError:
            response = ErrorResponse(
                error="Authentication Error",
                message="Token has expired"
            )
            return jsonify(response.model_dump()), 401
            
        except jwt.InvalidTokenError:
            response = ErrorResponse(
                error="Authentication Error",
                message="Invalid token"
            )
            return jsonify(response.model_dump()), 401
        
        return f(*args, **kwargs)
    
    return decorated

def service_auth_required(f):
    """Decorator to require service authentication"""
    @wraps(f)
    def decorated(*args, **kwargs):
        service_key = request.headers.get('X-Service-Key')
        expected_key = current_app.config.get('SERVICE_KEY')
        
        if not service_key or service_key != expected_key:
            response = ErrorResponse(
                error="Authentication Error",
                message="Invalid service key"
            )
            return jsonify(response.model_dump()), 403
            
        return f(*args, **kwargs)
    
    return decorated

def roles_required(*roles):
    """Decorator to require specific roles for route access"""
    def decorator(f):
        @wraps(f)
        def decorated(*args, **kwargs):
            if not hasattr(g, 'current_user_id'):
                response = ErrorResponse(
                    error="Authentication Error",
                    message="No authenticated user"
                )
                return jsonify(response.model_dump()), 401
            
            # This should be implemented based on your role management system
            user_roles = get_user_roles(g.current_user_id)
            
            if not any(role in user_roles for role in roles):
                response = ErrorResponse(
                    error="Authorization Error",
                    message="Insufficient permissions"
                )
                return jsonify(response.model_dump()), 403
                
            return f(*args, **kwargs)
        return decorated
    return decorator

def get_user_roles(user_id: int) -> list:
    """Get user roles - implement based on your role management system"""
    # This is a placeholder - implement based on your system
    return [] 
```


### FILE: backend\shared\middleware\error_handler.py
```
from functools import wraps
from flask import jsonify, current_app
from pydantic import ValidationError
from sqlalchemy.exc import SQLAlchemyError, IntegrityError
from jwt.exceptions import PyJWTError
from ..schemas.base import ErrorResponse
import logging

logger = logging.getLogger(__name__)

class APIError(Exception):
    """Base exception for API errors"""
    def __init__(self, message: str, status_code: int = 400, details: dict = None):
        self.message = message
        self.status_code = status_code
        self.details = details
        super().__init__(message)

def handle_api_errors(app):
    """Register error handlers for the Flask app"""
    
    @app.errorhandler(APIError)
    def handle_api_error(error):
        response = ErrorResponse(
            error="API Error",
            message=error.message,
            details=error.details
        )
        return jsonify(response.model_dump()), error.status_code

    @app.errorhandler(ValidationError)
    def handle_validation_error(error):
        response = ErrorResponse(
            error="Validation Error",
            message="Invalid request data",
            details={"errors": error.errors()}
        )
        return jsonify(response.model_dump()), 400

    @app.errorhandler(PyJWTError)
    def handle_jwt_error(error):
        response = ErrorResponse(
            error="Authentication Error",
            message=str(error)
        )
        return jsonify(response.model_dump()), 401

    @app.errorhandler(IntegrityError)
    def handle_integrity_error(error):
        response = ErrorResponse(
            error="Database Error",
            message="Data integrity violation",
            details={"error": str(error.orig)}
        )
        return jsonify(response.model_dump()), 409

    @app.errorhandler(SQLAlchemyError)
    def handle_db_error(error):
        logger.error(f"Database error: {str(error)}")
        response = ErrorResponse(
            error="Database Error",
            message="An error occurred while processing your request"
        )
        return jsonify(response.model_dump()), 500

    @app.errorhandler(404)
    def handle_404(error):
        response = ErrorResponse(
            error="Not Found",
            message="The requested resource was not found"
        )
        return jsonify(response.model_dump()), 404

    @app.errorhandler(405)
    def handle_405(error):
        response = ErrorResponse(
            error="Method Not Allowed",
            message=f"The {request.method} method is not allowed for this endpoint"
        )
        return jsonify(response.model_dump()), 405

    @app.errorhandler(500)
    def handle_500(error):
        logger.error(f"Internal server error: {str(error)}")
        response = ErrorResponse(
            error="Internal Server Error",
            message="An unexpected error occurred"
        )
        return jsonify(response.model_dump()), 500

def error_handler(f):
    """Decorator to handle errors in routes"""
    @wraps(f)
    def decorated(*args, **kwargs):
        try:
            return f(*args, **kwargs)
        except Exception as e:
            logger.error(f"Error in {f.__name__}: {str(e)}")
            if not isinstance(e, APIError):
                e = APIError(str(e), 500)
            response = ErrorResponse(
                error=e.__class__.__name__,
                message=str(e),
                details=getattr(e, 'details', None)
            )
            return jsonify(response.model_dump()), e.status_code
    return decorated 
```


### FILE: backend\shared\middleware\rate_limiter.py
```
from functools import wraps
from flask import request, jsonify, current_app
from redis import Redis
from datetime import datetime
import logging
from ..schemas.base import ErrorResponse

logger = logging.getLogger(__name__)

class RateLimiter:
    def __init__(self, redis_url=None):
        self.redis = Redis.from_url(
            redis_url or current_app.config.get('REDIS_URL', 'redis://localhost:6379/0')
        )

    def is_rate_limited(self, key: str, limit: int, window: int) -> tuple[bool, int]:
        """
        Check if request is rate limited
        
        Args:
            key: Rate limit key
            limit: Maximum number of requests
            window: Time window in seconds
            
        Returns:
            Tuple of (is_limited, remaining_requests)
        """
        pipe = self.redis.pipeline()
        now = datetime.utcnow().timestamp()
        window_start = now - window
        
        # Remove old entries
        pipe.zremrangebyscore(key, '-inf', window_start)
        # Add current request
        pipe.zadd(key, {str(now): now})
        # Count requests in window
        pipe.zcard(key)
        # Set expiry
        pipe.expire(key, window)
        
        _, _, count, _ = pipe.execute()
        
        return count > limit, max(0, limit - count)

def rate_limit(limit: int, window: int, key_func=None):
    """
    Rate limiting decorator
    
    Args:
        limit: Maximum number of requests
        window: Time window in seconds
        key_func: Optional function to generate rate limit key
    """
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            limiter = RateLimiter()
            
            # Get rate limit key
            if key_func:
                key = f"rate_limit:{f.__name__}:{key_func(request)}"
            else:
                key = f"rate_limit:{f.__name__}:{request.remote_addr}"
            
            is_limited, remaining = limiter.is_rate_limited(key, limit, window)
            
            if is_limited:
                response = ErrorResponse(
                    error="Rate Limit Exceeded",
                    message="Too many requests",
                    details={
                        "limit": limit,
                        "window": window,
                        "retry_after": window
                    }
                )
                return jsonify(response.model_dump()), 429
            
            # Add rate limit headers
            response = f(*args, **kwargs)
            if isinstance(response, tuple):
                response, status_code = response
            else:
                status_code = 200
                
            response.headers['X-RateLimit-Limit'] = str(limit)
            response.headers['X-RateLimit-Remaining'] = str(remaining)
            response.headers['X-RateLimit-Reset'] = str(int(datetime.utcnow().timestamp() + window))
            
            return response, status_code
            
        return decorated_function
    return decorator 
```


### FILE: backend\shared\middleware\request_id.py
```
"""
Request ID middleware module for tracking requests across services.
Generates and propagates request and correlation IDs.
"""

import logging
import uuid
import threading
from functools import wraps
from flask import Flask, request, g, has_request_context, current_app
from werkzeug.wsgi import ClosingIterator
from werkzeug.exceptions import HTTPException
from typing import Optional, Dict, Any, Callable, Union, List, Tuple

try:
    from . import Middleware
except (ImportError, ValueError):
    # Fallback if parent module not available
    class Middleware:
        """Base middleware class fallback"""
        def __init__(self, app=None, **kwargs):
            self.app = app
            if app is not None:
                self.init_app(app, **kwargs)
                
        def init_app(self, app, **kwargs):
            pass

# Thread-local storage for request ID when Flask context is not available
_request_id_local = threading.local()

logger = logging.getLogger(__name__)

class RequestIdMiddleware(Middleware):
    """
    WSGI middleware that assigns a unique request ID to each incoming request.
    Optionally preserves request ID from request header if present.
    """
    
    def __init__(self, app=None, **kwargs):
        """Initialize middleware with optional app"""
        self.app = app
        self.request_id_header = 'X-Request-ID'
        self.correlation_id_header = 'X-Correlation-ID'
        self.include_in_response = True
        
        if app is not None:
            self.init_app(app, **kwargs)
            
    def init_app(self, app: Flask, **kwargs):
        """
        Initialize middleware with Flask application.
        
        Args:
            app: Flask application
            request_id_header: Name of header containing request ID
            correlation_id_header: Name of header containing correlation ID
            include_in_response: Whether to include request/correlation IDs in response
        """
        # Store configuration
        self.request_id_header = kwargs.get('request_id_header', self.request_id_header)
        self.correlation_id_header = kwargs.get('correlation_id_header', self.correlation_id_header)
        self.include_in_response = kwargs.get('include_in_response', self.include_in_response)
        
        # Register middleware with Flask
        app.before_request(self.before_request)
        app.after_request(self.after_request)
        app.teardown_request(self.teardown_request)
        
        # Add endpoint to get current request ID (useful for testing/debugging)
        app.add_url_rule('/_request_id', '_request_id', self.request_id_endpoint)
        
        # Wrap application with WSGI middleware
        if not hasattr(app, 'wsgi_app_wrapped_by_request_id') or not app.wsgi_app_wrapped_by_request_id:
            original_wsgi_app = app.wsgi_app
            app.wsgi_app = self
            app.wsgi_app_wrapped_by_request_id = True
            self.app = original_wsgi_app
            
        logger.info(f"RequestIdMiddleware initialized with headers: {self.request_id_header}, {self.correlation_id_header}")
        
    def __call__(self, environ, start_response):
        """
        WSGI middleware implementation.
        
        Args:
            environ: WSGI environment
            start_response: WSGI start_response function
            
        Returns:
            WSGI response
        """
        # Extract request ID from environment or generate new one
        request_id = environ.get('HTTP_' + self.request_id_header.replace('-', '_').upper())
        correlation_id = environ.get('HTTP_' + self.correlation_id_header.replace('-', '_').upper())
        
        # Generate IDs if not present
        if not request_id:
            request_id = str(uuid.uuid4())
        
        if not correlation_id:
            correlation_id = request_id
            
        # Store in environment for downstream WSGI applications
        environ['request_id'] = request_id
        environ['correlation_id'] = correlation_id
        
        # Store in thread-local for access outside request context
        _request_id_local.request_id = request_id
        _request_id_local.correlation_id = correlation_id
        
        # Function to intercept the status and headers
        def custom_start_response(status, headers, exc_info=None):
            # Add request ID header to response if configured
            if self.include_in_response:
                headers_list = list(headers)
                headers_list.append((self.request_id_header, request_id))
                headers_list.append((self.correlation_id_header, correlation_id))
                headers = headers_list
            
            return start_response(status, headers, exc_info)
        
        # Process request
        try:
            return ClosingIterator(
                self.app(environ, custom_start_response),
                self.cleanup_request
            )
        except Exception as e:
            # Clean up if an exception occurs
            self.cleanup_request()
            raise
    
    def before_request(self):
        """Before request handler for Flask."""
        # Get request ID from headers or generate new one
        request_id = request.headers.get(self.request_id_header)
        correlation_id = request.headers.get(self.correlation_id_header)
        
        # Generate IDs if not present
        if not request_id:
            request_id = str(uuid.uuid4())
        
        if not correlation_id:
            correlation_id = request_id
        
        # Store in Flask g for access within request
        g.request_id = request_id
        g.correlation_id = correlation_id
        
        # Store in thread-local for access outside request context
        _request_id_local.request_id = request_id
        _request_id_local.correlation_id = correlation_id
        
        logger.debug(f"Request {request_id} started: {request.method} {request.path}")
    
    def after_request(self, response):
        """
        After request handler for Flask.
        
        Args:
            response: Flask response
            
        Returns:
            Modified response with request ID headers
        """
        # Add request ID headers to response if configured
        if self.include_in_response:
            response.headers.setdefault(
                self.request_id_header, 
                getattr(g, 'request_id', 'unknown')
            )
            response.headers.setdefault(
                self.correlation_id_header, 
                getattr(g, 'correlation_id', 'unknown')
            )
        
        logger.debug(f"Request {getattr(g, 'request_id', 'unknown')} completed with status {response.status_code}")
        return response
    
    def teardown_request(self, exception=None):
        """
        Teardown request handler for Flask.
        
        Args:
            exception: Exception if an error occurred during request processing
        """
        if exception:
            logger.error(f"Request {getattr(g, 'request_id', 'unknown')} failed: {str(exception)}")
    
    def cleanup_request(self):
        """Clean up request resources."""
        # Clear thread-local storage
        if hasattr(_request_id_local, 'request_id'):
            del _request_id_local.request_id
        if hasattr(_request_id_local, 'correlation_id'):
            del _request_id_local.correlation_id
    
    def request_id_endpoint(self):
        """Endpoint that returns the current request ID."""
        return {
            'request_id': get_request_id(),
            'correlation_id': get_correlation_id()
        }


# Helper functions to access request IDs outside middleware
def get_request_id() -> str:
    """
    Get the current request ID.
    
    Returns:
        str: Request ID from Flask g, or thread-local, or None
    """
    if has_request_context():
        return getattr(g, 'request_id', None)
    
    return getattr(_request_id_local, 'request_id', None)


def get_correlation_id() -> str:
    """
    Get the current correlation ID.
    
    Returns:
        str: Correlation ID from Flask g, or thread-local, or None
    """
    if has_request_context():
        return getattr(g, 'correlation_id', None)
    
    return getattr(_request_id_local, 'correlation_id', None)


def with_request_id(func):
    """
    Decorator that ensures a request ID exists for the decorated function.
    
    Args:
        func: Function to decorate
        
    Returns:
        Decorated function
    """
    @wraps(func)
    def wrapper(*args, **kwargs):
        # Generate request ID if none exists
        if not get_request_id():
            request_id = str(uuid.uuid4())
            _request_id_local.request_id = request_id
            _request_id_local.correlation_id = request_id
            
            # If in Flask context, store in g
            if has_request_context():
                g.request_id = request_id
                g.correlation_id = request_id
        
        # Call original function
        return func(*args, **kwargs)
    
    return wrapper


# Module exports
__all__ = [
    'RequestIdMiddleware',
    'get_request_id',
    'get_correlation_id',
    'with_request_id'
] 
```


### FILE: backend\shared\middleware\validation.py
```
from functools import wraps
from flask import request, jsonify
from pydantic import BaseModel, ValidationError
from typing import Type, List, Union, Dict, Any
from ..schemas.base import ErrorResponse
import logging
from ..database import transaction

logger = logging.getLogger(__name__)

def validate_schema(schema_class: Type[BaseModel], allow_bulk: bool = False):
    """
    Enhanced decorator to validate request data against a Pydantic schema
    
    Args:
        schema_class: Pydantic model class to validate against
        allow_bulk: Whether to allow bulk validation of a list of items
    """
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            try:
                # Get request data based on content type
                if request.is_json:
                    data = request.get_json()
                elif request.form:
                    data = request.form.to_dict()
                else:
                    data = request.args.to_dict()
                
                # Handle bulk validation if allowed and data is a list
                if allow_bulk and isinstance(data, list):
                    validated_data = [schema_class(**item) for item in data]
                else:
                    validated_data = schema_class(**data)
                
                # Add validated data to kwargs
                kwargs['data'] = validated_data
                
                # Wrap the function call in a transaction
                with transaction():
                    return f(*args, **kwargs)
                
            except ValidationError as e:
                logger.error(f"Validation error: {str(e)}")
                response = ErrorResponse(
                    error="Validation Error",
                    message="Invalid request data",
                    details={"errors": e.errors()}
                )
                return jsonify(response.model_dump()), 400
                
            except Exception as e:
                logger.error(f"Error validating request data: {str(e)}")
                response = ErrorResponse(
                    error="Validation Error",
                    message="Error processing request data"
                )
                return jsonify(response.model_dump()), 400
                
        return decorated_function
    return decorator

def validate_nested_schema(schema_class: Type[BaseModel], field_path: str):
    """
    Decorator to validate nested data in request against a Pydantic schema
    
    Args:
        schema_class: Pydantic model class to validate against
        field_path: Dot-notation path to the nested data (e.g. "user.profile")
    """
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            try:
                data = request.get_json()
                
                # Navigate to nested data using field path
                nested_data = data
                for field in field_path.split('.'):
                    nested_data = nested_data.get(field, {})
                
                # Validate nested data
                validated_data = schema_class(**nested_data)
                
                # Add validated data to kwargs using field path
                kwargs[field_path.replace('.', '_')] = validated_data
                
                # Wrap the function call in a transaction
                with transaction():
                    return f(*args, **kwargs)
                
            except ValidationError as e:
                logger.error(f"Validation error in nested schema: {str(e)}")
                response = ErrorResponse(
                    error="Validation Error",
                    message=f"Invalid data in {field_path}",
                    details={"errors": e.errors()}
                )
                return jsonify(response.model_dump()), 400
                
            except Exception as e:
                logger.error(f"Error validating nested data: {str(e)}")
                response = ErrorResponse(
                    error="Validation Error",
                    message="Error processing request data"
                )
                return jsonify(response.model_dump()), 400
                
        return decorated_function
    return decorator

def validate_query_params(*required_params):
    """
    Decorator to validate required query parameters
    
    Args:
        *required_params: Names of required query parameters
    """
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            missing_params = [
                param for param in required_params 
                if param not in request.args
            ]
            
            if missing_params:
                response = ErrorResponse(
                    error="Validation Error",
                    message="Missing required query parameters",
                    details={"missing_params": missing_params}
                )
                return jsonify(response.model_dump()), 400
                
            return f(*args, **kwargs)
        return decorated_function
    return decorator 
```


### FILE: backend\shared\models\base.py
```
from datetime import datetime
from typing import Type, TypeVar, Optional, Dict, Any
from pydantic import BaseModel
from sqlalchemy.inspection import inspect
from ..database import db, transaction

T = TypeVar('T', bound=BaseModel)

class BaseModelMixin:
    """Base model mixin with enhanced schema conversion methods"""
    
    @classmethod
    def from_schema(cls, schema: BaseModel, **kwargs) -> 'BaseModelMixin':
        """
        Create a new model instance from a Pydantic schema
        
        Args:
            schema: Pydantic schema instance
            **kwargs: Additional fields to set on the model
        """
        schema_dict = schema.model_dump(exclude_unset=True)
        schema_dict.update(kwargs)
        
        # Filter out fields that don't exist in the model
        model_fields = {c.key for c in inspect(cls).columns}
        filtered_dict = {k: v for k, v in schema_dict.items() if k in model_fields}
        
        return cls(**filtered_dict)
    
    def update_from_schema(self, schema: BaseModel, exclude_fields: Optional[set] = None) -> None:
        """
        Update model instance from a Pydantic schema
        
        Args:
            schema: Pydantic schema instance
            exclude_fields: Set of field names to exclude from update
        """
        exclude_fields = exclude_fields or set()
        schema_dict = schema.model_dump(exclude_unset=True)
        
        # Filter out excluded fields and fields that don't exist in the model
        model_fields = {c.key for c in inspect(self.__class__).columns}
        filtered_dict = {
            k: v for k, v in schema_dict.items() 
            if k in model_fields and k not in exclude_fields
        }
        
        for field, value in filtered_dict.items():
            setattr(self, field, value)
    
    def to_schema(self, schema_class: Type[T], include_fields: Optional[set] = None) -> T:
        """
        Convert model instance to a Pydantic schema
        
        Args:
            schema_class: Target Pydantic schema class
            include_fields: Optional set of field names to include (if None, includes all fields)
        """
        model_dict = {}
        for column in inspect(self.__class__).columns:
            if include_fields is None or column.key in include_fields:
                value = getattr(self, column.key)
                model_dict[column.key] = value
        
        return schema_class(**model_dict)
    
    def save(self) -> 'BaseModelMixin':
        """Save the model instance to the database"""
        with transaction():
            db.session.add(self)
        return self
    
    def delete(self) -> None:
        """Delete the model instance from the database"""
        with transaction():
            db.session.delete(self)
    
    @classmethod
    def get_by_id(cls, id: int) -> Optional['BaseModelMixin']:
        """Get model instance by ID"""
        return cls.query.get(id)
    
    def to_dict(self, exclude: Optional[set] = None) -> Dict[str, Any]:
        """
        Convert model instance to dictionary
        
        Args:
            exclude: Optional set of field names to exclude
        """
        exclude = exclude or set()
        return {
            c.key: getattr(self, c.key)
            for c in inspect(self.__class__).columns
            if c.key not in exclude
        } 
```


### FILE: backend\shared\schemas\base.py
```
from datetime import datetime
from typing import Optional
from pydantic import BaseModel, ConfigDict

class BaseSchema(BaseModel):
    """Base schema class with common fields and configuration"""
    model_config = ConfigDict(from_attributes=True)
    
    id: Optional[int] = None
    created_at: Optional[datetime] = None
    updated_at: Optional[datetime] = None

    model_config = ConfigDict(json_encoders={
        datetime: lambda dt: dt.isoformat()
    })

class ErrorResponse(BaseModel):
    """Standard error response schema"""
    error: str
    message: Optional[str] = None
    details: Optional[dict] = None

class SuccessResponse(BaseModel):
    """Standard success response schema"""
    status: str = "success"
    message: Optional[str] = None
    data: Optional[dict] = None 
```


### FILE: backend\shared\secrets\README.md
```
# Secrets Management Module

This module provides a unified interface for managing secrets across various backends. It allows services to securely access sensitive information without hardcoding secrets in the codebase.

## Features

- **Multiple Backend Support**: Works with environment variables, file-based secrets, HashiCorp Vault, and AWS Secrets Manager.
- **Automatic Provider Detection**: Automatically detects the appropriate provider based on the environment.
- **Consistent Interface**: Provides a unified interface regardless of the underlying secrets backend.
- **Caching**: Implements caching to improve performance and reduce API calls.
- **Secure by Default**: Follows security best practices for handling sensitive information.

## Usage

### Basic Usage

```python
from backend.shared.secrets import get_secret

# Get a secret
db_password = get_secret('database/password')
api_key = get_secret('api/key')

# Use the secret
db_connection = connect_to_db(password=db_password)
```

### Getting Multiple Secrets

```python
from backend.shared.secrets import get_secrets

# Get multiple secrets at once
credentials = get_secrets(['database/username', 'database/password', 'api/key'])
print(f"Connecting as {credentials['database/username']}")
```

### Checking if a Secret Exists

```python
from backend.shared.secrets import has_secret

# Check if a secret exists
if has_secret('optional/feature/api_key'):
    # Use the optional feature
    api_key = get_secret('optional/feature/api_key')
    enable_feature(api_key)
```

### Explicitly Setting the Provider

```python
from backend.shared.secrets import set_secret_manager
from backend.shared.secrets.vault import VaultSecretManager

# Create a custom provider
manager = VaultSecretManager(url='https://vault.example.com:8200', token='my-token')

# Set it as the global provider
set_secret_manager(manager)
```

## Supported Providers

### Environment Variables (`EnvSecretManager`)

Uses environment variables to store secrets. This is the simplest provider and serves as a fallback.

Environment variables can be prefixed to organize secrets:
```
DB_PASSWORD=mysecretpassword
API_KEY=mysecretapikey
```

With the default prefix of `''` (empty string), you would access these as:
```python
db_password = get_secret('DB_PASSWORD')
api_key = get_secret('API_KEY')
```

With a prefix of `SECRET_`, you would set:
```
SECRET_DB_PASSWORD=mysecretpassword
SECRET_API_KEY=mysecretapikey
```

And access them as:
```python
db_password = get_secret('DB_PASSWORD')
api_key = get_secret('API_KEY')
```

### File-Based Secrets (`FileSecretManager`)

Uses files to store secrets. This is useful for Docker and Kubernetes environments that mount secrets as files.

Example directory structure:
```
/app/secrets/
  database/
    username
    password
  api/
    key
```

You would access these as:
```python
db_username = get_secret('database/username')
db_password = get_secret('database/password')
api_key = get_secret('api/key')
```

### HashiCorp Vault (`VaultSecretManager`)

Uses HashiCorp Vault for secret management. This is a production-ready solution with advanced features like secret rotation, access control, and audit logging.

Requires the `hvac` package to be installed.

Example Vault structure:
```
secret/
  database/
    username: myuser
    password: mypassword
  api/
    key: myapikey
```

You would access these as:
```python
db_username = get_secret('database/username')
db_password = get_secret('database/password')
api_key = get_secret('api/key')
```

### AWS Secrets Manager (`AWSSecretManager`)

Uses AWS Secrets Manager for secret management. This is a fully managed service that makes it easy to rotate, manage, and retrieve secrets.

Requires the `boto3` package to be installed.

Example AWS Secrets Manager structure:
```
myapp/database
myapp/api
```

You would access these as:
```python
db_secrets = get_secret('database')  # Returns the entire JSON object
api_secrets = get_secret('api')
```

Or with specific keys:
```python
db_password = get_secret('database#password')  # Uses '#' to separate the secret name from the key
api_key = get_secret('api#key')
```

## Configuration

The module can be configured using environment variables:

- `SECRET_MANAGER_TYPE`: The provider to use (`env`, `file`, `vault`, or `aws`).
- `SECRET_MANAGER_PREFIX`: The prefix for environment variables (for `EnvSecretManager`).
- `SECRET_MANAGER_PATH`: The path to the secrets directory (for `FileSecretManager`).
- `VAULT_ADDR`, `VAULT_TOKEN`: Configuration for the Vault provider.
- `AWS_REGION`, `AWS_SECRET_PREFIX`: Configuration for the AWS Secrets Manager provider.

## Security Considerations

- **Memory Management**: Secrets are stored as strings in memory, which means they could potentially be exposed in memory dumps or logs. Consider using secure string types if available in your environment.
- **Logging**: Be careful not to log secrets. The module avoids logging secret values, but you should ensure your application code doesn't log them either.
- **Transport Security**: Ensure that communication with secret backends (like Vault or AWS) is encrypted using TLS.
- **Access Control**: Use the principle of least privilege when setting up access to secret backends.

## Development

### Adding a New Provider

To add a new provider:

1. Create a new file in the `secrets` directory (e.g., `mybackend.py`).
2. Implement a class that inherits from `SecretManager` and implements all required methods.
3. Update the `__init__.py` file to import and register the new provider.

Example:

```python
from .base import SecretManager

class MyBackendSecretManager(SecretManager):
    def __init__(self, config_param=None):
        self.config_param = config_param
        self._cache = {}
        
    def get_secret(self, key, default=None):
        # Implementation
        
    def get_secrets(self, keys):
        # Implementation
        
    def has_secret(self, key):
        # Implementation
```

Then update `__init__.py`:

```python
try:
    from .mybackend import MyBackendSecretManager
    HAS_MYBACKEND = True
except ImportError:
    HAS_MYBACKEND = False

def get_secret_manager(manager_type=None):
    # ...
    elif manager_type == 'mybackend' and HAS_MYBACKEND:
        return MyBackendSecretManager()
    # ...
``` 
```


### FILE: backend\shared\secrets\__init__.py
```
"""
Secrets management module.
Provides a unified interface for accessing secrets from various backends.
"""

import os
import logging

logger = logging.getLogger(__name__)

# Import secret managers
try:
    from .env import EnvSecretManager
    HAS_ENV = True
except ImportError:
    HAS_ENV = False

try:
    from .file import FileSecretManager
    HAS_FILE = True
except ImportError:
    HAS_FILE = False

try:
    from .vault import VaultSecretManager
    HAS_VAULT = True
except ImportError:
    HAS_VAULT = False

try:
    from .aws import AWSSecretManager
    HAS_AWS = True
except ImportError:
    HAS_AWS = False

# Global secret manager instance
_secret_manager = None

def get_secret_manager(manager_type=None):
    """
    Get a secret manager instance.
    
    Args:
        manager_type: The type of secret manager to use.
            Options: 'env', 'file', 'vault', 'aws'
            If None, will try to determine from environment variables.
            
    Returns:
        A secret manager instance.
    """
    # Try to determine the manager type from environment variables
    if manager_type is None:
        manager_type = os.environ.get('SECRET_MANAGER_TYPE', 'env').lower()
    
    # Create the appropriate manager
    if manager_type == 'env' and HAS_ENV:
        prefix = os.environ.get('SECRET_MANAGER_PREFIX', '')
        return EnvSecretManager(prefix=prefix)
    elif manager_type == 'file' and HAS_FILE:
        path = os.environ.get('SECRET_MANAGER_PATH', '/app/secrets')
        return FileSecretManager(path=path)
    elif manager_type == 'vault' and HAS_VAULT:
        url = os.environ.get('VAULT_ADDR', 'http://localhost:8200')
        token = os.environ.get('VAULT_TOKEN')
        role_id = os.environ.get('VAULT_ROLE_ID')
        secret_id = os.environ.get('VAULT_SECRET_ID')
        
        if token:
            return VaultSecretManager(url=url, token=token)
        elif role_id and secret_id:
            return VaultSecretManager(url=url, role_id=role_id, secret_id=secret_id)
        else:
            logger.warning("Vault secret manager requested but no token or AppRole credentials provided")
            return None
    elif manager_type == 'aws' and HAS_AWS:
        region = os.environ.get('AWS_REGION')
        prefix = os.environ.get('AWS_SECRET_PREFIX', '')
        return AWSSecretManager(region_name=region, prefix=prefix)
    else:
        logger.warning(f"Unknown or unavailable secret manager type: {manager_type}, falling back to env")
        if HAS_ENV:
            return EnvSecretManager()
        else:
            logger.error("No secret manager available")
            return None

def _get_manager():
    """
    Get the global secret manager instance, creating it if necessary.
    
    Returns:
        The global secret manager instance.
    """
    global _secret_manager
    if _secret_manager is None:
        _secret_manager = get_secret_manager()
    return _secret_manager

def set_secret_manager(manager):
    """
    Set the global secret manager instance.
    
    Args:
        manager: A secret manager instance.
    """
    global _secret_manager
    _secret_manager = manager

def get_secret(key, default=None):
    """
    Get a secret by key.
    
    Args:
        key: The secret key.
        default: The default value to return if the secret is not found.
        
    Returns:
        The secret value, or default if not found.
    """
    manager = _get_manager()
    if manager is None:
        logger.error(f"No secret manager available, cannot get secret: {key}")
        return default
    return manager.get_secret(key, default)

def get_secrets(keys):
    """
    Get multiple secrets by keys.
    
    Args:
        keys: A list of secret keys.
        
    Returns:
        A dictionary of secret keys to values.
    """
    manager = _get_manager()
    if manager is None:
        logger.error(f"No secret manager available, cannot get secrets: {keys}")
        return {}
    return manager.get_secrets(keys)

def has_secret(key):
    """
    Check if a secret exists.
    
    Args:
        key: The secret key.
        
    Returns:
        True if the secret exists, False otherwise.
    """
    manager = _get_manager()
    if manager is None:
        logger.error(f"No secret manager available, cannot check secret: {key}")
        return False
    return manager.has_secret(key) 
```


### FILE: backend\shared\secrets\aws.py
```
"""
AWS Secrets Manager secret manager.
Retrieves secrets from AWS Secrets Manager.
"""

import os
import json
import logging
from .base import SecretManager

try:
    import boto3
    from botocore.exceptions import ClientError
    HAS_BOTO3 = True
except ImportError:
    HAS_BOTO3 = False

logger = logging.getLogger(__name__)

class AWSSecretManager(SecretManager):
    """
    Secret manager that retrieves secrets from AWS Secrets Manager.
    Requires the boto3 package to be installed.
    """
    
    def __init__(self, 
                 region_name=None, 
                 prefix=None,
                 aws_access_key_id=None,
                 aws_secret_access_key=None,
                 profile_name=None):
        """
        Initialize AWS Secrets Manager secret manager.
        
        Args:
            region_name: AWS region name (defaults to AWS_REGION env var)
            prefix: Optional prefix for secret names
            aws_access_key_id: AWS access key ID (defaults to AWS_ACCESS_KEY_ID env var)
            aws_secret_access_key: AWS secret access key (defaults to AWS_SECRET_ACCESS_KEY env var)
            profile_name: AWS profile name (defaults to AWS_PROFILE env var)
        """
        if not HAS_BOTO3:
            raise ImportError("boto3 package is required for AWSSecretManager")
        
        self.region_name = region_name or os.environ.get('AWS_REGION') or os.environ.get('AWS_DEFAULT_REGION')
        if not self.region_name:
            raise ValueError("AWS region not provided and AWS_REGION environment variable not set")
        
        self.prefix = prefix
        self.aws_access_key_id = aws_access_key_id or os.environ.get('AWS_ACCESS_KEY_ID')
        self.aws_secret_access_key = aws_secret_access_key or os.environ.get('AWS_SECRET_ACCESS_KEY')
        self.profile_name = profile_name or os.environ.get('AWS_PROFILE')
        
        self.client = None
        self.cache = {}
        self._initialize_client()
    
    def _initialize_client(self):
        """Initialize AWS Secrets Manager client."""
        try:
            kwargs = {'region_name': self.region_name}
            
            if self.aws_access_key_id and self.aws_secret_access_key:
                kwargs['aws_access_key_id'] = self.aws_access_key_id
                kwargs['aws_secret_access_key'] = self.aws_secret_access_key
            
            if self.profile_name:
                kwargs['profile_name'] = self.profile_name
            
            self.client = boto3.client('secretsmanager', **kwargs)
            logger.info(f"Successfully initialized AWS Secrets Manager client in region {self.region_name}")
        except Exception as e:
            logger.error(f"Error initializing AWS Secrets Manager client: {str(e)}")
            raise
    
    def get_secret(self, key, default=None):
        """
        Get a secret from AWS Secrets Manager.
        
        Args:
            key: The secret key to retrieve
            default: Default value if secret not found
            
        Returns:
            The secret value, or default if not found
        """
        if not self.client:
            logger.error("AWS Secrets Manager client not initialized")
            return default
        
        # Check cache first
        if key in self.cache:
            logger.debug(f"Retrieved secret {self._format_key(key)} from cache")
            return self.cache[key]
        
        # Construct secret name with prefix
        secret_name = key
        if self.prefix:
            secret_name = f"{self.prefix}/{key}"
        
        try:
            response = self.client.get_secret_value(SecretId=secret_name)
            
            # Extract the secret value
            if 'SecretString' in response:
                secret_value = response['SecretString']
                
                # Try to parse as JSON
                try:
                    secret_json = json.loads(secret_value)
                    
                    # If this is a JSON document with a key that matches our key name,
                    # return just that value; otherwise return the whole document
                    if isinstance(secret_json, dict):
                        # If the key name is just the last part of the path, extract it
                        key_parts = key.split('/')
                        short_key = key_parts[-1]
                        
                        if short_key in secret_json:
                            self.cache[key] = secret_json[short_key]
                            logger.debug(f"Retrieved secret {self._format_key(key)} from AWS Secrets Manager (JSON field)")
                            return secret_json[short_key]
                    
                    # Otherwise return the whole JSON document
                    self.cache[key] = secret_json
                    logger.debug(f"Retrieved secret {self._format_key(key)} from AWS Secrets Manager (JSON)")
                    return secret_json
                except json.JSONDecodeError:
                    # Not JSON, return as string
                    self.cache[key] = secret_value
                    logger.debug(f"Retrieved secret {self._format_key(key)} from AWS Secrets Manager (string)")
                    return secret_value
            
            elif 'SecretBinary' in response:
                # Binary secrets are less common but supported
                import base64
                binary_data = response['SecretBinary']
                self.cache[key] = binary_data
                logger.debug(f"Retrieved secret {self._format_key(key)} from AWS Secrets Manager (binary)")
                return binary_data
            
            logger.error(f"Unknown secret format for {self._format_key(key)}")
            return default
            
        except ClientError as e:
            error_code = e.response.get('Error', {}).get('Code', 'Unknown')
            if error_code == 'ResourceNotFoundException':
                logger.debug(f"Secret {self._format_key(key)} not found in AWS Secrets Manager")
                return default
            else:
                logger.error(f"Error retrieving secret {self._format_key(key)} from AWS Secrets Manager: {str(e)}")
                return default
        except Exception as e:
            logger.error(f"Error retrieving secret {self._format_key(key)} from AWS Secrets Manager: {str(e)}")
            return default
    
    def get_secrets(self, keys):
        """
        Get multiple secrets from AWS Secrets Manager.
        
        Args:
            keys: List of secret keys to retrieve
            
        Returns:
            Dictionary of key-value pairs for found secrets
        """
        result = {}
        for key in keys:
            value = self.get_secret(key)
            if value is not None:
                result[key] = value
        
        return result
    
    def has_secret(self, key):
        """
        Check if a secret exists in AWS Secrets Manager.
        
        Args:
            key: The secret key to check
            
        Returns:
            True if the secret exists, False otherwise
        """
        if key in self.cache:
            return True
        
        secret_name = key
        if self.prefix:
            secret_name = f"{self.prefix}/{key}"
        
        try:
            self.client.describe_secret(SecretId=secret_name)
            return True
        except ClientError as e:
            error_code = e.response.get('Error', {}).get('Code', 'Unknown')
            if error_code == 'ResourceNotFoundException':
                return False
            else:
                logger.error(f"Error checking secret {self._format_key(key)}: {str(e)}")
                return False
        except Exception as e:
            logger.error(f"Error checking secret {self._format_key(key)}: {str(e)}")
            return False 
```


### FILE: backend\shared\secrets\base.py
```
"""
Base class for secret managers.
Defines the interface that all secret managers must implement.
"""

from abc import ABC, abstractmethod


class SecretManager(ABC):
    """
    Abstract base class for secret managers.
    
    All secret managers must implement the methods defined in this class.
    """
    
    @abstractmethod
    def get_secret(self, key, default=None):
        """
        Get a secret by key.
        
        Args:
            key: The secret key.
            default: The default value to return if the secret is not found.
            
        Returns:
            The secret value, or default if not found.
        """
        pass
    
    @abstractmethod
    def get_secrets(self, keys):
        """
        Get multiple secrets by keys.
        
        Args:
            keys: A list of secret keys.
            
        Returns:
            A dictionary of secret keys to values.
        """
        pass
    
    @abstractmethod
    def has_secret(self, key):
        """
        Check if a secret exists.
        
        Args:
            key: The secret key.
            
        Returns:
            True if the secret exists, False otherwise.
        """
        pass
    
    def _sanitize_key(self, key):
        """
        Sanitize a secret key to match the backend's requirements.
        
        Args:
            key: The secret key to sanitize
            
        Returns:
            Sanitized key
        """
        # Default implementation just converts to uppercase
        # Subclasses can override this if needed
        return key.upper()
    
    def _format_key(self, key):
        """
        Format a secret key for display (e.g., for logging).
        Masks the actual key if it's sensitive.
        
        Args:
            key: The secret key to format
            
        Returns:
            Formatted key safe for display
        """
        key = str(key).lower()
        
        # List of partial key names that should be masked when displayed
        sensitive_keys = [
            'password', 'secret', 'key', 'token', 'credential', 
            'auth', 'access', 'private', 'cert', 'signature'
        ]
        
        if any(sensitive in key for sensitive in sensitive_keys):
            parts = key.split('_')
            
            # Keep the first part visible if it's not sensitive
            if not any(sensitive in parts[0].lower() for sensitive in sensitive_keys):
                return f"{parts[0]}_***"
            else:
                return "***"
        
        return key 
```


### FILE: backend\shared\secrets\env.py
```
"""
Environment variable secret manager.
Retrieves secrets from environment variables.
"""

import os
import logging
from .base import SecretManager

logger = logging.getLogger(__name__)

class EnvSecretManager(SecretManager):
    """
    Secret manager that retrieves secrets from environment variables.
    
    This is the simplest secret manager and serves as a fallback.
    """
    
    def __init__(self, prefix=''):
        """
        Initialize the environment variable secret manager.
        
        Args:
            prefix: Prefix for environment variables (default: '').
                   For example, if prefix is 'SECRET_', then the secret
                   'database/password' would be retrieved from the
                   environment variable 'SECRET_DATABASE_PASSWORD'.
        """
        self.prefix = prefix
        logger.info(f"Initialized environment variable secret manager with prefix '{prefix}'")
    
    def _format_key(self, key):
        """
        Format a key for use with environment variables.
        
        Args:
            key: The secret key.
            
        Returns:
            The formatted key.
        """
        # Replace slashes and dots with underscores
        formatted_key = key.replace('/', '_').replace('.', '_').replace('-', '_')
        
        # Convert to uppercase
        formatted_key = formatted_key.upper()
        
        # Add prefix
        if self.prefix:
            formatted_key = f"{self.prefix}{formatted_key}"
        
        return formatted_key
    
    def get_secret(self, key, default=None):
        """
        Get a secret from an environment variable.
        
        Args:
            key: The secret key.
            default: The default value to return if the secret is not found.
            
        Returns:
            The secret value, or default if not found.
        """
        env_key = self._format_key(key)
        value = os.environ.get(env_key)
        
        if value is None:
            logger.debug(f"Secret not found in environment variables: {env_key}")
            return default
        
        logger.debug(f"Retrieved secret from environment variables: {env_key}")
        return value
    
    def get_secrets(self, keys):
        """
        Get multiple secrets from environment variables.
        
        Args:
            keys: A list of secret keys.
            
        Returns:
            A dictionary of secret keys to values.
        """
        result = {}
        
        for key in keys:
            value = self.get_secret(key)
            if value is not None:
                result[key] = value
        
        return result
    
    def has_secret(self, key):
        """
        Check if a secret exists in environment variables.
        
        Args:
            key: The secret key.
            
        Returns:
            True if the secret exists, False otherwise.
        """
        env_key = self._format_key(key)
        return env_key in os.environ 
```


### FILE: backend\shared\secrets\file.py
```
"""
File-based secret manager.
Retrieves secrets from files in a directory.
"""

import os
import json
import logging
from pathlib import Path
from .base import SecretManager

logger = logging.getLogger(__name__)

class FileSecretManager(SecretManager):
    """
    Secret manager that retrieves secrets from files.
    
    This is useful for Docker and Kubernetes environments that mount secrets as files.
    """
    
    def __init__(self, path='/app/secrets'):
        """
        Initialize the file-based secret manager.
        
        Args:
            path: Path to the secrets directory (default: '/app/secrets').
                 Can be a directory containing individual secret files,
                 or a JSON file containing multiple secrets.
        """
        self.path = Path(path)
        self._cache = {}
        self._is_json_file = self.path.is_file() and self.path.suffix.lower() == '.json'
        
        if self._is_json_file:
            logger.info(f"Initialized file-based secret manager with JSON file: {self.path}")
            self._load_json_file()
        else:
            logger.info(f"Initialized file-based secret manager with directory: {self.path}")
    
    def _load_json_file(self):
        """
        Load secrets from a JSON file.
        """
        try:
            if not self.path.exists():
                logger.warning(f"Secrets file does not exist: {self.path}")
                return
            
            with open(self.path, 'r') as f:
                self._cache = json.load(f)
            
            logger.debug(f"Loaded {len(self._cache)} secrets from JSON file")
        except Exception as e:
            logger.error(f"Error loading secrets from JSON file: {str(e)}")
    
    def _get_file_path(self, key):
        """
        Get the file path for a secret key.
        
        Args:
            key: The secret key.
            
        Returns:
            The file path.
        """
        # Replace dots with slashes
        key_path = key.replace('.', '/')
        
        # Ensure the key doesn't start with a slash
        if key_path.startswith('/'):
            key_path = key_path[1:]
        
        return self.path / key_path
    
    def get_secret(self, key, default=None):
        """
        Get a secret from a file.
        
        Args:
            key: The secret key.
            default: The default value to return if the secret is not found.
            
        Returns:
            The secret value, or default if not found.
        """
        if self._is_json_file:
            # For JSON files, use the cache
            value = self._cache.get(key)
            if value is None:
                logger.debug(f"Secret not found in JSON file: {key}")
                return default
            
            logger.debug(f"Retrieved secret from JSON file: {key}")
            return value
        else:
            # For directories, read the file
            file_path = self._get_file_path(key)
            
            if not file_path.exists():
                logger.debug(f"Secret file does not exist: {file_path}")
                return default
            
            try:
                with open(file_path, 'r') as f:
                    value = f.read().strip()
                
                logger.debug(f"Retrieved secret from file: {file_path}")
                return value
            except Exception as e:
                logger.error(f"Error reading secret file: {str(e)}")
                return default
    
    def get_secrets(self, keys):
        """
        Get multiple secrets from files.
        
        Args:
            keys: A list of secret keys.
            
        Returns:
            A dictionary of secret keys to values.
        """
        result = {}
        
        for key in keys:
            value = self.get_secret(key)
            if value is not None:
                result[key] = value
        
        return result
    
    def has_secret(self, key):
        """
        Check if a secret exists in files.
        
        Args:
            key: The secret key.
            
        Returns:
            True if the secret exists, False otherwise.
        """
        if self._is_json_file:
            return key in self._cache
        else:
            file_path = self._get_file_path(key)
            return file_path.exists() 
```


### FILE: backend\shared\secrets\vault.py
```
"""
HashiCorp Vault secret manager.
Retrieves secrets from HashiCorp Vault.
"""

import os
import logging
from .base import SecretManager

try:
    import hvac
    HAS_HVAC = True
except ImportError:
    HAS_HVAC = False

logger = logging.getLogger(__name__)

class VaultSecretManager(SecretManager):
    """
    Secret manager that retrieves secrets from HashiCorp Vault.
    Requires the hvac package to be installed.
    """
    
    def __init__(self, 
                 url=None, 
                 token=None, 
                 path_prefix='secret/',
                 auth_method='token',
                 role_id=None,
                 secret_id=None):
        """
        Initialize HashiCorp Vault secret manager.
        
        Args:
            url: Vault server URL (defaults to VAULT_ADDR env var)
            token: Vault token (defaults to VAULT_TOKEN env var)
            path_prefix: Path prefix for secrets (defaults to 'secret/')
            auth_method: Authentication method ('token', 'approle', etc.)
            role_id: AppRole role ID (for 'approle' auth method)
            secret_id: AppRole secret ID (for 'approle' auth method)
        """
        if not HAS_HVAC:
            raise ImportError("hvac package is required for VaultSecretManager")
        
        self.url = url or os.environ.get('VAULT_ADDR')
        if not self.url:
            raise ValueError("Vault URL not provided and VAULT_ADDR environment variable not set")
        
        self.token = token or os.environ.get('VAULT_TOKEN')
        self.path_prefix = path_prefix.rstrip('/') + '/'
        self.auth_method = auth_method
        self.role_id = role_id or os.environ.get('VAULT_ROLE_ID')
        self.secret_id = secret_id or os.environ.get('VAULT_SECRET_ID')
        
        self.client = None
        self._initialize_client()
    
    def _initialize_client(self):
        """Initialize Vault client and authenticate."""
        try:
            self.client = hvac.Client(url=self.url)
            
            if self.auth_method == 'token' and self.token:
                self.client.token = self.token
            elif self.auth_method == 'approle' and self.role_id and self.secret_id:
                self.client.auth.approle.login(
                    role_id=self.role_id,
                    secret_id=self.secret_id
                )
            else:
                raise ValueError(f"Unsupported auth method or missing credentials: {self.auth_method}")
            
            if not self.client.is_authenticated():
                raise ValueError("Failed to authenticate with Vault")
            
            logger.info(f"Successfully authenticated to Vault at {self.url}")
        except Exception as e:
            logger.error(f"Error initializing Vault client: {str(e)}")
            raise
    
    def get_secret(self, key, default=None):
        """
        Get a secret from Vault.
        
        Args:
            key: The secret key to retrieve
            default: Default value if secret not found
            
        Returns:
            The secret value, or default if not found
        """
        if not self.client or not self.client.is_authenticated():
            logger.error("Vault client not initialized or not authenticated")
            return default
        
        try:
            # Split key into path and key parts (e.g., 'database/password' -> 'database', 'password')
            parts = key.split('/')
            if len(parts) > 1:
                # Key includes a path
                path = '/'.join(parts[:-1])
                key_name = parts[-1]
                full_path = f"{self.path_prefix}{path}"
            else:
                # Key is just a name
                full_path = self.path_prefix.rstrip('/')
                key_name = key
            
            # Read from Vault
            response = self.client.secrets.kv.v2.read_secret_version(
                path=full_path,
                mount_point='secret'
            )
            
            # Extract the value
            if response and 'data' in response and 'data' in response['data']:
                data = response['data']['data']
                if key_name in data:
                    logger.debug(f"Retrieved secret {self._format_key(key)} from Vault")
                    return data[key_name]
            
            logger.debug(f"Secret {self._format_key(key)} not found in Vault")
            return default
        except Exception as e:
            logger.error(f"Error retrieving secret {self._format_key(key)} from Vault: {str(e)}")
            return default
    
    def get_secrets(self, keys):
        """
        Get multiple secrets from Vault.
        
        Args:
            keys: List of secret keys to retrieve
            
        Returns:
            Dictionary of key-value pairs for found secrets
        """
        result = {}
        for key in keys:
            value = self.get_secret(key)
            if value is not None:
                result[key] = value
        
        return result
    
    def has_secret(self, key):
        """
        Check if a secret exists in Vault.
        
        Args:
            key: The secret key to check
            
        Returns:
            True if the secret exists, False otherwise
        """
        return self.get_secret(key) is not None 
```


### FILE: backend\shared\utils\__init__.py
```
"""
Shared utilities module for backend services.
Provides common utilities for HTTP requests, date handling, and more.
"""

# Import commonly used utilities for easier access
try:
    from .http import (
        get, post, put, delete, patch,
        make_request, add_request_id_headers
    )
except ImportError:
    pass 
```


### FILE: backend\shared\utils\data_seeder.py
```
import logging
from flask import Flask
from sqlalchemy.exc import IntegrityError
from typing import List, Type, Any, Dict

logger = logging.getLogger(__name__)

class DataSeeder:
    def __init__(self, app: Flask, db):
        self.app = app
        self.db = db
        self.seeders = []

    def register_seeder(self, model: Type[Any], data: List[Dict[str, Any]], unique_fields: List[str]):
        """Register a seeder for a model"""
        self.seeders.append({
            'model': model,
            'data': data,
            'unique_fields': unique_fields
        })

    def _exists(self, model: Type[Any], data: Dict[str, Any], unique_fields: List[str]) -> bool:
        """Check if a record already exists based on unique fields"""
        filters = {field: data[field] for field in unique_fields if field in data}
        return model.query.filter_by(**filters).first() is not None

    def run_seeder(self, seeder: Dict) -> bool:
        """Run a single seeder"""
        model = seeder['model']
        data_list = seeder['data']
        unique_fields = seeder['unique_fields']
        
        try:
            for data in data_list:
                if not self._exists(model, data, unique_fields):
                    instance = model(**data)
                    self.db.session.add(instance)
            
            self.db.session.commit()
            logger.info(f"Successfully seeded {model.__name__}")
            return True
        except IntegrityError as e:
            self.db.session.rollback()
            logger.error(f"Error seeding {model.__name__}: {str(e)}")
            return False
        except Exception as e:
            self.db.session.rollback()
            logger.error(f"Unexpected error seeding {model.__name__}: {str(e)}")
            return False

    def run_all_seeders(self) -> bool:
        """Run all registered seeders"""
        success = True
        with self.app.app_context():
            for seeder in self.seeders:
                if not self.run_seeder(seeder):
                    success = False
        return success

    def run_seeder_for_model(self, model_name: str) -> bool:
        """Run seeder for a specific model"""
        with self.app.app_context():
            for seeder in self.seeders:
                if seeder['model'].__name__ == model_name:
                    return self.run_seeder(seeder)
        logger.warning(f"No seeder found for model: {model_name}")
        return False 
```


### FILE: backend\shared\utils\database.py
```
from functools import wraps
from typing import Any, Callable, Optional, TypeVar, List
from flask import current_app
from sqlalchemy.exc import SQLAlchemyError, IntegrityError
from contextlib import contextmanager
from shared.database import db, transaction  # Import from shared.database
import logging

logger = logging.getLogger(__name__)

T = TypeVar('T')

@contextmanager
def transaction_context():
    """
    Context manager for database transactions.
    Alias for shared.database.transaction to maintain compatibility.
    
    Usage:
        with transaction_context() as session:
            session.add(user)
    """
    with transaction():
        yield db.session

def with_transaction(f: Callable[..., T]) -> Callable[..., T]:
    """
    Decorator to handle database transactions and rollback on error.
    
    Usage:
        @with_transaction
        def my_db_function():
            # Your database operations here
            pass
    """
    @wraps(f)
    def decorated(*args: Any, **kwargs: Any) -> T:
        try:
            result = f(*args, **kwargs)
            if db.session.is_active:
                db.session.commit()
            return result
        except Exception as e:
            if db.session.is_active:
                db.session.rollback()
            logger.error(f"Database error in {f.__name__}: {str(e)}")
            raise
        finally:
            if db.session:
                db.session.close()
    return decorated

class DatabaseManager:
    """
    Utility class for handling database operations safely
    with automatic error handling and transactions.
    """
    def __init__(self, db_instance):
        self.db = db_instance

    def safe_commit(self) -> bool:
        """Safely commit database changes with automatic rollback on error"""
        try:
            self.db.session.commit()
            return True
        except SQLAlchemyError as e:
            self.db.session.rollback()
            logger.error(f"Failed to commit changes: {str(e)}")
            return False

    def safe_add(self, obj: Any, auto_commit: bool = True) -> bool:
        """Safely add an object to the database"""
        try:
            self.db.session.add(obj)
            if auto_commit:
                return self.safe_commit()
            return True
        except SQLAlchemyError as e:
            if auto_commit:
                self.db.session.rollback()
            logger.error(f"Error adding object to database: {str(e)}")
            raise

    def safe_delete(self, obj: Any, auto_commit: bool = True) -> bool:
        """Safely delete an object from the database"""
        try:
            self.db.session.delete(obj)
            if auto_commit:
                return self.safe_commit()
            return True
        except SQLAlchemyError as e:
            if auto_commit:
                self.db.session.rollback()
            logger.error(f"Error deleting object from database: {str(e)}")
            raise

    def safe_bulk_add(self, objects: List[Any], auto_commit: bool = True) -> bool:
        """Safely add multiple objects to the database"""
        try:
            self.db.session.bulk_save_objects(objects)
            if auto_commit:
                return self.safe_commit()
            return True
        except SQLAlchemyError as e:
            if auto_commit:
                self.db.session.rollback()
            logger.error(f"Error bulk adding objects to database: {str(e)}")
            raise

    def safe_bulk_delete(self, objects: List[Any], auto_commit: bool = True) -> bool:
        """Safely delete multiple objects from the database"""
        try:
            for obj in objects:
                self.db.session.delete(obj)
            if auto_commit:
                return self.safe_commit()
            return True
        except SQLAlchemyError as e:
            if auto_commit:
                self.db.session.rollback()
            logger.error(f"Error bulk deleting objects from database: {str(e)}")
            raise 
```


### FILE: backend\shared\utils\http.py
```
"""
HTTP utility module for making requests with proper request ID propagation.
"""

import logging
import requests
from typing import Dict, Any, Optional, Union, List
import json
import time

# Try to import request ID functions, with fallbacks if not available
try:
    from ..middleware.request_id import get_request_id, get_correlation_id
except (ImportError, ValueError):
    # Simple fallback implementations
    def get_request_id():
        return None
        
    def get_correlation_id():
        return None

logger = logging.getLogger(__name__)

def add_request_id_headers(headers: Optional[Dict[str, str]] = None) -> Dict[str, str]:
    """
    Add request ID headers to an existing headers dictionary.
    
    Args:
        headers: Existing headers dictionary or None
        
    Returns:
        Headers dictionary with request ID headers added
    """
    if headers is None:
        headers = {}
    
    # Add request ID headers if they exist
    request_id = get_request_id()
    if request_id:
        headers.setdefault('X-Request-ID', request_id)
    
    correlation_id = get_correlation_id()
    if correlation_id:
        headers.setdefault('X-Correlation-ID', correlation_id)
    
    return headers

def make_request(
    method: str,
    url: str,
    *,
    headers: Optional[Dict[str, str]] = None,
    params: Optional[Dict[str, Any]] = None,
    json_data: Optional[Dict[str, Any]] = None,
    data: Optional[Union[Dict[str, Any], str, bytes]] = None,
    files: Optional[Dict[str, Any]] = None,
    auth: Optional[Any] = None,
    timeout: Union[float, tuple] = 10.0,
    verify: bool = True,
    cert: Optional[Union[str, tuple]] = None,
    allow_redirects: bool = True,
    proxies: Optional[Dict[str, str]] = None,
    stream: bool = False,
    retry_count: int = 3,
    retry_backoff_factor: float = 0.3,
    retry_status_codes: Optional[List[int]] = None
) -> requests.Response:
    """
    Make an HTTP request with proper request ID propagation and retries.
    
    Args:
        method: HTTP method (GET, POST, PUT, DELETE, etc.)
        url: URL to request
        headers: Optional request headers
        params: Optional URL parameters
        json_data: Optional JSON data to send
        data: Optional form data to send
        files: Optional files to upload
        auth: Optional authentication tuple or object
        timeout: Request timeout in seconds (default: 10.0)
        verify: Whether to verify SSL certificates
        cert: Optional SSL client certificate
        allow_redirects: Whether to follow redirects
        proxies: Optional proxy servers
        stream: Whether to stream the response
        retry_count: Number of retries for transient errors
        retry_backoff_factor: Backoff factor for retries
        retry_status_codes: Status codes to retry (default: 429, 500, 502, 503, 504)
        
    Returns:
        Response object
    """
    # Add request ID headers
    headers = add_request_id_headers(headers)
    
    # Default retry status codes
    if retry_status_codes is None:
        retry_status_codes = [429, 500, 502, 503, 504]
    
    # Logging context
    log_context = {
        "method": method,
        "url": url,
        "service": url.split('/')[2] if '://' in url else url.split('/')[0]
    }
    
    if params:
        log_context["params"] = params
    
    logger.debug(f"Making {method} request to {url}", extra=log_context)
    
    # Retry loop
    last_exception = None
    for retry in range(retry_count + 1):
        try:
            # Starting timer for the request
            start_time = time.time()
            
            # Make the request
            response = requests.request(
                method=method.upper(),
                url=url,
                headers=headers,
                params=params,
                json=json_data,
                data=data,
                files=files,
                auth=auth,
                timeout=timeout,
                verify=verify,
                cert=cert,
                allow_redirects=allow_redirects,
                proxies=proxies,
                stream=stream
            )
            
            # Calculate request duration
            duration = time.time() - start_time
            log_context["duration"] = f"{duration:.3f}s"
            log_context["status_code"] = response.status_code
            
            # Check if we should retry based on status code
            if response.status_code in retry_status_codes and retry < retry_count:
                logger.warning(
                    f"Received status {response.status_code} from {url}, retrying ({retry+1}/{retry_count})",
                    extra=log_context
                )
                time.sleep(retry_backoff_factor * (2 ** retry))
                continue
            
            # Log success or non-retryable failure
            if response.status_code < 400:
                logger.debug(
                    f"Successfully called {url} ({response.status_code})",
                    extra=log_context
                )
            else:
                logger.error(
                    f"Error calling {url} ({response.status_code}): {response.text[:100]}",
                    extra=log_context
                )
            
            return response
            
        except (requests.RequestException, IOError) as e:
            last_exception = e
            if retry < retry_count:
                logger.warning(
                    f"Request to {url} failed: {str(e)}, retrying ({retry+1}/{retry_count})",
                    extra=log_context
                )
                time.sleep(retry_backoff_factor * (2 ** retry))
            else:
                logger.error(
                    f"Request to {url} failed after {retry_count} retries: {str(e)}",
                    extra=log_context
                )
    
    # If we get here, all retries failed
    if last_exception:
        raise last_exception
    
    # This should never happen, but just in case
    raise RuntimeError(f"Failed to make request to {url} after {retry_count} retries")


# Convenience methods for common HTTP verbs
def get(url, **kwargs):
    """Make a GET request."""
    return make_request("GET", url, **kwargs)

def post(url, **kwargs):
    """Make a POST request."""
    return make_request("POST", url, **kwargs)

def put(url, **kwargs):
    """Make a PUT request."""
    return make_request("PUT", url, **kwargs)

def delete(url, **kwargs):
    """Make a DELETE request."""
    return make_request("DELETE", url, **kwargs)

def patch(url, **kwargs):
    """Make a PATCH request."""
    return make_request("PATCH", url, **kwargs)


# Export symbols
__all__ = [
    'make_request',
    'add_request_id_headers',
    'get',
    'post',
    'put',
    'delete',
    'patch'
] 
```


### FILE: backend\shared\utils\migrations_manager.py
```
import os
import sys
import logging
from flask import Flask
from flask_migrate import Migrate, upgrade
from sqlalchemy import text
from sqlalchemy.exc import OperationalError
import time
from datetime import datetime

logger = logging.getLogger(__name__)

class MigrationsManager:
    def __init__(self, app: Flask, db, max_retries=5, retry_interval=5):
        self.app = app
        self.db = db
        self.migrate = Migrate(app, db)
        self.max_retries = max_retries
        self.retry_interval = retry_interval
        self.migration_history = []

    def wait_for_db(self):
        """Wait for database to be ready"""
        logger.info("Waiting for database...")
        for attempt in range(self.max_retries):
            try:
                with self.app.app_context():
                    self.db.session.execute(text('SELECT 1'))
                logger.info("Database is ready!")
                return True
            except OperationalError as e:
                if attempt == self.max_retries - 1:
                    logger.error(f"Database connection failed after {self.max_retries} attempts: {e}")
                    return False
                logger.warning(f"Database not ready (attempt {attempt + 1}/{self.max_retries}), waiting...")
                time.sleep(self.retry_interval)

    def backup_database(self):
        """Create a backup of the database before migrations"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_dir = os.path.join(self.app.root_path, 'db_backups')
            os.makedirs(backup_dir, exist_ok=True)
            backup_file = os.path.join(backup_dir, f'backup_{timestamp}.sql')
            
            # Get database URL from app config
            db_url = self.app.config['SQLALCHEMY_DATABASE_URI']
            
            # Execute pg_dump
            os.system(f'pg_dump {db_url} > {backup_file}')
            logger.info(f"Database backup created: {backup_file}")
            return backup_file
        except Exception as e:
            logger.error(f"Failed to create database backup: {e}")
            return None

    def run_migrations(self):
        """Run database migrations"""
        try:
            with self.app.app_context():
                logger.info("Starting database migrations...")
                # Create backup before migrations
                backup_file = self.backup_database()
                
                # Run migrations
                upgrade()
                
                logger.info("Database migrations completed successfully!")
                return True
        except Exception as e:
            logger.error(f"Error running migrations: {e}")
            if backup_file:
                logger.info(f"A backup was created at: {backup_file}")
            return False

    def verify_migrations(self):
        """Verify all migrations have been applied"""
        try:
            with self.app.app_context():
                # Check if all tables exist
                for table in self.db.metadata.tables:
                    if not self.db.engine.dialect.has_table(self.db.engine, table):
                        logger.error(f"Table {table} does not exist!")
                        return False
                logger.info("All database tables verified!")
                return True
        except Exception as e:
            logger.error(f"Error verifying migrations: {e}")
            return False

    def check_migration_status(self):
        """Check current migration status"""
        try:
            with self.app.app_context():
                from flask_migrate import current
                return current()
        except Exception as e:
            logger.error(f"Error checking migration status: {e}")
            return None

    def initialize_database(self):
        """Initialize database with migrations"""
        if not self.wait_for_db():
            logger.error("Could not connect to database")
            sys.exit(1)

        if not self.run_migrations():
            logger.error("Failed to run migrations")
            sys.exit(1)

        if not self.verify_migrations():
            logger.error("Failed to verify migrations")
            sys.exit(1)

        logger.info("Database initialization completed successfully!") 
```


### FILE: config\.env.development
```
# Database Configuration
POSTGRES_DB=meetingapp
POSTGRES_USER=dev_user
POSTGRES_PASSWORD=dev-password-123
POSTGRES_HOST=postgres-db
POSTGRES_PORT=5432
DATABASE_URL=postgresql://dev_user:dev-password-123@postgres-db:5432/meetingapp

# Redis Configuration
REDIS_HOST=redis-cache
REDIS_PORT=6379
REDIS_PASSWORD=dev-redis-123
REDIS_URL=redis://:dev-redis-123@redis-cache:6379/0

# JWT Configuration
JWT_SECRET_KEY=dev-jwt-secret-key-123
JWT_EXPIRY_DAYS=1

# Frontend URLs
NEXT_PUBLIC_API_URL=http://localhost:30963
NEXT_PUBLIC_WS_URL=ws://localhost:30283
NEXT_PUBLIC_BASE_URL=http://localhost:30000

# Backend Configuration
FLASK_ENV=development
FLASK_APP=app.py
API_HOST=0.0.0.0
API_PORT=5000
WS_HOST=0.0.0.0
WS_PORT=3001

# CORS Configuration
CORS_ORIGINS=http://localhost:30000,http://meeting-app.local,http://localhost:3000

# Logging
LOG_LEVEL=debug 
```


### FILE: config\secrets.production
```
ï»¿ 
```


### FILE: frontend\.dockerignore
```
# Git
.git
.gitignore

# Node.js
node_modules/
npm-debug.log
yarn-debug.log
yarn-error.log
.npm/
.yarn/
*.tgz

# Next.js
.next/
out/
.vercel/

# Docker
Dockerfile*
docker-compose*
.dockerignore

# IDE
.idea/
.vscode/
*.swp
*.swo

# Logs
logs/
*.log

# Data
data/ 
```


### FILE: frontend\.eslintrc.json
```
{
  "extends": [
    "next/core-web-vitals",
    "eslint:recommended",
    "plugin:react/recommended",
    "plugin:react-hooks/recommended",
    "plugin:@typescript-eslint/recommended"
  ],
  "parser": "@typescript-eslint/parser",
  "plugins": ["@typescript-eslint", "react", "react-hooks"],
  "rules": {
    // TypeScript-specific rules
    "@typescript-eslint/explicit-module-boundary-types": "off",
    "@typescript-eslint/no-explicit-any": "warn",
    "@typescript-eslint/no-unused-vars": ["warn", { 
      "argsIgnorePattern": "^_", 
      "varsIgnorePattern": "^_" 
    }],
    "@typescript-eslint/ban-ts-comment": "warn",
    
    // React-specific rules
    "react/react-in-jsx-scope": "off",
    "react/prop-types": "off",
    "react/display-name": "off",
    "react-hooks/rules-of-hooks": "error",
    "react-hooks/exhaustive-deps": "warn",
    
    // General rules
    "no-console": ["warn", { "allow": ["warn", "error", "info"] }],
    "no-debugger": "warn",
    "eqeqeq": ["error", "always", { "null": "ignore" }],
    "no-var": "error",
    "prefer-const": "warn",
    "prefer-template": "warn"
  },
  "settings": {
    "react": {
      "version": "detect"
    }
  },
  "overrides": [
    {
      "files": ["**/*.test.ts", "**/*.test.tsx", "**/__tests__/**/*"],
      "env": {
        "jest": true
      },
      "rules": {
        "@typescript-eslint/no-explicit-any": "off"
      }
    }
  ],
  "env": {
    "browser": true,
    "node": true,
    "es6": true
  }
} 
```


### FILE: frontend\DEBUGGING.md
```
# Frontend Debugging Guide

This document provides guidance on debugging the Next.js frontend application.

## Environment Setup

Before you begin, ensure that you have the correct environment variables set up. The application uses the following environment variables:

```
# Required environment variables
NEXT_PUBLIC_API_URL=http://localhost:5000
NEXT_PUBLIC_AUTH_URL=http://localhost:5001
NEXT_PUBLIC_WS_URL=ws://localhost:3001
NEXT_PUBLIC_APP_NAME=Meeting App
NEXT_PUBLIC_APP_VERSION=1.0.0

# Optional environment variables
NEXT_PUBLIC_ENABLE_DEBUG_TOOLS=true  # Enable debug tools (default: true in development, false in production)
NEXT_PUBLIC_ENABLE_ANALYTICS=false   # Enable analytics (default: false)
```

## Debugging Tools

### Built-in Debug Overlay

The application includes a built-in debug overlay that can be toggled by pressing `Ctrl+Shift+D` in development mode. The debug overlay provides:

- Current log level control
- Pending API requests
- Recent API responses
- Application state capture

### URL Parameters

You can control certain aspects of the application by adding query parameters to the URL:

- `?log_level=1` - Set log level (0=TRACE, 1=DEBUG, 2=INFO, 3=WARN, 4=ERROR, 5=NONE)
- `?debug=true` - Force enable debug mode

### Console Logging

The application uses a structured logging system with different log levels:

```typescript
import logger from '@/utils/logger';

// Different log levels
logger.trace('Detailed trace information');
logger.debug('Debugging information');
logger.info('General information');
logger.warn('Warning message');
logger.error('Error message');

// Logging with context
const componentLogger = createLogger('ComponentName');
componentLogger.info('Component initialized');
```

## Browser DevTools

### React Developer Tools

Install the [React Developer Tools](https://chrome.google.com/webstore/detail/react-developer-tools/fmkadmapgofadopljbjfkapdkoienihi) extension for Chrome or Firefox to inspect component props, state, and hierarchy.

### Network Tab

The Network tab in browser DevTools is essential for debugging API requests:

1. Open DevTools (F12 or Ctrl+Shift+I)
2. Go to the Network tab
3. Filter by "Fetch/XHR" to see only API requests
4. Look for the `X-Request-ID` header in requests to correlate with backend logs

### Debugging API Requests

All API requests include a unique `X-Request-ID` header that can be used to trace requests from the frontend to the backend.

Example of manually inspecting an API request:

```typescript
// Get a reference to the API client
import { apiClient } from '@/services/api/client';

// Make a request
const response = await apiClient.get('/api/meetings');

// Check response
console.log('Response:', response);

// If there was an error
if (response.error) {
  console.error('Error:', response.error);
}
```

## Error Handling

### Error Boundaries

The application uses React Error Boundaries to catch and display errors gracefully. You can wrap specific components with an error boundary for more granular error handling:

```typescript
import ErrorBoundary from '@/components/ErrorBoundary';

// In your component
return (
  <ErrorBoundary
    fallback={<div>Something went wrong with this component</div>}
    onError={(error) => console.error('Component error:', error)}
  >
    <YourComponent />
  </ErrorBoundary>
);
```

### Debugging Production Errors

For production debugging, check the browser console for error messages. All unhandled errors are logged and could be sent to an error tracking service.

## Debugging Specific Issues

### State Management Issues

Use the Debug Context to capture and inspect application state:

```typescript
import { useDebug } from '@/contexts/DebugContext';

function YourComponent() {
  const { captureState } = useDebug();
  
  // Capture state for debugging
  useEffect(() => {
    captureState('componentState', { 
      // Your component state here
    });
  }, [captureState, /* your dependencies */]);
  
  // ...
}
```

### Performance Issues

Use the `why-did-you-render` package to track unnecessary re-renders:

```typescript
// In your component file
import React from 'react';

if (process.env.NODE_ENV === 'development') {
  YourComponent.whyDidYouRender = true;
}

// Or enable globally for specific components in _app.tsx
```

### WebSocket Debugging

For WebSocket connection issues:

1. Check the browser console for connection errors
2. Verify the NEXT_PUBLIC_WS_URL environment variable
3. Use the Network tab in DevTools, filter by "WS" to see WebSocket connections
4. Look for the `X-Request-ID` and `X-Correlation-ID` headers in the initial WebSocket handshake

## Running in Debug Mode

To run the application with Node.js inspector for step-by-step debugging:

```bash
npm run start:debug
```

Then connect your IDE's debugger or open Chrome DevTools and navigate to chrome://inspect.

## Bundle Analysis

To analyze the bundle size:

```bash
npm run analyze
```

This will generate a report showing the size of each bundle and help identify large dependencies.

## TypeScript Type Checking

Run TypeScript type checking:

```bash
npx tsc --noEmit
```

## Common Issues and Solutions

1. **API Requests Failing**
   - Check network tab for status codes
   - Verify API URL environment variable
   - Check CORS settings
   - Look for authentication issues (expired tokens)

2. **Component Not Rendering**
   - Check if it's wrapped in a conditional that evaluates to false
   - Verify that parent components are rendering
   - Check for errors in the console

3. **Slow Performance**
   - Use React DevTools Profiler to identify slow components
   - Look for unnecessary re-renders
   - Check for expensive operations in render functions
   - Verify that proper memoization is used (useMemo, useCallback)

4. **Authentication Issues**
   - Check local storage for token expiration
   - Verify that tokens are being sent with requests
   - Look for CORS issues with credentials

## Useful Debugging Commands

```javascript
// In browser console

// Get current environment config
console.log(window.__NEXT_DATA__.props.pageProps.env);

// Get app state
console.log(window.__APP_STATE__);

// Force garbage collection (Chrome only, requires --enable-precise-memory-info flag)
window.gc();

// Check for memory leaks
performance.memory;

// Monitor events on an element
monitorEvents(document.querySelector('#your-element-id'));
``` 
```


### FILE: frontend\Dockerfile
```
# Build stage
FROM node:18-slim AS builder

WORKDIR /app

# Copy package files
COPY package*.json ./

# Install dependencies
RUN npm install

# Create necessary directories
RUN mkdir -p /app/public /app/src

# Copy app source by category to avoid Windows permission issues
COPY public/ /app/public/
COPY src/ /app/src/
COPY *.js /app/
COPY *.json /app/
COPY *.css /app/

# Build the application
RUN npm run build

# Production stage
FROM node:18-slim AS runner

WORKDIR /app

# Set environment variables
ENV NODE_ENV=production
ENV PORT=3000

# Create public directory if it doesn't exist
RUN mkdir -p public

# Copy necessary files from builder
COPY --from=builder /app/next.config.js ./
COPY --from=builder /app/public/ ./public/
COPY --from=builder /app/.next ./.next
COPY --from=builder /app/node_modules ./node_modules
COPY --from=builder /app/package.json ./package.json

# Expose port
EXPOSE 3000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:3000/api/health || exit 1

# Start the application - updated to use standalone server
CMD ["node", ".next/standalone/server.js"] 
```


### FILE: frontend\next-env.d.ts
```
/// <reference types="next" />
/// <reference types="next/image-types/global" />

// NOTE: This file should not be edited
// see https://nextjs.org/docs/pages/building-your-application/configuring/typescript for more information.

```


### FILE: frontend\next.config.js
```
const path = require('path');

/** @type {import('next').NextConfig} */
const nextConfig = {
  reactStrictMode: true,
  
  // Default environment variables
  env: {
    // App information
    NEXT_PUBLIC_APP_NAME: 'Meeting App',
    NEXT_PUBLIC_APP_VERSION: process.env.NEXT_PUBLIC_APP_VERSION || '1.0.0',
    
    // API endpoints with defaults
    NEXT_PUBLIC_API_URL: process.env.NEXT_PUBLIC_API_URL || 'http://localhost:5000',
    NEXT_PUBLIC_AUTH_URL: process.env.NEXT_PUBLIC_AUTH_URL || 'http://localhost:5001',
    NEXT_PUBLIC_WS_URL: process.env.NEXT_PUBLIC_WS_URL || 'ws://localhost:3001',
    
    // Feature flags
    NEXT_PUBLIC_ENABLE_ANALYTICS: process.env.NEXT_PUBLIC_ENABLE_ANALYTICS || 'false',
    NEXT_PUBLIC_ENABLE_DEBUG_TOOLS: process.env.NODE_ENV !== 'production' ? 'true' : (process.env.NEXT_PUBLIC_ENABLE_DEBUG_TOOLS || 'false'),
    
    // Timeouts and limits
    NEXT_PUBLIC_API_TIMEOUT_MS: process.env.NEXT_PUBLIC_API_TIMEOUT_MS || '30000',
    NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS: process.env.NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS || '5000',
    NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB: process.env.NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB || '5',
  },
  
  // Images configuration
  images: {
    domains: ['localhost'],
  },
  
  // Enable SWC minification
  swcMinify: true,
  
  // Output standalone build
  output: 'standalone',
  
  // Disable source maps in production
  productionBrowserSourceMaps: false,
  
  // Configure webpack
  webpack: (config, { dev, isServer }) => {
    // External dependencies
    config.externals = [...config.externals, { 'simple-peer': 'SimplePeer' }];
    
    // Path aliases
    config.resolve = {
      ...config.resolve,
      alias: {
        ...config.resolve.alias,
        '@': path.join(__dirname, 'src'),
      },
    };
    
    // Example: Add environment variable injection through DefinePlugin
    // if (dev) {
    //   const webpack = require('webpack');
    //   config.plugins.push(
    //     new webpack.DefinePlugin({
    //       'process.env.APP_BUILD_TIME': JSON.stringify(new Date().toISOString()),
    //     })
    //   );
    // }
    
    return config;
  },
  
  // Header configurations
  async headers() {
    return [
      {
        source: '/(.*)',
        headers: [
          {
            key: 'X-Content-Type-Options',
            value: 'nosniff',
          },
          {
            key: 'X-Frame-Options',
            value: 'DENY',
          },
          {
            key: 'X-XSS-Protection',
            value: '1; mode=block',
          },
        ],
      },
      {
        source: '/:path*',
        headers: [
          { 
            key: 'Access-Control-Allow-Origin', 
            value: process.env.NODE_ENV === 'development' 
              ? 'http://localhost:5000' 
              : 'http://api.meeting-app.local' 
          },
          { key: 'Access-Control-Allow-Methods', value: 'GET,OPTIONS,PATCH,DELETE,POST,PUT' },
          { key: 'Access-Control-Allow-Headers', value: 'X-Requested-With, Content-Type, Authorization' },
          { key: 'Access-Control-Allow-Credentials', value: 'true' }
        ],
      },
    ];
  },
}

module.exports = nextConfig 
```


### FILE: frontend\package.json
```
{
  "name": "meeting-app-frontend",
  "version": "1.0.0",
  "description": "Frontend for the meeting application",
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint",
    "lint:fix": "next lint --fix",
    "format": "prettier --write \"**/*.{js,jsx,ts,tsx,json,md}\"",
    "format:check": "prettier --check \"**/*.{js,jsx,ts,tsx,json,md}\"",
    "analyze": "cross-env ANALYZE=true next build",
    "start:debug": "cross-env NODE_OPTIONS='--inspect' next dev"
  },
  "dependencies": {
    "next": "^13.4.19",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "socket.io-client": "^4.7.2",
    "axios": "^1.4.0",
    "@mui/material": "^5.14.5",
    "@mui/icons-material": "^5.14.5",
    "@emotion/react": "^11.11.1",
    "@emotion/styled": "^11.11.0",
    "formik": "^2.4.3",
    "yup": "^1.2.0",
    "@react-oauth/google": "^0.11.1",
    "simple-peer": "^9.11.1"
  },
  "devDependencies": {
    "@types/node": "^20.10.0",
    "@types/react": "^18.2.20",
    "@types/react-dom": "^18.2.7",
    "@types/fabric": "^5.3.7",
    "@types/simple-peer": "^9.11.8",
    "@types/socket.io-client": "^3.0.0",
    "typescript": "^5.3.0",
    "eslint": "^8.47.0",
    "eslint-config-next": "14.0.0",
    "tailwindcss": "^3.3.5",
    "postcss": "^8.4.31",
    "autoprefixer": "^10.4.16",
    "@typescript-eslint/eslint-plugin": "^6.4.0",
    "@typescript-eslint/parser": "^6.4.0",
    "cross-env": "^7.0.3",
    "eslint-plugin-react": "^7.33.2",
    "eslint-plugin-react-hooks": "^4.6.0",
    "prettier": "^3.0.2",
    "why-did-you-render": "^7.0.1"
  }
} 
```


### FILE: frontend\postcss.config.js
```
module.exports = {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
} 
```


### FILE: frontend\tailwind.config.js
```
/** @type {import('tailwindcss').Config} */
module.exports = {
  content: [
    './src/pages/**/*.{js,ts,jsx,tsx}',
    './src/components/**/*.{js,ts,jsx,tsx}',
    './src/app/**/*.{js,ts,jsx,tsx}',
  ],
  theme: {
    extend: {},
  },
  plugins: [],
} 
```


### FILE: frontend\tsconfig.json
```
{
  "compilerOptions": {
    "target": "es5",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "forceConsistentCasingInFileNames": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": [
    "next-env.d.ts", 
    "src/types/*.d.ts",
    "**/*.ts", 
    "**/*.tsx", 
    ".next/types/**/*.ts"
  ],
  "exclude": ["node_modules"]
} 
```


### FILE: frontend\src\components\ErrorBoundary.tsx
```
import React, { Component, ErrorInfo, ReactNode } from 'react';
import logger from '@/utils/logger';
import { isDevelopment } from '@/config/environment';

interface Props {
  children: ReactNode;
  fallback?: ReactNode | ((error: Error, errorInfo: ErrorInfo) => ReactNode);
  onError?: (error: Error, errorInfo: ErrorInfo) => void;
}

interface State {
  hasError: boolean;
  error?: Error;
  errorInfo?: ErrorInfo;
}

/**
 * Error boundary component to catch JavaScript errors in child component tree.
 * Displays a fallback UI instead of crashing the whole app.
 */
class ErrorBoundary extends Component<Props, State> {
  constructor(props: Props) {
    super(props);
    this.state = { hasError: false };
  }

  static getDerivedStateFromError(error: Error): State {
    // Update state so the next render will show the fallback UI
    return { hasError: true, error };
  }

  componentDidCatch(error: Error, errorInfo: ErrorInfo): void {
    // Capture the error details
    this.setState({ errorInfo });
    
    // Log the error
    logger.error('Error caught by ErrorBoundary:', error);
    logger.error('Component stack:', errorInfo.componentStack);
    
    // Call the onError callback if provided
    if (this.props.onError) {
      this.props.onError(error, errorInfo);
    }
    
    // In development, log to console for easier debugging
    if (isDevelopment) {
      console.error('Error caught by ErrorBoundary:', error);
      console.error('Component stack:', errorInfo.componentStack);
    }
  }

  render(): ReactNode {
    const { hasError, error, errorInfo } = this.state;
    const { children, fallback } = this.props;

    if (hasError && error) {
      // Check for custom fallback render function
      if (typeof fallback === 'function' && errorInfo) {
        return fallback(error, errorInfo);
      }
      
      // Use provided fallback component
      if (fallback) {
        return fallback;
      }
      
      // Default fallback UI
      return (
        <div className="error-boundary">
          <div className="error-container">
            <h2>Something went wrong</h2>
            <p className="error-message">{error.message}</p>
            {isDevelopment && errorInfo && (
              <details className="error-details">
                <summary>Component Stack</summary>
                <pre>{errorInfo.componentStack}</pre>
              </details>
            )}
            <button
              className="error-reset-button"
              onClick={() => this.setState({ hasError: false, error: undefined, errorInfo: undefined })}
            >
              Try again
            </button>
          </div>
        </div>
      );
    }

    // When there's no error, render children
    return children;
  }
}

/**
 * HOC to wrap a component with an error boundary
 */
export function withErrorBoundary<P extends object>(
  Component: React.ComponentType<P>,
  errorBoundaryProps?: Omit<Props, 'children'>
) {
  const displayName = Component.displayName || Component.name || 'Component';
  
  const WrappedComponent = (props: P) => (
    <ErrorBoundary {...errorBoundaryProps}>
      <Component {...props} />
    </ErrorBoundary>
  );
  
  WrappedComponent.displayName = `withErrorBoundary(${displayName})`;
  
  return WrappedComponent;
}

export default ErrorBoundary; 
```


### FILE: frontend\src\components\layout\Layout.tsx
```
import React from 'react';
import { useRouter } from 'next/router';
import { useAuth } from '@/contexts/AuthContext';

interface LayoutProps {
  children: React.ReactNode;
}

export default function Layout({ children }: LayoutProps) {
  const router = useRouter();
  const { user, logout } = useAuth();

  const handleLogout = async () => {
    await logout();
    router.push('/login');
  };

  const getUserDisplayName = () => {
    if (!user) return '';
    if (user.first_name && user.last_name) {
      return `${user.first_name} ${user.last_name}`;
    }
    return user.email;
  };

  return (
    <div className="min-h-screen bg-gray-100">
      {/* Navigation */}
      <nav className="bg-white shadow-sm">
        <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
          <div className="flex justify-between h-16">
            <div className="flex items-center">
              <button onClick={() => router.push('/')} className="text-xl font-bold text-blue-600">
                Meeting App
              </button>
            </div>
            <div className="flex items-center">
              {user ? (
                <div className="flex items-center space-x-4">
                  <span className="text-gray-700">{getUserDisplayName()}</span>
                  <button
                    onClick={handleLogout}
                    className="bg-red-500 hover:bg-red-600 text-white px-4 py-2 rounded-md text-sm font-medium"
                  >
                    Logout
                  </button>
                </div>
              ) : (
                <button
                  onClick={() => router.push('/login')}
                  className="bg-blue-500 hover:bg-blue-600 text-white px-4 py-2 rounded-md text-sm font-medium"
                >
                  Login
                </button>
              )}
            </div>
          </div>
        </div>
      </nav>

      {/* Main content */}
      <main className="py-10">
        <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
          {children}
        </div>
      </main>
    </div>
  );
} 
```


### FILE: frontend\src\components\meeting\Chat.tsx
```
import React, { useState, useEffect, useRef } from 'react';
import { useWebSocket } from '@/contexts/WebSocketContext';
import { useAuth } from '@/contexts/AuthContext';

interface Message {
  userId: number;
  message: string;
  timestamp: string;
}

interface ChatProps {
  roomId?: string;
}

export default function Chat({ roomId }: ChatProps) {
  const { socket, isConnected, sendMessage } = useWebSocket();
  const { user } = useAuth();
  const [messages, setMessages] = useState<Message[]>([]);
  const [newMessage, setNewMessage] = useState('');
  const messagesEndRef = useRef<HTMLDivElement>(null);

  // Scroll to bottom when new messages arrive
  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  // Listen for chat messages
  useEffect(() => {
    if (!socket || !isConnected || !roomId) return;

    const handleChatMessage = (message: Message) => {
      setMessages(prev => [...prev, message]);
    };

    socket.on('chat-message', handleChatMessage);

    return () => {
      socket.off('chat-message', handleChatMessage);
    };
  }, [socket, isConnected, roomId]);

  const handleSubmit = (e: React.FormEvent) => {
    e.preventDefault();
    if (!newMessage.trim() || !roomId) return;

    sendMessage(roomId, newMessage.trim());
    setNewMessage('');
  };

  return (
    <div className="flex flex-col h-full bg-white">
      {/* Messages */}
      <div className="flex-1 overflow-y-auto p-4 space-y-4">
        {messages.map((message, index) => (
          <div
            key={index}
            className={`flex ${
              message.userId === user?.id ? 'justify-end' : 'justify-start'
            }`}
          >
            <div
              className={`max-w-[70%] rounded-lg px-4 py-2 ${
                message.userId === user?.id
                  ? 'bg-blue-500 text-white'
                  : 'bg-gray-100 text-gray-900'
              }`}
            >
              <div className="text-sm">{message.message}</div>
              <div className="text-xs mt-1 opacity-75">
                {new Date(message.timestamp).toLocaleTimeString(undefined, {
                  hour: '2-digit',
                  minute: '2-digit',
                  hour12: true
                })}
              </div>
            </div>
          </div>
        ))}
        <div ref={messagesEndRef} />
      </div>

      {/* Input */}
      <form onSubmit={handleSubmit} className="border-t p-4">
        <div className="flex space-x-2">
          <input
            type="text"
            value={newMessage}
            onChange={(e) => setNewMessage(e.target.value)}
            placeholder="Type a message..."
            className="flex-1 rounded-lg border border-gray-300 px-4 py-2 focus:outline-none focus:ring-2 focus:ring-blue-500"
          />
          <button
            type="submit"
            disabled={!newMessage.trim()}
            className="bg-blue-500 text-white px-4 py-2 rounded-lg hover:bg-blue-600 focus:outline-none focus:ring-2 focus:ring-blue-500 disabled:opacity-50"
          >
            Send
          </button>
        </div>
      </form>
    </div>
  );
} 
```


### FILE: frontend\src\components\meeting\VideoConference.tsx
```
import React, { useEffect, useRef, useState } from 'react';
import SimplePeer from 'simple-peer';
import { useWebSocket } from '@/contexts/WebSocketContext';
import { useAuth } from '@/contexts/AuthContext';

interface Peer {
  userId: string;
  stream: MediaStream;
  peer: SimplePeer.Instance;
}

interface VideoConferenceProps {
  roomId: string;
}

interface UserConnectedEvent {
  userId: string;
}

interface UserDisconnectedEvent {
  userId: string;
}

interface SignalEvent {
  userId: string;
  signal: SimplePeer.SignalData;
}

export default function VideoConference({ roomId }: VideoConferenceProps) {
  const { socket, isConnected } = useWebSocket();
  const { user } = useAuth();
  const [peers, setPeers] = useState<Map<string, Peer>>(new Map());
  const [localStream, setLocalStream] = useState<MediaStream | null>(null);
  const [isMuted, setIsMuted] = useState(false);
  const [isVideoOff, setIsVideoOff] = useState(false);
  const localVideoRef = useRef<HTMLVideoElement>(null);

  // Initialize local media stream
  useEffect(() => {
    const initializeMedia = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: true,
          audio: true
        });
        setLocalStream(stream);
        if (localVideoRef.current) {
          localVideoRef.current.srcObject = stream;
        }
      } catch (err) {
        console.error('Failed to get media devices:', err);
      }
    };

    initializeMedia();

    return () => {
      localStream?.getTracks().forEach((track: MediaStreamTrack) => track.stop());
    };
  }, []);

  // Handle socket events
  useEffect(() => {
    if (!socket || !isConnected || !localStream) return;

    // Join the room
    socket.emit('join-room', { roomId });

    // Handle new user connections
    socket.on('user-connected', ({ userId }: UserConnectedEvent) => {
      if (userId === user?.id?.toString()) return;
      
      const peer = createPeer(userId, localStream);
      setPeers((prev: Map<string, Peer>) => new Map(prev).set(userId, {
        userId,
        stream: localStream,
        peer
      }));
    });

    // Handle user disconnections
    socket.on('user-disconnected', ({ userId }: UserDisconnectedEvent) => {
      if (peers.has(userId)) {
        peers.get(userId)?.peer.destroy();
        const newPeers = new Map(peers);
        newPeers.delete(userId);
        setPeers(newPeers);
      }
    });

    // Handle incoming signals
    socket.on('signal', ({ userId, signal }: SignalEvent) => {
      const peer = peers.get(userId)?.peer;
      if (peer) {
        peer.signal(signal);
      }
    });

    return () => {
      socket.off('user-connected');
      socket.off('user-disconnected');
      socket.off('signal');
      peers.forEach((peer: Peer) => peer.peer.destroy());
    };
  }, [socket, isConnected, localStream, roomId, user?.id]);

  // Create a new peer connection
  const createPeer = (userId: string, stream: MediaStream): SimplePeer.Instance => {
    const peer = new SimplePeer({
      initiator: true,
      trickle: false,
      stream
    });

    peer.on('signal', (signal: SimplePeer.SignalData) => {
      socket?.emit('signal', { userId, signal });
    });

    peer.on('stream', (remoteStream: MediaStream) => {
      setPeers((prev: Map<string, Peer>) => {
        const newPeers = new Map(prev);
        const peerData = newPeers.get(userId);
        if (peerData) {
          newPeers.set(userId, {
            ...peerData,
            stream: remoteStream
          });
        }
        return newPeers;
      });
    });

    return peer;
  };

  // Toggle audio
  const toggleAudio = () => {
    if (localStream) {
      localStream.getAudioTracks().forEach((track: MediaStreamTrack) => {
        track.enabled = !track.enabled;
      });
      setIsMuted(!isMuted);
    }
  };

  // Toggle video
  const toggleVideo = () => {
    if (localStream) {
      localStream.getVideoTracks().forEach((track: MediaStreamTrack) => {
        track.enabled = !track.enabled;
      });
      setIsVideoOff(!isVideoOff);
    }
  };

  return (
    <div className="h-full flex flex-col">
      {/* Controls */}
      <div className="bg-gray-800 p-4 flex items-center justify-center space-x-4">
        <button
          onClick={toggleAudio}
          className={`p-2 rounded-full ${isMuted ? 'bg-red-500' : 'bg-gray-600'}`}
        >
          {isMuted ? 'Unmute' : 'Mute'}
        </button>
        <button
          onClick={toggleVideo}
          className={`p-2 rounded-full ${isVideoOff ? 'bg-red-500' : 'bg-gray-600'}`}
        >
          {isVideoOff ? 'Start Video' : 'Stop Video'}
        </button>
      </div>

      {/* Video Grid */}
      <div className="flex-1 grid grid-cols-2 md:grid-cols-3 lg:grid-cols-4 gap-4 p-4">
        {/* Local Video */}
        <div className="relative aspect-video bg-gray-900 rounded-lg overflow-hidden">
          <video
            ref={localVideoRef}
            autoPlay
            playsInline
            muted
            className="w-full h-full object-cover"
          />
          <div className="absolute bottom-2 left-2 text-white text-sm bg-black bg-opacity-50 px-2 py-1 rounded">
            You
          </div>
        </div>

        {/* Remote Videos */}
        {Array.from(peers.values()).map((peer: Peer) => (
          <div key={peer.userId} className="relative aspect-video bg-gray-900 rounded-lg overflow-hidden">
            <video
              autoPlay
              playsInline
              ref={(video: HTMLVideoElement | null) => {
                if (video) video.srcObject = peer.stream;
              }}
              className="w-full h-full object-cover"
            />
            <div className="absolute bottom-2 left-2 text-white text-sm bg-black bg-opacity-50 px-2 py-1 rounded">
              User {peer.userId}
            </div>
          </div>
        ))}
      </div>
    </div>
  );
} 
```


### FILE: frontend\src\components\meeting\Whiteboard.tsx
```
import React, { useEffect, useRef, useState } from 'react';
import { useWebSocket } from '@/contexts/WebSocketContext';

interface WhiteboardProps {
  roomId?: string;
}

interface DrawData {
  type: 'start' | 'draw' | 'end';
  x: number;
  y: number;
  color: string;
  width: number;
}

export default function Whiteboard({ roomId }: WhiteboardProps) {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const contextRef = useRef<CanvasRenderingContext2D | null>(null);
  const { socket, isConnected, sendWhiteboardUpdate } = useWebSocket();
  const [isDrawing, setIsDrawing] = useState(false);
  const [color, setColor] = useState('#000000');
  const [lineWidth, setLineWidth] = useState(2);

  // Initialize canvas
  useEffect(() => {
    if (!canvasRef.current) return;

    const canvas = canvasRef.current;
    const context = canvas.getContext('2d');
    if (!context) return;

    // Set canvas size
    const parent = canvas.parentElement;
    if (parent) {
      canvas.width = parent.clientWidth;
      canvas.height = parent.clientHeight;
    }

    // Configure context
    context.lineCap = 'round';
    context.strokeStyle = color;
    context.lineWidth = lineWidth;
    contextRef.current = context;

    // Handle window resize
    const handleResize = () => {
      if (parent) {
        const imageData = context.getImageData(0, 0, canvas.width, canvas.height);
        canvas.width = parent.clientWidth;
        canvas.height = parent.clientHeight;
        context.putImageData(imageData, 0, 0);
        context.lineCap = 'round';
        context.strokeStyle = color;
        context.lineWidth = lineWidth;
      }
    };

    window.addEventListener('resize', handleResize);
    return () => window.removeEventListener('resize', handleResize);
  }, [color, lineWidth]);

  // Handle whiteboard updates from other users
  useEffect(() => {
    if (!socket || !isConnected || !roomId || !contextRef.current) return;

    const handleWhiteboardUpdate = ({ data }: { data: DrawData }) => {
      const context = contextRef.current;
      if (!context) return;

      context.strokeStyle = data.color;
      context.lineWidth = data.width;

      switch (data.type) {
        case 'start':
          context.beginPath();
          context.moveTo(data.x, data.y);
          break;
        case 'draw':
          context.lineTo(data.x, data.y);
          context.stroke();
          break;
        case 'end':
          context.closePath();
          break;
      }

      // Reset to current user's settings
      context.strokeStyle = color;
      context.lineWidth = lineWidth;
    };

    socket.on('whiteboard-update', handleWhiteboardUpdate);

    return () => {
      socket.off('whiteboard-update', handleWhiteboardUpdate);
    };
  }, [socket, isConnected, roomId, color, lineWidth]);

  const startDrawing = (e: React.MouseEvent<HTMLCanvasElement>) => {
    if (!contextRef.current || !roomId) return;

    const { offsetX, offsetY } = e.nativeEvent;
    contextRef.current.beginPath();
    contextRef.current.moveTo(offsetX, offsetY);
    setIsDrawing(true);

    sendWhiteboardUpdate(roomId, {
      type: 'start',
      x: offsetX,
      y: offsetY,
      color,
      width: lineWidth,
    });
  };

  const draw = (e: React.MouseEvent<HTMLCanvasElement>) => {
    if (!isDrawing || !contextRef.current || !roomId) return;

    const { offsetX, offsetY } = e.nativeEvent;
    contextRef.current.lineTo(offsetX, offsetY);
    contextRef.current.stroke();

    sendWhiteboardUpdate(roomId, {
      type: 'draw',
      x: offsetX,
      y: offsetY,
      color,
      width: lineWidth,
    });
  };

  const stopDrawing = () => {
    if (!contextRef.current || !roomId) return;

    contextRef.current.closePath();
    setIsDrawing(false);

    sendWhiteboardUpdate(roomId, {
      type: 'end',
      x: 0,
      y: 0,
      color,
      width: lineWidth,
    });
  };

  const clearCanvas = () => {
    if (!canvasRef.current || !contextRef.current) return;

    const canvas = canvasRef.current;
    const context = contextRef.current;
    context.clearRect(0, 0, canvas.width, canvas.height);
  };

  return (
    <div className="flex flex-col h-full">
      {/* Controls */}
      <div className="p-4 border-b flex items-center space-x-4">
        <input
          type="color"
          value={color}
          onChange={(e) => setColor(e.target.value)}
          className="w-8 h-8 rounded-full"
        />
        <select
          value={lineWidth}
          onChange={(e) => setLineWidth(Number(e.target.value))}
          className="border rounded px-2 py-1"
        >
          <option value="2">Thin</option>
          <option value="4">Medium</option>
          <option value="6">Thick</option>
        </select>
        <button
          onClick={clearCanvas}
          className="px-4 py-1 bg-red-500 text-white rounded hover:bg-red-600"
        >
          Clear
        </button>
      </div>

      {/* Canvas */}
      <div className="flex-1 relative">
        <canvas
          ref={canvasRef}
          onMouseDown={startDrawing}
          onMouseMove={draw}
          onMouseUp={stopDrawing}
          onMouseLeave={stopDrawing}
          className="absolute inset-0 bg-white cursor-crosshair"
        />
      </div>
    </div>
  );
} 
```


### FILE: frontend\src\config\environment.ts
```
/**
 * Centralized environment configuration.
 * This module provides consistent access to environment variables
 * and validates their presence at runtime.
 */

// Required environment variables that must be defined
interface RequiredEnvVars {
  // API URLs
  NEXT_PUBLIC_API_URL: string;
  NEXT_PUBLIC_AUTH_URL: string;
  NEXT_PUBLIC_WS_URL: string;
  
  // Other required configs
  NEXT_PUBLIC_APP_NAME: string;
  NEXT_PUBLIC_APP_VERSION: string;
}

// Optional environment variables with defaults
interface OptionalEnvVars {
  // Feature flags
  NEXT_PUBLIC_ENABLE_ANALYTICS: boolean;
  NEXT_PUBLIC_ENABLE_DEBUG_TOOLS: boolean;
  
  // Timeouts and limits
  NEXT_PUBLIC_API_TIMEOUT_MS: number;
  NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS: number;
  NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB: number;
}

// Environment configuration type
export type EnvConfig = RequiredEnvVars & OptionalEnvVars;

/**
 * Get environment variable with type checking
 */
function getEnvVar<T>(key: string, defaultValue?: T, parser?: (value: string) => T): T {
  const value = process.env[key];
  
  // Handle undefined values
  if (value === undefined) {
    if (defaultValue !== undefined) {
      return defaultValue;
    }
    throw new Error(`Environment variable ${key} is not defined`);
  }
  
  // Parse value if parser is provided
  if (parser) {
    try {
      return parser(value);
    } catch (error) {
      console.error(`Failed to parse environment variable ${key}:`, error);
      if (defaultValue !== undefined) {
        return defaultValue;
      }
      throw new Error(`Failed to parse environment variable ${key}`);
    }
  }
  
  // Return value as is
  return value as unknown as T;
}

/**
 * Boolean parser for environment variables
 */
function parseBoolean(value: string): boolean {
  return value.toLowerCase() === 'true';
}

/**
 * Number parser for environment variables
 */
function parseNumber(value: string): number {
  const parsed = Number(value);
  if (isNaN(parsed)) {
    throw new Error(`Value "${value}" cannot be parsed as a number`);
  }
  return parsed;
}

/**
 * Environment configuration
 */
export const env: EnvConfig = {
  // Required environment variables
  NEXT_PUBLIC_API_URL: getEnvVar('NEXT_PUBLIC_API_URL'),
  NEXT_PUBLIC_AUTH_URL: getEnvVar('NEXT_PUBLIC_AUTH_URL'),
  NEXT_PUBLIC_WS_URL: getEnvVar('NEXT_PUBLIC_WS_URL'),
  NEXT_PUBLIC_APP_NAME: getEnvVar('NEXT_PUBLIC_APP_NAME'),
  NEXT_PUBLIC_APP_VERSION: getEnvVar('NEXT_PUBLIC_APP_VERSION'),
  
  // Optional environment variables with defaults
  NEXT_PUBLIC_ENABLE_ANALYTICS: getEnvVar('NEXT_PUBLIC_ENABLE_ANALYTICS', false, parseBoolean),
  NEXT_PUBLIC_ENABLE_DEBUG_TOOLS: getEnvVar('NEXT_PUBLIC_ENABLE_DEBUG_TOOLS', process.env.NODE_ENV !== 'production', parseBoolean),
  NEXT_PUBLIC_API_TIMEOUT_MS: getEnvVar('NEXT_PUBLIC_API_TIMEOUT_MS', 30000, parseNumber),
  NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS: getEnvVar('NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS', 5000, parseNumber),
  NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB: getEnvVar('NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB', 5, parseNumber),
};

/**
 * Check if running in development mode
 */
export const isDevelopment = process.env.NODE_ENV === 'development';

/**
 * Check if running in production mode
 */
export const isProduction = process.env.NODE_ENV === 'production';

/**
 * Check if running in test mode
 */
export const isTest = process.env.NODE_ENV === 'test';

/**
 * Get base URL for the current environment
 */
export function getBaseUrl(): string {
  if (typeof window !== 'undefined') {
    return window.location.origin;
  }
  return env.NEXT_PUBLIC_API_URL;
}

export default env; 
```


### FILE: frontend\src\contexts\AuthContext.tsx
```
import { createContext, useContext, useState, useEffect, ReactNode } from 'react';
import { useRouter } from 'next/router';

interface User {
  id: number;
  email: string;
  first_name?: string;
  last_name?: string;
  profile_picture?: string;
  is_google_user: boolean;
}

interface AuthContextType {
  user: User | null;
  token: string | null;
  loading: boolean;
  error: string | null;
  login: (email: string, password: string) => Promise<void>;
  googleLogin: (token: string) => Promise<void>;
  logout: () => void;
  register: (email: string, password: string) => Promise<void>;
  resetPassword: (email: string) => Promise<void>;
  updatePassword: (email: string, token: string, newPassword: string) => Promise<void>;
  refreshToken: () => Promise<boolean>;
}

interface AuthProviderProps {
  children: ReactNode;
}

const AuthContext = createContext<AuthContextType | undefined>(undefined);

export function AuthProvider({ children }: AuthProviderProps) {
  const [user, setUser] = useState<User | null>(null);
  const [token, setToken] = useState<string | null>(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);
  const router = useRouter();

  const AUTH_API_URL = process.env.NEXT_PUBLIC_AUTH_URL || 'http://localhost:5001';

  useEffect(() => {
    // Check for stored token and validate it
    const storedToken = localStorage.getItem('auth_token');
    if (storedToken) {
      validateToken(storedToken);
    } else {
      setLoading(false);
    }
  }, []);

  const validateToken = async (authToken: string) => {
    try {
      const response = await fetch(`${AUTH_API_URL}/auth/validate`, {
        headers: {
          'Authorization': `Bearer ${authToken}`
        }
      });
      
      if (response.ok) {
        const userData = await response.json();
        setUser(userData);
        setToken(authToken);
      } else {
        localStorage.removeItem('auth_token');
        setToken(null);
        setUser(null);
      }
    } catch (err) {
      console.error('Token validation error:', err);
      localStorage.removeItem('auth_token');
      setToken(null);
      setUser(null);
    } finally {
      setLoading(false);
    }
  };

  const refreshToken = async (): Promise<boolean> => {
    try {
      const response = await fetch(`${AUTH_API_URL}/auth/refresh-token`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${token}`
        }
      });

      if (response.ok) {
        const data = await response.json();
        localStorage.setItem('auth_token', data.token);
        setToken(data.token);
        return true;
      }
      return false;
    } catch (err) {
      console.error('Token refresh error:', err);
      return false;
    }
  };

  const login = async (email: string, password: string) => {
    try {
      setError(null);
      const response = await fetch(`${AUTH_API_URL}/auth/login`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ email, password })
      });

      if (!response.ok) {
        const error = await response.json();
        throw new Error(error.error || 'Login failed');
      }

      const data = await response.json();
      localStorage.setItem('auth_token', data.token);
      setToken(data.token);
      setUser(data.user);
      router.push('/dashboard');
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Login failed');
      throw err;
    }
  };

  const googleLogin = async (token: string) => {
    try {
      setError(null);
      const response = await fetch('http://localhost:5001/auth/google/login', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ token })
      });

      if (!response.ok) {
        const error = await response.json();
        throw new Error(error.error || 'Google login failed');
      }

      const data = await response.json();
      localStorage.setItem('auth_token', data.token);
      setUser(data.user);
      router.push('/dashboard');
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Google login failed');
      throw err;
    }
  };

  const register = async (email: string, password: string) => {
    try {
      setError(null);
      const response = await fetch('http://localhost:5001/auth/register', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ email, password })
      });

      if (!response.ok) {
        const error = await response.json();
        throw new Error(error.error || 'Registration failed');
      }

      const data = await response.json();
      localStorage.setItem('auth_token', data.token);
      setUser(data.user);
      router.push('/dashboard');
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Registration failed');
      throw err;
    }
  };

  const resetPassword = async (email: string) => {
    try {
      setError(null);
      const response = await fetch('http://localhost:5001/auth/reset-password', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ email })
      });

      if (!response.ok) {
        const error = await response.json();
        throw new Error(error.error || 'Password reset failed');
      }
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Password reset failed');
      throw err;
    }
  };

  const updatePassword = async (email: string, token: string, newPassword: string) => {
    try {
      setError(null);
      const response = await fetch('http://localhost:5001/auth/reset-password', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ email, token, new_password: newPassword })
      });

      if (!response.ok) {
        const error = await response.json();
        throw new Error(error.error || 'Password update failed');
      }
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Password update failed');
      throw err;
    }
  };

  const logout = () => {
    localStorage.removeItem('auth_token');
    setUser(null);
    router.push('/login');
  };

  return (
    <AuthContext.Provider value={{
      user,
      token,
      loading,
      error,
      login,
      googleLogin,
      logout,
      register,
      resetPassword,
      updatePassword,
      refreshToken
    }}>
      {children}
    </AuthContext.Provider>
  );
}

export function useAuth() {
  const context = useContext(AuthContext);
  if (context === undefined) {
    throw new Error('useAuth must be used within an AuthProvider');
  }
  return context;
} 
```


### FILE: frontend\src\contexts\ChatContext.tsx
```
import React, { createContext, useContext, useEffect, useState } from 'react';
import { useWebSocket } from './WebSocketContext';

interface Message {
  id: string;
  userId: string;
  message: string;
  type: 'text' | 'file';
  fileUrl?: string;
  fileType?: string;
  fileSize?: number;
  timestamp: string;
  reactions?: Record<string, Set<string>>;
}

interface ChatContextType {
  messages: Message[];
  sendMessage: (message: string) => void;
  sendFile: (file: File) => Promise<void>;
  addReaction: (messageId: string, reaction: string) => void;
  isTyping: boolean;
  setIsTyping: (typing: boolean) => void;
  typingUsers: Set<string>;
}

interface UserTypingEvent {
  userId: string;
  isTyping: boolean;
}

interface MessageReactionEvent {
  messageId: string;
  reaction: string;
  userId: string;
  count: number;
}

const ChatContext = createContext<ChatContextType | undefined>(undefined);

export function ChatProvider({ children }: { children: React.ReactNode }) {
  const { socket } = useWebSocket();
  const [messages, setMessages] = useState<Message[]>([]);
  const [isTyping, setIsTyping] = useState(false);
  const [typingUsers, setTypingUsers] = useState<Set<string>>(new Set());
  const [typingTimeout, setTypingTimeout] = useState<ReturnType<typeof setTimeout> | null>(null);

  useEffect(() => {
    if (!socket) return;

    socket.on('chat_message', (message: Message) => {
      const messageWithUTC = {
        ...message,
        timestamp: new Date(message.timestamp).toISOString()
      };
      setMessages((prev: Message[]) => [...prev, messageWithUTC]);
    });

    socket.on('user_typing', ({ userId, isTyping }: UserTypingEvent) => {
      setTypingUsers((prev: Set<string>) => {
        const newSet = new Set(prev);
        if (isTyping) {
          newSet.add(userId);
        } else {
          newSet.delete(userId);
        }
        return newSet;
      });
    });

    socket.on('message_reaction', ({ messageId, reaction, userId, count }: MessageReactionEvent) => {
      setMessages((prev: Message[]) => {
        return prev.map((msg: Message) => {
          if (msg.id === messageId) {
            return {
              ...msg,
              reactions: {
                ...msg.reactions,
                [reaction]: new Set([...Array.from(msg.reactions?.[reaction] || []), userId])
              }
            };
          }
          return msg;
        });
      });
    });

    return () => {
      socket.off('chat_message');
      socket.off('user_typing');
      socket.off('message_reaction');
    };
  }, [socket]);

  const sendMessage = (message: string) => {
    if (!socket) return;
    socket.emit('chat_message', { message });
  };

  const sendFile = async (file: File) => {
    if (!socket) return;

    // Convert file to base64
    const reader = new FileReader();
    reader.readAsDataURL(file);

    reader.onload = () => {
      const base64 = reader.result as string;
      socket.emit('chat_message', {
        message: file.name,
        type: 'file',
        fileData: {
          name: file.name,
          type: file.type,
          size: file.size,
          url: base64
        }
      });
    };
  };

  const addReaction = (messageId: string, reaction: string) => {
    if (!socket) return;
    socket.emit('message_reaction', { messageId, reaction });
  };

  // Handle typing status
  useEffect(() => {
    if (!socket || !isTyping) return;

    socket.emit('user_typing', { isTyping: true });

    if (typingTimeout) {
      clearTimeout(typingTimeout);
    }

    const timeout = setTimeout(() => {
      socket.emit('user_typing', { isTyping: false });
      setIsTyping(false);
    }, 3000);

    setTypingTimeout(timeout);

    return () => {
      if (typingTimeout) {
        clearTimeout(typingTimeout);
      }
    };
  }, [isTyping, socket]);

  return (
    <ChatContext.Provider
      value={{
        messages,
        sendMessage,
        sendFile,
        addReaction,
        isTyping,
        setIsTyping,
        typingUsers
      }}
    >
      {children}
    </ChatContext.Provider>
  );
}

export function useChat() {
  const context = useContext(ChatContext);
  if (context === undefined) {
    throw new Error('useChat must be used within a ChatProvider');
  }
  return context;
} 
```


### FILE: frontend\src\contexts\DebugContext.tsx
```
import React, { createContext, useContext, useState, useEffect, useCallback } from 'react';
import { env, isDevelopment } from '@/config/environment';
import logger, { LogLevel, configureLogger } from '@/utils/logger';
import { getPendingRequests, abortAllRequests } from '@/services/api/client';

// Debug context state
interface DebugContextState {
  isDebugEnabled: boolean;
  toggleDebug: () => void;
  logLevel: LogLevel;
  setLogLevel: (level: LogLevel) => void;
  lastApiResponses: Array<{
    url: string;
    method: string;
    status: number;
    timestamp: number;
    duration: number;
  }>;
  pendingRequests: Array<{
    url: string;
    method: string;
    timestamp: number;
    duration: number;
  }>;
  appState: Record<string, any>;
  captureState: (key: string, value: any) => void;
  clearState: (key?: string) => void;
  abortAllRequests: () => void;
}

// Default context value
const defaultContext: DebugContextState = {
  isDebugEnabled: false,
  toggleDebug: () => {},
  logLevel: LogLevel.INFO,
  setLogLevel: () => {},
  lastApiResponses: [],
  pendingRequests: [],
  appState: {},
  captureState: () => {},
  clearState: () => {},
  abortAllRequests: () => {},
};

// Create context
const DebugContext = createContext<DebugContextState>(defaultContext);

// Maximum number of API responses to store
const MAX_API_RESPONSES = 100;

/**
 * Debug context provider component
 */
export const DebugProvider: React.FC<{
  children: React.ReactNode;
  initialEnabled?: boolean;
}> = ({ children, initialEnabled = env.NEXT_PUBLIC_ENABLE_DEBUG_TOOLS }) => {
  // Debug state
  const [isDebugEnabled, setIsDebugEnabled] = useState<boolean>(
    isDevelopment && (initialEnabled === true || initialEnabled === 'true')
  );
  
  // Log level state
  const [logLevel, setLogLevelState] = useState<LogLevel>(
    isDevelopment ? LogLevel.DEBUG : LogLevel.INFO
  );
  
  // API history state
  const [lastApiResponses, setLastApiResponses] = useState<Array<{
    url: string;
    method: string;
    status: number;
    timestamp: number;
    duration: number;
  }>>([]);
  
  // App state capture
  const [appState, setAppState] = useState<Record<string, any>>({});
  
  // Toggle debug mode
  const toggleDebug = useCallback(() => {
    setIsDebugEnabled(prev => !prev);
  }, []);
  
  // Set log level
  const setLogLevel = useCallback((level: LogLevel) => {
    setLogLevelState(level);
    configureLogger({ level });
    
    // Log the change
    logger.info(`Log level set to ${LogLevel[level]}`);
  }, []);
  
  // Capture application state for debugging
  const captureState = useCallback((key: string, value: any) => {
    setAppState(prev => ({
      ...prev,
      [key]: value,
      _lastUpdated: Date.now(),
    }));
  }, []);
  
  // Clear captured state
  const clearState = useCallback((key?: string) => {
    if (key) {
      setAppState(prev => {
        const newState = { ...prev };
        delete newState[key];
        return {
          ...newState,
          _lastUpdated: Date.now(),
        };
      });
    } else {
      setAppState({ _lastUpdated: Date.now() });
    }
  }, []);
  
  // Get pending requests
  const [pendingRequests, setPendingRequests] = useState<Array<{
    url: string;
    method: string;
    timestamp: number;
    duration: number;
  }>>([]);
  
  // Register API response listener
  useEffect(() => {
    if (!isDebugEnabled || !isDevelopment) {
      return;
    }
    
    // Register event listener for API responses
    const handleApiResponse = (event: CustomEvent) => {
      const { url, method, status, timestamp, duration } = event.detail;
      
      setLastApiResponses(prev => {
        const newResponses = [
          { url, method, status, timestamp, duration },
          ...prev,
        ].slice(0, MAX_API_RESPONSES);
        
        return newResponses;
      });
    };
    
    // Create custom event for API responses
    window.addEventListener('api-response', handleApiResponse as EventListener);
    
    // Clean up
    return () => {
      window.removeEventListener('api-response', handleApiResponse as EventListener);
    };
  }, [isDebugEnabled]);
  
  // Register keyboard shortcut for debug mode
  useEffect(() => {
    if (!isDevelopment) {
      return;
    }
    
    // Toggle debug mode with Ctrl+Shift+D
    const handleKeyDown = (event: KeyboardEvent) => {
      if (event.ctrlKey && event.shiftKey && event.key === 'D') {
        toggleDebug();
      }
    };
    
    window.addEventListener('keydown', handleKeyDown);
    
    // Clean up
    return () => {
      window.removeEventListener('keydown', handleKeyDown);
    };
  }, [toggleDebug]);
  
  // Update pending requests
  useEffect(() => {
    if (!isDebugEnabled || !isDevelopment) {
      return;
    }
    
    // Poll for pending requests
    const intervalId = setInterval(() => {
      const requests = getPendingRequests();
      const now = Date.now();
      
      setPendingRequests(
        requests.map(req => ({
          url: req.url,
          method: req.method,
          timestamp: req.timestamp,
          duration: now - req.timestamp,
        }))
      );
    }, 100);
    
    // Clean up
    return () => {
      clearInterval(intervalId);
    };
  }, [isDebugEnabled]);
  
  // Set initial log level
  useEffect(() => {
    configureLogger({ level: logLevel });
  }, [logLevel]);
  
  // Context value
  const contextValue: DebugContextState = {
    isDebugEnabled,
    toggleDebug,
    logLevel,
    setLogLevel,
    lastApiResponses,
    pendingRequests,
    appState,
    captureState,
    clearState,
    abortAllRequests,
  };
  
  return (
    <DebugContext.Provider value={contextValue}>
      {children}
      {isDebugEnabled && isDevelopment && (
        <DebugOverlay />
      )}
    </DebugContext.Provider>
  );
};

/**
 * Debug overlay component
 * Shown when debug mode is enabled
 */
const DebugOverlay: React.FC = () => {
  const [isExpanded, setIsExpanded] = useState<boolean>(false);
  const { logLevel, setLogLevel, lastApiResponses, pendingRequests, appState } = useContext(DebugContext);
  
  // Toggle expanded state
  const toggleExpanded = () => {
    setIsExpanded(prev => !prev);
  };
  
  // Format date
  const formatTime = (timestamp: number) => {
    const date = new Date(timestamp);
    return date.toLocaleTimeString();
  };
  
  // Handle log level change
  const handleLogLevelChange = (event: React.ChangeEvent<HTMLSelectElement>) => {
    setLogLevel(Number(event.target.value) as LogLevel);
  };
  
  // Minimize style
  if (!isExpanded) {
    return (
      <div className="debug-overlay-minimized">
        <button onClick={toggleExpanded}>ğŸ“Š Debug</button>
      </div>
    );
  }
  
  // Full debug overlay
  return (
    <div className="debug-overlay">
      <div className="debug-header">
        <h3>Debug Tools</h3>
        <button onClick={toggleExpanded}>Minimize</button>
      </div>
      
      <div className="debug-content">
        <div className="debug-section">
          <h4>Settings</h4>
          <div className="debug-setting">
            <label htmlFor="logLevel">Log Level:</label>
            <select 
              id="logLevel" 
              value={logLevel} 
              onChange={handleLogLevelChange}
            >
              <option value={LogLevel.TRACE}>Trace</option>
              <option value={LogLevel.DEBUG}>Debug</option>
              <option value={LogLevel.INFO}>Info</option>
              <option value={LogLevel.WARN}>Warning</option>
              <option value={LogLevel.ERROR}>Error</option>
              <option value={LogLevel.NONE}>None</option>
            </select>
          </div>
        </div>
        
        <div className="debug-section">
          <h4>Pending Requests ({pendingRequests.length})</h4>
          <div className="debug-requests">
            {pendingRequests.length === 0 ? (
              <p>No pending requests</p>
            ) : (
              <ul>
                {pendingRequests.map((request, index) => (
                  <li key={index}>
                    {request.method} {request.url} 
                    ({request.duration}ms, started at {formatTime(request.timestamp)})
                  </li>
                ))}
              </ul>
            )}
          </div>
        </div>
        
        <div className="debug-section">
          <h4>Recent API Responses</h4>
          <div className="debug-responses">
            {lastApiResponses.length === 0 ? (
              <p>No API responses yet</p>
            ) : (
              <ul>
                {lastApiResponses.slice(0, 5).map((response, index) => (
                  <li key={index} className={response.status >= 400 ? 'error' : 'success'}>
                    {response.method} {response.url} 
                    ({response.status}, {response.duration}ms, at {formatTime(response.timestamp)})
                  </li>
                ))}
              </ul>
            )}
          </div>
        </div>
        
        <div className="debug-section">
          <h4>Captured State</h4>
          <div className="debug-state">
            <pre>{JSON.stringify(appState, null, 2)}</pre>
          </div>
        </div>
      </div>
      
      <style jsx>{`
        .debug-overlay {
          position: fixed;
          bottom: 0;
          right: 0;
          width: 400px;
          max-height: 50vh;
          background-color: rgba(0, 0, 0, 0.8);
          color: white;
          border-top-left-radius: 8px;
          overflow: auto;
          z-index: 9999;
          font-family: monospace;
          font-size: 12px;
        }
        
        .debug-overlay-minimized {
          position: fixed;
          bottom: 10px;
          right: 10px;
          z-index: 9999;
        }
        
        .debug-header {
          display: flex;
          justify-content: space-between;
          align-items: center;
          padding: 8px;
          background-color: #333;
          border-bottom: 1px solid #555;
        }
        
        .debug-content {
          padding: 8px;
        }
        
        .debug-section {
          margin-bottom: 16px;
        }
        
        .debug-section h4 {
          margin-top: 0;
          margin-bottom: 8px;
          border-bottom: 1px solid #555;
        }
        
        .debug-requests, .debug-responses, .debug-state {
          max-height: 200px;
          overflow: auto;
        }
        
        ul {
          list-style: none;
          padding: 0;
          margin: 0;
        }
        
        li {
          padding: 4px 0;
          border-bottom: 1px solid #444;
        }
        
        li.error {
          color: #ff6b6b;
        }
        
        li.success {
          color: #69db7c;
        }
        
        .debug-setting {
          display: flex;
          align-items: center;
          margin-bottom: 8px;
        }
        
        .debug-setting label {
          margin-right: 8px;
        }
        
        button {
          background-color: #555;
          color: white;
          border: none;
          padding: 4px 8px;
          border-radius: 4px;
          cursor: pointer;
        }
        
        button:hover {
          background-color: #777;
        }
        
        pre {
          margin: 0;
          white-space: pre-wrap;
        }
      `}</style>
    </div>
  );
};

/**
 * Debug context hook
 */
export const useDebug = () => useContext(DebugContext);

export default DebugContext; 
```


### FILE: frontend\src\contexts\WebRTCContext.tsx
```
import React, { createContext, useContext, useEffect, useState, useCallback } from 'react';
import { useWebSocket } from './WebSocketContext';
import { useAuth } from './AuthContext';

interface MediaStreamError {
  name: string;
  message: string;
}

interface PeerConnection {
  userId: string;
  connection: RTCPeerConnection;
  stream: MediaStream;
}

interface SignalData {
  type: 'offer' | 'answer' | 'candidate';
  sdp?: string;
  candidate?: RTCIceCandidateInit;
}

interface WebRTCContextType {
  localStream: MediaStream | null;
  remoteStreams: Map<string, MediaStream>;
  error: MediaStreamError | null;
  startLocalStream: () => Promise<void>;
  stopLocalStream: () => void;
  toggleAudio: () => void;
  toggleVideo: () => void;
  startScreenShare: () => Promise<MediaStream | void>;
  stopScreenShare: () => void;
  isAudioEnabled: boolean;
  isVideoEnabled: boolean;
  isScreenSharing: boolean;
}

const WebRTCContext = createContext<WebRTCContextType>({
  localStream: null,
  remoteStreams: new Map(),
  error: null,
  startLocalStream: async () => {},
  stopLocalStream: () => {},
  toggleAudio: () => {},
  toggleVideo: () => {},
  startScreenShare: async () => {},
  stopScreenShare: () => {},
  isAudioEnabled: false,
  isVideoEnabled: false,
  isScreenSharing: false,
});

export const useWebRTC = () => useContext(WebRTCContext);

export const WebRTCProvider: React.FC<{ children: React.ReactNode }> = ({ children }) => {
  const [localStream, setLocalStream] = useState<MediaStream | null>(null);
  const [remoteStreams, setRemoteStreams] = useState<Map<string, MediaStream>>(new Map());
  const [error, setError] = useState<MediaStreamError | null>(null);
  const [isAudioEnabled, setIsAudioEnabled] = useState(true);
  const [isVideoEnabled, setIsVideoEnabled] = useState(true);
  const [isScreenSharing, setIsScreenSharing] = useState(false);
  const [screenStream, setScreenStream] = useState<MediaStream | null>(null);
  const [peerConnections] = useState<Map<string, PeerConnection>>(new Map());
  
  const { socket } = useWebSocket();
  const { user } = useAuth();

  const handleMediaError = (error: Error) => {
    setError({
      name: error.name,
      message: error.message
    });
    console.error('Media error:', error);
  };

  const startLocalStream = async () => {
    try {
      setError(null);
      const stream = await navigator.mediaDevices.getUserMedia({
        video: true,
        audio: true,
      });
      setLocalStream(stream);
      setIsAudioEnabled(true);
      setIsVideoEnabled(true);
    } catch (err) {
      handleMediaError(err instanceof Error ? err : new Error('Failed to access media devices'));
      throw err;
    }
  };

  const stopLocalStream = useCallback(() => {
    if (localStream) {
      localStream.getTracks().forEach(track => track.stop());
      setLocalStream(null);
      setIsAudioEnabled(false);
      setIsVideoEnabled(false);
    }
  }, [localStream]);

  const toggleAudio = useCallback(() => {
    if (localStream) {
      const audioTrack = localStream.getAudioTracks()[0];
      if (audioTrack) {
        audioTrack.enabled = !audioTrack.enabled;
        setIsAudioEnabled(audioTrack.enabled);
      }
    }
  }, [localStream]);

  const toggleVideo = useCallback(() => {
    if (localStream) {
      const videoTrack = localStream.getVideoTracks()[0];
      if (videoTrack) {
        videoTrack.enabled = !videoTrack.enabled;
        setIsVideoEnabled(videoTrack.enabled);
      }
    }
  }, [localStream]);

  const startScreenShare = async () => {
    try {
      setError(null);
      const stream = await navigator.mediaDevices.getDisplayMedia({
        video: true,
        audio: true
      });
      
      setScreenStream(stream);
      setIsScreenSharing(true);

      // Handle when user stops sharing via browser UI
      stream.getVideoTracks()[0].onended = () => {
        stopScreenShare();
      };

      return stream;
    } catch (err) {
      handleMediaError(err instanceof Error ? err : new Error('Failed to start screen sharing'));
      throw err;
    }
  };

  const stopScreenShare = useCallback(() => {
    if (screenStream) {
      screenStream.getTracks().forEach(track => track.stop());
      setScreenStream(null);
      setIsScreenSharing(false);
    }
  }, [screenStream]);

  // Clean up when component unmounts
  useEffect(() => {
    return () => {
      stopLocalStream();
      stopScreenShare();
      peerConnections.forEach(peer => {
        peer.connection.close();
      });
    };
  }, [stopLocalStream, stopScreenShare, peerConnections]);

  return (
    <WebRTCContext.Provider
      value={{
        localStream,
        remoteStreams,
        error,
        startLocalStream,
        stopLocalStream,
        toggleAudio,
        toggleVideo,
        startScreenShare,
        stopScreenShare,
        isAudioEnabled,
        isVideoEnabled,
        isScreenSharing,
      }}
    >
      {children}
    </WebRTCContext.Provider>
  );
}; 
```


### FILE: frontend\src\contexts\WebSocketContext.tsx
```
import React, { createContext, useContext, useEffect, useState, useCallback } from 'react';
import { io, Socket } from 'socket.io-client';
import { useAuth } from './AuthContext';

interface WebSocketContextType {
  socket: Socket | null;
  isConnected: boolean;
  connectionError: string | null;
  joinRoom: (roomId: string) => void;
  leaveRoom: (roomId: string) => void;
  sendMessage: (roomId: string, message: string) => void;
  sendSignal: (userId: string, signal: any) => void;
  sendWhiteboardUpdate: (roomId: string, data: any) => void;
}

const WebSocketContext = createContext<WebSocketContextType>({
  socket: null,
  isConnected: false,
  connectionError: null,
  joinRoom: () => {},
  leaveRoom: () => {},
  sendMessage: () => {},
  sendSignal: () => {},
  sendWhiteboardUpdate: () => {},
});

export const useWebSocket = () => useContext(WebSocketContext);

export const WebSocketProvider: React.FC<{ children: React.ReactNode }> = ({ children }) => {
  const [socket, setSocket] = useState<Socket | null>(null);
  const [isConnected, setIsConnected] = useState(false);
  const [connectionError, setConnectionError] = useState<string | null>(null);
  const [reconnectAttempts, setReconnectAttempts] = useState(0);
  const { token } = useAuth();

  const MAX_RECONNECT_ATTEMPTS = 5;
  const RECONNECT_INTERVAL = 5000;
  const WS_URL = process.env.NEXT_PUBLIC_WS_URL || 'ws://localhost:3001';

  const connectSocket = useCallback(() => {
    if (!token) return;

    try {
      const socketInstance = io(WS_URL, {
        auth: { token },
        transports: ['websocket'],
        reconnection: true,
        reconnectionAttempts: MAX_RECONNECT_ATTEMPTS,
        reconnectionDelay: RECONNECT_INTERVAL,
      });

      socketInstance.on('connect', () => {
        console.log('WebSocket connected');
        setIsConnected(true);
        setConnectionError(null);
        setReconnectAttempts(0);
      });

      socketInstance.on('disconnect', (reason) => {
        console.log('WebSocket disconnected:', reason);
        setIsConnected(false);
        if (reason === 'io server disconnect') {
          // Server initiated disconnect, attempt to reconnect
          setTimeout(() => {
            if (reconnectAttempts < MAX_RECONNECT_ATTEMPTS) {
              setReconnectAttempts(prev => prev + 1);
              socketInstance.connect();
            }
          }, RECONNECT_INTERVAL);
        }
      });

      socketInstance.on('connect_error', (error) => {
        console.error('WebSocket connection error:', error);
        setConnectionError(error.message);
        setIsConnected(false);
      });

      socketInstance.on('error', (error: Error) => {
        console.error('WebSocket error:', error);
        setConnectionError(error.message);
      });

      setSocket(socketInstance);

      return () => {
        socketInstance.disconnect();
      };
    } catch (error) {
      console.error('Error creating WebSocket connection:', error);
      setConnectionError(error instanceof Error ? error.message : 'Unknown error');
      return undefined;
    }
  }, [token, reconnectAttempts]);

  useEffect(() => {
    const cleanup = connectSocket();
    return () => cleanup?.();
  }, [connectSocket]);

  const joinRoom = useCallback((roomId: string) => {
    if (socket && isConnected) {
      socket.emit('join-room', { roomId });
    }
  }, [socket, isConnected]);

  const leaveRoom = useCallback((roomId: string) => {
    if (socket && isConnected) {
      socket.emit('leave-room', { roomId });
    }
  }, [socket, isConnected]);

  const sendMessage = useCallback((roomId: string, message: string) => {
    if (socket && isConnected) {
      socket.emit('send-message', { roomId, message });
    }
  }, [socket, isConnected]);

  const sendSignal = useCallback((userId: string, signal: any) => {
    if (socket && isConnected) {
      socket.emit('signal', { userId, signal });
    }
  }, [socket, isConnected]);

  const sendWhiteboardUpdate = useCallback((roomId: string, data: any) => {
    if (socket && isConnected) {
      socket.emit('whiteboard-update', { roomId, data });
    }
  }, [socket, isConnected]);

  return (
    <WebSocketContext.Provider
      value={{
        socket,
        isConnected,
        connectionError,
        joinRoom,
        leaveRoom,
        sendMessage,
        sendSignal,
        sendWhiteboardUpdate,
      }}
    >
      {children}
    </WebSocketContext.Provider>
  );
}; 
```


### FILE: frontend\src\contexts\WhiteboardContext.tsx
```
import React, { createContext, useContext, useEffect, useRef, useState, useCallback } from 'react';
import { fabric } from 'fabric';
import { useWebSocket } from './WebSocketContext';

interface Point {
  x: number;
  y: number;
}

interface DrawingPath {
  points: Point[];
  color: string;
  width: number;
  type: 'brush' | 'eraser';
}

interface DrawingObject {
  type: string;
  options: fabric.IObjectOptions & {
    path?: DrawingPath;
    points?: Point[];
    radius?: number;
    width?: number;
    height?: number;
    text?: string;
  };
}

interface FabricCanvasJSON {
  version: string;
  objects: fabric.Object[];
  background?: string;
}

interface CanvasState extends FabricCanvasJSON {
  // Additional state properties if needed
}

interface WhiteboardState {
  objects: fabric.Object[];
  background: string;
  dimensions: {
    width: number;
    height: number;
  };
}

interface WhiteboardContextType {
  canvas: fabric.Canvas | null;
  currentColor: string;
  setCurrentColor: (color: string) => void;
  currentBrushSize: number;
  setCurrentBrushSize: (size: number) => void;
  clearCanvas: () => void;
  undo: () => void;
  redo: () => void;
  addText: (text: string) => void;
  addShape: (type: 'rectangle' | 'circle' | 'line') => void;
  setMode: (mode: 'draw' | 'erase' | 'select') => void;
  currentMode: string;
  canUndo: boolean;
  canRedo: boolean;
  saveState: () => WhiteboardState;
  loadState: (state: WhiteboardState) => void;
}

const WhiteboardContext = createContext<WhiteboardContextType | undefined>(undefined);

export function WhiteboardProvider({ children }: { children: React.ReactNode }) {
  const { socket } = useWebSocket();
  const [canvas, setCanvas] = useState<fabric.Canvas | null>(null);
  const [currentColor, setCurrentColor] = useState('#000000');
  const [currentBrushSize, setCurrentBrushSize] = useState(2);
  const [currentMode, setCurrentMode] = useState<string>('draw');
  const [canUndo, setCanUndo] = useState(false);
  const [canRedo, setCanRedo] = useState(false);
  
  const canvasRef = useRef<HTMLCanvasElement | null>(null);
  const historyRef = useRef<CanvasState[]>([]);
  const redoHistoryRef = useRef<CanvasState[]>([]);

  useEffect(() => {
    if (!canvasRef.current) return;

    const newCanvas = new fabric.Canvas(canvasRef.current, {
      isDrawingMode: true,
      width: window.innerWidth * 0.8,
      height: window.innerHeight * 0.8,
      backgroundColor: '#ffffff'
    });

    newCanvas.freeDrawingBrush.color = currentColor;
    newCanvas.freeDrawingBrush.width = currentBrushSize;

    newCanvas.on('object:added', () => {
      const rawState = canvas?.toJSON() as FabricCanvasJSON;
      if (rawState) {
        const state: CanvasState = {
          version: rawState.version || '5.3.0',
          objects: rawState.objects || [],
          background: rawState.background
        };
        historyRef.current.push(state);
        redoHistoryRef.current = [];
        updateUndoRedoState();
      }
    });

    setCanvas(newCanvas);

    const handleResize = () => {
      newCanvas.setDimensions({
        width: window.innerWidth * 0.8,
        height: window.innerHeight * 0.8
      });
      newCanvas.renderAll();
    };

    window.addEventListener('resize', handleResize);

    return () => {
      window.removeEventListener('resize', handleResize);
      newCanvas.dispose();
    };
  }, []);

  const updateUndoRedoState = useCallback(() => {
    setCanUndo(historyRef.current.length > 0);
    setCanRedo(redoHistoryRef.current.length > 0);
  }, []);

  const setMode = useCallback((mode: 'draw' | 'erase' | 'select') => {
    if (!canvas) return;

    setCurrentMode(mode);
    canvas.isDrawingMode = mode === 'draw';

    if (mode === 'erase') {
      canvas.freeDrawingBrush = new fabric.PencilBrush(canvas);
      canvas.freeDrawingBrush.color = '#ffffff';
      canvas.freeDrawingBrush.width = 20;
      canvas.isDrawingMode = true;
    } else if (mode === 'draw') {
      canvas.freeDrawingBrush = new fabric.PencilBrush(canvas);
      canvas.freeDrawingBrush.color = currentColor;
      canvas.freeDrawingBrush.width = currentBrushSize;
    }

    canvas.selection = mode === 'select';
    canvas.renderAll();
  }, [canvas, currentColor, currentBrushSize]);

  const clearCanvas = useCallback(() => {
    if (!canvas) return;
    
    canvas.clear();
    canvas.backgroundColor = '#ffffff';
    canvas.renderAll();
    
    // Save state for undo
    const state = canvas.toJSON() as CanvasState;
    if (state) {
      historyRef.current.push(state);
      updateUndoRedoState();
    }

    // Emit clear event
    socket?.emit('whiteboard-clear');
  }, [canvas, socket, updateUndoRedoState]);

  const undo = useCallback(() => {
    if (!canvas || historyRef.current.length === 0) return;

    const currentState = canvas.toJSON() as CanvasState;
    redoHistoryRef.current.push(currentState);
    
    const previousState = historyRef.current.pop();
    if (previousState) {
      canvas.loadFromJSON(previousState, () => {
        canvas.renderAll();
        updateUndoRedoState();
      });
    }
  }, [canvas, updateUndoRedoState]);

  const redo = useCallback(() => {
    if (!canvas || redoHistoryRef.current.length === 0) return;

    const currentState = canvas.toJSON() as CanvasState;
    historyRef.current.push(currentState);
    
    const nextState = redoHistoryRef.current.pop();
    if (nextState) {
      canvas.loadFromJSON(nextState, () => {
        canvas.renderAll();
        updateUndoRedoState();
      });
    }
  }, [canvas, updateUndoRedoState]);

  const addText = useCallback((text: string) => {
    if (!canvas) return;

    const textObject = new fabric.IText(text, {
      left: canvas.width! / 2,
      top: canvas.height! / 2,
      fontSize: 20,
      fill: currentColor
    });

    canvas.add(textObject);
    canvas.setActiveObject(textObject);
    canvas.renderAll();
  }, [canvas, currentColor]);

  const addShape = useCallback((type: 'rectangle' | 'circle' | 'line') => {
    if (!canvas) return;

    let shape: fabric.Object;

    switch (type) {
      case 'rectangle':
        shape = new fabric.Rect({
          left: canvas.width! / 2 - 25,
          top: canvas.height! / 2 - 25,
          width: 50,
          height: 50,
          fill: 'transparent',
          stroke: currentColor,
          strokeWidth: 2
        });
        break;
      case 'circle':
        shape = new fabric.Circle({
          left: canvas.width! / 2 - 25,
          top: canvas.height! / 2 - 25,
          radius: 25,
          fill: 'transparent',
          stroke: currentColor,
          strokeWidth: 2
        });
        break;
      case 'line':
        shape = new fabric.Line([50, 50, 200, 50], {
          left: canvas.width! / 2 - 75,
          top: canvas.height! / 2,
          stroke: currentColor,
          strokeWidth: 2
        });
        break;
      default:
        return;
    }

    canvas.add(shape);
    canvas.setActiveObject(shape);
    canvas.renderAll();
  }, [canvas, currentColor]);

  const saveState = (): WhiteboardState => {
    if (!canvas) {
      return {
        objects: [],
        background: '#ffffff',
        dimensions: { width: 800, height: 600 }
      };
    }

    const rawState = canvas.toJSON() as FabricCanvasJSON;
    return {
      objects: rawState.objects,
      background: rawState.background || '#ffffff',
      dimensions: {
        width: canvas.getWidth(),
        height: canvas.getHeight()
      }
    };
  };

  const loadState = useCallback((state: WhiteboardState) => {
    if (!canvas) return;

    canvas.clear();
    canvas.backgroundColor = state.background;
    canvas.setDimensions(state.dimensions);

    canvas.loadFromJSON({ objects: state.objects }, () => {
      canvas.renderAll();
      historyRef.current = [canvas.toJSON() as CanvasState];
      redoHistoryRef.current = [];
      updateUndoRedoState();
    });
  }, [canvas, updateUndoRedoState]);

  return (
    <WhiteboardContext.Provider
      value={{
        canvas,
        currentColor,
        setCurrentColor,
        currentBrushSize,
        setCurrentBrushSize,
        clearCanvas,
        undo,
        redo,
        addText,
        addShape,
        setMode,
        currentMode,
        canUndo,
        canRedo,
        saveState,
        loadState
      }}
    >
      {children}
    </WhiteboardContext.Provider>
  );
}

export function useWhiteboard() {
  const context = useContext(WhiteboardContext);
  if (context === undefined) {
    throw new Error('useWhiteboard must be used within a WhiteboardProvider');
  }
  return context;
} 
```


### FILE: frontend\src\pages\_app.tsx
```
import React from 'react';
import type { AppProps } from 'next/app';
import Head from 'next/head';
import ErrorBoundary from '@/components/ErrorBoundary';
import { DebugProvider } from '@/contexts/DebugContext';
import logger from '@/utils/logger';
import { env, isDevelopment } from '@/config/environment';
import '@/styles/globals.css';

// Report unhandled promise rejections
if (typeof window !== 'undefined') {
  window.addEventListener('unhandledrejection', (event) => {
    logger.error('Unhandled Promise Rejection:', event.reason);
    
    // Track with analytics or error reporting service
    // if (!isDevelopment) {
    //   // Example: send to error tracking service
    //   // errorTrackingService.captureException(event.reason);
    // }
  });
  
  // Report uncaught errors
  window.addEventListener('error', (event) => {
    logger.error('Uncaught Error:', event.error || event.message);
    
    // Track with analytics or error reporting service
    // if (!isDevelopment) {
    //   // Example: send to error tracking service
    //   // errorTrackingService.captureException(event.error);
    // }
  });
}

// Custom error handler for error boundary
const handleError = (error: Error) => {
  logger.error('Error caught by root ErrorBoundary:', error);
  
  // Track with analytics or error reporting service
  // if (!isDevelopment) {
  //   // Example: send to error tracking service
  //   // errorTrackingService.captureException(error);
  // }
};

function MyApp({ Component, pageProps }: AppProps) {
  // Log when app renders (helpful for debugging during refreshes/navigation)
  React.useEffect(() => {
    logger.debug(`App rendered at ${new Date().toISOString()}`);
  }, []);
  
  return (
    <>
      <Head>
        <title>{env.NEXT_PUBLIC_APP_NAME}</title>
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <meta name="description" content="A comprehensive meeting management application" />
      </Head>
      
      <DebugProvider>
        <ErrorBoundary onError={handleError}>
          <Component {...pageProps} />
        </ErrorBoundary>
      </DebugProvider>
    </>
  );
}

export default MyApp; 
```


### FILE: frontend\src\pages\_error.tsx
```
import React from 'react';
import { NextPage } from 'next';
import Head from 'next/head';
import Link from 'next/link';
import { useRouter } from 'next/router';
import logger from '@/utils/logger';

interface ErrorProps {
  statusCode?: number;
  message?: string;
  hasGetInitialPropsRun?: boolean;
  err?: Error;
}

/**
 * Custom Next.js error page that handles both 404s and other error codes.
 */
const ErrorPage: NextPage<ErrorProps> = ({ statusCode, message, hasGetInitialPropsRun, err }) => {
  const router = useRouter();
  
  // Log the error when component mounts
  React.useEffect(() => {
    // Only log if we have an actual error (skip 404s for non-existent routes)
    if (statusCode && statusCode !== 404) {
      logger.error(`Error page displayed with status: ${statusCode}, URL: ${router.asPath}`);
      
      if (err) {
        logger.error('Error details:', err);
      }
    }
  }, [statusCode, err, router.asPath]);

  // Handle 404 errors
  if (statusCode === 404) {
    return (
      <>
        <Head>
          <title>Page Not Found | Meeting App</title>
        </Head>
        <div className="error-page not-found">
          <div className="error-container">
            <h1>404</h1>
            <h2>Page Not Found</h2>
            <p>Sorry, we couldn't find the page you're looking for.</p>
            <div className="error-actions">
              <Link href="/" className="btn btn-primary">
                Go to Home
              </Link>
              <button 
                className="btn btn-secondary" 
                onClick={() => router.back()}
              >
                Go Back
              </button>
            </div>
          </div>
        </div>
      </>
    );
  }

  // Handle other errors
  return (
    <>
      <Head>
        <title>Error | Meeting App</title>
      </Head>
      <div className="error-page">
        <div className="error-container">
          <h1>{statusCode || 'Error'}</h1>
          <h2>Something went wrong</h2>
          <p>{message || 'An unexpected error occurred'}</p>
          
          {process.env.NODE_ENV === 'development' && err && (
            <details className="error-details">
              <summary>Error Details</summary>
              <pre>{err.message}</pre>
              <pre>{err.stack}</pre>
            </details>
          )}
          
          <div className="error-actions">
            <Link href="/" className="btn btn-primary">
              Go to Home
            </Link>
            <button 
              className="btn btn-secondary" 
              onClick={() => router.reload()}
            >
              Reload Page
            </button>
          </div>
        </div>
      </div>
    </>
  );
};

// This gets called on server-side errors
ErrorPage.getInitialProps = async ({ res, err, asPath }) => {
  const errorInitialProps: ErrorProps = {
    hasGetInitialPropsRun: true,
    statusCode: res?.statusCode || (err ? 500 : 404),
  };
  
  // Keep the original error for debugging in development
  if (process.env.NODE_ENV === 'development' && err) {
    errorInitialProps.err = err;
    errorInitialProps.message = err.message;
    
    // Log the error on the server side
    console.error(`Server-side error occurred on ${asPath}:`, err);
  }
  
  return errorInitialProps;
};

export default ErrorPage; 
```


### FILE: frontend\src\pages\dashboard.tsx
```
/// <reference types="node" />
import React, { useState, useEffect, FormEvent, ChangeEvent } from 'react';
import { useRouter } from 'next/router';
import { useAuth } from '@/contexts/AuthContext';
import Layout from '@/components/layout/Layout';

interface Meeting {
  id: number;
  title: string;
  description: string;
  start_time: string;
  end_time: string;
  created_by: number;
  created_at: string;
  updated_at: string;
  ended_at: string | null;
}

declare global {
  namespace NodeJS {
    interface ProcessEnv {
      NEXT_PUBLIC_API_URL: string;
    }
  }
}

export default function Dashboard() {
  const router = useRouter();
  const { token } = useAuth();
  const [meetings, setMeetings] = useState<Meeting[]>([]);
  const [isCreating, setIsCreating] = useState(false);
  const [isJoining, setIsJoining] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [title, setTitle] = useState('');
  const [description, setDescription] = useState('');
  const [startTime, setStartTime] = useState('');
  const [endTime, setEndTime] = useState('');
  const [meetingId, setMeetingId] = useState('');
  const [error, setError] = useState('');

  useEffect(() => {
    if (token) {
      fetchMeetings();
    }
  }, [token]);

  const fetchMeetings = async () => {
    setIsLoading(true);
    try {
      const apiUrl = process.env.NEXT_PUBLIC_API_URL;
      if (!apiUrl) {
        throw new Error('API URL is not configured');
      }

      const response = await fetch(`${apiUrl}/api/meetings/list?active_only=true`, {
        headers: {
          Authorization: `Bearer ${token}`
        }
      });

      if (!response.ok) {
        const errorData = await response.json();
        throw new Error(errorData.error || 'Failed to fetch meetings');
      }

      const data = await response.json();
      setMeetings(data);
    } catch (err) {
      console.error('Error fetching meetings:', err);
      setError(err instanceof Error ? err.message : 'Failed to fetch meetings');
    } finally {
      setIsLoading(false);
    }
  };

  const handleCreateMeeting = async (e: FormEvent<HTMLFormElement>) => {
    e.preventDefault();
    setError('');
    
    try {
      // Enhanced client-side validation
      const trimmedTitle = title.trim();
      const trimmedDesc = description.trim();
      
      if (!trimmedTitle) {
        setError('Meeting title is required');
        return;
      }

      if (trimmedTitle.length > 200) {
        setError('Meeting title cannot exceed 200 characters');
        return;
      }

      if (trimmedDesc.length > 2000) {
        setError('Meeting description cannot exceed 2000 characters');
        return;
      }

      if (!startTime || !endTime) {
        setError('Start time and end time are required');
        return;
      }

      const startDate = new Date(startTime);
      const endDate = new Date(endTime);
      const now = new Date();

      if (isNaN(startDate.getTime()) || isNaN(endDate.getTime())) {
        setError('Invalid date format');
        return;
      }

      if (startDate < now) {
        setError('Meeting cannot start in the past');
        return;
      }

      if (startDate >= endDate) {
        setError('Start time must be before end time');
        return;
      }

      const duration = (endDate.getTime() - startDate.getTime()) / 1000; // in seconds
      if (duration < 300) { // 5 minutes
        setError('Meeting must be at least 5 minutes long');
        return;
      }

      if (duration > 86400) { // 24 hours
        setError('Meeting cannot be longer than 24 hours');
        return;
      }

      const oneYearFromNow = new Date();
      oneYearFromNow.setFullYear(oneYearFromNow.getFullYear() + 1);
      if (startDate > oneYearFromNow) {
        setError('Cannot schedule meetings more than 1 year in advance');
        return;
      }

      setIsCreating(true);
      const apiUrl = process.env.NEXT_PUBLIC_API_URL;
      if (!apiUrl) {
        throw new Error('API URL is not configured');
      }

      const response = await fetch(`${apiUrl}/api/meetings/create`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          Authorization: `Bearer ${token}`
        },
        body: JSON.stringify({
          title: trimmedTitle,
          description: trimmedDesc,
          start_time: startDate.toISOString(),
          end_time: endDate.toISOString()
        })
      });

      const data = await response.json();
      
      if (!response.ok) {
        throw new Error(data.error || 'Failed to create meeting');
      }

      // Update meetings list and reset form
      setMeetings((prevMeetings: Meeting[]) => [...prevMeetings, data]);
      setTitle('');
      setDescription('');
      setStartTime('');
      setEndTime('');
      setError('');
      
      // Show success message or redirect
      router.push(`/meeting/${data.id}`);
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to create meeting');
    } finally {
      setIsCreating(false);
    }
  };

  const handleJoinMeeting = async (e: FormEvent<HTMLFormElement>) => {
    e.preventDefault();
    setError('');

    try {
      // Validate meeting ID
      const meetingIdNum = parseInt(meetingId);
      if (isNaN(meetingIdNum) || meetingIdNum <= 0) {
        setError('Please enter a valid meeting ID');
        return;
      }

      setIsJoining(true);
      const apiUrl = process.env.NEXT_PUBLIC_API_URL;
      if (!apiUrl) {
        throw new Error('API URL is not configured');
      }

      const response = await fetch(`${apiUrl}/api/meetings/join/${meetingIdNum}`, {
        headers: {
          Authorization: `Bearer ${token}`
        }
      });

      const data = await response.json();

      if (!response.ok) {
        // Handle specific error cases
        if (data.starts_in_minutes) {
          setError(`Meeting starts in ${data.starts_in_minutes} minutes`);
        } else {
          throw new Error(data.error || 'Failed to join meeting');
        }
        return;
      }

      // Check if meeting is about to end
      if (data.time_remaining_minutes < 5) {
        setError('Warning: Meeting will end in less than 5 minutes');
        // Continue anyway after warning
      }

      router.push(`/meeting/${meetingIdNum}`);
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to join meeting');
    } finally {
      setIsJoining(false);
    }
  };

  const dashboardContent = (
    <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
      <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
        {/* Create Meeting */}
        <div className="bg-white shadow rounded-lg p-6">
          <h2 className="text-lg font-semibold mb-4">Create New Meeting</h2>
          <form onSubmit={handleCreateMeeting}>
            <div className="mb-4">
              <label htmlFor="title" className="block text-sm font-medium text-gray-700">
                Meeting Title
              </label>
              <input
                type="text"
                id="title"
                value={title}
                onChange={(e: ChangeEvent<HTMLInputElement>) => setTitle(e.target.value)}
                className="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                required
              />
            </div>
            <div className="mb-4">
              <label htmlFor="description" className="block text-sm font-medium text-gray-700">
                Description
              </label>
              <textarea
                id="description"
                value={description}
                onChange={(e: ChangeEvent<HTMLTextAreaElement>) => setDescription(e.target.value)}
                className="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                rows={3}
              />
            </div>
            <div className="mb-4">
              <label htmlFor="startTime" className="block text-sm font-medium text-gray-700">
                Start Time
              </label>
              <input
                type="datetime-local"
                id="startTime"
                value={startTime}
                onChange={(e: ChangeEvent<HTMLInputElement>) => setStartTime(e.target.value)}
                className="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                required
              />
            </div>
            <div className="mb-4">
              <label htmlFor="endTime" className="block text-sm font-medium text-gray-700">
                End Time
              </label>
              <input
                type="datetime-local"
                id="endTime"
                value={endTime}
                onChange={(e: ChangeEvent<HTMLInputElement>) => setEndTime(e.target.value)}
                className="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                required
              />
            </div>
            <button
              type="submit"
              disabled={isCreating}
              className="w-full flex justify-center py-2 px-4 border border-transparent rounded-md shadow-sm text-sm font-medium text-white bg-blue-600 hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500 disabled:opacity-50"
            >
              {isCreating ? 'Creating...' : 'Create Meeting'}
            </button>
          </form>
        </div>

        {/* Join Meeting */}
        <div className="bg-white shadow rounded-lg p-6">
          <h2 className="text-lg font-semibold mb-4">Join Meeting</h2>
          <form onSubmit={handleJoinMeeting}>
            <div className="mb-4">
              <label htmlFor="meetingId" className="block text-sm font-medium text-gray-700">
                Meeting ID
              </label>
              <input
                type="number"
                id="meetingId"
                value={meetingId}
                onChange={(e: ChangeEvent<HTMLInputElement>) => setMeetingId(e.target.value)}
                className="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                required
              />
            </div>
            <button
              type="submit"
              disabled={isJoining}
              className="w-full flex justify-center py-2 px-4 border border-transparent rounded-md shadow-sm text-sm font-medium text-white bg-green-600 hover:bg-green-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-green-500 disabled:opacity-50"
            >
              {isJoining ? 'Joining...' : 'Join Meeting'}
            </button>
          </form>
        </div>
      </div>

      {error && (
        <div className="mt-6 bg-red-50 border border-red-400 text-red-700 px-4 py-3 rounded relative">
          {error}
        </div>
      )}

      {/* Recent Meetings */}
      <div className="mt-8">
        <h2 className="text-lg font-semibold mb-4">Recent Meetings</h2>
        <div className="bg-white shadow overflow-hidden sm:rounded-md">
          {isLoading ? (
            <div className="px-4 py-4 sm:px-6 text-center text-gray-500">
              <div className="animate-spin rounded-full h-8 w-8 border-t-2 border-b-2 border-blue-500 mx-auto"></div>
              <p className="mt-2">Loading meetings...</p>
            </div>
          ) : (
            <ul className="divide-y divide-gray-200">
              {meetings.map((meeting: Meeting) => (
                <li key={meeting.id}>
                  <div className="px-4 py-4 sm:px-6">
                    <div className="flex items-center justify-between">
                      <div className="flex-1 min-w-0">
                        <p className="text-sm font-medium text-blue-600 truncate">
                          {meeting.title}
                        </p>
                        <p className="mt-1 text-sm text-gray-500">
                          {new Date(meeting.start_time).toLocaleString()} - {new Date(meeting.end_time).toLocaleString()}
                        </p>
                        {meeting.description && (
                          <p className="mt-1 text-sm text-gray-500 truncate">
                            {meeting.description}
                          </p>
                        )}
                      </div>
                      <div className="ml-4 flex-shrink-0">
                        <button
                          onClick={() => router.push(`/meeting/${meeting.id}`)}
                          className="inline-flex items-center px-3 py-2 border border-transparent text-sm leading-4 font-medium rounded-md text-white bg-blue-600 hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500"
                        >
                          Join
                        </button>
                      </div>
                    </div>
                  </div>
                </li>
              ))}
              {meetings.length === 0 && (
                <li>
                  <div className="px-4 py-4 sm:px-6 text-center text-gray-500">
                    No recent meetings
                  </div>
                </li>
              )}
            </ul>
          )}
        </div>
      </div>
    </div>
  );

  return <Layout>{dashboardContent}</Layout>;
} 
```


### FILE: frontend\src\pages\forgot-password.tsx
```
import { useState } from 'react';
import { useAuth } from '@/contexts/AuthContext';
import Link from 'next/link';

export default function ForgotPassword() {
  const [email, setEmail] = useState('');
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState('');
  const [message, setMessage] = useState('');
  const { resetPassword } = useAuth();

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    setError('');
    setMessage('');
    setLoading(true);

    try {
      await resetPassword(email);
      setMessage('Check your email for password reset instructions');
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to reset password');
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="min-h-screen flex items-center justify-center bg-gray-50 py-12 px-4 sm:px-6 lg:px-8">
      <div className="max-w-md w-full space-y-8">
        <div>
          <h2 className="mt-6 text-center text-3xl font-extrabold text-gray-900">
            Reset your password
          </h2>
          <p className="mt-2 text-center text-sm text-gray-600">
            Enter your email address and we'll send you a link to reset your password.
          </p>
        </div>

        <form className="mt-8 space-y-6" onSubmit={handleSubmit}>
          <div>
            <label htmlFor="email" className="sr-only">Email address</label>
            <input
              id="email"
              name="email"
              type="email"
              required
              className="appearance-none rounded relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 sm:text-sm"
              placeholder="Email address"
              value={email}
              onChange={(e) => setEmail(e.target.value)}
            />
          </div>

          {error && (
            <div className="text-red-500 text-sm text-center">
              {error}
            </div>
          )}

          {message && (
            <div className="text-green-500 text-sm text-center">
              {message}
            </div>
          )}

          <div>
            <button
              type="submit"
              disabled={loading}
              className="group relative w-full flex justify-center py-2 px-4 border border-transparent text-sm font-medium rounded-md text-white bg-indigo-600 hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-indigo-500 disabled:opacity-50"
            >
              {loading ? 'Sending...' : 'Send reset link'}
            </button>
          </div>

          <div className="text-sm text-center">
            <Link href="/login" className="font-medium text-indigo-600 hover:text-indigo-500">
              Back to login
            </Link>
          </div>
        </form>
      </div>
    </div>
  );
} 
```


### FILE: frontend\src\pages\index.tsx
```
import { useEffect } from 'react';
import { useRouter } from 'next/router';

export default function Home() {
  const router = useRouter();

  useEffect(() => {
    router.replace('/login');
  }, []);

  return null;
} 
```


### FILE: frontend\src\pages\login.tsx
```
import { useState, FormEvent } from 'react';
import { useAuth } from '@/contexts/AuthContext';
import { useRouter } from 'next/router';
import Link from 'next/link';
import { GoogleLogin } from '@react-oauth/google';
import type { FormInputEvent } from '@/types/events';

export default function Login() {
  const [email, setEmail] = useState('');
  const [password, setPassword] = useState('');
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState('');
  const { login, googleLogin } = useAuth();
  const router = useRouter();

  const handleSubmit = async (e: FormEvent<HTMLFormElement>) => {
    e.preventDefault();
    setError('');
    setLoading(true);

    try {
      await login(email, password);
      router.push('/dashboard');
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Login failed');
    } finally {
      setLoading(false);
    }
  };

  const handleGoogleSuccess = async (credentialResponse: { credential: string }) => {
    try {
      await googleLogin(credentialResponse.credential);
      router.push('/dashboard');
    } catch (err) {
      setError('Google login failed');
    }
  };

  return (
    <div className="min-h-screen flex items-center justify-center bg-gray-50 py-12 px-4 sm:px-6 lg:px-8">
      <div className="max-w-md w-full space-y-8">
        <div>
          <h2 className="mt-6 text-center text-3xl font-extrabold text-gray-900">
            Sign in to your account
          </h2>
        </div>
        
        <form className="mt-8 space-y-6" onSubmit={handleSubmit}>
          <div className="rounded-md shadow-sm -space-y-px">
            <div>
              <label htmlFor="email" className="sr-only">Email address</label>
              <input
                id="email"
                name="email"
                type="email"
                required
                className="appearance-none rounded-none relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 rounded-t-md focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 focus:z-10 sm:text-sm"
                placeholder="Email address"
                value={email}
                onChange={(e) => setEmail(e.target.value)}
              />
            </div>
            <div>
              <label htmlFor="password" className="sr-only">Password</label>
              <input
                id="password"
                name="password"
                type="password"
                required
                className="appearance-none rounded-none relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 rounded-b-md focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 focus:z-10 sm:text-sm"
                placeholder="Password"
                value={password}
                onChange={(e) => setPassword(e.target.value)}
              />
            </div>
          </div>

          {error && (
            <div className="text-red-500 text-sm text-center">
              {error}
            </div>
          )}

          <div className="flex items-center justify-between">
            <div className="text-sm">
              <Link href="/forgot-password" className="font-medium text-indigo-600 hover:text-indigo-500">
                Forgot your password?
              </Link>
            </div>
            <div className="text-sm">
              <Link href="/register" className="font-medium text-indigo-600 hover:text-indigo-500">
                Create an account
              </Link>
            </div>
          </div>

          <div>
            <button
              type="submit"
              disabled={loading}
              className="group relative w-full flex justify-center py-2 px-4 border border-transparent text-sm font-medium rounded-md text-white bg-indigo-600 hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-indigo-500 disabled:opacity-50"
            >
              {loading ? 'Signing in...' : 'Sign in'}
            </button>
          </div>
        </form>

        <div className="mt-6">
          <div className="relative">
            <div className="absolute inset-0 flex items-center">
              <div className="w-full border-t border-gray-300" />
            </div>
            <div className="relative flex justify-center text-sm">
              <span className="px-2 bg-gray-50 text-gray-500">
                Or continue with
              </span>
            </div>
          </div>

          <div className="mt-6">
            <GoogleLogin
              onSuccess={handleGoogleSuccess}
              onError={() => setError('Google login failed')}
            />
          </div>
        </div>
      </div>
    </div>
  );
} 
```


### FILE: frontend\src\pages\register.tsx
```
import { useState } from 'react';
import { useAuth } from '@/contexts/AuthContext';
import { useRouter } from 'next/router';
import Link from 'next/link';

const PASSWORD_REQUIREMENTS = [
  { id: 1, text: 'At least 12 characters long' },
  { id: 2, text: 'Contains at least one uppercase letter' },
  { id: 3, text: 'Contains at least one lowercase letter' },
  { id: 4, text: 'Contains at least one number' },
  { id: 5, text: 'Contains at least one special character (@$!%*?&)' }
];

export default function Register() {
  const [email, setEmail] = useState('');
  const [password, setPassword] = useState('');
  const [confirmPassword, setConfirmPassword] = useState('');
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState('');
  const { register } = useAuth();
  const router = useRouter();

  const validatePassword = (password: string) => {
    const hasMinLength = password.length >= 12;
    const hasUpperCase = /[A-Z]/.test(password);
    const hasLowerCase = /[a-z]/.test(password);
    const hasNumber = /\d/.test(password);
    const hasSpecialChar = /[@$!%*?&]/.test(password);

    return hasMinLength && hasUpperCase && hasLowerCase && hasNumber && hasSpecialChar;
  };

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    setError('');

    if (password !== confirmPassword) {
      setError('Passwords do not match');
      return;
    }

    if (!validatePassword(password)) {
      setError('Password does not meet requirements');
      return;
    }

    setLoading(true);

    try {
      await register(email, password);
      router.push('/dashboard');
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Registration failed');
    } finally {
      setLoading(false);
    }
  };

  const checkPasswordRequirement = (requirement: string) => {
    switch (requirement) {
      case 'At least 12 characters long':
        return password.length >= 12;
      case 'Contains at least one uppercase letter':
        return /[A-Z]/.test(password);
      case 'Contains at least one lowercase letter':
        return /[a-z]/.test(password);
      case 'Contains at least one number':
        return /\d/.test(password);
      case 'Contains at least one special character (@$!%*?&)':
        return /[@$!%*?&]/.test(password);
      default:
        return false;
    }
  };

  return (
    <div className="min-h-screen flex items-center justify-center bg-gray-50 py-12 px-4 sm:px-6 lg:px-8">
      <div className="max-w-md w-full space-y-8">
        <div>
          <h2 className="mt-6 text-center text-3xl font-extrabold text-gray-900">
            Create your account
          </h2>
        </div>

        <form className="mt-8 space-y-6" onSubmit={handleSubmit}>
          <div className="rounded-md shadow-sm -space-y-px">
            <div>
              <label htmlFor="email" className="sr-only">Email address</label>
              <input
                id="email"
                name="email"
                type="email"
                required
                className="appearance-none rounded-none relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 rounded-t-md focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 focus:z-10 sm:text-sm"
                placeholder="Email address"
                value={email}
                onChange={(e) => setEmail(e.target.value)}
              />
            </div>
            <div>
              <label htmlFor="password" className="sr-only">Password</label>
              <input
                id="password"
                name="password"
                type="password"
                required
                className="appearance-none rounded-none relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 focus:z-10 sm:text-sm"
                placeholder="Password"
                value={password}
                onChange={(e) => setPassword(e.target.value)}
              />
            </div>
            <div>
              <label htmlFor="confirm-password" className="sr-only">Confirm Password</label>
              <input
                id="confirm-password"
                name="confirm-password"
                type="password"
                required
                className="appearance-none rounded-none relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 rounded-b-md focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 focus:z-10 sm:text-sm"
                placeholder="Confirm Password"
                value={confirmPassword}
                onChange={(e) => setConfirmPassword(e.target.value)}
              />
            </div>
          </div>

          <div className="rounded-md bg-gray-50 p-4">
            <h3 className="text-sm font-medium text-gray-900">Password Requirements</h3>
            <ul className="mt-2 text-sm text-gray-600 space-y-1">
              {PASSWORD_REQUIREMENTS.map((req) => (
                <li key={req.id} className="flex items-center">
                  <span className={`mr-2 ${checkPasswordRequirement(req.text) ? 'text-green-500' : 'text-gray-400'}`}>
                    {checkPasswordRequirement(req.text) ? 'âœ“' : 'â—‹'}
                  </span>
                  {req.text}
                </li>
              ))}
            </ul>
          </div>

          {error && (
            <div className="text-red-500 text-sm text-center">
              {error}
            </div>
          )}

          <div>
            <button
              type="submit"
              disabled={loading}
              className="group relative w-full flex justify-center py-2 px-4 border border-transparent text-sm font-medium rounded-md text-white bg-indigo-600 hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-indigo-500 disabled:opacity-50"
            >
              {loading ? 'Creating account...' : 'Create account'}
            </button>
          </div>

          <div className="text-sm text-center">
            Already have an account?{' '}
            <Link href="/login" className="font-medium text-indigo-600 hover:text-indigo-500">
              Sign in
            </Link>
          </div>
        </form>
      </div>
    </div>
  );
} 
```


### FILE: frontend\src\pages\resend-verification.tsx
```
import { useState, FormEvent } from 'react';
import Link from 'next/link';

export default function ResendVerification() {
  const [email, setEmail] = useState('');
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState('');
  const [success, setSuccess] = useState('');

  const handleSubmit = async (e: FormEvent<HTMLFormElement>) => {
    e.preventDefault();
    setError('');
    setSuccess('');
    setLoading(true);

    try {
      const response = await fetch(`${process.env.NEXT_PUBLIC_AUTH_API_URL}/auth/resend-verification`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ email }),
      });

      const data = await response.json();

      if (response.ok) {
        setSuccess(data.message || 'Verification email sent successfully');
        setEmail('');
      } else {
        setError(data.error || 'Failed to send verification email');
      }
    } catch (err) {
      setError('An error occurred while sending the verification email');
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="min-h-screen flex items-center justify-center bg-gray-50 py-12 px-4 sm:px-6 lg:px-8">
      <div className="max-w-md w-full space-y-8">
        <div>
          <h2 className="mt-6 text-center text-3xl font-extrabold text-gray-900">
            Resend Verification Email
          </h2>
          <p className="mt-2 text-center text-sm text-gray-600">
            Enter your email address and we'll send you a new verification link.
          </p>
        </div>

        <form className="mt-8 space-y-6" onSubmit={handleSubmit}>
          <div>
            <label htmlFor="email" className="sr-only">Email address</label>
            <input
              id="email"
              name="email"
              type="email"
              required
              className="appearance-none rounded relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 sm:text-sm"
              placeholder="Email address"
              value={email}
              onChange={(e) => setEmail(e.target.value)}
            />
          </div>

          {error && (
            <div className="rounded-md bg-red-50 p-4">
              <div className="flex">
                <div className="flex-shrink-0">
                  <svg className="h-5 w-5 text-red-400" viewBox="0 0 20 20" fill="currentColor">
                    <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM8.707 7.293a1 1 0 00-1.414 1.414L8.586 10l-1.293 1.293a1 1 0 101.414 1.414L10 11.414l1.293 1.293a1 1 0 001.414-1.414L11.414 10l1.293-1.293a1 1 0 00-1.414-1.414L10 8.586 8.707 7.293z" clipRule="evenodd" />
                  </svg>
                </div>
                <div className="ml-3">
                  <p className="text-sm font-medium text-red-800">{error}</p>
                </div>
              </div>
            </div>
          )}

          {success && (
            <div className="rounded-md bg-green-50 p-4">
              <div className="flex">
                <div className="flex-shrink-0">
                  <svg className="h-5 w-5 text-green-400" viewBox="0 0 20 20" fill="currentColor">
                    <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z" clipRule="evenodd" />
                  </svg>
                </div>
                <div className="ml-3">
                  <p className="text-sm font-medium text-green-800">{success}</p>
                </div>
              </div>
            </div>
          )}

          <div>
            <button
              type="submit"
              disabled={loading}
              className="group relative w-full flex justify-center py-2 px-4 border border-transparent text-sm font-medium rounded-md text-white bg-indigo-600 hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-indigo-500 disabled:opacity-50"
            >
              {loading ? 'Sending...' : 'Resend verification email'}
            </button>
          </div>

          <div className="text-sm text-center">
            <Link href="/login" className="font-medium text-indigo-600 hover:text-indigo-500">
              Return to login
            </Link>
          </div>
        </form>
      </div>
    </div>
  );
} 
```


### FILE: frontend\src\pages\api\health.ts
```
import type { NextApiRequest, NextApiResponse } from 'next'

export default function handler(req: NextApiRequest, res: NextApiResponse) {
  res.status(200).json({ status: 'healthy' });
} 
```


### FILE: frontend\src\pages\meeting\[id].tsx
```
import React, { useState, useEffect } from 'react';
import { useRouter } from 'next/router';
import { useAuth } from '@/contexts/AuthContext';
import Layout from '@/components/layout/Layout';
import VideoConference from '@/components/meeting/VideoConference';
import Whiteboard from '@/components/meeting/Whiteboard';
import Chat from '@/components/meeting/Chat';

interface Meeting {
  id: number;
  title: string;
  description: string;
  start_time: string;
  end_time: string;
  created_by: number;
  created_at: string;
  updated_at: string;
}

export default function MeetingRoom() {
  const router = useRouter();
  const { id } = router.query;
  const { token, user } = useAuth();
  const [meeting, setMeeting] = useState<Meeting | null>(null);
  const [activeTab, setActiveTab] = useState<'whiteboard' | 'chat'>('chat');
  const [error, setError] = useState('');

  useEffect(() => {
    if (id && token) {
      fetchMeetingDetails();
    }
  }, [id, token]);

  const fetchMeetingDetails = async () => {
    try {
      const response = await fetch(`${process.env.NEXT_PUBLIC_API_URL}/api/meetings/join/${id}`, {
        headers: {
          Authorization: `Bearer ${token}`
        }
      });

      if (!response.ok) {
        const errorData = await response.json();
        throw new Error(errorData.error || 'Meeting not found or inactive');
      }

      const data = await response.json();
      setMeeting(data);
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to join meeting');
      router.push('/dashboard');
    }
  };

  const handleEndMeeting = async () => {
    if (!meeting || meeting.created_by !== user?.id) return;

    try {
      const response = await fetch(`${process.env.NEXT_PUBLIC_API_URL}/api/meetings/end/${id}`, {
        method: 'POST',
        headers: {
          Authorization: `Bearer ${token}`
        }
      });

      if (!response.ok) {
        const errorData = await response.json();
        throw new Error(errorData.error || 'Failed to end meeting');
      }

      router.push('/dashboard');
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to end meeting');
    }
  };

  const MeetingInfo = ({ meeting }: { meeting: Meeting }) => (
    <div className="bg-white border-b px-4 py-2 flex items-center justify-between">
      <div>
        <h1 className="text-xl font-semibold">{meeting.title}</h1>
        <p className="text-sm text-gray-500">ID: {meeting.id}</p>
        <p className="text-sm text-gray-500">
          {new Date(meeting.start_time).toLocaleString()} - {new Date(meeting.end_time).toLocaleString()}
        </p>
      </div>
      <div className="flex items-center space-x-4">
        {meeting.created_by === user?.id && (
          <button
            onClick={handleEndMeeting}
            className="px-4 py-2 bg-red-500 text-white rounded hover:bg-red-600"
          >
            End Meeting
          </button>
        )}
        <button
          onClick={() => router.push('/dashboard')}
          className="px-4 py-2 bg-gray-100 text-gray-700 rounded hover:bg-gray-200"
        >
          Leave
        </button>
      </div>
    </div>
  );

  if (!meeting) {
    return (
      <Layout>
        <div className="flex items-center justify-center h-screen">
          <div className="animate-spin rounded-full h-32 w-32 border-t-2 border-b-2 border-blue-500" />
        </div>
      </Layout>
    );
  }

  return (
    <Layout>
      <div className="h-screen flex flex-col">
        {/* Header */}
        <MeetingInfo meeting={meeting} />

        {/* Main Content */}
        <div className="flex-grow grid grid-cols-12 gap-4 p-4">
          {/* Video Conference */}
          <div className="col-span-8 bg-gray-900 rounded-lg overflow-hidden">
            <VideoConference roomId={meeting.id.toString()} />
          </div>

          {/* Sidebar */}
          <div className="col-span-4 flex flex-col bg-white rounded-lg overflow-hidden">
            {/* Tabs */}
            <div className="flex border-b">
              <button
                onClick={() => setActiveTab('whiteboard')}
                className={`flex-1 px-4 py-2 text-sm font-medium ${
                  activeTab === 'whiteboard'
                    ? 'border-b-2 border-blue-500 text-blue-600'
                    : 'text-gray-500 hover:text-gray-700'
                }`}
              >
                Whiteboard
              </button>
              <button
                onClick={() => setActiveTab('chat')}
                className={`flex-1 px-4 py-2 text-sm font-medium ${
                  activeTab === 'chat'
                    ? 'border-b-2 border-blue-500 text-blue-600'
                    : 'text-gray-500 hover:text-gray-700'
                }`}
              >
                Chat
              </button>
            </div>

            {/* Tab Content */}
            <div className="flex-grow">
              {activeTab === 'whiteboard' ? <Whiteboard /> : <Chat roomId={meeting.id.toString()} />}
            </div>
          </div>
        </div>

        {error && (
          <div className="fixed bottom-4 right-4 bg-red-50 border border-red-400 text-red-700 px-4 py-3 rounded">
            {error}
          </div>
        )}
      </div>
    </Layout>
  );
} 
```


### FILE: frontend\src\pages\reset-password\[token].tsx
```
import { useState, useEffect } from 'react';
import { useAuth } from '@/contexts/AuthContext';
import { useRouter } from 'next/router';
import Link from 'next/link';

const PASSWORD_REQUIREMENTS = [
  { id: 1, text: 'At least 12 characters long' },
  { id: 2, text: 'Contains at least one uppercase letter' },
  { id: 3, text: 'Contains at least one lowercase letter' },
  { id: 4, text: 'Contains at least one number' },
  { id: 5, text: 'Contains at least one special character (@$!%*?&)' }
];

export default function ResetPassword() {
  const [email, setEmail] = useState('');
  const [password, setPassword] = useState('');
  const [confirmPassword, setConfirmPassword] = useState('');
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState('');
  const [message, setMessage] = useState('');
  const { updatePassword } = useAuth();
  const router = useRouter();
  const { token } = router.query;

  const validatePassword = (password: string) => {
    const hasMinLength = password.length >= 12;
    const hasUpperCase = /[A-Z]/.test(password);
    const hasLowerCase = /[a-z]/.test(password);
    const hasNumber = /\d/.test(password);
    const hasSpecialChar = /[@$!%*?&]/.test(password);

    return hasMinLength && hasUpperCase && hasLowerCase && hasNumber && hasSpecialChar;
  };

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    setError('');
    setMessage('');

    if (!token || typeof token !== 'string') {
      setError('Invalid reset token');
      return;
    }

    if (password !== confirmPassword) {
      setError('Passwords do not match');
      return;
    }

    if (!validatePassword(password)) {
      setError('Password does not meet requirements');
      return;
    }

    setLoading(true);

    try {
      await updatePassword(email, token, password);
      setMessage('Password updated successfully');
      setTimeout(() => {
        router.push('/login');
      }, 2000);
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to update password');
    } finally {
      setLoading(false);
    }
  };

  const checkPasswordRequirement = (requirement: string) => {
    switch (requirement) {
      case 'At least 12 characters long':
        return password.length >= 12;
      case 'Contains at least one uppercase letter':
        return /[A-Z]/.test(password);
      case 'Contains at least one lowercase letter':
        return /[a-z]/.test(password);
      case 'Contains at least one number':
        return /\d/.test(password);
      case 'Contains at least one special character (@$!%*?&)':
        return /[@$!%*?&]/.test(password);
      default:
        return false;
    }
  };

  return (
    <div className="min-h-screen flex items-center justify-center bg-gray-50 py-12 px-4 sm:px-6 lg:px-8">
      <div className="max-w-md w-full space-y-8">
        <div>
          <h2 className="mt-6 text-center text-3xl font-extrabold text-gray-900">
            Reset your password
          </h2>
        </div>

        <form className="mt-8 space-y-6" onSubmit={handleSubmit}>
          <div className="rounded-md shadow-sm -space-y-px">
            <div>
              <label htmlFor="email" className="sr-only">Email address</label>
              <input
                id="email"
                name="email"
                type="email"
                required
                className="appearance-none rounded-none relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 rounded-t-md focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 focus:z-10 sm:text-sm"
                placeholder="Email address"
                value={email}
                onChange={(e) => setEmail(e.target.value)}
              />
            </div>
            <div>
              <label htmlFor="password" className="sr-only">New Password</label>
              <input
                id="password"
                name="password"
                type="password"
                required
                className="appearance-none rounded-none relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 focus:z-10 sm:text-sm"
                placeholder="New Password"
                value={password}
                onChange={(e) => setPassword(e.target.value)}
              />
            </div>
            <div>
              <label htmlFor="confirm-password" className="sr-only">Confirm New Password</label>
              <input
                id="confirm-password"
                name="confirm-password"
                type="password"
                required
                className="appearance-none rounded-none relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 rounded-b-md focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 focus:z-10 sm:text-sm"
                placeholder="Confirm New Password"
                value={confirmPassword}
                onChange={(e) => setConfirmPassword(e.target.value)}
              />
            </div>
          </div>

          <div className="rounded-md bg-gray-50 p-4">
            <h3 className="text-sm font-medium text-gray-900">Password Requirements</h3>
            <ul className="mt-2 text-sm text-gray-600 space-y-1">
              {PASSWORD_REQUIREMENTS.map((req) => (
                <li key={req.id} className="flex items-center">
                  <span className={`mr-2 ${checkPasswordRequirement(req.text) ? 'text-green-500' : 'text-gray-400'}`}>
                    {checkPasswordRequirement(req.text) ? 'âœ“' : 'â—‹'}
                  </span>
                  {req.text}
                </li>
              ))}
            </ul>
          </div>

          {error && (
            <div className="text-red-500 text-sm text-center">
              {error}
            </div>
          )}

          {message && (
            <div className="text-green-500 text-sm text-center">
              {message}
            </div>
          )}

          <div>
            <button
              type="submit"
              disabled={loading}
              className="group relative w-full flex justify-center py-2 px-4 border border-transparent text-sm font-medium rounded-md text-white bg-indigo-600 hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-indigo-500 disabled:opacity-50"
            >
              {loading ? 'Updating password...' : 'Update password'}
            </button>
          </div>

          <div className="text-sm text-center">
            <Link href="/login" className="font-medium text-indigo-600 hover:text-indigo-500">
              Back to login
            </Link>
          </div>
        </form>
      </div>
    </div>
  );
} 
```


### FILE: frontend\src\pages\verify-email\[token].tsx
```
import { useEffect, useState } from 'react';
import { useRouter } from 'next/router';
import Link from 'next/link';

export default function VerifyEmail() {
  const [status, setStatus] = useState<'loading' | 'success' | 'error'>('loading');
  const [message, setMessage] = useState('');
  const router = useRouter();
  const { token } = router.query;

  useEffect(() => {
    if (!token) return;

    const verifyEmail = async () => {
      try {
        const response = await fetch(`${process.env.NEXT_PUBLIC_AUTH_API_URL}/auth/verify-email/${token}`, {
          method: 'GET',
          headers: {
            'Content-Type': 'application/json',
          },
        });

        const data = await response.json();

        if (response.ok) {
          setStatus('success');
          setMessage(data.message);
          // Redirect to login after 3 seconds
          setTimeout(() => {
            router.push('/login');
          }, 3000);
        } else {
          setStatus('error');
          setMessage(data.error || 'Verification failed');
        }
      } catch (err) {
        setStatus('error');
        setMessage('An error occurred during verification');
      }
    };

    verifyEmail();
  }, [token, router]);

  return (
    <div className="min-h-screen flex items-center justify-center bg-gray-50 py-12 px-4 sm:px-6 lg:px-8">
      <div className="max-w-md w-full space-y-8">
        <div>
          <h2 className="mt-6 text-center text-3xl font-extrabold text-gray-900">
            Email Verification
          </h2>
        </div>

        <div className="mt-8 space-y-6">
          {status === 'loading' && (
            <div className="text-center">
              <div className="animate-spin rounded-full h-12 w-12 border-b-2 border-indigo-600 mx-auto"></div>
              <p className="mt-4 text-gray-600">Verifying your email...</p>
            </div>
          )}

          {status === 'success' && (
            <div className="rounded-md bg-green-50 p-4">
              <div className="flex">
                <div className="flex-shrink-0">
                  <svg className="h-5 w-5 text-green-400" viewBox="0 0 20 20" fill="currentColor">
                    <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z" clipRule="evenodd" />
                  </svg>
                </div>
                <div className="ml-3">
                  <p className="text-sm font-medium text-green-800">{message}</p>
                  <p className="mt-2 text-sm text-green-700">
                    Redirecting to login page...
                  </p>
                </div>
              </div>
            </div>
          )}

          {status === 'error' && (
            <div className="rounded-md bg-red-50 p-4">
              <div className="flex">
                <div className="flex-shrink-0">
                  <svg className="h-5 w-5 text-red-400" viewBox="0 0 20 20" fill="currentColor">
                    <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM8.707 7.293a1 1 0 00-1.414 1.414L8.586 10l-1.293 1.293a1 1 0 101.414 1.414L10 11.414l1.293 1.293a1 1 0 001.414-1.414L11.414 10l1.293-1.293a1 1 0 00-1.414-1.414L10 8.586 8.707 7.293z" clipRule="evenodd" />
                  </svg>
                </div>
                <div className="ml-3">
                  <p className="text-sm font-medium text-red-800">{message}</p>
                  <div className="mt-2">
                    <Link href="/resend-verification" className="text-sm font-medium text-red-600 hover:text-red-500">
                      Resend verification email
                    </Link>
                  </div>
                </div>
              </div>
            </div>
          )}

          <div className="text-sm text-center">
            <Link href="/login" className="font-medium text-indigo-600 hover:text-indigo-500">
              Return to login
            </Link>
          </div>
        </div>
      </div>
    </div>
  );
} 
```


### FILE: frontend\src\services\api\client.ts
```
/**
 * API client with interceptors for debugging and error tracking.
 * Provides a standardized way to make API requests with automatic error handling.
 */

import { env, isDevelopment } from '@/config/environment';
import logger from '@/utils/logger';

// Request options type
export interface ApiRequestOptions extends RequestInit {
  params?: Record<string, string | number | boolean | undefined>;
  timeout?: number;
}

// Response type
export interface ApiResponse<T = any> {
  data: T;
  status: number;
  statusText: string;
  headers: Headers;
  error?: Error;
}

// Request tracking
interface PendingRequest {
  timestamp: number;
  url: string;
  method: string;
  abortController: AbortController;
}

// Global request tracking for debugging
const pendingRequests: PendingRequest[] = [];

/**
 * Creates a query string from params object
 */
function createQueryString(params?: Record<string, string | number | boolean | undefined>): string {
  if (!params) return '';
  
  const queryParams = new URLSearchParams();
  
  Object.entries(params).forEach(([key, value]) => {
    if (value !== undefined) {
      queryParams.append(key, String(value));
    }
  });
  
  const queryString = queryParams.toString();
  return queryString ? `?${queryString}` : '';
}

/**
 * Adds request ID header to requests
 */
function addRequestId(headers: Headers): Headers {
  // Generate a unique request ID if not already present
  if (!headers.has('X-Request-ID')) {
    headers.set('X-Request-ID', `frontend-${Date.now()}-${Math.random().toString(36).substring(2, 10)}`);
  }
  
  return headers;
}

/**
 * Formats the API URL based on the environment
 */
function formatUrl(path: string): string {
  // If the path is already a full URL, return it as is
  if (path.startsWith('http://') || path.startsWith('https://')) {
    return path;
  }
  
  // Remove leading slash if present
  const cleanPath = path.startsWith('/') ? path.substring(1) : path;
  
  // Combine API URL with path
  return `${env.NEXT_PUBLIC_API_URL}/${cleanPath}`;
}

/**
 * Fetch API with timeout and automatic error handling
 */
async function fetchWithTimeout(
  url: string, 
  options: ApiRequestOptions = {}
): Promise<Response> {
  const { timeout = env.NEXT_PUBLIC_API_TIMEOUT_MS, ...fetchOptions } = options;
  
  // Create abort controller for timeout
  const controller = new AbortController();
  const signal = controller.signal;
  
  // Set up timeout
  const timeoutId = setTimeout(() => {
    controller.abort();
  }, timeout);
  
  try {
    // Track request for debugging
    const pendingRequest: PendingRequest = {
      timestamp: Date.now(),
      url,
      method: options.method || 'GET',
      abortController: controller
    };
    
    pendingRequests.push(pendingRequest);
    
    // Make the request
    const response = await fetch(url, {
      ...fetchOptions,
      signal,
    });
    
    return response;
  } finally {
    // Clean up timeout and pending request
    clearTimeout(timeoutId);
    
    // Remove from pending requests
    const index = pendingRequests.findIndex(req => 
      req.url === url && req.abortController === controller
    );
    
    if (index !== -1) {
      pendingRequests.splice(index, 1);
    }
  }
}

/**
 * Make an API request with standardized error handling and logging
 */
export async function apiRequest<T = any>(
  path: string,
  options: ApiRequestOptions = {}
): Promise<ApiResponse<T>> {
  const startTime = performance.now();
  
  // Create a headers object to extract request ID if present
  const headersObj = new Headers(options.headers || {});
  const requestId = headersObj.get('X-Request-ID') || `req-${Date.now()}`;
  
  // Prepare request
  const { params, ...fetchOptions } = options;
  
  // Create URL with query parameters
  const queryString = createQueryString(params);
  const url = `${formatUrl(path)}${queryString}`;
  
  // Prepare headers with request ID
  const headers = new Headers(options.headers || {});
  addRequestId(headers);
  
  // Log request in development
  if (isDevelopment) {
    logger.debug(`API Request [${requestId}]: ${options.method || 'GET'} ${url}`);
    if (options.body) {
      try {
        let bodyContent = options.body;
        if (typeof bodyContent === 'string') {
          bodyContent = JSON.parse(bodyContent);
        }
        logger.debug(`Request body [${requestId}]:`, bodyContent);
      } catch (e) {
        // Ignore parsing errors for non-JSON bodies
      }
    }
  }
  
  try {
    // Make the request
    const response = await fetchWithTimeout(url, {
      ...fetchOptions,
      headers,
    });
    
    // Parse response data (handle different content types)
    let data: T;
    const contentType = response.headers.get('content-type');
    
    if (contentType?.includes('application/json')) {
      data = await response.json();
    } else if (contentType?.includes('text/')) {
      data = await response.text() as unknown as T;
    } else {
      // Handle binary data or other formats
      data = await response.blob() as unknown as T;
    }
    
    // Calculate request time
    const endTime = performance.now();
    const requestTime = endTime - startTime;
    
    // Log response in development
    if (isDevelopment) {
      logger.debug(
        `API Response [${requestId}]: ${response.status} ${response.statusText} (${requestTime.toFixed(2)}ms)`
      );
      logger.debug(`Response data [${requestId}]:`, data);
    }
    
    // Check if response is an error
    if (!response.ok) {
      // Format error for consistent handling
      const error = new Error(
        `API Error ${response.status}: ${response.statusText}`
      );
      
      // Add response data to error object for more details
      Object.assign(error, { response, data });
      
      // Log error
      logger.error(`API Error [${requestId}]: ${response.status} ${url}`, error);
      
      return {
        data,
        status: response.status,
        statusText: response.statusText,
        headers: response.headers,
        error,
      };
    }
    
    // Return successful response
    return {
      data,
      status: response.status,
      statusText: response.statusText,
      headers: response.headers,
    };
  } catch (error) {
    // Handle fetch errors (network, timeout, etc.)
    const apiError = error instanceof Error ? error : new Error(String(error));
    
    // Log error
    logger.error(`API Request Failed [${requestId}]: ${url}`, apiError);
    
    // Return error response
    return {
      data: null as unknown as T,
      status: apiError.name === 'AbortError' ? 408 : 0,
      statusText: apiError.name === 'AbortError' ? 'Request Timeout' : 'Network Error',
      headers: new Headers(),
      error: apiError,
    };
  }
}

/**
 * Helper for GET requests
 */
export function get<T = any>(
  path: string, 
  options: Omit<ApiRequestOptions, 'method' | 'body'> = {}
): Promise<ApiResponse<T>> {
  return apiRequest<T>(path, { ...options, method: 'GET' });
}

/**
 * Helper for POST requests
 */
export function post<T = any>(
  path: string, 
  data?: any, 
  options: Omit<ApiRequestOptions, 'method' | 'body'> = {}
): Promise<ApiResponse<T>> {
  const headers = new Headers(options.headers || {});
  if (data && !(data instanceof FormData)) {
    headers.set('Content-Type', 'application/json');
  }
  
  return apiRequest<T>(path, {
    ...options,
    method: 'POST',
    headers,
    body: data instanceof FormData ? data : data ? JSON.stringify(data) : undefined,
  });
}

/**
 * Helper for PUT requests
 */
export function put<T = any>(
  path: string, 
  data?: any, 
  options: Omit<ApiRequestOptions, 'method' | 'body'> = {}
): Promise<ApiResponse<T>> {
  const headers = new Headers(options.headers || {});
  if (data && !(data instanceof FormData)) {
    headers.set('Content-Type', 'application/json');
  }
  
  return apiRequest<T>(path, {
    ...options,
    method: 'PUT',
    headers,
    body: data instanceof FormData ? data : data ? JSON.stringify(data) : undefined,
  });
}

/**
 * Helper for DELETE requests
 */
export function del<T = any>(
  path: string, 
  options: Omit<ApiRequestOptions, 'method'> = {}
): Promise<ApiResponse<T>> {
  return apiRequest<T>(path, { ...options, method: 'DELETE' });
}

/**
 * Helper for PATCH requests
 */
export function patch<T = any>(
  path: string, 
  data?: any, 
  options: Omit<ApiRequestOptions, 'method' | 'body'> = {}
): Promise<ApiResponse<T>> {
  const headers = new Headers(options.headers || {});
  if (data && !(data instanceof FormData)) {
    headers.set('Content-Type', 'application/json');
  }
  
  return apiRequest<T>(path, {
    ...options,
    method: 'PATCH',
    headers,
    body: data instanceof FormData ? data : data ? JSON.stringify(data) : undefined,
  });
}

/**
 * Debug utility to get all pending requests
 */
export function getPendingRequests(): PendingRequest[] {
  return [...pendingRequests];
}

/**
 * Debug utility to abort all pending requests
 */
export function abortAllRequests(): void {
  pendingRequests.forEach(request => {
    request.abortController.abort();
  });
}

/**
 * Export API client with all methods
 */
export const apiClient = {
  request: apiRequest,
  get,
  post,
  put,
  delete: del,
  patch,
  getPendingRequests,
  abortAllRequests,
};

export default apiClient; 
```


### FILE: frontend\src\styles\globals.css
```
@tailwind base;
@tailwind components;
@tailwind utilities; 
```


### FILE: frontend\src\types\custom.d.ts
```
declare namespace NodeJS {
  interface ProcessEnv {
    NEXT_PUBLIC_AUTH_API_URL: string;
    NEXT_PUBLIC_GOOGLE_CLIENT_ID: string;
  }
}

declare module '@react-oauth/google' {
  export interface GoogleLoginResponse {
    credential: string;
  }

  export interface GoogleLoginProps {
    onSuccess: (response: GoogleLoginResponse) => void;
    onError: () => void;
  }

  export const GoogleLogin: React.FC<GoogleLoginProps>;
  export const GoogleOAuthProvider: React.FC<{
    clientId: string;
    children: React.ReactNode;
  }>;
} 
```


### FILE: frontend\src\types\events.ts
```
import { ChangeEvent, FormEvent } from 'react';

export type FormInputEvent = ChangeEvent<HTMLInputElement>;
export type FormSubmitEvent = FormEvent<HTMLFormElement>; 
```


### FILE: frontend\src\types\globals.d.ts
```
/**
 * Global declarations for the application.
 * This file provides type definitions for globals that may not be properly recognized.
 */

// Declare process.env for TypeScript
declare namespace NodeJS {
  interface ProcessEnv {
    NODE_ENV: 'development' | 'production' | 'test';
    NEXT_PUBLIC_API_URL: string;
    NEXT_PUBLIC_AUTH_URL: string;
    NEXT_PUBLIC_WS_URL: string;
    NEXT_PUBLIC_APP_NAME: string;
    NEXT_PUBLIC_APP_VERSION: string;
    NEXT_PUBLIC_ENABLE_ANALYTICS?: string;
    NEXT_PUBLIC_ENABLE_DEBUG_TOOLS?: string;
    NEXT_PUBLIC_API_TIMEOUT_MS?: string;
    NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS?: string;
    NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB?: string;
  }
}

// Make sure TypeScript knows process exists globally
declare const process: NodeJS.Process; 
```


### FILE: frontend\src\types\jsx.d.ts
```
import React from 'react';

declare global {
  namespace JSX {
    interface IntrinsicElements {
      [elemName: string]: any;
    }
  }
} 
```


### FILE: frontend\src\types\user.ts
```
export interface User {
  id: number;
  email: string;
  name: string;
  created_at: string;
  updated_at: string;
} 
```


### FILE: frontend\src\utils\logger.ts
```
/**
 * Logger utility for consistent logging across the application.
 * Provides different log levels and structured log format.
 */

import { env, isDevelopment } from '@/config/environment';

// Log levels
export enum LogLevel {
  TRACE = 0,
  DEBUG = 1,
  INFO = 2,
  WARN = 3,
  ERROR = 4,
  NONE = 5,
}

// Logger configuration
interface LoggerConfig {
  level: LogLevel;
  enableConsole: boolean;
  prefix?: string;
  includeTimestamp: boolean;
}

// Default configuration
const defaultConfig: LoggerConfig = {
  level: isDevelopment ? LogLevel.DEBUG : LogLevel.INFO,
  enableConsole: true,
  includeTimestamp: true,
};

// Current logger configuration
let currentConfig: LoggerConfig = { ...defaultConfig };

/**
 * Set logger configuration
 */
export function configureLogger(config: Partial<LoggerConfig>): void {
  currentConfig = { ...currentConfig, ...config };
}

/**
 * Format log message with timestamp and prefix
 */
function formatLogMessage(message: string, level: string): string {
  const parts: string[] = [];
  
  // Add timestamp
  if (currentConfig.includeTimestamp) {
    parts.push(`[${new Date().toISOString()}]`);
  }
  
  // Add log level
  parts.push(`[${level}]`);
  
  // Add prefix if available
  if (currentConfig.prefix) {
    parts.push(`[${currentConfig.prefix}]`);
  }
  
  // Add message
  parts.push(message);
  
  return parts.join(' ');
}

/**
 * Create console method with structured format
 */
function createLogMethod(
  level: LogLevel,
  methodName: 'log' | 'info' | 'debug' | 'warn' | 'error',
  levelName: string
) {
  return function(...args: any[]): void {
    // Skip if log level is too low
    if (level < currentConfig.level) {
      return;
    }
    
    // Skip if console logging is disabled
    if (!currentConfig.enableConsole) {
      return;
    }
    
    // Get message
    const message = args.map(arg => {
      if (typeof arg === 'object') {
        try {
          return JSON.stringify(arg);
        } catch (e) {
          return String(arg);
        }
      }
      return String(arg);
    }).join(' ');
    
    // Format message
    const formattedMessage = formatLogMessage(message, levelName);
    
    // Log to console
    console[methodName](formattedMessage);
    
    // Send to remote logging service if in production
    if (!isDevelopment && level >= LogLevel.ERROR) {
      // Here you would integrate with a service like Sentry
      // if (typeof window !== 'undefined' && window.Sentry) {
      //   window.Sentry.captureMessage(message, levelName.toLowerCase());
      // }
    }
  };
}

/**
 * Create debug context with custom prefix
 */
export function createLogger(prefix: string): Logger {
  return {
    trace: (...args: any[]) => {
      const prevPrefix = currentConfig.prefix;
      currentConfig.prefix = prefix;
      trace(...args);
      currentConfig.prefix = prevPrefix;
    },
    debug: (...args: any[]) => {
      const prevPrefix = currentConfig.prefix;
      currentConfig.prefix = prefix;
      debug(...args);
      currentConfig.prefix = prevPrefix;
    },
    info: (...args: any[]) => {
      const prevPrefix = currentConfig.prefix;
      currentConfig.prefix = prefix;
      info(...args);
      currentConfig.prefix = prevPrefix;
    },
    warn: (...args: any[]) => {
      const prevPrefix = currentConfig.prefix;
      currentConfig.prefix = prefix;
      warn(...args);
      currentConfig.prefix = prevPrefix;
    },
    error: (...args: any[]) => {
      const prevPrefix = currentConfig.prefix;
      currentConfig.prefix = prefix;
      error(...args);
      currentConfig.prefix = prevPrefix;
    },
  };
}

// Logger interface
export interface Logger {
  trace: (...args: any[]) => void;
  debug: (...args: any[]) => void;
  info: (...args: any[]) => void;
  warn: (...args: any[]) => void;
  error: (...args: any[]) => void;
}

// Create log methods
export const trace = createLogMethod(LogLevel.TRACE, 'debug', 'TRACE');
export const debug = createLogMethod(LogLevel.DEBUG, 'debug', 'DEBUG');
export const info = createLogMethod(LogLevel.INFO, 'info', 'INFO');
export const warn = createLogMethod(LogLevel.WARN, 'warn', 'WARN');
export const error = createLogMethod(LogLevel.ERROR, 'error', 'ERROR');

// Default logger
const logger: Logger = {
  trace,
  debug,
  info,
  warn,
  error,
};

// Initialize logger
if (typeof window !== 'undefined') {
  // Set log level from URL params for debugging
  const params = new URLSearchParams(window.location.search);
  const logLevel = params.get('log_level');
  if (logLevel) {
    const level = parseInt(logLevel, 10);
    if (!isNaN(level) && level >= 0 && level <= 5) {
      configureLogger({ level: level as LogLevel });
      debug(`Log level set to ${LogLevel[level]}`);
    }
  }
  
  // Log app initialization
  info(
    `App initialized: ${env.NEXT_PUBLIC_APP_NAME} ${env.NEXT_PUBLIC_APP_VERSION} - ${window.location.href}`
  );
}

export default logger; 
```


### FILE: k8s\flask-backend-deployment.yaml
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flask-backend
  labels:
    app: flask-backend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: flask-backend
  template:
    metadata:
      labels:
        app: flask-backend
    spec:
      containers:
      - name: flask-backend
        image: meeting-app-flask-backend:latest
        imagePullPolicy: Never
        ports:
        - containerPort: 5000
        env:
        - name: FLASK_ENV
          value: "production"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: database-url
        - name: SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: secret-key
        resources:
          limits:
            cpu: "500m"
            memory: "512Mi"
          requests:
            cpu: "200m"
            memory: "256Mi"
        readinessProbe:
          httpGet:
            path: /health
            port: 5000
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /health
            port: 5000
          initialDelaySeconds: 15
          periodSeconds: 10
---
apiVersion: v1
kind: Service
metadata:
  name: flask-backend
spec:
  type: ClusterIP
  ports:
  - port: 5000
    targetPort: 5000
    protocol: TCP
  selector:
    app: flask-backend 
```


### FILE: k8s\hpa.yaml
```
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: frontend-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: frontend
  minReplicas: 2
  maxReplicas: 5
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: flask-backend-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: flask-backend
  minReplicas: 3
  maxReplicas: 6
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: node-backend-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: node-backend
  minReplicas: 3
  maxReplicas: 6
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80 
```


### FILE: k8s\ingress.yaml
```
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: meeting-app-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
    nginx.ingress.kubernetes.io/websocket-services: "node-backend"
    nginx.ingress.kubernetes.io/enable-cors: "true"
    nginx.ingress.kubernetes.io/cors-allow-methods: "GET, PUT, POST, DELETE, PATCH, OPTIONS"
    nginx.ingress.kubernetes.io/cors-allow-credentials: "true"
    nginx.ingress.kubernetes.io/configuration-snippet: |
      more_set_headers "Access-Control-Allow-Origin: $http_origin";
spec:
  rules:
  - http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: frontend
            port:
              number: 3000
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: flask-backend
            port:
              number: 5000
      - path: /ws
        pathType: Prefix
        backend:
          service:
            name: node-backend
            port:
              number: 3001 
```


### FILE: k8s\node-backend-deployment.yaml
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: node-backend
  labels:
    app: node-backend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: node-backend
  template:
    metadata:
      labels:
        app: node-backend
    spec:
      containers:
      - name: node-backend
        image: meeting-app-node-backend:latest
        imagePullPolicy: Never
        ports:
        - containerPort: 3001
        env:
        - name: NODE_ENV
          value: "production"
        - name: WS_PORT
          value: "3001"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: database-url
        - name: SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: secret-key
        resources:
          limits:
            cpu: "500m"
            memory: "512Mi"
          requests:
            cpu: "200m"
            memory: "256Mi"
        readinessProbe:
          httpGet:
            path: /health
            port: 3001
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /health
            port: 3001
          initialDelaySeconds: 15
          periodSeconds: 10
---
apiVersion: v1
kind: Service
metadata:
  name: node-backend
spec:
  type: ClusterIP
  ports:
  - port: 3001
    targetPort: 3001
    protocol: TCP
  selector:
    app: node-backend 
```


### FILE: k8s\postgres-deployment.yaml
```
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
  labels:
    app: postgres
spec:
  serviceName: postgres
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:13-alpine
        ports:
        - containerPort: 5432
        env:
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: username
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: password
        - name: POSTGRES_DB
          value: "meetingapp"
        resources:
          limits:
            cpu: "1000m"
            memory: "1Gi"
          requests:
            cpu: "500m"
            memory: "512Mi"
        volumeMounts:
        - name: postgres-data
          mountPath: /var/lib/postgresql/data
        readinessProbe:
          exec:
            command: ["pg_isready", "-U", "postgres"]
          initialDelaySeconds: 5
          periodSeconds: 10
        livenessProbe:
          exec:
            command: ["pg_isready", "-U", "postgres"]
          initialDelaySeconds: 30
          periodSeconds: 20
  volumeClaimTemplates:
  - metadata:
      name: postgres-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
---
apiVersion: v1
kind: Service
metadata:
  name: postgres
spec:
  type: ClusterIP
  ports:
  - port: 5432
    targetPort: 5432
    protocol: TCP
  selector:
    app: postgres 
```


### FILE: k8s\secrets.yaml
```
apiVersion: v1
kind: Secret
metadata:
  name: db-credentials
type: Opaque
data:
  username: cG9zdGdyZXM=  # postgres
  password: cG9zdGdyZXM=  # postgres
  database-url: cG9zdGdyZXNxbDovL3Bvc3RncmVzOnBvc3RncmVzQHBvc3RncmVzOjU0MzIvbWVldGluZ2FwcA==  # postgresql://postgres:postgres@postgres:5432/meetingapp
---
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
type: Opaque
data:
  secret-key: eW91ci1zZWNyZXQta2V5LWhlcmU=  # your-secret-key-here 
```


### FILE: k8s\config\development\configmap.yaml
```
apiVersion: v1
kind: ConfigMap
metadata:
  name: meeting-app-config
  namespace: meeting-app
data:
  # Frontend environment variables
  NEXT_PUBLIC_API_URL: "http://localhost:30963"
  NEXT_PUBLIC_WS_URL: "ws://localhost:30283"
  NEXT_PUBLIC_BASE_URL: "http://localhost:30000"
  
  # Backend environment variables
  FLASK_ENV: "development"
  FLASK_APP: "app.py"
  API_HOST: "0.0.0.0"
  API_PORT: "5000"
  WS_HOST: "0.0.0.0"
  WS_PORT: "3001"
  
  # CORS Configuration
  CORS_ORIGINS: "http://localhost:30000,http://meeting-app.local,http://localhost:3000"
  
  # JWT Configuration
  JWT_EXPIRY_DAYS: "1"
  
  # Database configurations
  POSTGRES_DB: "meetingapp"
  POSTGRES_USER: "dev_user"
  POSTGRES_HOST: "postgres-db"
  POSTGRES_PORT: "5432"
  DATABASE_URL: "postgresql://dev_user:dev-password-123@postgres-db:5432/meetingapp"
  
  # Redis configuration
  REDIS_URL: "redis://:dev-redis-123@redis-cache:6379/0"
  REDIS_HOST: "redis-cache"
  REDIS_PORT: "6379"
  
  # Logging
  LOG_LEVEL: "debug" 
```


### FILE: k8s\config\development\deployment.yaml
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: meeting-backend
  namespace: meeting-app
  labels:
    app: meeting-backend
    component: api
spec:
  replicas: 1
  selector:
    matchLabels:
      app: meeting-backend
  template:
    metadata:
      labels:
        app: meeting-backend
    spec:
      initContainers:
      - name: init-db-check
        image: postgres:15-alpine
        command: ['sh', '-c', 'until pg_isready -h postgres-db -p 5432 -U $POSTGRES_USER; do echo waiting for database; sleep 2; done;']
        env:
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: meeting-app-secrets
              key: POSTGRES_USER
      - name: init-redis-check
        image: redis:7-alpine
        command: ['sh', '-c', 'until redis-cli -h redis-cache -a "$REDIS_PASSWORD" ping; do echo waiting for redis; sleep 2; done;']
        env:
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: meeting-app-secrets
              key: REDIS_PASSWORD
      - name: init-db-migrate
        image: meeting-app-backend:dev
        workingDir: /app
        command: ['python', '-c', 'import os; os.environ["FLASK_APP"] = "app.py"; os.environ["FLASK_NO_MIGRATE"] = "0"; from app import app; from flask_migrate import upgrade; with app.app_context(): upgrade()']
        envFrom:
        - configMapRef:
            name: meeting-app-config
        - secretRef:
            name: meeting-app-secrets
      containers:
      - name: api-server
        image: meeting-app-backend:dev
        imagePullPolicy: Never
        ports:
        - containerPort: 5000
          name: http-api
        envFrom:
        - configMapRef:
            name: meeting-app-config
        - secretRef:
            name: meeting-app-secrets
        resources:
          limits:
            memory: "256Mi"
            cpu: "200m"
          requests:
            memory: "128Mi"
            cpu: "100m"
        readinessProbe:
          httpGet:
            path: /health
            port: http-api
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /health
            port: http-api
          initialDelaySeconds: 15
          periodSeconds: 20
        volumeMounts:
        - name: tmp-data
          mountPath: /tmp
      - name: websocket-server
        image: meeting-app-websocket:dev
        imagePullPolicy: Never
        ports:
        - containerPort: 3001
          name: ws-api
        envFrom:
        - configMapRef:
            name: meeting-app-config
        - secretRef:
            name: meeting-app-secrets
        resources:
          limits:
            memory: "256Mi"
            cpu: "200m"
          requests:
            memory: "128Mi"
            cpu: "100m"
        readinessProbe:
          httpGet:
            path: /health
            port: ws-api
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /health
            port: ws-api
          initialDelaySeconds: 15
          periodSeconds: 20
      volumes:
      - name: tmp-data
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: meeting-backend-internal
  namespace: meeting-app
  labels:
    app: meeting-backend
    type: internal
spec:
  selector:
    app: meeting-backend
  ports:
  - name: http-api
    port: 5000
    targetPort: http-api
  - name: ws-api
    port: 3001
    targetPort: ws-api
---
apiVersion: v1
kind: Service
metadata:
  name: meeting-backend-external
  namespace: meeting-app
  labels:
    app: meeting-backend
    type: external
spec:
  type: NodePort
  selector:
    app: meeting-backend
  ports:
  - name: http-api
    port: 5000
    targetPort: http-api
    nodePort: 30963
  - name: ws-api
    port: 3001
    targetPort: ws-api
    nodePort: 30283 
```


### FILE: k8s\config\development\frontend-deployment.yaml
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: meeting-frontend
  namespace: meeting-app
  labels:
    app: meeting-frontend
    component: web
spec:
  replicas: 1
  selector:
    matchLabels:
      app: meeting-frontend
  template:
    metadata:
      labels:
        app: meeting-frontend
    spec:
      initContainers:
      - name: init-backend-check
        image: curlimages/curl:8.4.0
        command: ['sh', '-c', 'until curl -f ${NEXT_PUBLIC_API_URL}/health; do echo waiting for backend api; sleep 2; done;']
        env:
        - name: NEXT_PUBLIC_API_URL
          valueFrom:
            configMapKeyRef:
              name: meeting-app-config
              key: NEXT_PUBLIC_API_URL
      containers:
      - name: web-server
        image: meeting-app-frontend:dev
        imagePullPolicy: Never
        ports:
        - containerPort: 3000
          name: http-web
        env:
        - name: NODE_ENV
          value: "development"
        - name: NEXT_PUBLIC_API_URL
          valueFrom:
            configMapKeyRef:
              name: meeting-app-config
              key: NEXT_PUBLIC_API_URL
        - name: NEXT_PUBLIC_WS_URL
          valueFrom:
            configMapKeyRef:
              name: meeting-app-config
              key: NEXT_PUBLIC_WS_URL
        - name: NEXT_PUBLIC_BASE_URL
          valueFrom:
            configMapKeyRef:
              name: meeting-app-config
              key: NEXT_PUBLIC_BASE_URL
        resources:
          limits:
            memory: "256Mi"
            cpu: "200m"
          requests:
            memory: "128Mi"
            cpu: "100m"
        readinessProbe:
          httpGet:
            path: /api/health
            port: http-web
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 2
        livenessProbe:
          httpGet:
            path: /api/health
            port: http-web
          initialDelaySeconds: 15
          periodSeconds: 20
          timeoutSeconds: 2
        volumeMounts:
        - name: tmp-data
          mountPath: /tmp
        - name: next-cache
          mountPath: /app/.next/cache
      volumes:
      - name: tmp-data
        emptyDir: {}
      - name: next-cache
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: meeting-frontend-internal
  namespace: meeting-app
  labels:
    app: meeting-frontend
    type: internal
spec:
  selector:
    app: meeting-frontend
  ports:
  - name: http-web
    port: 3000
    targetPort: http-web
---
apiVersion: v1
kind: Service
metadata:
  name: meeting-frontend-external
  namespace: meeting-app
  labels:
    app: meeting-frontend
    type: external
spec:
  type: NodePort
  selector:
    app: meeting-frontend
  ports:
  - name: http-web
    port: 3000
    targetPort: http-web
    nodePort: 30000 
```


### FILE: k8s\config\development\ingress.yaml
```
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: meeting-app-ingress
  namespace: meeting-app
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
    nginx.ingress.kubernetes.io/use-regex: "true"
    nginx.ingress.kubernetes.io/enable-cors: "true"
    nginx.ingress.kubernetes.io/cors-allow-methods: "GET, PUT, POST, DELETE, PATCH, OPTIONS"
    nginx.ingress.kubernetes.io/cors-allow-credentials: "true"
    nginx.ingress.kubernetes.io/configuration-snippet: |
      more_set_headers "Access-Control-Allow-Origin: $http_origin";
spec:
  rules:
  - host: meeting-app.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: meeting-frontend-internal
            port:
              number: 3000
  - host: api.meeting-app.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: meeting-backend-internal
            port:
              number: 5000
  - host: ws.meeting-app.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: meeting-backend-internal
            port:
              number: 3001 
```


### FILE: k8s\config\development\network-policies.yaml
```
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: frontend-policy
  namespace: meeting-app
spec:
  podSelector:
    matchLabels:
      app: meeting-frontend
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: ingress-nginx
    ports:
    - protocol: TCP
      port: 3000
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: meeting-backend
    ports:
    - protocol: TCP
      port: 5000
    - protocol: TCP
      port: 3001
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: backend-policy
  namespace: meeting-app
spec:
  podSelector:
    matchLabels:
      app: meeting-backend
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: meeting-frontend
    ports:
    - protocol: TCP
      port: 5000
    - protocol: TCP
      port: 3001
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: postgres-db
    ports:
    - protocol: TCP
      port: 5432
  - to:
    - podSelector:
        matchLabels:
          app: redis-cache
    ports:
    - protocol: TCP
      port: 6379
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: database-policy
  namespace: meeting-app
spec:
  podSelector:
    matchLabels:
      app: postgres-db
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: meeting-backend
    ports:
    - protocol: TCP
      port: 5432
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: cache-policy
  namespace: meeting-app
spec:
  podSelector:
    matchLabels:
      app: redis-cache
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: meeting-backend
    ports:
    - protocol: TCP
      port: 6379 
```


### FILE: k8s\config\development\postgres.yaml
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: postgres-db
  namespace: meeting-app
  labels:
    app: postgres-db
    component: database
spec:
  replicas: 1
  selector:
    matchLabels:
      app: postgres-db
  template:
    metadata:
      labels:
        app: postgres-db
    spec:
      containers:
      - name: postgres-server
        image: postgres:15-alpine
        ports:
        - containerPort: 5432
          name: pg-port
        env:
        - name: POSTGRES_DB
          valueFrom:
            configMapKeyRef:
              name: meeting-app-config
              key: POSTGRES_DB
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: meeting-app-secrets
              key: POSTGRES_USER
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: meeting-app-secrets
              key: POSTGRES_PASSWORD
        resources:
          limits:
            memory: "256Mi"
            cpu: "200m"
          requests:
            memory: "128Mi"
            cpu: "100m"
        readinessProbe:
          exec:
            command: ["pg_isready", "-U", "$(POSTGRES_USER)"]
          initialDelaySeconds: 5
          periodSeconds: 10
        livenessProbe:
          exec:
            command: ["pg_isready", "-U", "$(POSTGRES_USER)"]
          initialDelaySeconds: 15
          periodSeconds: 20
        volumeMounts:
        - name: postgres-data
          mountPath: /var/lib/postgresql/data
          subPath: postgres
      volumes:
      - name: postgres-data
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: postgres-db
  namespace: meeting-app
  labels:
    app: postgres-db
    type: internal
spec:
  selector:
    app: postgres-db
  ports:
  - name: pg-port
    port: 5432
    targetPort: pg-port 
```


### FILE: k8s\config\development\redis.yaml
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-cache
  namespace: meeting-app
  labels:
    app: redis-cache
    component: cache
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis-cache
  template:
    metadata:
      labels:
        app: redis-cache
    spec:
      containers:
      - name: redis-server
        image: redis:7-alpine
        args: ["--requirepass", "$(REDIS_PASSWORD)"]
        ports:
        - containerPort: 6379
          name: redis-port
        env:
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: meeting-app-secrets
              key: REDIS_PASSWORD
        resources:
          limits:
            memory: "128Mi"
            cpu: "100m"
          requests:
            memory: "64Mi"
            cpu: "50m"
        livenessProbe:
          tcpSocket:
            port: redis-port
          initialDelaySeconds: 15
          periodSeconds: 20
        readinessProbe:
          tcpSocket:
            port: redis-port
          initialDelaySeconds: 5
          periodSeconds: 10
        volumeMounts:
        - name: redis-data
          mountPath: /data
      volumes:
      - name: redis-data
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: redis-cache
  namespace: meeting-app
  labels:
    app: redis-cache
    type: internal
spec:
  selector:
    app: redis-cache
  ports:
  - name: redis-port
    port: 6379
    targetPort: redis-port 
```


### FILE: k8s\config\development\secrets.yaml
```
apiVersion: v1
kind: Secret
metadata:
  name: meeting-app-secrets
  namespace: meeting-app
type: Opaque
stringData:
  POSTGRES_USER: dev_user
  POSTGRES_PASSWORD: dev-password-123
  JWT_SECRET_KEY: dev-jwt-secret-123
  REDIS_PASSWORD: dev-redis-123
  GRAFANA_ADMIN_PASSWORD: dev-grafana-123 
```


### FILE: k8s\config\development\volumes.yaml
```
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: meeting-app-data
  namespace: meeting-app
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: local-path
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: meeting-app-logs
  namespace: meeting-app
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 2Gi
  storageClassName: local-path 
```


### FILE: k8s\logging\elasticsearch-deployment.yaml
```
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch
  labels:
    app: elasticsearch
spec:
  serviceName: elasticsearch
  replicas: 1
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
    spec:
      containers:
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0
        ports:
        - containerPort: 9200
          name: http
        - containerPort: 9300
          name: transport
        env:
        - name: discovery.type
          value: single-node
        - name: ES_JAVA_OPTS
          value: "-Xms512m -Xmx512m"
        resources:
          limits:
            cpu: "1000m"
            memory: "2Gi"
          requests:
            cpu: "500m"
            memory: "1Gi"
        volumeMounts:
        - name: elasticsearch-data
          mountPath: /usr/share/elasticsearch/data
        readinessProbe:
          httpGet:
            path: /_cluster/health
            port: 9200
          initialDelaySeconds: 30
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /_cluster/health
            port: 9200
          initialDelaySeconds: 60
          periodSeconds: 20
  volumeClaimTemplates:
  - metadata:
      name: elasticsearch-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
---
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch
spec:
  type: ClusterIP
  ports:
  - port: 9200
    targetPort: 9200
    protocol: TCP
    name: http
  - port: 9300
    targetPort: 9300
    protocol: TCP
    name: transport
  selector:
    app: elasticsearch 
```


### FILE: k8s\logging\filebeat-daemonset.yaml
```
apiVersion: v1
kind: ConfigMap
metadata:
  name: filebeat-config
data:
  filebeat.yml: |
    filebeat.inputs:
    - type: container
      paths:
        - /var/log/containers/*.log
      processors:
        - add_kubernetes_metadata:
            host: ${NODE_NAME}
            matchers:
            - logs_path:
                logs_path: "/var/log/containers/"

    output.logstash:
      hosts: ["logstash:5044"]

    logging.level: info
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: filebeat
  labels:
    app: filebeat
spec:
  selector:
    matchLabels:
      app: filebeat
  template:
    metadata:
      labels:
        app: filebeat
    spec:
      serviceAccountName: filebeat
      terminationGracePeriodSeconds: 30
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      containers:
      - name: filebeat
        image: docker.elastic.co/beats/filebeat:7.17.0
        args: [
          "-c", "/etc/filebeat.yml",
          "-e",
        ]
        env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        securityContext:
          runAsUser: 0
        resources:
          limits:
            memory: 200Mi
            cpu: 500m
          requests:
            memory: 100Mi
            cpu: 100m
        volumeMounts:
        - name: config
          mountPath: /etc/filebeat.yml
          readOnly: true
          subPath: filebeat.yml
        - name: data
          mountPath: /usr/share/filebeat/data
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: varlog
          mountPath: /var/log
          readOnly: true
      volumes:
      - name: config
        configMap:
          name: filebeat-config
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: varlog
        hostPath:
          path: /var/log
      - name: data
        hostPath:
          path: /var/lib/filebeat-data
          type: DirectoryOrCreate
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: filebeat
subjects:
- kind: ServiceAccount
  name: filebeat
  namespace: default
roleRef:
  kind: ClusterRole
  name: filebeat
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: filebeat
  labels:
    app: filebeat
rules:
- apiGroups: [""]
  resources:
  - namespaces
  - pods
  verbs:
  - get
  - watch
  - list
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: filebeat
  labels:
    app: filebeat 
```


### FILE: k8s\logging\logstash-deployment.yaml
```
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-config
data:
  logstash.yml: |
    http.host: "0.0.0.0"
    xpack.monitoring.enabled: false

  logstash.conf: |
    input {
      beats {
        port => 5044
      }
    }

    filter {
      if [kubernetes] {
        mutate {
          add_field => {
            "app" => "%{[kubernetes][labels][app]}"
            "namespace" => "%{[kubernetes][namespace]}"
            "pod" => "%{[kubernetes][pod][name]}"
          }
        }
      }
    }

    output {
      elasticsearch {
        hosts => ["elasticsearch:9200"]
        index => "logstash-%{+YYYY.MM.dd}"
      }
    }
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: logstash
  labels:
    app: logstash
spec:
  replicas: 1
  selector:
    matchLabels:
      app: logstash
  template:
    metadata:
      labels:
        app: logstash
    spec:
      containers:
      - name: logstash
        image: docker.elastic.co/logstash/logstash:7.17.0
        ports:
        - containerPort: 5044
          name: beats
        env:
        - name: LS_JAVA_OPTS
          value: "-Xms256m -Xmx256m"
        resources:
          limits:
            cpu: "1000m"
            memory: "1Gi"
          requests:
            cpu: "500m"
            memory: "512Mi"
        volumeMounts:
        - name: config
          mountPath: /usr/share/logstash/config
        - name: pipeline
          mountPath: /usr/share/logstash/pipeline
        readinessProbe:
          httpGet:
            path: /
            port: 9600
          initialDelaySeconds: 30
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /
            port: 9600
          initialDelaySeconds: 60
          periodSeconds: 20
      volumes:
      - name: config
        configMap:
          name: logstash-config
          items:
          - key: logstash.yml
            path: logstash.yml
      - name: pipeline
        configMap:
          name: logstash-config
          items:
          - key: logstash.conf
            path: logstash.conf
---
apiVersion: v1
kind: Service
metadata:
  name: logstash
spec:
  type: ClusterIP
  ports:
  - port: 5044
    targetPort: 5044
    protocol: TCP
    name: beats
  selector:
    app: logstash 
```


### FILE: k8s\monitoring\grafana-deployment.yaml
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  labels:
    app: grafana
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      containers:
      - name: grafana
        image: grafana/grafana:9.3.0
        ports:
        - containerPort: 3000
        env:
        - name: GF_SECURITY_ADMIN_USER
          valueFrom:
            secretKeyRef:
              name: grafana-credentials
              key: admin-user
        - name: GF_SECURITY_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              name: grafana-credentials
              key: admin-password
        resources:
          limits:
            cpu: "500m"
            memory: "512Mi"
          requests:
            cpu: "200m"
            memory: "256Mi"
        volumeMounts:
        - name: grafana-storage
          mountPath: /var/lib/grafana
        readinessProbe:
          httpGet:
            path: /api/health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /api/health
            port: 3000
          initialDelaySeconds: 60
          periodSeconds: 30
      volumes:
      - name: grafana-storage
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: grafana
spec:
  type: ClusterIP
  ports:
  - port: 3000
    targetPort: 3000
    protocol: TCP
  selector:
    app: grafana
---
apiVersion: v1
kind: Secret
metadata:
  name: grafana-credentials
type: Opaque
data:
  admin-user: YWRtaW4=  # admin
  admin-password: YWRtaW4xMjM=  # admin123 
```


### FILE: k8s\monitoring\prometheus-config.yaml
```
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s

    scrape_configs:
      - job_name: 'kubernetes-apiservers'
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
          action: keep
          regex: default;kubernetes;https

      - job_name: 'kubernetes-nodes'
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)

      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
        - role: pod
        relabel_configs:
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
          action: replace
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
          target_label: __address__
        - action: labelmap
          regex: __meta_kubernetes_pod_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_pod_name]
          action: replace
          target_label: kubernetes_pod_name

      - job_name: 'meeting-app-backend'
        static_configs:
        - targets: ['meeting-app:5000']

      - job_name: 'meeting-app-websocket'
        static_configs:
        - targets: ['meeting-app:3001']

      - job_name: 'meeting-app-frontend'
        static_configs:
        - targets: ['meeting-app-frontend:3000'] 
```


### FILE: k8s\monitoring\prometheus-deployment.yaml
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  labels:
    app: prometheus
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      serviceAccountName: prometheus
      containers:
      - name: prometheus
        image: prom/prometheus:v2.40.0
        args:
        - "--config.file=/etc/prometheus/prometheus.yml"
        - "--storage.tsdb.path=/prometheus"
        - "--web.console.libraries=/usr/share/prometheus/console_libraries"
        - "--web.console.templates=/usr/share/prometheus/consoles"
        ports:
        - containerPort: 9090
        volumeMounts:
        - name: prometheus-config
          mountPath: /etc/prometheus
        - name: prometheus-storage
          mountPath: /prometheus
        resources:
          limits:
            cpu: "1000m"
            memory: "1Gi"
          requests:
            cpu: "500m"
            memory: "512Mi"
      volumes:
      - name: prometheus-config
        configMap:
          name: prometheus-config
      - name: prometheus-storage
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
spec:
  type: ClusterIP
  ports:
  - port: 9090
    targetPort: 9090
    protocol: TCP
  selector:
    app: prometheus
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups:
  - extensions
  resources:
  - ingresses
  verbs: ["get", "list", "watch"]
- nonResourceURLs: ["/metrics"]
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: default 
```


### FILE: k8s\network-policies\flask-backend-policy.yaml
```
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: flask-backend-network-policy
spec:
  podSelector:
    matchLabels:
      app: meeting-app
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: meeting-app-frontend
    ports:
    - protocol: TCP
      port: 5000
  - from:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: ingress-nginx
    ports:
    - protocol: TCP
      port: 5000
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: postgres
    ports:
    - protocol: TCP
      port: 5432
  - to:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: kube-system
      podSelector:
        matchLabels:
          k8s-app: kube-dns
    ports:
    - protocol: UDP
      port: 53
    - protocol: TCP
      port: 53 
```


### FILE: k8s\network-policies\frontend-policy.yaml
```
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: frontend-network-policy
spec:
  podSelector:
    matchLabels:
      app: meeting-app-frontend
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: ingress-nginx
    ports:
    - protocol: TCP
      port: 3000
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: meeting-app
    ports:
    - protocol: TCP
      port: 5000
    - protocol: TCP
      port: 3001 
```


### FILE: k8s\network-policies\logging-policy.yaml
```
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: elasticsearch-policy
spec:
  podSelector:
    matchLabels:
      app: elasticsearch
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: logstash
    - podSelector:
        matchLabels:
          app: kibana
    ports:
    - protocol: TCP
      port: 9200
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: kube-system
    ports:
    - protocol: UDP
      port: 53
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: logstash-policy
spec:
  podSelector:
    matchLabels:
      app: logstash
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: filebeat
    ports:
    - protocol: TCP
      port: 5044
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: elasticsearch
    ports:
    - protocol: TCP
      port: 9200
  - to:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: kube-system
    ports:
    - protocol: UDP
      port: 53
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: kibana-policy
spec:
  podSelector:
    matchLabels:
      app: kibana
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: ingress-nginx
    ports:
    - protocol: TCP
      port: 5601
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: elasticsearch
    ports:
    - protocol: TCP
      port: 9200
  - to:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: kube-system
    ports:
    - protocol: UDP
      port: 53
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: filebeat-policy
spec:
  podSelector:
    matchLabels:
      app: filebeat
  policyTypes:
  - Egress
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: logstash
    ports:
    - protocol: TCP
      port: 5044
  - to:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: kube-system
    ports:
    - protocol: UDP
      port: 53 
```


### FILE: k8s\network-policies\monitoring-policy.yaml
```
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: monitoring-network-policy
spec:
  podSelector:
    matchLabels:
      app: prometheus
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: grafana
    ports:
    - protocol: TCP
      port: 9090
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: meeting-app
    ports:
    - protocol: TCP
      port: 5000
    - protocol: TCP
      port: 3001
  - to:
    - podSelector:
        matchLabels:
          app: meeting-app-frontend
    ports:
    - protocol: TCP
      port: 3000
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: grafana-network-policy
spec:
  podSelector:
    matchLabels:
      app: grafana
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: ingress-nginx
    ports:
    - protocol: TCP
      port: 3000
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: prometheus
    ports:
    - protocol: TCP
      port: 9090 
```


### FILE: k8s\network-policies\node-backend-policy.yaml
```
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: node-backend-network-policy
spec:
  podSelector:
    matchLabels:
      app: meeting-app
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: meeting-app-frontend
    ports:
    - protocol: TCP
      port: 3001
  - from:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: ingress-nginx
    ports:
    - protocol: TCP
      port: 3001
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: postgres
    ports:
    - protocol: TCP
      port: 5432
  - to:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: kube-system
      podSelector:
        matchLabels:
          k8s-app: kube-dns
    ports:
    - protocol: UDP
      port: 53
    - protocol: TCP
      port: 53 
```


### FILE: k8s\network-policies\postgres-policy.yaml
```
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: postgres-network-policy
spec:
  podSelector:
    matchLabels:
      app: postgres
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: meeting-app
    ports:
    - protocol: TCP
      port: 5432
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: kube-system
      podSelector:
        matchLabels:
          k8s-app: kube-dns
    ports:
    - protocol: UDP
      port: 53
    - protocol: TCP
      port: 53 
```


### FILE: k8s\network-policies\redis-policy.yaml
```
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: redis-network-policy
spec:
  podSelector:
    matchLabels:
      app: redis
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: meeting-app
    ports:
    - protocol: TCP
      port: 6379
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: kube-system
      podSelector:
        matchLabels:
          k8s-app: kube-dns
    ports:
    - protocol: UDP
      port: 53
    - protocol: TCP
      port: 53 
```


### FILE: monitoring\prometheus\prometheus.yml
```
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'auth-service'
    static_configs:
      - targets: ['auth-service:5001']

  - job_name: 'backend'
    static_configs:
      - targets: ['backend:5000']

  - job_name: 'websocket'
    static_configs:
      - targets: ['websocket:3001'] 
```


## SUMMARY
- Total files found: 239
- Files processed: 208
- Files skipped: 31
- Script version: 1.1.0
