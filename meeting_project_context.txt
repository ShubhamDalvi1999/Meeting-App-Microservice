# PROJECT STRUCTURE AND CONTENTS
# Project: F:\Full Stack Meeting App  with login

## FOLDER STRUCTURE

ğŸ“„ .gitignore
ğŸ“„ IMPLEMENTATION_REPORT.md
ğŸ“„ README.md
ğŸ“„ TROUBLESHOOTING.md
ğŸ“„ backend_logs.txt
ğŸ“„ custom_auth_dockerfile
ğŸ“„ docker-compose.test.yml
ğŸ“„ docker-compose.yml
ğŸ“„ migrate.ps1
ğŸ“„ migrate.sh
ğŸ“„ rebuild_docker.ps1
ğŸ“„ run-integration-tests.ps1
ğŸ“„ run-integration-tests.sh
ğŸ“„ run_tests.ps1
ğŸ“„ run_tests.sh
ğŸ“„ setup.ps1
ğŸ“„ setup.sh
ğŸ“„ start.ps1
ğŸ“„ start.sh
ğŸ“„ start.txt
ğŸ“„ test-backend.dockerfile
ğŸ“„ test-websocket.dockerfile
ğŸ“„ verify_system.bat
ğŸ“ .pytest_cache/
  ğŸ“„ .gitignore
  ğŸ“„ CACHEDIR.TAG
  ğŸ“„ README.md
  ğŸ“ v/
ğŸ“ backend/
  ğŸ“„ pytest.ini
  ğŸ“„ requirements.txt
  ğŸ“ .pytest_cache/
    ğŸ“„ .gitignore
    ğŸ“„ CACHEDIR.TAG
    ğŸ“„ README.md
    ğŸ“ v/
  ğŸ“ auth-service/
    ğŸ“„ .dockerignore
    ğŸ“„ .env.example
    ğŸ“„ Dockerfile
    ğŸ“„ alembic.ini
    ğŸ“„ pytest.ini
    ğŸ“„ requirements.txt
    ğŸ“„ setup.py
    ğŸ“ auth_service.egg-info/
      ğŸ“„ PKG-INFO
      ğŸ“„ SOURCES.txt
      ğŸ“„ dependency_links.txt
      ğŸ“„ requires.txt
      ğŸ“„ top_level.txt
    ğŸ“ instance/
    ğŸ“ migrations/
      ğŸ“„ alembic.ini
      ğŸ“„ env.py
      ğŸ“„ script.py.mako
      ğŸ“ versions/
        ğŸ“„ 001_initial.py
    ğŸ“ scripts/
      ğŸ“„ entrypoint.sh
      ğŸ“„ healthcheck.sh
    ğŸ“ src/
      ğŸ“„ app.py
      ğŸ“„ database.py
      ğŸ“ core/
        ğŸ“„ __init__.py
        ğŸ“„ config.py
        ğŸ“„ errors.py
        ğŸ“„ health.py
      ğŸ“ models/
        ğŸ“„ auth.py
      ğŸ“ routes/
        ğŸ“„ auth.py
      ğŸ“ schemas/
        ğŸ“„ auth.py
        ğŸ“„ base.py
      ğŸ“ tasks/
        ğŸ“„ cleanup.py
      ğŸ“ utils/
        ğŸ“„ auth.py
        ğŸ“„ data_seeder.py
        ğŸ“„ database.py
        ğŸ“„ email_service.py
        ğŸ“„ migrations_manager.py
        ğŸ“„ rate_limiter.py
        ğŸ“„ service_integration.py
        ğŸ“„ session_service.py
        ğŸ“„ token_service.py
  ğŸ“ backend/
    ğŸ“ shared/
      ğŸ“ log_utils/
  ğŸ“ flask-service/
    ğŸ“„ .dockerignore
    ğŸ“„ .env.example
    ğŸ“„ Dockerfile
    ğŸ“„ README.md
    ğŸ“„ entrypoint.sh
    ğŸ“„ fixed_app.py
    ğŸ“„ pytest.ini
    ğŸ“„ requirements.txt
    ğŸ“ backend/
      ğŸ“ shared/
        ğŸ“ log_utils/
    ğŸ“ meeting_shared/
    ğŸ“ migrations/
      ğŸ“„ alembic.ini
      ğŸ“„ env.py
      ğŸ“ versions/
        ğŸ“„ initial_schema.py
    ğŸ“ models/
    ğŸ“ scripts/
      ğŸ“„ create_migration.sh
      ğŸ“„ init_db.sh
      ğŸ“„ migrate.sh
      ğŸ“„ migration_validator.py
      ğŸ“„ show_migration_chain.py
      ğŸ“„ test_migrations.py
    ğŸ“ src/
      ğŸ“„ __init__.py
      ğŸ“„ app.py
      ğŸ“„ fixed_app.py
      ğŸ“ core/
        ğŸ“„ __init__.py
        ğŸ“„ config.py
        ğŸ“„ errors.py
        ğŸ“„ health.py
      ğŸ“ models/
        ğŸ“„ __init__.py
        ğŸ“„ meeting.py
        ğŸ“„ meeting_audit_log.py
        ğŸ“„ meeting_co_host.py
        ğŸ“„ meeting_participant.py
        ğŸ“„ user.py
      ğŸ“ routes/
        ğŸ“„ __init__.py
        ğŸ“„ auth.py
        ğŸ“„ auth_integration.py
        ğŸ“„ health.py
        ğŸ“„ meetings.py
      ğŸ“ schemas/
        ğŸ“„ audit_log.py
        ğŸ“„ base.py
        ğŸ“„ co_host.py
        ğŸ“„ meeting.py
        ğŸ“„ participant.py
      ğŸ“ services/
        ğŸ“„ __init__.py
      ğŸ“ tasks/
        ğŸ“„ __init__.py
        ğŸ“„ cleanup.py
        ğŸ“„ metrics.py
      ğŸ“ utils/
        ğŸ“„ auth_integration.py
        ğŸ“„ data_seeder.py
        ğŸ“„ database.py
        ğŸ“„ logger.py
        ğŸ“„ metrics.py
        ğŸ“„ migrations_manager.py
        ğŸ“„ responses.py
        ğŸ“„ socket_events.py
  ğŸ“ node-service/
    ğŸ“„ .dockerignore
    ğŸ“„ .env.example
    ğŸ“„ Dockerfile
    ğŸ“„ package-lock.json
    ğŸ“„ package.json
    ğŸ“ src/
      ğŸ“„ config.js
      ğŸ“„ server.js
      ğŸ“ services/
        ğŸ“„ chat.js
        ğŸ“„ webrtc.js
        ğŸ“„ whiteboard.js
      ğŸ“ utils/
        ğŸ“„ logger.js
        ğŸ“„ metrics.js
ğŸ“ config/
  ğŸ“„ .env.development
  ğŸ“„ secrets.production
ğŸ“ frontend/
  ğŸ“„ .dockerignore
  ğŸ“„ .env.local
  ğŸ“„ .env.production
  ğŸ“„ .eslintrc.json
  ğŸ“„ DEBUGGING.md
  ğŸ“„ Dockerfile
  ğŸ“„ next-env.d.ts
  ğŸ“„ next.config.js
  ğŸ“„ package.json
  ğŸ“„ postcss.config.js
  ğŸ“„ tailwind.config.js
  ğŸ“„ tsconfig.json
  ğŸ“ .next/
  ğŸ“ public/
  ğŸ“ src/
    ğŸ“ components/
      ğŸ“„ ErrorBoundary.tsx
      ğŸ“ layout/
        ğŸ“„ Layout.tsx
      ğŸ“ meeting/
        ğŸ“„ Chat.tsx
        ğŸ“„ VideoConference.tsx
        ğŸ“„ Whiteboard.tsx
    ğŸ“ config/
      ğŸ“„ environment.ts
    ğŸ“ contexts/
      ğŸ“„ AuthContext.tsx
      ğŸ“„ ChatContext.tsx
      ğŸ“„ DebugContext.tsx
      ğŸ“„ WebRTCContext.tsx
      ğŸ“„ WebSocketContext.tsx
      ğŸ“„ WhiteboardContext.tsx
    ğŸ“ hooks/
    ğŸ“ pages/
      ğŸ“„ _app.tsx
      ğŸ“„ _error.tsx
      ğŸ“„ config.js
      ğŸ“„ dashboard.tsx
      ğŸ“„ forgot-password.tsx
      ğŸ“„ index.tsx
      ğŸ“„ login.tsx
      ğŸ“„ register.tsx
      ğŸ“„ resend-verification.tsx
      ğŸ“ api/
        ğŸ“„ health.ts
      ğŸ“ meeting/
        ğŸ“„ [id].tsx
      ğŸ“ reset-password/
        ğŸ“„ [token].tsx
      ğŸ“ verify-email/
        ğŸ“„ [token].tsx
    ğŸ“ services/
      ğŸ“ api/
        ğŸ“„ client.ts
    ğŸ“ styles/
      ğŸ“„ globals.css
    ğŸ“ types/
      ğŸ“„ custom.d.ts
      ğŸ“„ events.ts
      ğŸ“„ globals.d.ts
      ğŸ“„ jsx.d.ts
      ğŸ“„ user.ts
    ğŸ“ utils/
      ğŸ“„ logger.ts
      ğŸ“„ runtimeConfig.ts
ğŸ“ meeting_shared/
  ğŸ“„ README.md
  ğŸ“„ __init__.py
  ğŸ“„ config.py
  ğŸ“„ database.py
  ğŸ“„ errors.py
  ğŸ“„ setup.py
  ğŸ“ discovery/
    ğŸ“„ __init__.py
    ğŸ“„ kubernetes.py
    ğŸ“„ static.py
  ğŸ“ middleware/
    ğŸ“„ __init__.py
    ğŸ“„ auth.py
    ğŸ“„ error_handler.py
    ğŸ“„ rate_limiter.py
    ğŸ“„ request_id.py
    ğŸ“„ validation.py
  ğŸ“ models/
    ğŸ“„ __init__.py
  ğŸ“ schemas/
    ğŸ“„ __init__.py
    ğŸ“„ base.py
  ğŸ“ secrets/
    ğŸ“„ __init__.py
    ğŸ“„ file.py
    ğŸ“„ vault.py
  ğŸ“ shared_logging/
    ğŸ“„ __init__.py
    ğŸ“„ config.py
    ğŸ“„ sampling.py
  ğŸ“ utils/
    ğŸ“„ __init__.py
    ğŸ“„ database.py
ğŸ“ monitoring/
  ğŸ“ grafana/
    ğŸ“ provisioning/
  ğŸ“ prometheus/
    ğŸ“„ prometheus.yml
ğŸ“ scripts/
  ğŸ“„ Generate-Secrets.ps1
  ğŸ“„ Set-Environment.ps1
  ğŸ“„ deploy-meeting-app.ps1
  ğŸ“„ setup-local-dev.ps1
  ğŸ“„ verify_auth_flow.py
  ğŸ“„ verify_db.py
  ğŸ“„ verify_meeting_crud.py


## FILE CONTENTS



### FILE: .gitignore
```
# Environment files
.env
.env.*
config/secrets.*
!.env.example

# Logs
logs/
*.log

# Dependencies
node_modules/
vendor/

# Build outputs
dist/
build/
*.pyc
__pycache__/
*.pytest_cache
*.coverage_html/
auth_service.egg-info/
flask_service.egg-info/


# IDE and editor files
.vscode/
.idea/
*.swp
*.swo

# Operating System
.DS_Store
Thumbs.db 

# Data files of the project generated by the backend services
# Used for testing purposes
data/


# Documentation files
docs/

# pytest cache
.pytest_cache/

client_secret_1004556025731-dgnou2c5vdui47ffbfievlil9ncqsrue.apps.googleusercontent.com.json
```


### FILE: IMPLEMENTATION_REPORT.md
```
# Implementation Report

## Completed Tasks

### 1. Infrastructure Stabilization

- âœ… Updated `docker-compose.yml` with improved health checks and startup sequence
- âœ… Enhanced `auth-service` Dockerfile with dependency checks and debugging info
- âœ… Verified `backend/flask-service/Dockerfile.fixed` properly addresses the OS module issue
- âœ… Added appropriate container dependencies to ensure proper startup order

### 2. Service Management Scripts

- âœ… Created `start.ps1` and `start.sh` scripts to enforce proper service startup sequence
- âœ… Created `migrate.ps1` and `migrate.sh` scripts to manage database migrations
- âœ… Made scripts compatible with both Windows and Unix-like systems

### 3. Documentation

- âœ… Created comprehensive `TROUBLESHOOTING.md` guide
- âœ… Updated `README.md` with clear setup and usage instructions
- âœ… Added detailed instructions for both Windows and Unix-like systems

## Next Steps

### 1. Complete Database Migration Implementation

- [ ] Implement migration code in backend service
- [ ] Test migration scripts with actual databases
- [ ] Create sample data seeder scripts for development

### 2. Auth Service Enhancements

- [ ] Enhance JWT token handling and validation
- [ ] Implement rate limiting for authentication endpoints
- [ ] Update session management and cleanup tasks
- [ ] Improve integration with the backend service

### 3. Backend Service Optimization

- [ ] Add Redis caching for frequently accessed data
- [ ] Implement performance monitoring with Prometheus metrics
- [ ] Enhance error handling with structured logging
- [ ] Optimize database queries

### 4. Testing and Validation

- [ ] Create automated tests for critical components
- [ ] Implement CI/CD pipeline for continuous testing
- [ ] Create test-docker-compose.yml for isolated testing

### 5. Monitoring and Maintenance

- [ ] Configure Prometheus metrics collection
- [ ] Set up Grafana dashboards for service monitoring
- [ ] Create maintenance scripts for backup and recovery

## Conclusion

The initial stabilization and infrastructure improvements have been completed. The core services have been enhanced for better reliability and maintainability. The updated documentation provides clear instructions for setup and troubleshooting.

The next phase of work should focus on the specific service enhancements outlined in the next steps section, particularly around authentication, performance optimization, and testing. 
```


### FILE: README.md
```
# Meeting Application

A comprehensive meeting management application with authentication, real-time communication, and calendar integration.

## System Architecture

The application is built using a microservices architecture consisting of:

- **Frontend**: Next.js application for the user interface
- **Backend API**: Flask-based API for meeting management
- **Auth Service**: Flask-based microservice for authentication and user management
- **WebSocket Service**: Node.js-based WebSocket server for real-time communication
- **Databases**: PostgreSQL for persistent data storage
- **Redis**: For caching, pub/sub messaging, and session storage
- **Monitoring**: Prometheus and Grafana for metrics and monitoring
- **Shared Package**: Common utilities and middleware shared across services

### Shared Package

The `meeting_shared` package contains common functionality used across all microservices in the Meeting App. This ensures consistency and reduces code duplication.

#### Installation

For development, install the package in editable mode:

```bash
# From the project root
pip install -e meeting_shared
```

Or add to your service's requirements.txt:
```
-e ../meeting_shared
```

#### Components

- **shared_logging**: Structured JSON logging with request ID tracking
  ```python
  from meeting_shared.shared_logging import setup_logging
  
  # Initialize logging
  logger = setup_logging(app, service_name="my-service")
  ```

- **middleware**: Flask middleware components
  ```python
  from meeting_shared.middleware import register_middleware
  from meeting_shared.middleware.auth import jwt_required
  
  # Register all middleware
  register_middleware(app)
  
  # Use auth decorator
  @app.route("/protected")
  @jwt_required
  def protected_route():
      return {"message": "Protected resource"}
  ```

- **discovery**: Service discovery utilities
  ```python
  from meeting_shared.discovery import get_service_url
  
  # Get URL for a service
  auth_url = get_service_url("auth-service")
  ```

- **secrets**: Secret management
  ```python
  from meeting_shared.secrets import get_secret
  
  # Get a secret
  api_key = get_secret("api.key")
  ```

#### Development Guidelines

1. **Adding New Features**
   - Place shared code in the appropriate module
   - Update tests in the `tests/` directory
   - Document new functionality in docstrings

2. **Dependencies**
   - Add new dependencies to `setup.py`
   - Keep dependencies minimal and version-pinned

3. **Testing**
   ```bash
   # Run tests
   cd meeting_shared
   pytest
   ```

4. **Code Style**
   - Follow PEP 8
   - Use type hints
   - Document public interfaces

5. **Version Control**
   - Create feature branches from `main`
   - Write descriptive commit messages
   - Update CHANGELOG.md for significant changes

#### Docker Integration

The shared package is automatically mounted in development:
```yaml
volumes:
  - ./meeting_shared:/app/meeting_shared
```

For production, it's installed during the build process:
```dockerfile
COPY meeting_shared /app/meeting_shared/
RUN pip install -e /app/meeting_shared
```

### Advanced Features

The application includes several advanced features for enterprise-grade deployments:

- **Service Discovery**: Dynamic service location and communication between microservices
- **Secret Management**: Secure handling of sensitive information across various backends
- **Integration Testing**: Comprehensive testing of service interactions
- **Centralized Logging**: Structured logging with correlation IDs across services
- **Circuit Breaking**: Resilient service communication with automatic failure handling
- **Performance Monitoring**: Real-time metrics and monitoring

## Prerequisites

- Docker and Docker Compose
- Git
- Make (optional, for using Makefile)

### Windows-Specific Requirements

- Docker Desktop
- PowerShell 5.0 or higher for running scripts
- Git Bash for bash scripts (optional)

## Quick Start

### Setting Up Environment

1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/meeting-app.git
   cd meeting-app
   ```

2. Create a `.env` file by copying the example:
   ```bash
   # For Linux/macOS
   cp .env.example .env
   
   # For Windows
   copy .env.example .env
   ```

3. Modify the `.env` file with your desired configuration values.

### Starting the Application

#### Using Scripts (Recommended)

For Windows:
```powershell
# Ensure PowerShell execution policy allows running scripts
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser

# Run the start script
.\start.ps1
```

For Linux/macOS:
```bash
# Make the script executable
chmod +x start.sh

# Run the start script
./start.sh
```

#### Manual Startup

Start the services in the following order:

```bash
# 1. Start database services
docker-compose up -d postgres auth-db redis

# 2. Wait for databases to initialize
sleep 15

# 3. Start the auth service
docker-compose up -d auth-service

# 4. Wait for auth service
sleep 10

# 5. Start the backend service
docker-compose up -d backend

# 6. Start remaining services
docker-compose up -d websocket frontend prometheus grafana
```

### Database Migrations

Run migrations to initialize the database schema:

For Windows:
```powershell
.\migrate.ps1 -ForceInit -Upgrade
```

For Linux/macOS:
```bash
chmod +x migrate.sh
./migrate.sh --force-init --upgrade
```

## Accessing the Application

Once all services are started, you can access the application at:

- **Frontend**: [http://localhost:3000](http://localhost:3000)
- **Backend API**: [http://localhost:5000](http://localhost:5000)
- **Auth Service**: [http://localhost:5001](http://localhost:5001)
- **WebSocket Service**: [http://localhost:3001](http://localhost:3001)
- **Prometheus**: [http://localhost:9090](http://localhost:9090)
- **Grafana**: [http://localhost:3002](http://localhost:3002)

## Development

### Rebuilding Services

If you need to rebuild a specific service after code changes:

```bash
docker-compose build <service-name>
docker-compose up -d <service-name>
```

### Viewing Logs

To view logs for a specific service:

```bash
docker-compose logs <service-name>
```

To follow logs in real-time:

```bash
docker-compose logs -f <service-name>
```

### Running Tests

#### Unit Tests

```bash
docker-compose -f docker-compose.test.yml up
```

#### Integration Tests

Run integration tests to verify service interactions:

```bash
# For Windows
.\run-integration-tests.ps1

# For Linux/macOS
chmod +x run-integration-tests.sh
./run-integration-tests.sh
```

## Advanced Features

### Service Discovery

The application includes a flexible service discovery system that supports multiple backends:

- **Environment Variables**: Simple configuration for development
- **Static Configuration**: JSON/YAML-based configuration for Docker Compose
- **Consul**: For production deployments with health checks
- **Kubernetes**: Native service discovery in Kubernetes environments

For more information, see the [Service Discovery Documentation](backend/shared/discovery/README.md).

### Secret Management

Secure handling of sensitive information with support for multiple backends:

- **Environment Variables**: Simple configuration for development
- **File-Based**: For Docker and Kubernetes secrets
- **HashiCorp Vault**: Advanced secret management with rotation
- **AWS Secrets Manager**: Cloud-native secret management

For more information, see the [Secret Management Documentation](backend/shared/secrets/README.md).

### Integration Testing

The application includes a comprehensive integration testing framework:

- **Service Mocking**: Mock responses from dependent services
- **Authentication Testing**: Verify authentication flows
- **End-to-End Testing**: Test complete user journeys

To run integration tests:

```bash
# For auth service
cd backend/auth-service
python -m pytest tests/integration

# For backend service
cd backend/flask-service
python -m pytest tests/integration
```

## Troubleshooting

For common issues and solutions, please refer to the [Troubleshooting Guide](TROUBLESHOOTING.md).

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

# Backend Architecture Standardization

This document summarizes the standardization changes implemented to improve consistency, reliability, and maintainability across backend services.

## Key Improvements

1. **Standardized Configuration System**
   - Unified configuration classes across services
   - Environment-specific configs (development, testing, production)
   - Service-specific configs (auth, flask, websocket)
   - Consistent environment variable handling

2. **Unified Logging Framework**
   - Structured JSON logging with consistent formatting
   - Request ID and correlation ID tracking in logs
   - Configurable log levels and outputs
   - Third-party library log level management

3. **Consistent Middleware Architecture**
   - Standard middleware interface
   - Centralized middleware registration
   - Request ID middleware for request tracking
   - Fallback mechanisms for backward compatibility

4. **Standardized Error Handling**
   - Common error classes with consistent responses
   - Structured error responses with request IDs
   - Detailed logging of exceptions
   - Consistent HTTP status codes

5. **HTTP Utilities Standardization**
   - Request ID propagation in HTTP requests
   - Retry mechanisms for transient failures
   - Consistent logging of HTTP requests
   - Simplified API for common HTTP methods

6. **Import System Improvements**
   - Fallback mechanisms for backward compatibility
   - Clear import paths for shared modules
   - Graceful handling of missing dependencies

7. **Application Factory Standardization**
   - Consistent initialization across services
   - Standard health check endpoints
   - Unified extension registration
   - Proper error handling during startup

## Project Structure

```
backend/
â”œâ”€â”€ shared/                      # Shared modules used across services
â”‚   â”œâ”€â”€ __init__.py              # Shared module import helpers
â”‚   â”œâ”€â”€ config.py                # Standardized configuration
â”‚   â”œâ”€â”€ errors.py                # Common error classes
â”‚   â”œâ”€â”€ logging/                 # Logging framework
â”‚   â”‚   â”œâ”€â”€ __init__.py          # Logging module exports
â”‚   â”‚   â””â”€â”€ config.py            # Logging configuration
â”‚   â”œâ”€â”€ middleware/              # Shared middleware
â”‚   â”‚   â”œâ”€â”€ __init__.py          # Middleware registration
â”‚   â”‚   â””â”€â”€ request_id.py        # Request ID middleware
â”‚   â””â”€â”€ utils/                   # Utility functions
â”‚       â”œâ”€â”€ __init__.py          # Utils module exports
â”‚       â””â”€â”€ http.py              # HTTP request utilities
â”œâ”€â”€ auth-service/                # Authentication service
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ app.py               # Main application factory
â”‚       â””â”€â”€ core/                # Core functionality
â””â”€â”€ flask-service/               # Main backend API service
    â””â”€â”€ src/
        â”œâ”€â”€ app.py               # Main application factory
        â””â”€â”€ core/                # Core functionality
```

## Benefits of Standardization

1. **Improved Maintainability**
   - Consistent patterns make code easier to understand
   - Reduced duplication across services
   - Centralized configuration and error handling

2. **Enhanced Reliability**
   - Robust error handling and logging
   - Request tracking across services
   - Proper fallback mechanisms

3. **Better Observability**
   - Structured logs with request context
   - Consistent health check endpoints
   - Detailed error information

4. **Simplified Development**
   - Standard interfaces for common functionality
   - Reduced cognitive load for developers
   - Easier onboarding for new team members

## Next Steps

1. Add comprehensive test coverage for shared modules
2. Implement distributed tracing with OpenTelemetry
3. Add centralized metrics collection
4. Create deployment automation for shared modules
5. Add comprehensive documentation 
```


### FILE: TROUBLESHOOTING.md
```
# Troubleshooting Guide

This document outlines common issues you might encounter when setting up or running the Meeting Application and provides solutions for resolving them.

## Table of Contents

1. [Docker Issues](#docker-issues)
2. [Database Issues](#database-issues)
3. [Service Connectivity Issues](#service-connectivity-issues)
4. [Authentication Issues](#authentication-issues)
5. [Frontend Issues](#frontend-issues)
6. [Windows-Specific Issues](#windows-specific-issues)

## Docker Issues

### Issue: Docker containers fail to build

**Symptoms:**
- `docker-compose build` fails with permission errors or "unknown file mode" errors
- Errors about missing files during build

**Solutions:**
- Make sure you're using the correct `.dockerignore` files in each service directory
- On Windows, use `Dockerfile.fixed` for the backend service
- Ensure line endings are consistent (LF, not CRLF) in scripts copied to containers

### Issue: Docker containers exit immediately after starting

**Symptoms:**
- `docker-compose up` shows containers starting but then stopping
- `docker-compose ps` shows containers in "Exit" state

**Solutions:**
- Check container logs with `docker-compose logs <service-name>`
- Verify environment variables are properly set in `.env` file
- Make sure entrypoint scripts have proper execute permissions
- Ensure database connectivity (containers may exit if DB connection fails)

### Issue: Services can't connect to each other

**Symptoms:**
- Logs show connection refused errors
- Services can't find each other by hostname

**Solutions:**
- Ensure all services are on the same Docker network
- Use correct service hostnames (as defined in docker-compose.yml)
- Verify ports are exposed correctly
- Check that service dependencies are properly defined in docker-compose.yml

## Database Issues

### Issue: Database migrations fail

**Symptoms:**
- Flask migrations show "Multiple heads" error
- Services exit with "database not ready" or "database not initialized"

**Solutions:**
- Merge migration heads using `./migrate.ps1 -Merge` or `./migrate.sh --merge`
- Verify database credentials in `.env` file
- Check that migrations are properly initialized with `./migrate.ps1 -ForceInit`
- Ensure PostgreSQL is running and accessible

### Issue: Database connection timeouts

**Symptoms:**
- Services report "database connection timeout"
- Intermittent database errors

**Solutions:**
- Increase healthcheck timeouts and retries in docker-compose.yml
- Ensure PostgreSQL has adequate resources
- Check for network issues between services
- Verify connection string format in environment variables

## Service Connectivity Issues

### Issue: Auth service not responding

**Symptoms:**
- Authentication fails
- Backend logs show auth service connectivity issues

**Solutions:**
- Check if auth-service is running with `docker-compose ps`
- Verify `AUTH_SERVICE_URL` environment variable is set correctly
- Ensure auth-service is healthy with `curl http://localhost:5001/health`
- Check auth-service logs with `docker-compose logs auth-service`

### Issue: Backend API not accessible

**Symptoms:**
- Frontend can't connect to backend
- `curl http://localhost:5000/health` fails

**Solutions:**
- Verify backend service is running with `docker-compose ps`
- Check backend logs with `docker-compose logs backend`
- Ensure port 5000 is exposed and not blocked by firewall
- Verify `NEXT_PUBLIC_API_URL` is set correctly for frontend

## Authentication Issues

### Issue: JWT token validation fails

**Symptoms:**
- Users get logged out unexpectedly
- API requests return 401 Unauthorized

**Solutions:**
- Ensure `JWT_SECRET_KEY` is identical across all services
- Check token expiration settings
- Verify clock synchronization between services
- Make sure `SERVICE_KEY` for inter-service communication is correct

### Issue: User registration fails

**Symptoms:**
- New users can't register
- Registration form submits but returns errors

**Solutions:**
- Check auth-service logs
- Verify email validation settings
- Ensure database connectivity for auth-service
- Check for duplicate email prevention logic

## Frontend Issues

### Issue: Frontend fails to build

**Symptoms:**
- `docker-compose build frontend` fails
- Next.js build errors

**Solutions:**
- Check for proper Node.js version in frontend Dockerfile
- Ensure all dependencies are correctly installed
- Verify proper volume mounts for node_modules
- Check if `.next` directory has correct permissions

### Issue: Frontend can't connect to backend services

**Symptoms:**
- API requests fail
- Console shows CORS errors or connection refused

**Solutions:**
- Verify environment variables in frontend service:
  - `NEXT_PUBLIC_API_URL`
  - `NEXT_PUBLIC_WS_URL`
  - `NEXT_PUBLIC_AUTH_URL`
- Ensure CORS is properly configured in backend and auth services
- Check network connectivity between containers

## Windows-Specific Issues

### Issue: File permission errors in Docker

**Symptoms:**
- "unknown file mode" errors
- Permission denied when copying files

**Solutions:**
- Use `.dockerignore` files to exclude problem files/directories
- Use explicit COPY commands in Dockerfile rather than copying entire directories
- Set Git to use LF line endings: `git config --global core.autocrlf input`

### Issue: Scripts won't execute

**Symptoms:**
- PowerShell scripts show security errors
- Bash scripts fail with "bad interpreter"

**Solutions:**
- For PowerShell: Set execution policy with `Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser`
- For bash scripts in Windows: Use `bash script.sh` instead of `./script.sh`
- Ensure scripts have correct line endings (LF for bash scripts)
- Make sure scripts have executable permission: `chmod +x script.sh` (in WSL or Git Bash)

## Getting Help

If you're still experiencing issues:
1. Check the service logs: `docker-compose logs -f`
2. Review the application logs in `logs/` directory
3. Check the GitHub issues
4. Contact the development team 
```


### FILE: backend_logs.txt (SKIPPED - Binary file)


### FILE: custom_auth_dockerfile
```
FROM python:3.9-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    build-essential \
    curl \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# Create necessary directories
RUN mkdir -p /app/meeting_shared/schemas /app/src /app/logs

# Copy requirements first to leverage Docker cache
COPY backend/auth-service/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Create the fixed base.py with BaseSchema class
RUN echo '"""
Base schemas for API responses.
"""

from typing import Optional, Dict, Any
from pydantic import BaseModel

class BaseSchema(BaseModel):
    """Base schema that all other schemas should inherit from."""
    class Config:
        orm_mode = True
        validate_assignment = True
        arbitrary_types_allowed = True
        extra = "forbid"

class ErrorResponse(BaseModel):
    """Standard error response model."""
    error: str
    message: str
    details: Optional[Dict[str, Any]] = None 

class SuccessResponse(BaseModel):
    """Standard success response model."""
    success: bool = True
    data: Optional[Dict[str, Any]] = {}
    message: Optional[str] = "Operation completed successfully"
' > /app/meeting_shared/schemas/base.py

# Create __init__.py in schemas directory
RUN echo '' > /app/meeting_shared/schemas/__init__.py

# Set environment variables
ENV PYTHONPATH=/app/src:/app/meeting_shared
ENV FLASK_APP=src/app.py
ENV FLASK_ENV=development
ENV SERVICE_TYPE=auth

# Create entrypoint script
COPY backend/auth-service/scripts/entrypoint.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=15s --retries=3 \
    CMD curl -f http://localhost:5001/health || exit 1

EXPOSE 5001

# Use entrypoint script
ENTRYPOINT ["/entrypoint.sh"] 
```


### FILE: docker-compose.test.yml
```
# yaml-language-server: $schema=https://raw.githubusercontent.com/compose-spec/compose-spec/master/schema/compose-spec.json
version: '3.8'

services:
  flask-service-tests:
    build:
      context: .
      dockerfile: backend/flask-service/Dockerfile
    environment:
      - FLASK_ENV=testing
      - PYTHONPATH=/app/src:/app/meeting_shared
      - TESTING="true"
      - DATABASE_URL="sqlite:///:memory:"
      - REDIS_URL="redis://redis:6379/1"
      - JWT_SECRET_KEY=test-secret-key
      - SERVICE_KEY=test-service-key
    volumes:
      - ./meeting_shared:/app/meeting_shared
      - ./backend/flask-service/src:/app/src
      - ./backend/flask-service/tests:/app/tests
    command: pytest -v tests/

  auth-service-tests:
    build:
      context: .
      dockerfile: backend/auth-service/Dockerfile
    environment:
      - FLASK_ENV=testing
      - PYTHONPATH=/app/src:/app/meeting_shared
      - TESTING="true"
      - AUTH_DATABASE_URL="sqlite:///:memory:"
      - REDIS_URL="redis://redis:6379/1"
      - JWT_SECRET_KEY=test-secret-key
      - SERVICE_KEY=test-service-key
    volumes:
      - ./meeting_shared:/app/meeting_shared
      - ./backend/auth-service/src:/app/src
      - ./backend/auth-service/tests:/app/tests
    command: pytest -v tests/

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=meetingapp
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres123
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d meetingapp"]
      interval: 5s
      timeout: 5s
      retries: 5

  backend:
    image: test-backend-with-apscheduler
    command: python -c "import flask; print('Flask version:', flask.__version__); import flask_wtf; print('Flask-WTF version:', flask_wtf.__version__); import apscheduler; print('APScheduler version:', apscheduler.__version__); import sys; print(sys.path)"
    volumes:
      - ./backend/flask-service:/app
      - ./backend/shared:/app/shared
    environment:
      - PYTHONPATH=/app:/app/shared
    depends_on:
      - postgres
      - redis

  websocket:
    image: node:18-slim
    command: bash -c "cd /app && npm install && npm install prom-client && node -e \"console.log('Node version:', process.version); try { require('prom-client'); console.log('prom-client is installed'); } catch(e) { console.log('Error loading prom-client:', e.message); }; console.log('Keeping container alive...'); setInterval(() => {}, 1000);\""
    volumes:
      - ./backend/node-service:/app
    environment:
      - NODE_ENV=production
      - REDIS_URL=redis://:dev-redis-123@redis:6379/0
    depends_on:
      - redis 
```


### FILE: docker-compose.yml
```
version: '3.8'

services:
  # Databases
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 10s
      retries: 10

  auth-db:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=${AUTH_DB_NAME}
      - POSTGRES_USER=${AUTH_DB_USER}
      - POSTGRES_PASSWORD=${AUTH_DB_PASSWORD}
    ports:
      - "5433:5432"
    volumes:
      - auth_db_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${AUTH_DB_USER} -d ${AUTH_DB_NAME}"]
      interval: 10s
      timeout: 10s
      retries: 10

  redis:
    image: redis:7-alpine
    command: redis-server --requirepass ${REDIS_PASSWORD}
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 10s
      retries: 10

  # Backend Services
  auth-service:
    build:
      context: .
      dockerfile: backend/auth-service/Dockerfile
    environment:
      - FLASK_ENV=development
      - FLASK_DEBUG=1
      - SERVICE_TYPE=auth
      - AUTH_DB_USER=${AUTH_DB_USER}
      - AUTH_DB_PASSWORD=${AUTH_DB_PASSWORD}
      - AUTH_DB_NAME=${AUTH_DB_NAME}
      - AUTH_DATABASE_URL=${AUTH_DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - SERVICE_KEY=${SERVICE_KEY}
      - CORS_ORIGINS=${CORS_ORIGINS}
      - SMTP_SERVER=${SMTP_SERVER}
      - SMTP_PORT=${SMTP_PORT}
      - SMTP_USERNAME=${SMTP_USERNAME}
      - SMTP_PASSWORD=${SMTP_PASSWORD}
      - FRONTEND_URL=${FRONTEND_URL}
      - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
      - GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET}
      - PYTHONPATH=/app/src:/app/meeting_shared
    volumes:
      - ./meeting_shared:/app/meeting_shared
      - ./backend/auth-service/src:/app/src
      - auth_service_logs:/app/logs
    ports:
      - "5001:5001"
    depends_on:
      auth-db:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 30s

  backend:
    build:
      context: .
      dockerfile: backend/flask-service/Dockerfile
    volumes:
      - ./meeting_shared:/app/meeting_shared
      - ./backend/flask-service/src:/app/src
      - backend_logs:/app/logs
    ports:
      - "5000:5000"
    environment:
      - FLASK_ENV=development
      - FLASK_DEBUG=1
      - SERVICE_TYPE=flask
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - SERVICE_KEY=${SERVICE_KEY}
      - AUTH_SERVICE_URL=${AUTH_SERVICE_URL}
      - CORS_ORIGINS=${CORS_ORIGINS}
      - PYTHONPATH=/app/src:/app/meeting_shared
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      auth-service:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 30s

  websocket:
    build:
      context: ./backend/node-service
      dockerfile: Dockerfile
    volumes:
      - websocket_data:/app
      - websocket_logs:/app/logs
    ports:
      - "3001:3001"
    environment:
      - NODE_ENV=production
      - REDIS_URL=${REDIS_URL}
    depends_on:
      redis:
        condition: service_healthy
      backend:
        condition: service_started
    healthcheck:
      test: ["CMD", "/healthcheck.sh"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 30s

  # Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL}
        - NEXT_PUBLIC_AUTH_URL=${NEXT_PUBLIC_AUTH_URL}
        - NEXT_PUBLIC_WS_URL=${NEXT_PUBLIC_WS_URL}
        - NEXT_PUBLIC_BASE_URL=${NEXT_PUBLIC_BASE_URL}
        - NEXT_PUBLIC_GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
        - NEXT_PUBLIC_APP_NAME="Meeting App"
        - NEXT_PUBLIC_APP_VERSION=1.0.0
        - NEXT_PUBLIC_ENABLE_ANALYTICS=false
        - NEXT_PUBLIC_ENABLE_DEBUG_TOOLS=false
        - NEXT_PUBLIC_API_TIMEOUT_MS=30000
        - NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS=5000
        - NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB=5
    environment:
      - NODE_ENV=production
      - PORT=3000
      - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL}
      - NEXT_PUBLIC_WS_URL=${NEXT_PUBLIC_WS_URL}
      - NEXT_PUBLIC_AUTH_URL=${NEXT_PUBLIC_AUTH_URL}
      - NEXT_PUBLIC_BASE_URL=${NEXT_PUBLIC_BASE_URL}
      - NEXT_PUBLIC_GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
      - NEXT_PUBLIC_APP_NAME="Meeting App"
      - NEXT_PUBLIC_APP_VERSION=1.0.0
      - NEXT_PUBLIC_ENABLE_ANALYTICS=false
      - NEXT_PUBLIC_ENABLE_DEBUG_TOOLS=false
      - NEXT_PUBLIC_API_TIMEOUT_MS=30000
      - NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS=5000
      - NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB=5
      - HOST=0.0.0.0
    command: node server.js
    ports:
      - "3000:3000"
    depends_on:
      backend:
        condition: service_started
      websocket:
        condition: service_started
      auth-service:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s

  # Monitoring
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./monitoring/prometheus:/etc/prometheus:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    ports:
      - "9090:9090"
    depends_on:
      - backend
      - auth-service

  grafana:
    image: grafana/grafana:latest
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - grafana_data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    ports:
      - "3003:3000"
    depends_on:
      - prometheus

volumes:
  postgres_data:
  auth_db_data:
  redis_data:
  auth_service_data:
  backend_data:
  auth_service_logs:
  backend_logs:
  websocket_data:
  websocket_logs:
  frontend_data:
  frontend_node_modules:
  frontend_next:
  prometheus_data:
  grafana_data: 
```


### FILE: migrate.ps1
```
# migrate.ps1 - Database migration management for the meeting application

param (
    [switch]$ShowCurrent,
    [switch]$Upgrade,
    [switch]$Merge,
    [switch]$ForceInit
)

function Show-Help {
    Write-Host "Database Migration Management Script" -ForegroundColor Cyan
    Write-Host "Usage: ./migrate.ps1 [options]" -ForegroundColor Cyan
    Write-Host ""
    Write-Host "Options:" -ForegroundColor Yellow
    Write-Host "  -ShowCurrent  : Show current migration versions" -ForegroundColor Gray
    Write-Host "  -Upgrade      : Apply all pending migrations" -ForegroundColor Gray
    Write-Host "  -Merge        : Merge migration heads if multiple heads exist" -ForegroundColor Gray
    Write-Host "  -ForceInit    : Force initialize migrations if they don't exist" -ForegroundColor Gray
    Write-Host ""
    Write-Host "Example: ./migrate.ps1 -Upgrade" -ForegroundColor Green
}

# Check if any param was passed, otherwise show help
if (-not ($ShowCurrent -or $Upgrade -or $Merge -or $ForceInit)) {
    Show-Help
    exit 0
}

# Show current migration versions
if ($ShowCurrent) {
    Write-Host "Checking current migration state for backend..." -ForegroundColor Green
    docker-compose exec -T backend flask db current
    
    Write-Host "Checking current migration state for auth-service..." -ForegroundColor Green
    docker-compose exec -T auth-service flask db current
}

# Force initialize migrations if they don't exist
if ($ForceInit) {
    Write-Host "Force initializing migrations for backend (if needed)..." -ForegroundColor Yellow
    docker-compose exec -T backend bash -c "if [ ! -f migrations/alembic.ini ]; then flask db init; fi"
    
    Write-Host "Force initializing migrations for auth-service (if needed)..." -ForegroundColor Yellow
    docker-compose exec -T auth-service bash -c "if [ ! -f migrations/alembic.ini ]; then flask db init; fi"
}

# Merge migration heads if multiple heads exist
if ($Merge) {
    Write-Host "Merging migration heads for backend..." -ForegroundColor Yellow
    docker-compose exec -T backend flask db merge heads -m "merge_migration_heads"
    
    Write-Host "Merging migration heads for auth-service..." -ForegroundColor Yellow
    docker-compose exec -T auth-service flask db merge heads -m "merge_migration_heads"
}

# Apply all pending migrations
if ($Upgrade) {
    Write-Host "Applying pending migrations for backend..." -ForegroundColor Green
    docker-compose exec -T backend flask db upgrade
    
    Write-Host "Applying pending migrations for auth-service..." -ForegroundColor Green
    docker-compose exec -T auth-service flask db upgrade
}

Write-Host "Migration operations completed" -ForegroundColor Cyan 
```


### FILE: migrate.sh
```
#!/bin/bash
# migrate.sh - Database migration management for the meeting application

# Initialize flags
SHOW_CURRENT=false
UPGRADE=false
MERGE=false
FORCE_INIT=false

# Parse arguments
for arg in "$@"; do
  case $arg in
    --show-current)
      SHOW_CURRENT=true
      ;;
    --upgrade)
      UPGRADE=true
      ;;
    --merge)
      MERGE=true
      ;;
    --force-init)
      FORCE_INIT=true
      ;;
    --help)
      echo -e "\e[36mDatabase Migration Management Script\e[0m"
      echo -e "\e[36mUsage: ./migrate.sh [options]\e[0m"
      echo ""
      echo -e "\e[33mOptions:\e[0m"
      echo -e "\e[90m  --show-current : Show current migration versions\e[0m"
      echo -e "\e[90m  --upgrade      : Apply all pending migrations\e[0m"
      echo -e "\e[90m  --merge        : Merge migration heads if multiple heads exist\e[0m"
      echo -e "\e[90m  --force-init   : Force initialize migrations if they don't exist\e[0m"
      echo ""
      echo -e "\e[32mExample: ./migrate.sh --upgrade\e[0m"
      exit 0
      ;;
  esac
done

# If no arguments provided, show help
if [[ "$SHOW_CURRENT" == "false" && "$UPGRADE" == "false" && "$MERGE" == "false" && "$FORCE_INIT" == "false" ]]; then
  echo -e "\e[36mDatabase Migration Management Script\e[0m"
  echo -e "\e[36mUsage: ./migrate.sh [options]\e[0m"
  echo ""
  echo -e "\e[33mOptions:\e[0m"
  echo -e "\e[90m  --show-current : Show current migration versions\e[0m"
  echo -e "\e[90m  --upgrade      : Apply all pending migrations\e[0m"
  echo -e "\e[90m  --merge        : Merge migration heads if multiple heads exist\e[0m"
  echo -e "\e[90m  --force-init   : Force initialize migrations if they don't exist\e[0m"
  echo ""
  echo -e "\e[32mExample: ./migrate.sh --upgrade\e[0m"
  exit 0
fi

# Show current migration versions
if [[ "$SHOW_CURRENT" == "true" ]]; then
  echo -e "\e[32mChecking current migration state for backend...\e[0m"
  docker-compose exec -T backend flask db current
  
  echo -e "\e[32mChecking current migration state for auth-service...\e[0m"
  docker-compose exec -T auth-service flask db current
fi

# Force initialize migrations if they don't exist
if [[ "$FORCE_INIT" == "true" ]]; then
  echo -e "\e[33mForce initializing migrations for backend (if needed)...\e[0m"
  docker-compose exec -T backend bash -c "if [ ! -f migrations/alembic.ini ]; then flask db init; fi"
  
  echo -e "\e[33mForce initializing migrations for auth-service (if needed)...\e[0m"
  docker-compose exec -T auth-service bash -c "if [ ! -f migrations/alembic.ini ]; then flask db init; fi"
fi

# Merge migration heads if multiple heads exist
if [[ "$MERGE" == "true" ]]; then
  echo -e "\e[33mMerging migration heads for backend...\e[0m"
  docker-compose exec -T backend flask db merge heads -m "merge_migration_heads"
  
  echo -e "\e[33mMerging migration heads for auth-service...\e[0m"
  docker-compose exec -T auth-service flask db merge heads -m "merge_migration_heads"
fi

# Apply all pending migrations
if [[ "$UPGRADE" == "true" ]]; then
  echo -e "\e[32mApplying pending migrations for backend...\e[0m"
  docker-compose exec -T backend flask db upgrade
  
  echo -e "\e[32mApplying pending migrations for auth-service...\e[0m"
  docker-compose exec -T auth-service flask db upgrade
fi

echo -e "\e[36mMigration operations completed\e[0m" 
```


### FILE: rebuild_docker.ps1
```
# Stop and remove all containers
Write-Host "Stopping and removing all containers..." -ForegroundColor Green
docker-compose down

# Remove all images related to the project
Write-Host "Removing all project images..." -ForegroundColor Green
docker rmi fullstackmeetingappwithlogin-backend fullstackmeetingappwithlogin-auth-service fullstackmeetingappwithlogin-frontend fullstackmeetingappwithlogin-websocket -f

# Clean Docker build cache
Write-Host "Cleaning Docker build cache..." -ForegroundColor Green
docker builder prune -f

# Rebuild all images without cache
Write-Host "Rebuilding all images without cache..." -ForegroundColor Green
docker-compose build --no-cache

# Start all services
Write-Host "Starting all services..." -ForegroundColor Green
docker-compose up -d

# Display container status
Write-Host "Container status:" -ForegroundColor Green
docker-compose ps

Write-Host "Rebuild complete! Check logs with 'docker-compose logs -f'" -ForegroundColor Green 
```


### FILE: run-integration-tests.ps1
```
# PowerShell script to run integration tests for all services
# Usage: .\run-integration-tests.ps1 [service]
# If service is specified, only run tests for that service

param (
    [string]$Service = ""
)

# Set error action preference
$ErrorActionPreference = "Stop"

# Function to display colored output
function Write-ColorOutput {
    param (
        [string]$Message,
        [string]$Color = "White"
    )
    Write-Host $Message -ForegroundColor $Color
}

# Function to run tests for a specific service
function Invoke-ServiceTests {
    param (
        [string]$ServiceName,
        [string]$Directory
    )
    
    Write-ColorOutput "Running integration tests for $ServiceName..." "Cyan"
    
    # Check if directory exists
    if (-not (Test-Path $Directory)) {
        Write-ColorOutput "Directory not found: $Directory" "Yellow"
        return $false
    }
    
    # Check if tests directory exists
    $TestsDir = Join-Path $Directory "tests\integration"
    if (-not (Test-Path $TestsDir)) {
        Write-ColorOutput "Tests directory not found: $TestsDir" "Yellow"
        return $false
    }
    
    # Run the tests
    try {
        Push-Location $Directory
        Write-ColorOutput "Running tests in $Directory..." "Cyan"
        
        # Install test dependencies if needed
        if (Test-Path "requirements.txt") {
            Write-ColorOutput "Installing dependencies..." "Cyan"
            python -m pip install -r requirements.txt
        }
        
        # Run pytest
        python -m pytest tests\integration -v
        $TestResult = $LASTEXITCODE
        
        if ($TestResult -eq 0) {
            Write-ColorOutput "âœ… $ServiceName tests passed!" "Green"
            return $true
        } else {
            Write-ColorOutput "âŒ $ServiceName tests failed!" "Red"
            return $false
        }
    } catch {
        Write-ColorOutput "Error running tests: $_" "Red"
        return $false
    } finally {
        Pop-Location
    }
}

# Main script
Write-ColorOutput "=== Running Integration Tests ===" "Magenta"

# Check Python installation
try {
    $PythonVersion = python --version
    Write-ColorOutput "Using $PythonVersion" "Cyan"
} catch {
    Write-ColorOutput "Python not found. Please install Python 3.8 or higher." "Red"
    exit 1
}

# Initialize results tracking
$AllPassed = $true
$Services = @{
    "auth-service" = "backend\auth-service";
    "backend" = "backend\flask-service";
}

# Run tests for specific service or all services
if ($Service) {
    if ($Services.ContainsKey($Service)) {
        $Directory = $Services[$Service]
        $Passed = Invoke-ServiceTests -ServiceName $Service -Directory $Directory
        $AllPassed = $AllPassed -and $Passed
    } else {
        Write-ColorOutput "Unknown service: $Service" "Red"
        Write-ColorOutput "Available services: $($Services.Keys -join ', ')" "Yellow"
        exit 1
    }
} else {
    # Run tests for all services
    foreach ($ServiceItem in $Services.GetEnumerator()) {
        $Passed = Invoke-ServiceTests -ServiceName $ServiceItem.Key -Directory $ServiceItem.Value
        $AllPassed = $AllPassed -and $Passed
    }
}

# Display final results
Write-ColorOutput "`n=== Integration Test Results ===" "Magenta"
if ($AllPassed) {
    Write-ColorOutput "âœ… All integration tests passed!" "Green"
    exit 0
} else {
    Write-ColorOutput "âŒ Some integration tests failed!" "Red"
    exit 1
} 
```


### FILE: run-integration-tests.sh
```
#!/bin/bash
# Bash script to run integration tests for all services
# Usage: ./run-integration-tests.sh [service]
# If service is specified, only run tests for that service

# Exit on error
set -e

# Function to display colored output
function print_color() {
    local color=$1
    local message=$2
    
    case $color in
        "red")
            echo -e "\033[0;31m$message\033[0m"
            ;;
        "green")
            echo -e "\033[0;32m$message\033[0m"
            ;;
        "yellow")
            echo -e "\033[0;33m$message\033[0m"
            ;;
        "blue")
            echo -e "\033[0;34m$message\033[0m"
            ;;
        "magenta")
            echo -e "\033[0;35m$message\033[0m"
            ;;
        "cyan")
            echo -e "\033[0;36m$message\033[0m"
            ;;
        *)
            echo "$message"
            ;;
    esac
}

# Function to run tests for a specific service
function run_service_tests() {
    local service_name=$1
    local directory=$2
    
    print_color "cyan" "Running integration tests for $service_name..."
    
    # Check if directory exists
    if [ ! -d "$directory" ]; then
        print_color "yellow" "Directory not found: $directory"
        return 1
    fi
    
    # Check if tests directory exists
    local tests_dir="$directory/tests/integration"
    if [ ! -d "$tests_dir" ]; then
        print_color "yellow" "Tests directory not found: $tests_dir"
        return 1
    fi
    
    # Run the tests
    pushd "$directory" > /dev/null
    print_color "cyan" "Running tests in $directory..."
    
    # Install test dependencies if needed
    if [ -f "requirements.txt" ]; then
        print_color "cyan" "Installing dependencies..."
        python -m pip install -r requirements.txt
    fi
    
    # Run pytest
    python -m pytest tests/integration -v
    local test_result=$?
    
    if [ $test_result -eq 0 ]; then
        print_color "green" "âœ… $service_name tests passed!"
        popd > /dev/null
        return 0
    else
        print_color "red" "âŒ $service_name tests failed!"
        popd > /dev/null
        return 1
    fi
}

# Main script
print_color "magenta" "=== Running Integration Tests ==="

# Check Python installation
if ! command -v python &> /dev/null; then
    print_color "red" "Python not found. Please install Python 3.8 or higher."
    exit 1
fi

python_version=$(python --version)
print_color "cyan" "Using $python_version"

# Initialize results tracking
all_passed=true
declare -A services
services["auth-service"]="backend/auth-service"
services["backend"]="backend/flask-service"

# Run tests for specific service or all services
if [ $# -gt 0 ]; then
    service=$1
    if [ -n "${services[$service]}" ]; then
        directory=${services[$service]}
        if ! run_service_tests "$service" "$directory"; then
            all_passed=false
        fi
    else
        print_color "red" "Unknown service: $service"
        print_color "yellow" "Available services: ${!services[*]}"
        exit 1
    fi
else
    # Run tests for all services
    for service in "${!services[@]}"; do
        directory=${services[$service]}
        if ! run_service_tests "$service" "$directory"; then
            all_passed=false
        fi
    done
fi

# Display final results
print_color "magenta" $'\n=== Integration Test Results ==='
if $all_passed; then
    print_color "green" "âœ… All integration tests passed!"
    exit 0
else
    print_color "red" "âŒ Some integration tests failed!"
    exit 1
fi 
```


### FILE: run_tests.ps1
```
param(
    [switch]$coverage,
    [switch]$unit,
    [switch]$integration,
    [string]$service,
    [switch]$rebuild
)

# Function to show help
function Show-Help {
    Write-Host @"
Test Runner Script
Usage: ./run_tests.ps1 [-coverage] [-unit] [-integration] [-service <name>] [-rebuild]

Options:
  -coverage      Run tests with coverage report
  -unit          Run only unit tests
  -integration   Run only integration tests
  -service       Specify service to test (auth-service or flask-service)
  -rebuild       Rebuild containers before running tests

Examples:
  ./run_tests.ps1                     # Run all tests
  ./run_tests.ps1 -coverage           # Run all tests with coverage
  ./run_tests.ps1 -unit -service auth # Run auth service unit tests
  ./run_tests.ps1 -rebuild            # Rebuild and run all tests
"@
    exit
}

# Show help if no arguments provided
if ($args.Count -eq 0 -and -not $coverage -and -not $unit -and -not $integration -and -not $service -and -not $rebuild) {
    Show-Help
}

# Base command
$cmd = "docker-compose -f docker-compose.test.yml"

# Add rebuild flag if specified
if ($rebuild) {
    $cmd += " build"
}

# Prepare test command based on flags
$test_cmd = "pytest -v"
if ($coverage) {
    $test_cmd += " --cov=src --cov=meeting_shared --cov-report=term-missing --cov-report=html"
}
if ($unit) {
    $test_cmd += " tests/unit/"
}
if ($integration) {
    $test_cmd += " tests/integration/"
}

# Run tests based on service flag
if ($service) {
    switch ($service) {
        "auth" {
            Write-Host "Running auth-service tests..."
            Invoke-Expression "$cmd run auth-service-tests $test_cmd"
        }
        "flask" {
            Write-Host "Running flask-service tests..."
            Invoke-Expression "$cmd run flask-service-tests $test_cmd"
        }
        default {
            Write-Host "Invalid service specified. Use 'auth' or 'flask'."
            exit 1
        }
    }
} else {
    # Run all services
    Write-Host "Running all tests..."
    Invoke-Expression "$cmd up --abort-on-container-exit"
} 
```


### FILE: run_tests.sh
```
 
```


### FILE: setup.ps1
```
# Function to check if a command exists
function Test-Command {
    param($Command)
    $oldPreference = $ErrorActionPreference
    $ErrorActionPreference = 'stop'
    try { if (Get-Command $Command) { return $true } }
    catch { return $false }
    finally { $ErrorActionPreference = $oldPreference }
}

# Function to wait for service health
function Wait-ServiceHealth {
    param($Service)
    $maxAttempts = 30
    $attempt = 1

    Write-Host "Waiting for $Service to be healthy..."
    while ($attempt -le $maxAttempts) {
        $status = docker-compose ps $Service | Select-String "healthy"
        if ($status) {
            Write-Host "$Service is healthy!" -ForegroundColor Green
            return $true
        }
        Write-Host "Attempt $attempt of $maxAttempts`: $Service is not ready yet..."
        Start-Sleep -Seconds 5
        $attempt++
    }
    Write-Host "Error: $Service failed to become healthy" -ForegroundColor Red
    return $false
}

# Check for required tools
Write-Host "Checking required tools..." -ForegroundColor Cyan
$requiredTools = @("docker", "docker-compose", "node", "npm")
foreach ($tool in $requiredTools) {
    if (-not (Test-Command $tool)) {
        Write-Host "Error: $tool is not installed" -ForegroundColor Red
        exit 1
    }
}
Write-Host "All required tools are installed" -ForegroundColor Green

# Create .env file if it doesn't exist
if (-not (Test-Path .env)) {
    Write-Host "Creating .env file from template..." -ForegroundColor Cyan
    Copy-Item .env.example .env
    Write-Host "Created .env file. Please update it with your configurations." -ForegroundColor Yellow
}

# Create necessary directories
Write-Host "Creating necessary directories..." -ForegroundColor Cyan
$directories = @(
    "logs",
    "logs/auth-service",
    "logs/backend",
    "logs/websocket",
    "data/postgres",
    "data/redis",
    "data/auth-db"
)

foreach ($dir in $directories) {
    if (-not (Test-Path $dir)) {
        New-Item -ItemType Directory -Path $dir | Out-Null
        Write-Host "Created directory: $dir" -ForegroundColor Green
    }
}

# Stop any running containers
Write-Host "Stopping any existing containers..." -ForegroundColor Cyan
docker-compose down

# Build and start core services first
Write-Host "Starting core services..." -ForegroundColor Cyan
docker-compose up -d postgres redis auth-db
Start-Sleep -Seconds 10

# Wait for core services
$coreServices = @("postgres", "redis", "auth-db")
foreach ($service in $coreServices) {
    if (-not (Wait-ServiceHealth $service)) {
        Write-Host "Error: Failed to start core service $service" -ForegroundColor Red
        docker-compose logs $service
        docker-compose down
        exit 1
    }
}

# Start auth service
Write-Host "Starting auth service..." -ForegroundColor Cyan
docker-compose up -d auth-service
if (-not (Wait-ServiceHealth "auth-service")) {
    Write-Host "Error: Failed to start auth-service" -ForegroundColor Red
    docker-compose logs auth-service
    docker-compose down
    exit 1
}

# Run auth service migrations
Write-Host "Running auth service migrations..." -ForegroundColor Cyan
docker-compose exec -T auth-service flask db upgrade
if ($LASTEXITCODE -ne 0) {
    Write-Host "Error: Auth service migrations failed" -ForegroundColor Red
    exit 1
}

# Start remaining services
Write-Host "Starting remaining services..." -ForegroundColor Cyan
docker-compose up -d backend websocket frontend

# Wait for remaining services
$remainingServices = @("backend", "websocket", "frontend")
foreach ($service in $remainingServices) {
    if (-not (Wait-ServiceHealth $service)) {
        Write-Host "Error: Failed to start $service" -ForegroundColor Red
        docker-compose logs $service
        docker-compose down
        exit 1
    }
}

# Run backend migrations
Write-Host "Running backend migrations..." -ForegroundColor Cyan
docker-compose exec -T backend flask db upgrade
if ($LASTEXITCODE -ne 0) {
    Write-Host "Error: Backend migrations failed" -ForegroundColor Red
    exit 1
}

Write-Host @"

ğŸ‰ Setup completed successfully! ğŸ‰

Application URLs:
- Frontend: http://localhost:3000
- Backend API: http://localhost:5000
- Auth Service: http://localhost:5001
- WebSocket: ws://localhost:3001
- Metrics: http://localhost:9090

Useful commands:
- View logs: docker-compose logs -f
- Stop services: docker-compose down
- Restart services: docker-compose restart
- View specific service logs: docker-compose logs -f [service_name]

"@ -ForegroundColor Green 
```


### FILE: setup.sh
```
#!/bin/bash

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Function to check if a command exists
command_exists() {
    command -v "$1" >/dev/null 2>&1
}

# Function to wait for service health
wait_for_service() {
    local service=$1
    local max_attempts=30
    local attempt=1

    echo -e "${CYAN}Waiting for $service to be healthy...${NC}"
    while [ $attempt -le $max_attempts ]; do
        if docker-compose ps "$service" | grep -q "healthy"; then
            echo -e "${GREEN}$service is healthy!${NC}"
            return 0
        fi
        echo "Attempt $attempt/$max_attempts: $service is not ready yet..."
        sleep 5
        attempt=$((attempt + 1))
    done
    echo -e "${RED}Error: $service failed to become healthy${NC}"
    return 1
}

# Check for required tools
echo -e "${CYAN}Checking required tools...${NC}"
required_tools=("docker" "docker-compose" "node" "npm")
for tool in "${required_tools[@]}"; do
    if ! command_exists "$tool"; then
        echo -e "${RED}Error: $tool is not installed${NC}"
        exit 1
    fi
done
echo -e "${GREEN}All required tools are installed${NC}"

# Create .env file if it doesn't exist
if [ ! -f .env ]; then
    echo -e "${CYAN}Creating .env file from template...${NC}"
    cp .env.example .env
    echo -e "${YELLOW}Created .env file. Please update it with your configurations.${NC}"
fi

# Create necessary directories
echo -e "${CYAN}Creating necessary directories...${NC}"
directories=(
    "logs"
    "logs/auth-service"
    "logs/backend"
    "logs/websocket"
    "data/postgres"
    "data/redis"
    "data/auth-db"
)

for dir in "${directories[@]}"; do
    if [ ! -d "$dir" ]; then
        mkdir -p "$dir"
        echo -e "${GREEN}Created directory: $dir${NC}"
    fi
done

# Stop any running containers
echo -e "${CYAN}Stopping any existing containers...${NC}"
docker-compose down

# Build and start core services first
echo -e "${CYAN}Starting core services...${NC}"
docker-compose up -d postgres redis auth-db
sleep 10

# Wait for core services
core_services=("postgres" "redis" "auth-db")
for service in "${core_services[@]}"; do
    if ! wait_for_service "$service"; then
        echo -e "${RED}Error: Failed to start core service $service${NC}"
        docker-compose logs "$service"
        docker-compose down
        exit 1
    fi
done

# Start auth service
echo -e "${CYAN}Starting auth service...${NC}"
docker-compose up -d auth-service
if ! wait_for_service "auth-service"; then
    echo -e "${RED}Error: Failed to start auth-service${NC}"
    docker-compose logs auth-service
    docker-compose down
    exit 1
fi

# Run auth service migrations
echo -e "${CYAN}Running auth service migrations...${NC}"
if ! docker-compose exec -T auth-service flask db upgrade; then
    echo -e "${RED}Error: Auth service migrations failed${NC}"
    exit 1
fi

# Start remaining services
echo -e "${CYAN}Starting remaining services...${NC}"
docker-compose up -d backend websocket frontend

# Wait for remaining services
remaining_services=("backend" "websocket" "frontend")
for service in "${remaining_services[@]}"; do
    if ! wait_for_service "$service"; then
        echo -e "${RED}Error: Failed to start $service${NC}"
        docker-compose logs "$service"
        docker-compose down
        exit 1
    fi
done

# Run backend migrations
echo -e "${CYAN}Running backend migrations...${NC}"
if ! docker-compose exec -T backend flask db upgrade; then
    echo -e "${RED}Error: Backend migrations failed${NC}"
    exit 1
fi

# Print success message
echo -e "${GREEN}
ğŸ‰ Setup completed successfully! ğŸ‰

Application URLs:
- Frontend: http://localhost:3000
- Backend API: http://localhost:5000
- Auth Service: http://localhost:5001
- WebSocket: ws://localhost:3001
- Metrics: http://localhost:9090

Useful commands:
- View logs: docker-compose logs -f
- Stop services: docker-compose down
- Restart services: docker-compose restart
- View specific service logs: docker-compose logs -f [service_name]
${NC}" 
```


### FILE: start.ps1
```
# Start.ps1 - Enforces the correct startup sequence for the meeting application

Write-Host "Starting database services..." -ForegroundColor Green
docker-compose up -d postgres auth-db redis
Write-Host "Waiting for database services to be ready (15 seconds)..." -ForegroundColor Yellow
Start-Sleep -Seconds 15

Write-Host "Starting authentication service..." -ForegroundColor Green
docker-compose up -d auth-service
Write-Host "Waiting for authentication service to initialize (10 seconds)..." -ForegroundColor Yellow
Start-Sleep -Seconds 10

Write-Host "Starting backend service..." -ForegroundColor Green
docker-compose up -d backend
Write-Host "Waiting for backend service to initialize (10 seconds)..." -ForegroundColor Yellow
Start-Sleep -Seconds 10

Write-Host "Starting websocket service..." -ForegroundColor Green
docker-compose up -d websocket
Write-Host "Waiting for websocket service to initialize (5 seconds)..." -ForegroundColor Yellow
Start-Sleep -Seconds 5

Write-Host "Starting frontend service..." -ForegroundColor Green
docker-compose up -d frontend

Write-Host "Starting monitoring services..." -ForegroundColor Green
docker-compose up -d prometheus grafana

Write-Host "All services started. Check status with: docker-compose ps" -ForegroundColor Cyan
docker-compose ps

Write-Host "Application is now available at:" -ForegroundColor Green
Write-Host "  Frontend: http://localhost:3000" -ForegroundColor Cyan
Write-Host "  Backend API: http://localhost:5000" -ForegroundColor Cyan
Write-Host "  Auth API: http://localhost:5001" -ForegroundColor Cyan
Write-Host "  WebSocket: http://localhost:3001" -ForegroundColor Cyan
Write-Host "  Prometheus: http://localhost:9090" -ForegroundColor Cyan
Write-Host "  Grafana: http://localhost:3002" -ForegroundColor Cyan 
```


### FILE: start.sh
```
#!/bin/bash
# start.sh - Enforces the correct startup sequence for the meeting application

echo -e "\e[32mStarting database services...\e[0m"
docker-compose up -d postgres auth-db redis
echo -e "\e[33mWaiting for database services to be ready (15 seconds)...\e[0m"
sleep 15

echo -e "\e[32mStarting authentication service...\e[0m"
docker-compose up -d auth-service
echo -e "\e[33mWaiting for authentication service to initialize (10 seconds)...\e[0m"
sleep 10

echo -e "\e[32mStarting backend service...\e[0m"
docker-compose up -d backend
echo -e "\e[33mWaiting for backend service to initialize (10 seconds)...\e[0m"
sleep 10

echo -e "\e[32mStarting websocket service...\e[0m"
docker-compose up -d websocket
echo -e "\e[33mWaiting for websocket service to initialize (5 seconds)...\e[0m"
sleep 5

echo -e "\e[32mStarting frontend service...\e[0m"
docker-compose up -d frontend

echo -e "\e[32mStarting monitoring services...\e[0m"
docker-compose up -d prometheus grafana

echo -e "\e[36mAll services started. Check status with: docker-compose ps\e[0m"
docker-compose ps

echo -e "\e[32mApplication is now available at:\e[0m"
echo -e "\e[36m  Frontend: http://localhost:3000\e[0m"
echo -e "\e[36m  Backend API: http://localhost:5000\e[0m"
echo -e "\e[36m  Auth API: http://localhost:5001\e[0m"
echo -e "\e[36m  WebSocket: http://localhost:3001\e[0m"
echo -e "\e[36m  Prometheus: http://localhost:9090\e[0m"
echo -e "\e[36m  Grafana: http://localhost:3002\e[0m" 
```


### FILE: start.txt
```
# Build all services
docker-compose build

# Start the core services first
docker-compose up -d postgres auth-db redis

# Wait for about 10 seconds for databases to initialize
sleep 10

# Start the auth service
docker-compose up -d auth-service

# Wait for auth service to be ready
sleep 10

# Start remaining services
docker-compose up -d backend websocket frontend

# Wait for all services to be ready
sleep 10

# Start monitoring services
docker-compose up -d prometheus grafana

# Wait for monitoring services to be ready
sleep 10

```


### FILE: test-backend.dockerfile
```
FROM python:3.11-slim

WORKDIR /app

RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    postgresql-client \
    curl \
    && rm -rf /var/lib/apt/lists/*

COPY backend/flask-service/requirements.txt .
RUN pip install --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

ENV PYTHONPATH=/app:/app/shared
ENV FLASK_APP=src.app
ENV FLASK_DEBUG=1

CMD ["python", "-c", "import sys; print(sys.path); from flask import Flask; print('Flask version:', Flask.__version__); import flask_wtf; print('Flask-WTF version:', flask_wtf.__version__)"] 
```


### FILE: test-websocket.dockerfile
```
FROM node:18-slim

WORKDIR /app

RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    curl \
    && rm -rf /var/lib/apt/lists/*

COPY backend/node-service/package.json .
RUN npm install && \
    npm install prom-client && \
    npm cache clean --force

ENV NODE_ENV=production
ENV PORT=3001

CMD ["node", "-e", "console.log('Node version:', process.version); try { require('prom-client'); console.log('prom-client is installed'); } catch(e) { console.log('Error loading prom-client:', e.message); }"] 
```


### FILE: verify_system.bat
```
@echo off
echo ===== Meeting App System Verification =====
echo.

echo Step 1: Verifying database connections...
python scripts\verify_db.py
if %ERRORLEVEL% NEQ 0 (
    echo Database verification failed!
    exit /b 1
)

echo.
echo Step 2: Verifying meeting CRUD operations...
python scripts\verify_meeting_crud.py
if %ERRORLEVEL% NEQ 0 (
    echo Meeting CRUD verification failed!
    exit /b 1
)

echo.
echo Step 3: Verifying JWT authentication flow...
python scripts\verify_auth_flow.py
if %ERRORLEVEL% NEQ 0 (
    echo Authentication flow verification failed!
    exit /b 1
)

echo.
echo ===== All verifications passed successfully! =====
exit /b 0 
```


### FILE: .pytest_cache\.gitignore
```
# Created by pytest automatically.
*

```


### FILE: .pytest_cache\CACHEDIR.TAG
```
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag created by pytest.
# For information about cache directory tags, see:
#	https://bford.info/cachedir/spec.html

```


### FILE: .pytest_cache\README.md
```
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.

```


### FILE: backend\pytest.ini
```
[pytest]
# Test discovery settings
testpaths = auth-service/tests flask-service/tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Test output settings
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(message)s (%(filename)s:%(lineno)s)
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Test execution settings
addopts = 
    --verbose
    --strict-markers
    # Coverage settings
    --cov=.
    --cov-report=term
    --cov-report=html:.coverage_html
    # JUnit XML report for CI integration
    --junitxml=test-results.xml
    # Output test durations
    --durations=10

# Markers
markers =
    unit: Unit tests
    integration: Integration tests
    slow: Tests that are slow to execute
    auth: Authentication-related tests
    meetings: Meeting-related tests
    api: API endpoint tests
    service: Service layer tests
    utils: Utility function tests
    model: Data model tests
    error: Error handling tests
    logging: Logging-related tests
    middleware: Middleware-related tests
    schema: Schema-related tests

# Fail on warnings
filterwarnings =
    error
    # Ignore specific warnings as needed
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::ImportWarning

# Cache
cache_dir = .pytest_cache 
```


### FILE: backend\requirements.txt
```
Flask==2.2.5
Flask-SQLAlchemy==3.0.5
Flask-Migrate==4.0.4
Flask-Cors==4.0.0
psycopg2-binary==2.9.7
python-dotenv==1.0.0
PyJWT==2.8.0
bcrypt==4.0.1
gunicorn==21.2.0
python-jose==3.3.0
email-validator>=2.1.0
redis==5.0.0
bleach==6.0.0
google-auth-oauthlib==1.0.0
requests==2.31.0
pydantic>=2.5.2
marshmallow==3.20.1
Flask-WTF==1.1.1
Werkzeug==2.2.3
APScheduler==3.10.4
psutil==5.9.5
pytest==7.4.0
pytest-cov==4.1.0
sentry-sdk[flask]==1.28.1
structlog==23.1.0
logging-formatter-anticrlf==1.2.1 
```


### FILE: backend\.pytest_cache\.gitignore
```
# Created by pytest automatically.
*

```


### FILE: backend\.pytest_cache\CACHEDIR.TAG
```
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag created by pytest.
# For information about cache directory tags, see:
#	https://bford.info/cachedir/spec.html

```


### FILE: backend\.pytest_cache\README.md
```
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.

```


### FILE: backend\auth-service\.dockerignore
```
# Git
.git
.gitignore

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
*.egg-info/
.installed.cfg
*.egg

# Docker
docker-compose*
.dockerignore

# IDE
.idea/
.vscode/
*.swp
*.swo

# Logs
logs/
*.log

# Data
data/
**/*.pyc
venv/
.pytest_cache/
.coverage 
```


### FILE: backend\auth-service\.env.example
```
# Database
AUTH_DATABASE_URL=postgresql://postgres:postgres@localhost:5432/auth_db

# JWT
JWT_SECRET_KEY=your-secret-key-here

# Google OAuth
GOOGLE_CLIENT_ID=your-google-client-id
GOOGLE_CLIENT_SECRET=your-google-client-secret

# Redis (for session management)
REDIS_URL=redis://localhost:6379/0

# Email Configuration
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-specific-password
FRONTEND_URL=http://localhost:3000

# Service Integration
FLASK_SERVICE_URL=http://backend:5000
SERVICE_SYNC_ENABLED=true

# Service
PORT=5001
FLASK_ENV=development
FLASK_APP=src/app.py 
```


### FILE: backend\auth-service\Dockerfile
```
FROM python:3.9-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    build-essential \
    curl \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# Create necessary directories
RUN mkdir -p /app/meeting_shared /app/src /app/logs

# Copy requirements first to leverage Docker cache
COPY backend/auth-service/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Set environment variables
ENV PYTHONPATH=/app/src:/app/meeting_shared
ENV FLASK_APP=src/app.py
ENV FLASK_ENV=development
ENV SERVICE_TYPE=auth

# Create entrypoint script
COPY backend/auth-service/scripts/entrypoint.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=15s --retries=3 \
    CMD curl -f http://localhost:5001/health || exit 1

EXPOSE 5001

# Use entrypoint script
ENTRYPOINT ["/entrypoint.sh"] 
```


### FILE: backend\auth-service\alembic.ini
```
[alembic]
script_location = migrations
# Let the application handle the database URL
sqlalchemy.url = 

[post_write_hooks]
hooks = black
black.type = console_scripts
black.entrypoint = black
black.options = -l 79 REVISION_SCRIPT_FILENAME

[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S 
```


### FILE: backend\auth-service\pytest.ini
```
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Environment variables for testing
env =
    FLASK_ENV=testing
    PYTHONPATH=src:../../meeting_shared
    TESTING=true
    AUTH_DATABASE_URL=sqlite:///:memory:
    REDIS_URL=redis://localhost:6379/1
    JWT_SECRET_KEY=test-secret-key
    SERVICE_KEY=test-service-key

# Logging configuration
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)s] %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Test collection settings
addopts = -v --tb=short --strict-markers 
```


### FILE: backend\auth-service\requirements.txt
```
# Flask and extensions
Flask==2.3.3
Flask-SQLAlchemy==3.0.5
Flask-Migrate==4.0.4
Flask-Cors==4.0.0
Flask-WTF==1.2.1
Werkzeug==2.3.7

# Database
psycopg2-binary==2.9.7
SQLAlchemy==1.4.41

# Authentication
PyJWT==2.8.0
bcrypt==4.0.1
google-auth-oauthlib==1.0.0

# Utilities
python-dotenv==1.0.0
requests==2.31.0
redis==5.0.0
pydantic>=2.5.2
email-validator==2.0.0.post2
gunicorn==21.2.0
APScheduler==3.10.4

# Resilience
tenacity==8.2.3
circuitbreaker==1.4.0

# Monitoring and logging
prometheus-client==0.19.0
sentry-sdk==1.39.1
structlog==23.1.0
python-json-logger==2.0.7

# Service discovery and secrets
python-consul==1.1.0
kubernetes==28.1.0
hvac==1.1.1
boto3==1.29.6

# Testing
pytest==7.4.3
pytest-flask==1.3.0
pytest-cov==4.1.0
responses==0.23.3

# Local shared package - installed via Dockerfile
# -e ../../meeting_shared 
```


### FILE: backend\auth-service\setup.py
```
from setuptools import setup, find_packages

setup(
    name="auth-service",
    version="0.1.0",
    packages=find_packages(),
    install_requires=[
        'Flask==2.3.3',
        'Flask-SQLAlchemy==3.0.5',
        'Flask-Migrate==4.0.4',
        'Flask-Cors==4.0.0',
        'Flask-WTF==1.2.1',
        'psycopg2-binary==2.9.7',
        'python-dotenv==1.0.0',
        'PyJWT==2.8.0',
        'bcrypt==4.0.1',
        'google-auth-oauthlib==1.0.0',
        'requests==2.31.0',
        'email-validator==2.0.0.post2',
        'redis==5.0.0',
        'pydantic>=2.5.2',
        'gunicorn==21.2.0',
        'APScheduler==3.10.4',
        'tenacity==8.2.3',
        'circuitbreaker==1.4.0',
        'prometheus-client==0.19.0',
        'sentry-sdk==1.39.1'
    ],
) 
```


### FILE: backend\auth-service\auth_service.egg-info\PKG-INFO
```
Metadata-Version: 2.1
Name: auth-service
Version: 0.1.0

```


### FILE: backend\auth-service\auth_service.egg-info\SOURCES.txt
```
setup.py
auth_service.egg-info/PKG-INFO
auth_service.egg-info/SOURCES.txt
auth_service.egg-info/dependency_links.txt
auth_service.egg-info/requires.txt
auth_service.egg-info/top_level.txt
```


### FILE: backend\auth-service\auth_service.egg-info\dependency_links.txt
```


```


### FILE: backend\auth-service\auth_service.egg-info\requires.txt
```
Flask==2.3.3
Flask-SQLAlchemy==3.0.5
Flask-Migrate==4.0.4
Flask-Cors==4.0.0
Flask-WTF==1.2.1
psycopg2-binary==2.9.7
python-dotenv==1.0.0
PyJWT==2.8.0
bcrypt==4.0.1
google-auth-oauthlib==1.0.0
requests==2.31.0
email-validator==2.0.0.post2
redis==5.0.0
pydantic>=2.5.2
gunicorn==21.2.0
APScheduler==3.10.4
tenacity==8.2.3
circuitbreaker==1.4.0
prometheus-client==0.19.0
sentry-sdk==1.39.1

```


### FILE: backend\auth-service\auth_service.egg-info\top_level.txt
```


```


### FILE: backend\auth-service\migrations\alembic.ini
```
[alembic]
script_location = migrations
sqlalchemy.url = driver://user:pass@localhost/dbname

[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S 
```


### FILE: backend\auth-service\migrations\env.py
```
from logging.config import fileConfig

from sqlalchemy import engine_from_config
from sqlalchemy import pool

from alembic import context
from src.app import create_app
from src.database import db

config = context.config

if config.config_file_name is not None:
    fileConfig(config.config_file_name)

app = create_app(initialize_db=False)
target_metadata = db.metadata

def run_migrations_offline() -> None:
    url = app.config["SQLALCHEMY_DATABASE_URI"]
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()

def run_migrations_online() -> None:
    configuration = config.get_section(config.config_ini_section)
    configuration["sqlalchemy.url"] = app.config["SQLALCHEMY_DATABASE_URI"]
    connectable = engine_from_config(
        configuration,
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection,
            target_metadata=target_metadata
        )

        with context.begin_transaction():
            context.run_migrations()

if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online() 
```


### FILE: backend\auth-service\migrations\script.py.mako
```
"""${message}

Revision ID: ${up_revision}
Revises: ${down_revision | comma,n}
Create Date: ${create_date}

"""
from alembic import op
import sqlalchemy as sa
${imports if imports else ""}

# revision identifiers, used by Alembic.
revision = ${repr(up_revision)}
down_revision = ${repr(down_revision)}
branch_labels = ${repr(branch_labels)}
depends_on = ${repr(depends_on)}


def upgrade() -> None:
    ${upgrades if upgrades else "pass"}


def downgrade() -> None:
    ${downgrades if downgrades else "pass"} 
```


### FILE: backend\auth-service\migrations\versions\001_initial.py
```
"""Initial migration

Revision ID: 001
Revises: 
Create Date: 2024-02-07 19:56:00.000000

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '001'
down_revision = None
branch_labels = None
depends_on = None

def upgrade():
    # Create auth_users table
    op.create_table('auth_users',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('email', sa.String(length=255), nullable=False),
        sa.Column('password_hash', sa.Text(), nullable=True),
        sa.Column('is_google_user', sa.Boolean(), nullable=False, default=False),
        sa.Column('first_login', sa.Boolean(), nullable=False, default=True),
        sa.Column('is_email_verified', sa.Boolean(), nullable=False, default=False),
        sa.Column('created_at', sa.DateTime(), nullable=False),
        sa.Column('updated_at', sa.DateTime(), nullable=False),
        sa.Column('last_login', sa.DateTime(), nullable=True),
        sa.Column('first_name', sa.String(length=100), nullable=True),
        sa.Column('last_name', sa.String(length=100), nullable=True),
        sa.Column('profile_picture', sa.String(length=255), nullable=True),
        sa.Column('google_id', sa.String(length=255), nullable=True),
        sa.Column('google_refresh_token', sa.Text(), nullable=True),
        sa.Column('failed_login_attempts', sa.Integer(), nullable=False, default=0),
        sa.Column('locked_until', sa.DateTime(), nullable=True),
        sa.Column('password_last_changed', sa.DateTime(), nullable=True),
        sa.Column('require_password_change', sa.Boolean(), nullable=False, default=False),
        sa.Column('last_failed_login', sa.DateTime(), nullable=True),
        sa.Column('security_audit_log', postgresql.JSON(astext_type=sa.Text()), nullable=True),
        sa.PrimaryKeyConstraint('id'),
        sa.UniqueConstraint('email'),
        sa.UniqueConstraint('google_id')
    )

    # Create password_reset_tokens table
    op.create_table('password_reset_tokens',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('user_id', sa.Integer(), nullable=False),
        sa.Column('token', sa.Text(), nullable=False),
        sa.Column('expires_at', sa.DateTime(), nullable=False),
        sa.Column('created_at', sa.DateTime(), nullable=False),
        sa.Column('used', sa.Boolean(), nullable=False, default=False),
        sa.ForeignKeyConstraint(['user_id'], ['auth_users.id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id')
    )

    # Create user_sessions table
    op.create_table('user_sessions',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('user_id', sa.Integer(), nullable=False),
        sa.Column('token', sa.Text(), nullable=False),
        sa.Column('refresh_token', sa.Text(), nullable=True),
        sa.Column('device_info', postgresql.JSON(astext_type=sa.Text()), nullable=True),
        sa.Column('ip_address', sa.String(length=45), nullable=True),
        sa.Column('created_at', sa.DateTime(), nullable=False),
        sa.Column('expires_at', sa.DateTime(), nullable=False),
        sa.Column('refresh_token_expires_at', sa.DateTime(), nullable=True),
        sa.Column('revoked', sa.Boolean(), nullable=False, default=False),
        sa.Column('revoked_at', sa.DateTime(), nullable=True),
        sa.Column('revocation_reason', sa.String(length=100), nullable=True),
        sa.Column('last_used_at', sa.DateTime(), nullable=True),
        sa.Column('device_name', sa.String(length=100), nullable=True),
        sa.Column('device_type', sa.String(length=50), nullable=True),
        sa.Column('user_agent', sa.Text(), nullable=True),
        sa.ForeignKeyConstraint(['user_id'], ['auth_users.id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id')
    )

    # Create email_verifications table
    op.create_table('email_verifications',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('user_id', sa.Integer(), nullable=False),
        sa.Column('token', sa.String(length=255), nullable=False),
        sa.Column('expires_at', sa.DateTime(), nullable=False),
        sa.Column('created_at', sa.DateTime(), nullable=False),
        sa.Column('is_used', sa.Boolean(), nullable=False, default=False),
        sa.ForeignKeyConstraint(['user_id'], ['auth_users.id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id'),
        sa.UniqueConstraint('token')
    )

    # Create password_history table
    op.create_table('password_history',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('user_id', sa.Integer(), nullable=False),
        sa.Column('password_hash', sa.Text(), nullable=False),
        sa.Column('created_at', sa.DateTime(), nullable=False),
        sa.ForeignKeyConstraint(['user_id'], ['auth_users.id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id')
    )

def downgrade():
    op.drop_table('password_history')
    op.drop_table('email_verifications')
    op.drop_table('user_sessions')
    op.drop_table('password_reset_tokens')
    op.drop_table('auth_users') 
```


### FILE: backend\auth-service\scripts\entrypoint.sh
```
#!/bin/bash
set -e

echo "Waiting for auth-db..."
while ! pg_isready -h auth-db -p 5432 -U $AUTH_DB_USER; do
    sleep 1
done
echo "Postgres is up - executing command"

# List directory structure for debugging
echo "Directory structure in /app:"
ls -la /app

# Check if meeting_shared is properly mounted
if [ ! -d "/app/meeting_shared" ] || [ -z "$(ls -A /app/meeting_shared)" ]; then
    echo "WARNING: Shared modules not properly mounted. Volume mount issue possible."
fi

# Run migrations if they exist
if [ -f "migrations/env.py" ]; then
    echo "Running database migrations..."
    flask db upgrade
else
    echo "Warning: Migrations failed, but continuing..."
fi

# Start the application
exec gunicorn --bind 0.0.0.0:5001 \
    --workers 2 \
    --worker-class gthread \
    --threads 4 \
    --timeout 120 \
    --access-logfile - \
    --error-logfile - \
    "src.app:create_app()" 
```


### FILE: backend\auth-service\scripts\healthcheck.sh
```
#!/bin/bash

# Wait for database to be ready
until PGPASSWORD=$POSTGRES_PASSWORD psql -h "$DB_HOST" -U "$POSTGRES_USER" -d "$POSTGRES_DB" -c '\q'; do
  >&2 echo "Postgres is unavailable - sleeping"
  sleep 1
done

>&2 echo "Postgres is up - executing command"

# Check if migrations are up to date
python -c "from src.app import create_app; from flask_migrate import current; app = create_app(initialize_db=False); assert current(app), 'Migrations are not up to date'"

# Check if required tables exist
PGPASSWORD=$POSTGRES_PASSWORD psql -h "$DB_HOST" -U "$POSTGRES_USER" -d "$POSTGRES_DB" -c "\dt" | grep -q "auth_users"

exit $? 
```


### FILE: backend\auth-service\src\app.py
```
"""
Auth service application factory.
"""

import os
import logging
import random
import string

# Patch werkzeug.security.gen_salt to avoid secrets.choice issue
import werkzeug.security
def patched_gen_salt(length):
    """Generate a random string of SALT_CHARS with specified length."""
    if length <= 0:
        raise ValueError('Salt length must be positive')
    return ''.join(random.choice(werkzeug.security.SALT_CHARS) for _ in range(length))
werkzeug.security.gen_salt = patched_gen_salt

from flask import Flask, jsonify, g, current_app
from meeting_shared.config import get_config
from meeting_shared.shared_logging import setup_logging
from meeting_shared.middleware import register_middleware
from meeting_shared.database import init_db, db

logger = logging.getLogger(__name__)

def create_app(config_name=None):
    """Create Flask application."""
    app = Flask(__name__)
    
    # Load configuration
    config = get_config(config_name or os.getenv('FLASK_ENV', 'default'))
    app.config.from_object(config)
    logger.info(f"Initialized with configuration: {config_name or 'default'}")
    
    # Setup logging first
    setup_logging(app)
    logger.info("Logging configured")
    
    # Register middleware (before routes)
    register_middleware(app)
    logger.info("Middleware registered")
    
    # Initialize database
    init_db(app)  # This initializes the global db instance
    app.db = db   # Also store it on the app for easy access
    logger.info("Database initialized")
    
    # Register health check endpoint
    @app.route('/health')
    def health_check():
        """Health check endpoint with database verification."""
        status = "healthy"
        database_status = "available"
        
        # Verify database connection
        try:
            # Use current_app context to ensure we're using the correct app context
            db.session.execute('SELECT 1')
            status_code = 200
        except Exception as e:
            logger.error(f"Health check database error: {str(e)}")
            database_status = "unavailable"
            status = "degraded"
            status_code = 500
            
        return jsonify({
            'status': status,
            'service': app.config.get('APP_NAME', 'auth-service'),
            'database': database_status,
            'request_id': g.get('request_id', 'none')
        }), status_code
    
    # Register blueprints here
    from .routes.auth import auth_bp
    app.register_blueprint(auth_bp, url_prefix='/api/auth')
    
    logger.info("Auth service initialization sequence complete")
    logger.info(f"Registered routes: {[rule.rule for rule in app.url_map.iter_rules()]}")
    
    return app 
```


### FILE: backend\auth-service\src\database.py
```
"""
This module re-exports the shared database module to maintain
backward compatibility with code that imports from here.
"""

from meeting_shared.database import db, transaction, init_db

# No need to initialize another SQLAlchemy instance
# as we're using the one from the shared module 
```


### FILE: backend\auth-service\src\core\__init__.py
```
"""
Core module for auth service functionality and initialization.
Provides centralized logging, error handling, and configuration.
"""

import logging
import os
import sys
import json
from pathlib import Path

# Try to import shared modules
try:
    from meeting_shared.shared_logging import configure_logging, get_logger
    from meeting_shared.middleware.request_id import RequestIdMiddleware
    SHARED_MODULES_AVAILABLE = True
except ImportError:
    SHARED_MODULES_AVAILABLE = False

# Configure application-wide logging
def setup_logging(log_level=None):
    """
    Configure application-wide logging with appropriate handlers and formatters.
    
    Args:
        log_level: Optional override for log level (default is from environment or INFO)
    """
    if not log_level:
        log_level = os.environ.get('LOG_LEVEL', 'INFO').upper()
    
    # Use shared logging if available
    if SHARED_MODULES_AVAILABLE:
        # Configure using shared module
        config = {
            'level': log_level,
            'service_name': 'auth-service',
            'json_enabled': os.environ.get('JSON_LOGS', 'true').lower() == 'true',
            'file_enabled': os.environ.get('LOG_TO_FILE', 'false').lower() == 'true',
            'file_path': os.environ.get('LOG_FILE', 'logs/auth-service.log'),
        }
        configure_logging(config)
        logger = get_logger(__name__)
    else:
        # Fall back to basic logging
        logging_format = os.environ.get(
            'LOG_FORMAT', 
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        # Configure root logger
        root_logger = logging.getLogger()
        root_logger.setLevel(getattr(logging, log_level))
        
        # Remove existing handlers
        for handler in list(root_logger.handlers):
            root_logger.removeHandler(handler)
        
        # Add console handler
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(getattr(logging, log_level))
        console_formatter = logging.Formatter(logging_format)
        console_handler.setFormatter(console_formatter)
        root_logger.addHandler(console_handler)
        
        # Add file handler if requested
        if os.environ.get('LOG_TO_FILE', 'false').lower() == 'true':
            log_file = os.environ.get('LOG_FILE', 'logs/auth-service.log')
            os.makedirs(os.path.dirname(log_file), exist_ok=True)
            
            file_handler = logging.FileHandler(log_file)
            file_handler.setLevel(getattr(logging, log_level))
            file_formatter = logging.Formatter(logging_format)
            file_handler.setFormatter(file_formatter)
            root_logger.addHandler(file_handler)
        
        logger = logging.getLogger(__name__)
    
    logger.info(f"Logging initialized at level {log_level}")
    
    return logger

def log_system_info():
    """
    Log system and environment information for debugging purposes.
    """
    import platform
    import socket
    from datetime import datetime
    
    logger = logging.getLogger(__name__)
    
    # Collect system information
    system_info = {
        'timestamp': datetime.utcnow().isoformat() + 'Z',
        'hostname': socket.gethostname(),
        'platform': platform.platform(),
        'python_version': platform.python_version(),
        'environment': os.environ.get('FLASK_ENV', 'production'),
        'debug': os.environ.get('DEBUG', 'false').lower() == 'true',
    }
    
    # Log system information
    logger.info(f"System info: {json.dumps(system_info)}")
    
    # Log environment variables (filtered)
    safe_vars = {k: v for k, v in os.environ.items() 
               if not any(secret in k.lower() 
                        for secret in ['key', 'secret', 'token', 'password', 'auth'])}
    
    logger.debug(f"Environment variables: {json.dumps(safe_vars)}")

def log_directory_structure(base_path='/app', max_depth=2):
    """
    Log the directory structure for debugging purposes.
    """
    logger = logging.getLogger(__name__)
    logger.info(f"Directory structure of {base_path} (max depth: {max_depth})")
    
    def _log_dir(path, depth=0):
        if depth > max_depth:
            return
        
        try:
            path_obj = Path(path)
            
            # Skip if path doesn't exist
            if not path_obj.exists():
                logger.warning(f"Path does not exist: {path}")
                return
            
            # Log directory entries
            if path_obj.is_dir():
                indent = '  ' * depth
                
                # Get directory contents
                try:
                    contents = list(path_obj.iterdir())
                    
                    # Log count of items
                    logger.info(f"{indent}{path} ({len(contents)} items)")
                    
                    # Sort contents (directories first)
                    contents.sort(key=lambda p: (0 if p.is_dir() else 1, p.name))
                    
                    # Log each item
                    for item in contents:
                        if item.is_dir():
                            _log_dir(item, depth + 1)
                        else:
                            try:
                                stat = item.stat()
                                size_kb = stat.st_size / 1024
                                logger.info(f"{indent}  {item.name} ({size_kb:.1f} KB)")
                            except Exception as e:
                                logger.info(f"{indent}  {item.name} (error: {str(e)})")
                except Exception as e:
                    logger.error(f"Error listing directory {path}: {str(e)}")
        except Exception as e:
            logger.error(f"Error logging directory structure: {str(e)}")
    
    # Start logging directory structure
    _log_dir(base_path)

def register_extensions(app):
    """
    Register Flask extensions with the app.
    
    Args:
        app: Flask application instance
    """
    # Register request ID middleware if available
    if SHARED_MODULES_AVAILABLE:
        RequestIdMiddleware(app)
        app.logger.info("Registered RequestIdMiddleware")

def init_app(app):
    """
    Initialize the Flask application with core functionality.
    
    Args:
        app: Flask application instance
    """
    # Set up logging
    setup_logging()
    
    # Register extensions
    register_extensions(app)
    
    # Log system information
    log_system_info()
    
    # Log directory structure for debugging
    if app.debug:
        log_directory_structure()
    
    # Register error handlers
    from .errors import register_error_handlers
    register_error_handlers(app)
    
    app.logger.info("Core initialization complete") 
```


### FILE: backend\auth-service\src\core\config.py
```
"""
Centralized configuration management for the auth service.
Handles environment variables and provides environment-specific settings.
"""

import os
import logging
from pathlib import Path

logger = logging.getLogger(__name__)

class BaseConfig:
    """Base configuration settings shared across all environments"""
    # Application settings
    APP_NAME = "Auth Service"
    API_PREFIX = "/api"
    
    # Environment settings
    DEBUG = False
    TESTING = False
    
    # Security settings
    SECRET_KEY = os.environ.get("JWT_SECRET_KEY")
    SERVICE_KEY = os.environ.get("SERVICE_KEY")
    JWT_ALGORITHM = "HS256"
    JWT_ACCESS_TOKEN_EXPIRES = 60 * 60  # 1 hour
    JWT_REFRESH_TOKEN_EXPIRES = 30 * 24 * 60 * 60  # 30 days
    BCRYPT_LOG_ROUNDS = 13
    
    # Database settings 
    SQLALCHEMY_DATABASE_URI = os.environ.get("AUTH_DATABASE_URL")
    SQLALCHEMY_TRACK_MODIFICATIONS = False
    
    # Redis settings
    REDIS_URL = os.environ.get("REDIS_URL", "redis://localhost:6379/0")
    REDIS_TOKEN_BLACKLIST_DB = 1
    
    # CORS settings
    CORS_ORIGINS = os.environ.get("CORS_ORIGINS", "http://localhost:3000").split(",")
    CORS_METHODS = ["GET", "POST", "PUT", "DELETE", "OPTIONS"]
    CORS_HEADERS = ["Content-Type", "Authorization", "X-Service-Key"]
    
    # Email settings
    SMTP_SERVER = os.environ.get("SMTP_SERVER", "smtp.gmail.com")
    SMTP_PORT = int(os.environ.get("SMTP_PORT", 587))
    SMTP_USERNAME = os.environ.get("SMTP_USERNAME", "")
    SMTP_PASSWORD = os.environ.get("SMTP_PASSWORD", "")
    SMTP_USE_TLS = True
    EMAIL_SENDER = os.environ.get("EMAIL_SENDER", "noreply@example.com")
    
    # Frontend settings
    FRONTEND_URL = os.environ.get("FRONTEND_URL", "http://localhost:3000")
    
    # Authentication settings
    PASSWORD_RESET_TOKEN_EXPIRES = 24 * 60 * 60  # 24 hours
    EMAIL_VERIFICATION_TOKEN_EXPIRES = 48 * 60 * 60  # 48 hours
    FAILED_LOGIN_ATTEMPTS = 5
    ACCOUNT_LOCKOUT_TIME = 15 * 60  # 15 minutes
    
    # File paths
    ROOT_DIR = Path("/app")
    LOG_DIR = ROOT_DIR / "logs"
    
    # Ensure directories exist
    LOG_DIR.mkdir(exist_ok=True)

    # OAuth settings
    GOOGLE_CLIENT_ID = os.environ.get("GOOGLE_CLIENT_ID", "")
    GOOGLE_CLIENT_SECRET = os.environ.get("GOOGLE_CLIENT_SECRET", "")

class DevelopmentConfig(BaseConfig):
    """Development environment specific configuration"""
    DEBUG = True
    LOG_LEVEL = "DEBUG"
    
    # More lenient security settings for development
    BCRYPT_LOG_ROUNDS = 4
    JWT_ACCESS_TOKEN_EXPIRES = 24 * 60 * 60  # 24 hours in development
    
    # Enable detailed error messages and SQL query logging
    SQLALCHEMY_ECHO = True
    
    # Development-specific settings
    PRESERVE_CONTEXT_ON_EXCEPTION = False
    
    # Extended CORS settings for development
    CORS_ORIGINS = os.environ.get("CORS_ORIGINS", 
                                 "http://localhost:3000,http://localhost:3001,http://localhost:5000,http://localhost:5001").split(",")

class TestingConfig(BaseConfig):
    """Testing environment specific configuration"""
    TESTING = True
    DEBUG = True
    
    # Use in-memory database for testing
    SQLALCHEMY_DATABASE_URI = os.environ.get("TEST_AUTH_DATABASE_URL", "sqlite:///:memory:")
    
    # Disable CSRF protection for testing
    WTF_CSRF_ENABLED = False
    
    # Faster password hashing for tests
    BCRYPT_LOG_ROUNDS = 4
    
    # Shorter token expiration for testing
    JWT_ACCESS_TOKEN_EXPIRES = 300  # 5 minutes
    JWT_REFRESH_TOKEN_EXPIRES = 600  # 10 minutes
    
    # Mock external services
    REDIS_URL = os.environ.get("TEST_REDIS_URL", "redis://localhost:6379/2")
    
    # Disable email sending in tests
    MAIL_SUPPRESS_SEND = True

class ProductionConfig(BaseConfig):
    """Production environment specific configuration"""
    LOG_LEVEL = "INFO"
    
    # Production security settings
    WTF_CSRF_SSL_STRICT = True
    PREFERRED_URL_SCHEME = 'https'
    
    # Set stricter CORS
    CORS_ORIGINS = os.environ.get("CORS_ORIGINS", "https://yourdomain.com").split(",")
    
    # Production database settings
    SQLALCHEMY_ENGINE_OPTIONS = {
        'pool_size': 10,
        'pool_recycle': 3600,
        'pool_pre_ping': True
    }

# Dictionary of available configurations
config = {
    "development": DevelopmentConfig,
    "testing": TestingConfig,
    "production": ProductionConfig,
    # Default to development
    "default": DevelopmentConfig
}

def get_config(config_name=None):
    """
    Get the configuration for the current environment.
    
    Args:
        config_name: Optional configuration name override
        
    Returns:
        Configuration class
    """
    if not config_name:
        config_name = os.environ.get("FLASK_ENV", "development").lower()
    
    selected_config = config.get(config_name, config["default"])
    logger.info(f"Using '{config_name}' configuration for auth service")
    
    # Validate critical settings
    if not selected_config.SECRET_KEY and config_name == "production":
        logger.critical("JWT_SECRET_KEY not set in production environment!")
    
    if not selected_config.SQLALCHEMY_DATABASE_URI:
        logger.critical("AUTH_DATABASE_URL not set! Application may fail to start")
    
    return selected_config 
```


### FILE: backend\auth-service\src\core\errors.py
```
"""
Centralized error handling for the auth service.
Provides standardized error responses and detailed logging of exceptions.
"""

import traceback
import logging
import json
import os
from datetime import datetime
from flask import jsonify, request, current_app

logger = logging.getLogger(__name__)

# Try to import standardized errors from shared module
try:
    # Try to import from backend.meeting_shared first
    from backend.meeting_shared.errors import (
        APIError, ValidationError, AuthenticationError, AuthorizationError,
        UserExistsError, UserNotFoundError, TokenError, ResourceNotFoundError,
        ResourceExistsError, ServiceError, ConfigurationError, DependencyError,
        RateLimitError, EmailError, HAS_REQUEST_ID
    )
    SHARED_ERRORS_AVAILABLE = True
    logger.info("Successfully imported shared error classes")
except ImportError:
    try:
        # Try to import from meeting_shared as fallback
        from meeting_shared.errors import (
            APIError, ValidationError, AuthenticationError, AuthorizationError,
            UserExistsError, UserNotFoundError, TokenError, ResourceNotFoundError,
            ResourceExistsError, ServiceError, ConfigurationError, DependencyError,
            RateLimitError, EmailError, HAS_REQUEST_ID
        )
        SHARED_ERRORS_AVAILABLE = True
        logger.info("Successfully imported shared error classes using fallback path")
    except ImportError:
        SHARED_ERRORS_AVAILABLE = False
        logger.warning("Could not import shared error classes, using local definitions")
        
        # Try to import request ID functionality
        try:
            from backend.meeting_shared.middleware.request_id import get_request_id
            HAS_REQUEST_ID = True
        except ImportError:
            try:
                from meeting_shared.middleware.request_id import get_request_id
                HAS_REQUEST_ID = True
            except ImportError:
                HAS_REQUEST_ID = False

        # Define error classes locally if shared module is not available
        class APIError(Exception):
            """Base exception class for API errors with status code and message"""
            
            def __init__(self, message, status_code=400, details=None):
                self.message = message
                self.status_code = status_code
                self.details = details or {}
                self.timestamp = datetime.utcnow().isoformat() + 'Z'
                
                # Add request ID if available
                if HAS_REQUEST_ID:
                    self.request_id = get_request_id()
                else:
                    self.request_id = None
            
            def to_dict(self):
                """Convert exception to dictionary representation"""
                error_dict = {
                    'error': True,
                    'status_code': self.status_code,
                    'message': self.message,
                    'timestamp': self.timestamp
                }
                
                # Include request ID if available
                if hasattr(self, 'request_id') and self.request_id:
                    error_dict['request_id'] = self.request_id
                
                # Include request URL and method if in a request context
                try:
                    error_dict['path'] = request.path
                    error_dict['method'] = request.method
                except RuntimeError:
                    # Not in a request context
                    pass
                
                # Include additional details if provided
                if self.details:
                    error_dict['details'] = self.details
                
                return error_dict

        class ValidationError(APIError):
            """Exception for data validation errors"""
            
            def __init__(self, message="Validation error", details=None):
                super().__init__(message, status_code=422, details=details)

        class AuthenticationError(APIError):
            """Exception for authentication failures"""
            
            def __init__(self, message="Authentication required", details=None):
                super().__init__(message, status_code=401, details=details)

        class AuthorizationError(APIError):
            """Exception for authorization failures"""
            
            def __init__(self, message="Not authorized", details=None):
                super().__init__(message, status_code=403, details=details)

        class UserExistsError(APIError):
            """Exception for duplicate user registration"""
            
            def __init__(self, message="User already exists", details=None):
                super().__init__(message, status_code=409, details=details)

        class UserNotFoundError(APIError):
            """Exception for user not found"""
            
            def __init__(self, message="User not found", details=None):
                super().__init__(message, status_code=404, details=details)

        class TokenError(APIError):
            """Exception for token validation failures"""
            
            def __init__(self, message="Invalid or expired token", details=None):
                super().__init__(message, status_code=401, details=details)

        class RateLimitError(APIError):
            """Exception for rate limiting"""
            
            def __init__(self, message="Rate limit exceeded", details=None):
                super().__init__(message, status_code=429, details=details)

        class ServiceError(APIError):
            """Exception for service failures"""
            
            def __init__(self, message="Service error", details=None):
                super().__init__(message, status_code=500, details=details)

        class EmailError(APIError):
            """Exception for email sending failures"""
            
            def __init__(self, message="Failed to send email", details=None):
                super().__init__(message, status_code=500, details=details)
                
        class ResourceNotFoundError(APIError):
            """Exception for resource not found"""
            
            def __init__(self, message="Resource not found", details=None):
                super().__init__(message, status_code=404, details=details)
                
        class ResourceExistsError(APIError):
            """Exception for resource already exists"""
            
            def __init__(self, message="Resource already exists", details=None):
                super().__init__(message, status_code=409, details=details)
                
        class ConfigurationError(APIError):
            """Exception for configuration errors"""
            
            def __init__(self, message="Configuration error", details=None):
                super().__init__(message, status_code=500, details=details)
                
        class DependencyError(APIError):
            """Exception for dependency failures"""
            
            def __init__(self, message="Dependency error", details=None):
                super().__init__(message, status_code=503, details=details)

def register_error_handlers(app):
    """
    Register all error handlers with the Flask app.
    
    Args:
        app: Flask application instance
    """
    # Custom exceptions
    app.register_error_handler(APIError, handle_api_error)
    app.register_error_handler(ValidationError, handle_api_error)
    app.register_error_handler(AuthenticationError, handle_api_error)
    app.register_error_handler(AuthorizationError, handle_api_error)
    app.register_error_handler(UserExistsError, handle_api_error)
    app.register_error_handler(UserNotFoundError, handle_api_error)
    app.register_error_handler(TokenError, handle_api_error)
    app.register_error_handler(RateLimitError, handle_api_error)
    app.register_error_handler(ServiceError, handle_api_error)
    app.register_error_handler(EmailError, handle_api_error)
    app.register_error_handler(ResourceNotFoundError, handle_api_error)
    app.register_error_handler(ResourceExistsError, handle_api_error)
    app.register_error_handler(ConfigurationError, handle_api_error)
    app.register_error_handler(DependencyError, handle_api_error)
    
    # Standard HTTP errors
    app.register_error_handler(400, handle_bad_request)
    app.register_error_handler(401, handle_unauthorized)
    app.register_error_handler(403, handle_forbidden)
    app.register_error_handler(404, handle_not_found)
    app.register_error_handler(405, handle_method_not_allowed)
    app.register_error_handler(422, handle_unprocessable_entity)
    app.register_error_handler(429, handle_rate_limit_exceeded)
    app.register_error_handler(500, handle_server_error)
    
    # Catch-all for any other exceptions
    app.register_error_handler(Exception, handle_exception)
    
    logger.info("Registered error handlers")

def handle_api_error(error):
    """
    Handler for API errors.
    
    Args:
        error: APIError instance
        
    Returns:
        JSON response with error details
    """
    response = jsonify(error.to_dict())
    response.status_code = error.status_code
    
    # Add request ID header if available
    if hasattr(error, 'request_id') and error.request_id:
        response.headers['X-Request-ID'] = error.request_id
    
    # Log the error
    if error.status_code >= 500:
        logger.error(f"API Error: {error.message}", extra={'status_code': error.status_code})
    else:
        logger.info(f"API Error: {error.message}", extra={'status_code': error.status_code})
    
    return response

def handle_bad_request(error):
    """
    Handler for 400 Bad Request errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = APIError("Bad request", status_code=400)
    return handle_api_error(api_error)

def handle_unauthorized(error):
    """
    Handler for 401 Unauthorized errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = AuthenticationError("Authentication required")
    return handle_api_error(api_error)

def handle_forbidden(error):
    """
    Handler for 403 Forbidden errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = AuthorizationError("Access forbidden")
    return handle_api_error(api_error)

def handle_not_found(error):
    """
    Handler for 404 Not Found errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = ResourceNotFoundError("Resource not found")
    return handle_api_error(api_error)

def handle_method_not_allowed(error):
    """
    Handler for 405 Method Not Allowed errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = APIError("Method not allowed", status_code=405)
    return handle_api_error(api_error)

def handle_unprocessable_entity(error):
    """
    Handler for 422 Unprocessable Entity errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    # Extract validation errors from WTForms if available
    details = {}
    if hasattr(error, 'data') and 'errors' in error.data:
        details = {'fields': error.data['errors']}
    
    api_error = ValidationError("Validation error", details=details)
    return handle_api_error(api_error)

def handle_rate_limit_exceeded(error):
    """
    Handler for 429 Too Many Requests errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = RateLimitError("Rate limit exceeded")
    return handle_api_error(api_error)

def handle_server_error(error):
    """
    Handler for 500 Internal Server Error errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    # Log the full stack trace
    logger.error(f"Server error: {str(error)}", exc_info=True)
    
    # Create a more detailed error in development
    is_development = current_app.config.get('ENV') == 'development'
    
    details = None
    if is_development:
        details = {
            'traceback': traceback.format_exc(),
            'error_type': error.__class__.__name__
        }
    
    api_error = ServiceError("Internal server error", details=details)
    return handle_api_error(api_error)

def handle_exception(error):
    """
    Catch-all handler for uncaught exceptions.
    
    Args:
        error: Exception instance
        
    Returns:
        JSON response with error details
    """
    # Log the full stack trace
    logger.error(f"Uncaught exception: {str(error)}", exc_info=True)
    
    # Create a more detailed error in development
    is_development = current_app.config.get('ENV') == 'development'
    
    details = None
    if is_development:
        details = {
            'traceback': traceback.format_exc(),
            'error_type': error.__class__.__name__
        }
    
    message = str(error) if is_development else "An unexpected error occurred"
    
    api_error = ServiceError(message, details=details)
    return handle_api_error(api_error) 
```


### FILE: backend\auth-service\src\core\health.py
```
"""
Health check module for auth service health monitoring and diagnostics.
Provides comprehensive health checks for all auth service dependencies.
"""

import logging
import time
import os
import socket
import platform
import psutil
from datetime import datetime
from flask import Blueprint, jsonify, current_app, request, g

from .config import get_config
from meeting_shared.middleware.request_id import get_request_id

logger = logging.getLogger(__name__)

# Try to import request ID functionality
try:
    HAS_REQUEST_ID = True
except ImportError:
    HAS_REQUEST_ID = False

# Create health blueprint
health_bp = Blueprint('health', __name__)

@health_bp.route('/health', methods=['GET'])
def health_check():
    """
    Health check endpoint for the auth service.
    Performs comprehensive checks on all dependencies.
    
    Returns:
        JSON response with health status and checks
    """
    start_time = time.time()
    
    # Initialize response
    response = {
        'service': 'auth-service',
        'status': 'healthy',
        'version': os.environ.get('VERSION', 'dev'),
        'environment': current_app.config.get('ENV', 'production'),
        'timestamp': datetime.utcnow().isoformat() + 'Z',
        'checks': {}
    }
    
    # Add request ID if available
    if HAS_REQUEST_ID:
        request_id = get_request_id()
        if request_id:
            response['request_id'] = request_id
    
    # Perform database check
    db_status = _check_database()
    response['checks']['database'] = db_status
    
    # Perform Redis check
    redis_status = _check_redis()
    response['checks']['redis'] = redis_status
    
    # Perform email service check
    email_status = _check_email_service()
    response['checks']['email'] = email_status
    
    # Perform OAuth check
    oauth_status = _check_oauth()
    response['checks']['oauth'] = oauth_status
    
    # Add system information
    response['system'] = _get_system_info()
    
    # Determine overall status
    if any(check.get('status') == 'critical' for check in response['checks'].values()):
        response['status'] = 'critical'
    elif any(check.get('status') == 'warning' for check in response['checks'].values()):
        response['status'] = 'warning'
    
    # Add response time
    response['response_time_ms'] = round((time.time() - start_time) * 1000, 2)
    
    # Set appropriate status code
    status_code = 200
    if response['status'] == 'critical':
        status_code = 503  # Service Unavailable
    elif response['status'] == 'warning':
        status_code = 200  # Still OK but with warnings
    
    # Log health check result
    logger_fn = logger.error if response['status'] == 'critical' else \
               logger.warning if response['status'] == 'warning' else \
               logger.info
    
    logger_fn(f"Health check result: {response['status']}")
    
    # Create response
    json_response = jsonify(response)
    
    # Add request ID to response headers if available
    if HAS_REQUEST_ID and get_request_id():
        json_response.headers['X-Request-ID'] = get_request_id()
    
    return json_response, status_code

def _check_database():
    """
    Check database connection and health.
    
    Returns:
        dict: Database health check result
    """
    from flask_sqlalchemy import SQLAlchemy
    from sqlalchemy import text
    from sqlalchemy.exc import SQLAlchemyError
    
    start_time = time.time()
    db = SQLAlchemy(current_app)
    
    try:
        # Execute simple query to check database connection
        with db.engine.connect() as conn:
            result = conn.execute(text("SELECT 1"))
            assert result.scalar() == 1
        
        # Check connection pool statistics
        pool_info = {
            'size': db.engine.pool.size(),
            'checkedin': db.engine.pool.checkedin(),
            'overflow': db.engine.pool.overflow(),
            'checkedout': db.engine.pool.checkedout(),
        }
        
        # Database connection string (mask sensitive info)
        db_url = _mask_connection_string(current_app.config['SQLALCHEMY_DATABASE_URI'])
        
        return {
            'status': 'healthy',
            'response_time_ms': round((time.time() - start_time) * 1000, 2),
            'pool': pool_info,
            'database_url': db_url
        }
    except SQLAlchemyError as e:
        logger.error(f"Database health check failed: {str(e)}")
        return {
            'status': 'critical',
            'error': str(e),
            'response_time_ms': round((time.time() - start_time) * 1000, 2)
        }
    except Exception as e:
        logger.error(f"Unexpected error during database health check: {str(e)}")
        return {
            'status': 'critical',
            'error': str(e),
            'response_time_ms': round((time.time() - start_time) * 1000, 2)
        }

def _check_redis():
    """
    Check Redis connection and health.
    
    Returns:
        dict: Redis health check result
    """
    import redis
    from redis.exceptions import RedisError
    
    start_time = time.time()
    redis_url = current_app.config.get('REDIS_URL')
    
    if not redis_url:
        return {
            'status': 'warning',
            'error': 'Redis URL not configured',
            'response_time_ms': 0
        }
    
    try:
        # Connect to Redis
        r = redis.from_url(redis_url)
        
        # Test connection with a ping
        assert r.ping()
        
        # Get Redis info
        info = r.info()
        
        redis_info = {
            'version': info.get('redis_version'),
            'used_memory_human': info.get('used_memory_human'),
            'connected_clients': info.get('connected_clients'),
            'uptime_in_seconds': info.get('uptime_in_seconds'),
        }
        
        return {
            'status': 'healthy',
            'response_time_ms': round((time.time() - start_time) * 1000, 2),
            'info': redis_info,
            'redis_url': _mask_connection_string(redis_url)
        }
    except RedisError as e:
        logger.error(f"Redis health check failed: {str(e)}")
        return {
            'status': 'critical' if current_app.config.get('REDIS_REQUIRED', True) else 'warning',
            'error': str(e),
            'response_time_ms': round((time.time() - start_time) * 1000, 2)
        }
    except Exception as e:
        logger.error(f"Unexpected error during Redis health check: {str(e)}")
        return {
            'status': 'critical' if current_app.config.get('REDIS_REQUIRED', True) else 'warning',
            'error': str(e),
            'response_time_ms': round((time.time() - start_time) * 1000, 2)
        }

def _check_email_service():
    """
    Check email service configuration and connectivity.
    
    Returns:
        dict: Email service health check result
    """
    start_time = time.time()
    
    # Check if email is configured
    smtp_server = current_app.config.get('SMTP_SERVER')
    smtp_port = current_app.config.get('SMTP_PORT')
    smtp_username = current_app.config.get('SMTP_USERNAME')
    
    if not smtp_server or not smtp_port:
        return {
            'status': 'warning',
            'error': 'Email service not fully configured',
            'response_time_ms': 0
        }
    
    # Only check connectivity if email is configured
    if smtp_server and smtp_port:
        import socket
        
        try:
            # Try to connect to the SMTP server
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(3.0)  # 3 second timeout
            
            # Only test connectivity, don't try to authenticate
            result = sock.connect_ex((smtp_server, int(smtp_port)))
            sock.close()
            
            if result == 0:
                return {
                    'status': 'healthy',
                    'response_time_ms': round((time.time() - start_time) * 1000, 2),
                    'smtp_server': smtp_server,
                    'smtp_port': smtp_port,
                    'configured': True
                }
            else:
                return {
                    'status': 'warning',
                    'error': f'Could not connect to SMTP server (error code: {result})',
                    'response_time_ms': round((time.time() - start_time) * 1000, 2),
                    'smtp_server': smtp_server,
                    'smtp_port': smtp_port,
                    'configured': True
                }
        except Exception as e:
            logger.warning(f"Email service check failed: {str(e)}")
            return {
                'status': 'warning',
                'error': str(e),
                'response_time_ms': round((time.time() - start_time) * 1000, 2),
                'smtp_server': smtp_server,
                'smtp_port': smtp_port,
                'configured': True
            }
    
    return {
        'status': 'warning',
        'message': 'Email service not configured',
        'response_time_ms': round((time.time() - start_time) * 1000, 2),
        'configured': False
    }

def _check_oauth():
    """
    Check OAuth provider configuration.
    
    Returns:
        dict: OAuth provider health check result
    """
    start_time = time.time()
    
    # Check if Google OAuth is configured
    google_client_id = current_app.config.get('GOOGLE_CLIENT_ID')
    google_client_secret = current_app.config.get('GOOGLE_CLIENT_SECRET')
    
    google_configured = bool(google_client_id and google_client_secret)
    
    oauth_providers = {
        'google': {
            'configured': google_configured
        }
    }
    
    # Determine status based on configuration
    if not any(provider['configured'] for provider in oauth_providers.values()):
        status = 'warning'
        message = 'No OAuth providers configured'
    else:
        status = 'healthy'
        message = 'OAuth providers configured'
    
    return {
        'status': status,
        'message': message,
        'response_time_ms': round((time.time() - start_time) * 1000, 2),
        'providers': oauth_providers
    }

def _get_system_info():
    """
    Get system information for diagnostics.
    
    Returns:
        dict: System information
    """
    # Get CPU and memory info
    try:
        memory = psutil.virtual_memory()
        memory_info = {
            'total_gb': round(memory.total / (1024**3), 2),
            'available_gb': round(memory.available / (1024**3), 2),
            'used_percent': memory.percent
        }
        
        cpu_info = {
            'percent': psutil.cpu_percent(interval=0.1),
            'count': psutil.cpu_count(),
            'load': _get_load_avg()
        }
        
        disk = psutil.disk_usage('/')
        disk_info = {
            'total_gb': round(disk.total / (1024**3), 2),
            'free_gb': round(disk.free / (1024**3), 2),
            'used_percent': disk.percent
        }
    except Exception as e:
        logger.warning(f"Error getting system metrics: {str(e)}")
        memory_info = cpu_info = disk_info = {'error': str(e)}
    
    return {
        'hostname': socket.gethostname(),
        'os': platform.platform(),
        'python_version': platform.python_version(),
        'uptime': _get_uptime(),
        'memory': memory_info,
        'cpu': cpu_info,
        'disk': disk_info
    }

def _get_load_avg():
    """
    Get system load average if available.
    
    Returns:
        list: Load averages for 1, 5, and 15 minutes
    """
    try:
        if hasattr(os, 'getloadavg'):
            return list(os.getloadavg())
        return None
    except (AttributeError, OSError):
        return None

def _get_uptime():
    """
    Get system uptime if available.
    
    Returns:
        float: System uptime in seconds
    """
    try:
        return psutil.boot_time()
    except Exception:
        return None

def _mask_connection_string(conn_string):
    """
    Mask sensitive information in connection strings.
    
    Args:
        conn_string: Connection string to mask
        
    Returns:
        str: Masked connection string
    """
    if not conn_string:
        return None
    
    try:
        # Simple approach: just mask anything after : or @ and before the next /
        import re
        masked = re.sub(r'(?<=:)[^/]+(?=/)', '***', conn_string)
        masked = re.sub(r'(?<=@)[^/]+(?=/)', '***', masked)
        return masked
    except Exception:
        # If anything goes wrong, return a fully masked string
        return "***MASKED***" 
```


### FILE: backend\auth-service\src\models\auth.py
```
from datetime import datetime, timedelta
from sqlalchemy.sql import func
import bcrypt
from ..schemas.auth import AuthUserCreate, AuthUserUpdate, AuthUserResponse, SessionCreate, EmailVerificationCreate
from ..database import db
from flask import current_app

class AuthUser(db.Model):
    __tablename__ = 'auth_users'

    id = db.Column(db.Integer, primary_key=True)
    email = db.Column(db.String(255), unique=True, nullable=False)
    password_hash = db.Column(db.Text, nullable=True)
    is_google_user = db.Column(db.Boolean, default=False)
    first_login = db.Column(db.Boolean, default=True)
    is_email_verified = db.Column(db.Boolean, default=False)
    created_at = db.Column(db.DateTime, default=func.now())
    updated_at = db.Column(db.DateTime, default=func.now(), onupdate=func.now())
    last_login = db.Column(db.DateTime)
    
    # Profile fields
    first_name = db.Column(db.String(100))
    last_name = db.Column(db.String(100))
    profile_picture = db.Column(db.String(255))
    
    # OAuth fields
    google_id = db.Column(db.String(255), unique=True, nullable=True)
    google_refresh_token = db.Column(db.Text, nullable=True)

    # Account security fields
    failed_login_attempts = db.Column(db.Integer, default=0)
    locked_until = db.Column(db.DateTime, nullable=True)
    password_last_changed = db.Column(db.DateTime, default=func.now())
    require_password_change = db.Column(db.Boolean, default=False)
    last_failed_login = db.Column(db.DateTime, nullable=True)
    security_audit_log = db.Column(db.JSON, nullable=True)

    @classmethod
    def from_schema(cls, user_create: AuthUserCreate):
        """Create a new user from schema"""
        user = cls(
            email=user_create.email.lower(),
            first_name=user_create.first_name,
            last_name=user_create.last_name
        )
        user.set_password(user_create.password)
        return user

    def update_from_schema(self, user_update: AuthUserUpdate):
        """Update user from schema"""
        for field, value in user_update.model_dump(exclude_unset=True).items():
            setattr(self, field, value)

    def to_schema(self) -> AuthUserResponse:
        """Convert to response schema"""
        return AuthUserResponse.model_validate(self)

    def set_password(self, password: str):
        """Hash and set the user's password with history tracking"""
        if not password:
            raise ValueError("Password cannot be empty")
            
        # Check password history
        if self.password_hash:
            # Store old password in history
            history = PasswordHistory(
                user_id=self.id,
                password_hash=self.password_hash
            )
            db.session.add(history)
            
            # Check if password was used recently
            recent_passwords = PasswordHistory.query.filter_by(
                user_id=self.id
            ).order_by(PasswordHistory.created_at.desc()).limit(5).all()
            
            for old_pw in recent_passwords:
                if bcrypt.checkpw(password.encode('utf-8'), old_pw.password_hash.encode('utf-8')):
                    raise ValueError("Password was used recently. Please choose a different password.")

        salt = bcrypt.gensalt()
        self.password_hash = bcrypt.hashpw(password.encode('utf-8'), salt).decode('utf-8')
        self.password_last_changed = datetime.utcnow()
        self.require_password_change = False
        
        # Log password change
        self._log_security_event("password_changed")

    def check_password(self, password: str) -> bool:
        """Verify the user's password with account lockout"""
        if self.is_locked():
            return False
            
        if not self.password_hash:
            return False
            
        is_valid = bcrypt.checkpw(password.encode('utf-8'), self.password_hash.encode('utf-8'))
        
        if not is_valid:
            self.failed_login_attempts += 1
            self.last_failed_login = datetime.utcnow()
            
            # Lock account after 5 failed attempts
            if self.failed_login_attempts >= 5:
                self.locked_until = datetime.utcnow() + timedelta(minutes=15)
                self._log_security_event("account_locked", {"reason": "too_many_failed_attempts"})
            
            db.session.commit()
            return False
            
        # Reset failed attempts on successful login
        self.failed_login_attempts = 0
        self.locked_until = None
        db.session.commit()
        return True

    def is_locked(self) -> bool:
        """Check if the account is locked"""
        if not self.locked_until:
            return False
        return datetime.utcnow() < self.locked_until

    def unlock(self):
        """Unlock the account"""
        self.locked_until = None
        self.failed_login_attempts = 0
        self._log_security_event("account_unlocked")
        db.session.commit()

    def force_password_change(self):
        """Force user to change password on next login"""
        self.require_password_change = True
        self._log_security_event("password_change_required")
        db.session.commit()

    def _log_security_event(self, event_type: str, details: dict = None):
        """Log security-related events"""
        if self.security_audit_log is None:
            self.security_audit_log = []
            
        event = {
            "type": event_type,
            "timestamp": datetime.utcnow().isoformat(),
            "details": details or {}
        }
        
        self.security_audit_log.append(event)
        if len(self.security_audit_log) > 100:  # Keep last 100 events
            self.security_audit_log = self.security_audit_log[-100:]

    def create_session(self, device_info=None, expires_at=None) -> 'UserSession':
        """Create a new session for the user"""
        session_data = SessionCreate(
            user_id=self.id,
            device_info=device_info,
            ip_address=device_info.get('ip_address') if device_info else None,
            expires_at=expires_at or datetime.utcnow() + timedelta(days=7)
        )
        session = UserSession.from_schema(session_data)
        db.session.add(session)
        return session

    def create_verification_token(self) -> 'EmailVerification':
        """Create a new email verification token"""
        import secrets
        token_data = EmailVerificationCreate(
            user_id=self.id,
            token=secrets.token_urlsafe(32),
            expires_at=datetime.utcnow() + timedelta(hours=24)
        )
        verification = EmailVerification.from_schema(token_data)
        db.session.add(verification)
        return verification

class PasswordResetToken(db.Model):
    __tablename__ = 'password_reset_tokens'

    id = db.Column(db.Integer, primary_key=True)
    user_id = db.Column(db.Integer, db.ForeignKey('auth_users.id', ondelete='CASCADE'), nullable=False)
    token = db.Column(db.Text, nullable=False)
    expires_at = db.Column(db.DateTime, nullable=False)
    created_at = db.Column(db.DateTime, default=func.now())
    used = db.Column(db.Boolean, default=False)

    user = db.relationship('AuthUser', backref=db.backref('reset_tokens', lazy=True))

    @classmethod
    def from_schema(cls, token_data):
        return cls(
            user_id=token_data.user_id,
            token=token_data.token,
            expires_at=token_data.expires_at
        )

class UserSession(db.Model):
    __tablename__ = 'user_sessions'

    id = db.Column(db.Integer, primary_key=True)
    user_id = db.Column(db.Integer, db.ForeignKey('auth_users.id', ondelete='CASCADE'), nullable=False)
    token = db.Column(db.Text, nullable=False)
    refresh_token = db.Column(db.Text, nullable=True)
    device_info = db.Column(db.JSON, nullable=True)
    ip_address = db.Column(db.String(45), nullable=True)
    created_at = db.Column(db.DateTime, default=func.now())
    expires_at = db.Column(db.DateTime, nullable=False)
    refresh_token_expires_at = db.Column(db.DateTime, nullable=True)
    revoked = db.Column(db.Boolean, default=False)
    revoked_at = db.Column(db.DateTime, nullable=True)
    revocation_reason = db.Column(db.String(100), nullable=True)
    last_used_at = db.Column(db.DateTime, nullable=True)
    device_name = db.Column(db.String(100), nullable=True)
    device_type = db.Column(db.String(50), nullable=True)
    user_agent = db.Column(db.Text, nullable=True)

    user = db.relationship('AuthUser', backref=db.backref('sessions', lazy=True))

    @classmethod
    def from_schema(cls, session_data: SessionCreate):
        import secrets
        return cls(
            user_id=session_data.user_id,
            token=secrets.token_urlsafe(32),
            refresh_token=secrets.token_urlsafe(32) if session_data.include_refresh_token else None,
            device_info=session_data.device_info,
            ip_address=session_data.ip_address,
            expires_at=session_data.expires_at,
            refresh_token_expires_at=session_data.refresh_token_expires_at,
            device_name=session_data.device_info.get('name') if session_data.device_info else None,
            device_type=session_data.device_info.get('type') if session_data.device_info else None,
            user_agent=session_data.device_info.get('user_agent') if session_data.device_info else None
        )

    def revoke(self, reason: str = None):
        """Revoke the session"""
        self.revoked = True
        self.revoked_at = datetime.utcnow()
        self.revocation_reason = reason
        db.session.commit()

    def refresh(self) -> 'UserSession':
        """Create a new session using the refresh token"""
        if self.revoked or not self.refresh_token or datetime.utcnow() > self.refresh_token_expires_at:
            raise ValueError("Invalid or expired refresh token")
        
        import secrets
        new_session = UserSession(
            user_id=self.user_id,
            token=secrets.token_urlsafe(32),
            refresh_token=secrets.token_urlsafe(32),
            device_info=self.device_info,
            ip_address=self.ip_address,
            expires_at=datetime.utcnow() + timedelta(days=1),
            refresh_token_expires_at=datetime.utcnow() + timedelta(days=30),
            device_name=self.device_name,
            device_type=self.device_type,
            user_agent=self.user_agent
        )
        
        self.revoke("Refreshed")
        db.session.add(new_session)
        db.session.commit()
        return new_session

    def update_last_used(self):
        """Update the last used timestamp"""
        self.last_used_at = datetime.utcnow()
        try:
            db.session.commit()
        except Exception as e:
            db.session.rollback()
            current_app.logger.error(f"Error updating session last_used timestamp: {str(e)}")
            return False
        return True

class EmailVerification(db.Model):
    __tablename__ = 'email_verifications'

    id = db.Column(db.Integer, primary_key=True)
    user_id = db.Column(db.Integer, db.ForeignKey('auth_users.id', ondelete='CASCADE'), nullable=False)
    token = db.Column(db.String(255), unique=True, nullable=False)
    expires_at = db.Column(db.DateTime, nullable=False)
    created_at = db.Column(db.DateTime, default=func.now())
    is_used = db.Column(db.Boolean, default=False)

    user = db.relationship('AuthUser', backref=db.backref('email_verifications', lazy=True))

    @classmethod
    def from_schema(cls, verification_data: EmailVerificationCreate):
        return cls(
            user_id=verification_data.user_id,
            token=verification_data.token,
            expires_at=verification_data.expires_at
        )

class PasswordHistory(db.Model):
    __tablename__ = 'password_history'

    id = db.Column(db.Integer, primary_key=True)
    user_id = db.Column(db.Integer, db.ForeignKey('auth_users.id', ondelete='CASCADE'), nullable=False)
    password_hash = db.Column(db.Text, nullable=False)
    created_at = db.Column(db.DateTime, default=func.now())

    user = db.relationship('AuthUser', backref=db.backref('password_history', lazy=True)) 
```


### FILE: backend\auth-service\src\routes\auth.py
```
from flask import Blueprint, request, jsonify, current_app, g
from datetime import datetime, timedelta, timezone
import bcrypt
import jwt
from google.oauth2 import id_token
from google.auth.transport import requests as google_requests
import re
import secrets
from ..models.auth import AuthUser, PasswordResetToken, UserSession, EmailVerification
from meeting_shared.database import db, transaction
from meeting_shared.middleware.validation import validate_schema
from meeting_shared.middleware.rate_limiter import rate_limit
from meeting_shared.middleware.auth import jwt_required
from meeting_shared.schemas.base import ErrorResponse, SuccessResponse
from ..schemas.auth import (
    AuthUserCreate, AuthUserUpdate, AuthUserResponse, SessionCreate,
    EmailVerificationCreate, AuthUserLogin, GoogleLogin, PasswordReset,
    PasswordResetConfirm, TokenRefresh, SessionRevoke
)
from ..utils.email_service import send_verification_email
from ..utils.auth import get_current_user, get_current_session
import logging
from ..utils.rate_limiter import rate_limit as custom_rate_limit
from ..utils.database import with_transaction
import string
from functools import wraps
from ..utils.token_service import TokenService

logger = logging.getLogger(__name__)
auth_bp = Blueprint('auth', __name__)

def token_service():
    """Get token service instance"""
    return TokenService()

def service_auth_required(f):
    """Decorator to require service authentication key"""
    @wraps(f)
    def decorated(*args, **kwargs):
        service_key = request.headers.get('X-Service-Key')
        expected_key = current_app.config.get('SERVICE_KEY')
        
        if not service_key or service_key != expected_key:
            logger.warning(f"Invalid service key attempt from {request.remote_addr}")
            return jsonify({"error": "Invalid service key"}), 403
            
        return f(*args, **kwargs)
    
    return decorated

def validate_password(password):
    """Validate password strength"""
    if len(password) < 12:
        return False, "Password must be at least 12 characters long"
    
    if not any(c.isupper() for c in password):
        return False, "Password must contain at least one uppercase letter"
    
    if not any(c.islower() for c in password):
        return False, "Password must contain at least one lowercase letter"
    
    if not any(c.isdigit() for c in password):
        return False, "Password must contain at least one number"
    
    return True, None

def generate_verification_token():
    """Generate a secure verification token"""
    alphabet = string.ascii_letters + string.digits
    return ''.join(secrets.choice(alphabet) for _ in range(32))

@auth_bp.route('/register', methods=['POST'])
@custom_rate_limit(limit=5, window=3600)  # 5 registrations per hour
def register():
    data = request.get_json()
    
    # Validate request data
    try:
        user_data = AuthUserCreate(**data)
    except Exception as e:
        return jsonify({"error": str(e)}), 400
    
    # Validate password strength
    is_valid, error = validate_password(user_data.password)
    if not is_valid:
        return jsonify({"error": error}), 400
    
    # Check if user exists
    if AuthUser.query.filter_by(email=user_data.email).first():
        return jsonify({"error": "Email already registered"}), 409
    
    # Create user
    user = AuthUser.from_schema(user_data)
    current_app.db.session.add(user)
    current_app.db.session.commit()
    
    # Generate and send verification email
    verification = user.create_verification_token()
    if send_verification_email(user.email, verification.token):
        return jsonify({"message": "Registration successful. Please check your email to verify your account."}), 201
    else:
        return jsonify({"error": "Failed to send verification email"}), 500

@auth_bp.route('/verify-email/<token>', methods=['GET'])
@custom_rate_limit(limit=10, window=3600)  # 10 verification attempts per hour
@with_transaction
def verify_email(token):
    verification = EmailVerification.query.filter_by(
        token=token,
        is_used=False
    ).first()
    
    if not verification or verification.is_expired():
        return jsonify({"error": "Invalid or expired verification token"}), 400
    
    user = verification.user
    user.is_email_verified = True
    verification.is_used = True
    
    return jsonify({"message": "Email verified successfully"})

@auth_bp.route('/resend-verification', methods=['POST'])
@custom_rate_limit(limit=3, window=3600)  # 3 resend attempts per hour
def resend_verification():
    data = request.get_json()
    if not data or 'email' not in data:
        return jsonify({"error": "Email is required"}), 400
    
    user = AuthUser.query.filter_by(email=data['email']).first()
    if not user:
        return jsonify({"error": "User not found"}), 404
    
    if user.is_email_verified:
        return jsonify({"error": "Email is already verified"}), 400
    
    # Create new verification token
    verification = user.create_verification_token()
    
    # Send verification email
    if send_verification_email(user.email, verification.token):
        return jsonify({"message": "Verification email sent"})
    else:
        return jsonify({"error": "Failed to send verification email"}), 500

@auth_bp.route('/login', methods=['POST'])
@custom_rate_limit(limit=10, window=300)  # 10 login attempts per 5 minutes
def login():
    data = request.get_json()
    
    try:
        login_data = AuthUserLogin(**data)
    except Exception as e:
        return jsonify({"error": str(e)}), 400
    
    user = AuthUser.query.filter_by(email=login_data.email).first()
    if not user or not user.check_password(login_data.password):
        return jsonify({"error": "Invalid email or password"}), 401
    
    if not user.is_email_verified:
        return jsonify({"error": "Please verify your email before logging in"}), 403
    
    # Create session
    session = user.create_session(
        device_info=login_data.device_info
    )
    current_app.db.session.add(session)
    current_app.db.session.commit()
    
    return jsonify({
        "token": session.token,
        "refresh_token": session.refresh_token,
        "user": AuthUserResponse.from_orm(user).dict()
    })

@auth_bp.route('/google/login', methods=['POST'])
@validate_schema(GoogleLogin)
def google_login(data: GoogleLogin):
    """Handle Google OAuth login"""
    try:
        # Verify Google token
        idinfo = id_token.verify_oauth2_token(
            data.token,
            google_requests.Request(),
            current_app.config['GOOGLE_CLIENT_ID']
        )

        email = idinfo['email']
        
        with transaction():
            # Check if user exists
            user = AuthUser.query.filter_by(email=email).first()
            
            if not user:
                # Create new user
                user = AuthUser(
                    email=email,
                    is_google_user=True,
                    is_email_verified=True,
                    first_name=idinfo.get('given_name'),
                    last_name=idinfo.get('family_name'),
                    profile_picture=idinfo.get('picture'),
                    google_id=idinfo['sub']
                )
                db.session.add(user)
                db.session.flush()
            
            # Update Google info if needed
            if user.google_id != idinfo['sub']:
                user.google_id = idinfo['sub']
                user.is_google_user = True
            
            # Create session
            session = user.create_session(data.device_info)
            user.last_login = datetime.utcnow().replace(tzinfo=timezone.utc)
            
            return jsonify(SuccessResponse(
                message="Google login successful",
                data={
                    "token": session.token,
                    "refresh_token": session.refresh_token,
                    "user": user.to_schema().model_dump()
                }
            ).model_dump())

    except ValueError as e:
        # Invalid token
        logger.error(f"Invalid Google token: {str(e)}")
        return jsonify(ErrorResponse(
            error="Authentication Error",
            message="Invalid Google token"
        ).model_dump()), 401
    except Exception as e:
        logger.error(f"Google login error: {str(e)}")
        return jsonify(ErrorResponse(
            error="Authentication Error",
            message="Google login failed"
        ).model_dump()), 500

@auth_bp.route('/reset-password', methods=['POST'])
@custom_rate_limit(limit=3, window=3600)  # 3 reset attempts per hour
@validate_schema(PasswordReset)
def reset_password(data: PasswordReset):
    """Initiate password reset"""
    try:
        user = AuthUser.query.filter_by(email=data.email.lower()).first()
        if not user:
            # Return success even if user doesn't exist (security)
            return jsonify(SuccessResponse(
                message="If your email is registered, you will receive reset instructions"
            ).model_dump())

        with transaction():
            # Create reset token
            token = PasswordResetToken(
                user_id=user.id,
                token=secrets.token_urlsafe(32),
                expires_at=datetime.utcnow() + timedelta(hours=24)
            )
            db.session.add(token)
            
            # Send reset email (implement this)
            # send_password_reset_email(user.email, token.token)
            
            return jsonify(SuccessResponse(
                message="If your email is registered, you will receive reset instructions"
            ).model_dump())

    except Exception as e:
        logger.error(f"Password reset error: {str(e)}")
        return jsonify(ErrorResponse(
            error="Reset Error",
            message="Failed to process password reset"
        ).model_dump()), 500

@auth_bp.route('/reset-password/confirm', methods=['POST'])
@validate_schema(PasswordResetConfirm)
def confirm_reset_password(data: PasswordResetConfirm):
    """Confirm password reset"""
    try:
        # Find valid token
        token = PasswordResetToken.query.filter_by(
            token=data.token,
            used=False
        ).filter(PasswordResetToken.expires_at > datetime.utcnow()).first()

        if not token:
            return jsonify(ErrorResponse(
                error="Reset Error",
                message="Invalid or expired token"
            ).model_dump()), 400

        with transaction():
            # Update password
            user = token.user
            user.set_password(data.new_password)
            
            # Invalidate token
            token.used = True
            
            # Revoke all sessions
            UserSession.query.filter_by(user_id=user.id).update({
                'revoked': True,
                'revoked_at': datetime.utcnow().replace(tzinfo=timezone.utc),
                'revocation_reason': 'Password reset'
            })
            
            return jsonify(SuccessResponse(
                message="Password has been reset successfully"
            ).model_dump())

    except Exception as e:
        logger.error(f"Password reset confirmation error: {str(e)}")
        return jsonify(ErrorResponse(
            error="Reset Error",
            message="Failed to reset password"
        ).model_dump()), 500

@auth_bp.route('/refresh-token', methods=['POST'])
@validate_schema(TokenRefresh)
def refresh_token(data: TokenRefresh):
    """Refresh access token using refresh token"""
    try:
        # Find valid session by refresh token
        session = UserSession.query.filter_by(
            refresh_token=data.refresh_token,
            revoked=False
        ).filter(UserSession.refresh_token_expires_at > datetime.utcnow()).first()

        if not session:
            return jsonify(ErrorResponse(
                error="Authentication Error",
                message="Invalid or expired refresh token"
            ).model_dump()), 401

        with transaction():
            # Create new session
            new_session = session.refresh()
            
            return jsonify(SuccessResponse(
                message="Token refreshed successfully",
                data={
                    "token": new_session.token,
                    "refresh_token": new_session.refresh_token
                }
            ).model_dump())

    except Exception as e:
        logger.error(f"Token refresh error: {str(e)}")
        return jsonify(ErrorResponse(
            error="Authentication Error",
            message="Failed to refresh token"
        ).model_dump()), 500

@auth_bp.route('/sessions', methods=['GET'])
@jwt_required
def list_sessions():
    """List all active sessions for the current user"""
    try:
        current_user = get_current_user()
        sessions = UserSession.query.filter_by(
            user_id=current_user.id,
            revoked=False
        ).filter(UserSession.expires_at > datetime.utcnow()).all()
        
        return jsonify(SuccessResponse(
            message="Sessions retrieved successfully",
            data={
                "sessions": [session.to_schema().model_dump() for session in sessions],
                "total_count": len(sessions)
            }
        ).model_dump())

    except Exception as e:
        logger.error(f"Error listing sessions: {str(e)}")
        return jsonify(ErrorResponse(
            error="Session Error",
            message="Failed to list sessions"
        ).model_dump()), 500

@auth_bp.route('/sessions/<int:session_id>/revoke', methods=['POST'])
@jwt_required
@validate_schema(SessionRevoke)
def revoke_session(session_id: int, data: SessionRevoke):
    """Revoke a specific session"""
    try:
        current_user = get_current_user()
        current_session = get_current_session()
        
        # Find session
        session = UserSession.query.filter_by(
            id=session_id,
            user_id=current_user.id,
            revoked=False
        ).first()
        
        if not session:
            return jsonify(ErrorResponse(
                error="Session Error",
                message="Session not found"
            ).model_dump()), 404
            
        with transaction():
            session.revoke(reason=data.reason or "User initiated revocation")
            
            return jsonify(SuccessResponse(
                message="Session revoked successfully"
            ).model_dump())

    except Exception as e:
        logger.error(f"Error revoking session: {str(e)}")
        return jsonify(ErrorResponse(
            error="Session Error",
            message="Failed to revoke session"
        ).model_dump()), 500

@auth_bp.route('/sessions/revoke-all', methods=['POST'])
@jwt_required
def revoke_all_sessions():
    """Revoke all sessions except the current one"""
    try:
        current_user = get_current_user()
        current_session = get_current_session()
        
        with transaction():
            # Revoke all other sessions
            UserSession.query.filter(
                UserSession.user_id == current_user.id,
                UserSession.id != current_session.id,
                UserSession.revoked == False
            ).update({
                'revoked': True,
                'revoked_at': datetime.utcnow().replace(tzinfo=timezone.utc),
                'revocation_reason': 'User revoked all sessions'
            })
            
            return jsonify(SuccessResponse(
                message="All other sessions revoked successfully"
            ).model_dump())

    except Exception as e:
        logger.error(f"Error revoking all sessions: {str(e)}")
        return jsonify(ErrorResponse(
            error="Session Error",
            message="Failed to revoke sessions"
        ).model_dump()), 500

@auth_bp.route('/logout', methods=['POST'])
@jwt_required
def logout():
    """Log out user by revoking current session"""
    try:
        current_session = get_current_session()
        
        with transaction():
            current_session.revoke(reason="User logout", revoked_at=datetime.utcnow().replace(tzinfo=timezone.utc))
            
            return jsonify(SuccessResponse(
                message="Logged out successfully"
            ).model_dump())

    except Exception as e:
        logger.error(f"Logout error: {str(e)}")
        return jsonify(ErrorResponse(
            error="Logout Error",
            message="Failed to logout"
        ).model_dump()), 500

@auth_bp.route('/validate-token', methods=['POST'])
@service_auth_required
def validate_token():
    """
    Validate a JWT token
    This endpoint is used by other services to validate tokens
    """
    try:
        data = request.get_json()
        if not data or 'token' not in data:
            return jsonify({"error": "Token is required"}), 400
            
        token = data['token']
        
        try:
            # First, try to decode the token
            payload = jwt.decode(
                token,
                current_app.config['JWT_SECRET_KEY'],
                algorithms=['HS256']
            )
            
            # Check if user exists
            user_id = payload.get('user_id')
            if not user_id:
                return jsonify({"error": "Invalid token: missing user_id"}), 401
                
            user = AuthUser.query.get(user_id)
            if not user:
                return jsonify({"error": "User not found"}), 401
                
            # Verify if token belongs to a valid session
            session = UserSession.query.filter_by(
                token=token,
                revoked=False
            ).first()
            
            if not session:
                return jsonify({"error": "Invalid or revoked session"}), 401
                
            # Update last_used timestamp for the session
            session.update_last_used()
            
            # Return payload with additional user info
            response_data = {
                **payload,
                "is_active": not user.is_locked(),
                "is_email_verified": user.is_email_verified,
                "roles": user.roles
            }
            
            return jsonify({"data": response_data}), 200
            
        except jwt.ExpiredSignatureError:
            return jsonify({"error": "Token has expired"}), 401
        except jwt.InvalidTokenError as e:
            return jsonify({"error": f"Invalid token: {str(e)}"}), 401
            
    except Exception as e:
        logger.error(f"Error validating token: {str(e)}")
        return jsonify({"error": "Server error occurred during token validation"}), 500 
```


### FILE: backend\auth-service\src\schemas\auth.py
```
from datetime import datetime
from typing import Optional, Dict, Any, List
from pydantic import BaseModel, EmailStr, Field, validator, root_validator
from meeting_shared.schemas.base import BaseSchema
from pydantic.types import SecretStr

class AuthUserBase(BaseSchema):
    email: EmailStr
    is_google_user: bool = False
    first_login: bool = True
    is_email_verified: bool = False
    first_name: Optional[str] = Field(None, min_length=1, max_length=100)
    last_name: Optional[str] = Field(None, min_length=1, max_length=100)
    profile_picture: Optional[str] = None
    last_login: Optional[datetime] = None

class AuthUserCreate(BaseModel):
    email: EmailStr
    password: str = Field(..., min_length=12, max_length=72)
    first_name: Optional[str] = Field(None, min_length=1, max_length=100)
    last_name: Optional[str] = Field(None, min_length=1, max_length=100)

    @validator('password')
    def validate_password(cls, v):
        if not any(c.isupper() for c in v):
            raise ValueError('Password must contain at least one uppercase letter')
        if not any(c.islower() for c in v):
            raise ValueError('Password must contain at least one lowercase letter')
        if not any(c.isdigit() for c in v):
            raise ValueError('Password must contain at least one number')
        if not any(c in '@$!%*?&' for c in v):
            raise ValueError('Password must contain at least one special character (@$!%*?&)')
        return v

class AuthUserUpdate(BaseModel):
    first_name: Optional[str] = Field(None, min_length=1, max_length=100)
    last_name: Optional[str] = Field(None, min_length=1, max_length=100)
    profile_picture: Optional[str] = None

class AuthUserLogin(BaseModel):
    email: EmailStr
    password: str = Field(..., min_length=12, max_length=72)
    device_info: Optional[Dict[str, Any]] = None

class GoogleLogin(BaseModel):
    token: str
    device_info: Optional[Dict[str, Any]] = None

class PasswordReset(BaseModel):
    email: EmailStr

class PasswordResetConfirm(BaseModel):
    token: str
    new_password: str = Field(..., min_length=12, max_length=72)

    @validator('new_password')
    def validate_password(cls, v):
        if not any(c.isupper() for c in v):
            raise ValueError('Password must contain at least one uppercase letter')
        if not any(c.islower() for c in v):
            raise ValueError('Password must contain at least one lowercase letter')
        if not any(c.isdigit() for c in v):
            raise ValueError('Password must contain at least one number')
        if not any(c in '@$!%*?&' for c in v):
            raise ValueError('Password must contain at least one special character (@$!%*?&)')
        return v

class SessionCreate(BaseModel):
    user_id: int
    device_info: Optional[Dict[str, Any]] = None
    ip_address: Optional[str] = Field(None, max_length=45)
    expires_at: datetime
    include_refresh_token: bool = True
    refresh_token_expires_at: Optional[datetime] = None

class SessionResponse(BaseModel):
    token: str
    refresh_token: Optional[str] = None
    expires_at: datetime
    refresh_token_expires_at: Optional[datetime] = None
    device_info: Optional[Dict[str, Any]] = None
    device_name: Optional[str] = None
    device_type: Optional[str] = None
    created_at: datetime
    last_used_at: Optional[datetime] = None

class TokenRefresh(BaseModel):
    refresh_token: str
    device_info: Optional[Dict[str, Any]] = None

class SessionRevoke(BaseModel):
    session_id: int
    reason: Optional[str] = None

class ActiveSessionsResponse(BaseModel):
    sessions: List[SessionResponse]
    total_count: int

class EmailVerificationCreate(BaseModel):
    user_id: int
    token: str = Field(..., min_length=32)
    expires_at: datetime

class AuthUserResponse(AuthUserBase):
    id: int
    created_at: datetime
    updated_at: datetime 
```


### FILE: backend\auth-service\src\schemas\base.py
```
from datetime import datetime
from typing import Optional
from pydantic import BaseModel, ConfigDict

class BaseSchema(BaseModel):
    """Base schema class with common fields and configuration"""
    model_config = ConfigDict(from_attributes=True)
    
    id: Optional[int] = None
    created_at: Optional[datetime] = None
    updated_at: Optional[datetime] = None

    model_config = ConfigDict(json_encoders={
        datetime: lambda dt: dt.isoformat()
    }) 
```


### FILE: backend\auth-service\src\tasks\cleanup.py
```
import logging
from datetime import datetime, timedelta
from flask import current_app
from sqlalchemy.sql import text
from ..database import db
from ..models.auth import UserSession, EmailVerification, PasswordResetToken
from ..utils.database import transaction_context
from ..utils.session_service import SessionService
from ..utils.service_integration import ServiceIntegration

logger = logging.getLogger(__name__)

def cleanup_expired_data():
    """Cleanup expired sessions, tokens, and other temporary data"""
    try:
        start_time = datetime.utcnow()
        session_service = SessionService()
        service_integration = ServiceIntegration()
        
        logger.info("Starting cleanup of expired data")

        # Use direct SQL for more efficient deletion of expired sessions
        with transaction_context() as session:
            # Get count of sessions to be cleaned up for logging
            session_count_query = text("""
                SELECT COUNT(*) FROM user_sessions 
                WHERE expires_at < :now AND revoked = FALSE
            """)
            session_count = session.execute(
                session_count_query, 
                {"now": datetime.utcnow()}
            ).scalar() or 0
            
            # If there are sessions to clean up, process them in batches
            if session_count > 0:
                logger.info(f"Found {session_count} expired sessions to clean up")
                
                # Process in batches of 500 to avoid long-running transactions
                batch_size = 500
                batches_processed = 0
                total_processed = 0
                
                while total_processed < session_count:
                    # Update in batches
                    update_query = text("""
                        UPDATE user_sessions
                        SET revoked = TRUE,
                            revoked_at = :now,
                            revocation_reason = 'Expired'
                        WHERE id IN (
                            SELECT id FROM user_sessions
                            WHERE expires_at < :now AND revoked = FALSE
                            LIMIT :batch_size
                        )
                        RETURNING id
                    """)
                    
                    result = session.execute(
                        update_query, 
                        {
                            "now": datetime.utcnow(),
                            "batch_size": batch_size
                        }
                    )
                    
                    batch_processed = result.rowcount
                    if batch_processed == 0:
                        break  # No more to process
                        
                    total_processed += batch_processed
                    batches_processed += 1
                    
                    session.commit()  # Commit each batch
                    
                logger.info(f"Cleaned up {total_processed} expired sessions in {batches_processed} batches")
            else:
                logger.info("No expired sessions to clean up")
            
            # Cleanup expired email verifications
            expired_verifications = EmailVerification.query.filter(
                EmailVerification.expires_at < datetime.utcnow(),
                EmailVerification.is_used == False
            ).update({
                'is_used': True
            })
            
            if expired_verifications > 0:
                logger.info(f"Cleaned up {expired_verifications} expired email verifications")
            
            # Cleanup expired password reset tokens
            expired_tokens = PasswordResetToken.query.filter(
                PasswordResetToken.expires_at < datetime.utcnow(),
                PasswordResetToken.used == False
            ).update({
                'used': True
            })
            
            if expired_tokens > 0:
                logger.info(f"Cleaned up {expired_tokens} expired password reset tokens")
            
            # Sync cleanup with main service
            cleanup_data = {
                'expired_sessions': session_count,
                'expired_verifications': expired_verifications,
                'expired_tokens': expired_tokens,
                'cleanup_timestamp': datetime.utcnow().isoformat()
            }
            
            service_integration.sync_user_session(None, None, cleanup_data)
            
            # Calculate duration for monitoring
            duration = (datetime.utcnow() - start_time).total_seconds()
            logger.info(
                f"Cleanup completed in {duration:.2f} seconds - "
                f"Cleaned up {session_count} sessions, "
                f"{expired_verifications} verifications, "
                f"{expired_tokens} reset tokens"
            )
            
            # Store metrics in Redis for monitoring
            try:
                redis_client = current_app.extensions.get('redis')
                if redis_client:
                    metrics = {
                        'expired_sessions': session_count,
                        'expired_verifications': expired_verifications,
                        'expired_tokens': expired_tokens,
                        'duration_seconds': duration,
                        'timestamp': datetime.utcnow().isoformat()
                    }
                    redis_client.hmset('metrics:last_cleanup', metrics)
                    redis_client.expire('metrics:last_cleanup', 86400)  # Keep for 24 hours
                    
                    # Store history for trend analysis
                    redis_client.lpush('metrics:cleanup_history', session_count)
                    redis_client.ltrim('metrics:cleanup_history', 0, 30)  # Keep last 30 entries
            except Exception as e:
                logger.error(f"Failed to store cleanup metrics: {str(e)}")
            
    except Exception as e:
        logger.error(f"Error during cleanup: {str(e)}")
        db.session.rollback() 
```


### FILE: backend\auth-service\src\utils\auth.py
```
from functools import wraps
from flask import request, jsonify, current_app, g
import jwt
from ..models.auth import AuthUser, UserSession
from ..database import db

def jwt_required(f):
    @wraps(f)
    def decorated(*args, **kwargs):
        token = None
        if 'Authorization' in request.headers:
            token = request.headers['Authorization'].split(' ')[1]
        
        if not token:
            return jsonify({'error': 'Token is missing'}), 401
        
        try:
            data = jwt.decode(token, current_app.config['JWT_SECRET_KEY'], algorithms=['HS256'])
            current_user = AuthUser.query.get(data['user_id'])
            if not current_user:
                return jsonify({'error': 'User not found'}), 401
                
            # Store user in flask g object
            g.current_user = current_user
            
            # Get current session
            current_session = UserSession.query.filter_by(
                token=token,
                revoked=False
            ).first()
            if not current_session:
                return jsonify({'error': 'Invalid session'}), 401
            
            g.current_session = current_session
            
        except jwt.ExpiredSignatureError:
            return jsonify({'error': 'Token has expired'}), 401
        except jwt.InvalidTokenError:
            return jsonify({'error': 'Invalid token'}), 401
        
        return f(*args, **kwargs)
    
    return decorated

def get_current_user():
    """Get the current authenticated user"""
    return getattr(g, 'current_user', None)

def get_current_session():
    """Get the current user session"""
    return getattr(g, 'current_session', None) 
```


### FILE: backend\auth-service\src\utils\data_seeder.py
```
import logging
from flask import Flask
from sqlalchemy.exc import IntegrityError
from ..models.auth import AuthUser

logger = logging.getLogger(__name__)

class DataSeeder:
    def __init__(self, app: Flask, db):
        self.app = app
        self.db = db

    def seed_admin_user(self):
        """Seed admin user if not exists"""
        try:
            with self.app.app_context():
                if not AuthUser.query.filter_by(email='admin@example.com').first():
                    admin = AuthUser(
                        email='admin@example.com',
                        first_name='Admin',
                        last_name='User',
                        is_email_verified=True
                    )
                    admin.set_password('Admin123!')
                    self.db.session.add(admin)
                    self.db.session.commit()
                    logger.info("Admin user seeded successfully")
                    return True
                return True
        except Exception as e:
            logger.error(f"Error seeding admin user: {str(e)}")
            return False

    def run_all_seeders(self):
        """Run all data seeders"""
        try:
            success = True
            if not self.seed_admin_user():
                success = False
            return success
        except Exception as e:
            logger.error(f"Error running seeders: {str(e)}")
            return False 
```


### FILE: backend\auth-service\src\utils\database.py
```
from functools import wraps
from typing import Any, Callable, Optional, TypeVar
from flask import current_app
from sqlalchemy.exc import SQLAlchemyError
from contextlib import contextmanager
import logging

# Define TypeVar T for return type annotations
T = TypeVar('T')

# Import from shared modules if available, otherwise use local implementation
from meeting_shared.database import db, transaction

from meeting_shared.utils.database import transaction_context as shared_transaction_context
from meeting_shared.utils.database import with_transaction as shared_with_transaction
from meeting_shared.utils.database import DatabaseManager

logger = logging.getLogger(__name__)

# Re-export shared functions
transaction_context = shared_transaction_context
with_transaction = shared_with_transaction

logger.info("Using shared database utilities")

@contextmanager
def transaction_context():
    """
    Context manager for database transactions.
    Automatically handles commit and rollback.
    
    Usage:
        with transaction_context() as session:
            session.add(user)
    """
    try:
        yield db.session
        db.session.commit()
    except Exception as e:
        db.session.rollback()
        logger.error(f"Transaction error: {str(e)}")
        raise
    finally:
        db.session.close()

def with_transaction(f: Callable[..., T]) -> Callable[..., T]:
    """
    Decorator to wrap a function in a database transaction.
    Automatically handles commit and rollback.
    
    Usage:
        @with_transaction
        def create_user(data):
            user = User(**data)
            db.session.add(user)
            return user
    """
    @wraps(f)
    def decorated(*args: Any, **kwargs: Any) -> T:
        try:
            result = f(*args, **kwargs)
            db.session.commit()
            return result
        except Exception as e:
            db.session.rollback()
            logger.error(f"Database error in {f.__name__}: {str(e)}")
            raise
        finally:
            db.session.close()
    return decorated

# Common database utility functions (these should work with either implementation)
def safe_commit() -> bool:
    """Safely commit database changes"""
    try:
        db.session.commit()
        return True
    except SQLAlchemyError as e:
        db.session.rollback()
        logger.error(f"Database commit error: {str(e)}")
        return False

def safe_add(obj: Any, auto_commit: bool = True) -> bool:
    """Safely add an object to the database"""
    try:
        db.session.add(obj)
        if auto_commit:
            return safe_commit()
        return True
    except SQLAlchemyError as e:
        db.session.rollback()
        logger.error(f"Database add error: {str(e)}")
        return False

def safe_delete(obj: Any, auto_commit: bool = True) -> bool:
    """Safely delete an object from the database"""
    try:
        db.session.delete(obj)
        if auto_commit:
            return safe_commit()
        return True
    except SQLAlchemyError as e:
        db.session.rollback()
        logger.error(f"Database delete error: {str(e)}")
        return False

def cleanup_expired_sessions() -> int:
    """
    Cleanup expired sessions from the database.
    Returns the number of sessions cleaned up.
    """
    from datetime import datetime
    from ..models.auth import UserSession
    
    try:
        count = UserSession.query.filter(
            UserSession.expires_at < datetime.utcnow(),
            UserSession.revoked == False
        ).update({
            'revoked': True,
            'revocation_reason': 'Expired'
        })
        db.session.commit()
        return count
    except SQLAlchemyError as e:
        db.session.rollback()
        logger.error(f"Error cleaning up expired sessions: {str(e)}")
        raise
    finally:
        db.session.close() 
```


### FILE: backend\auth-service\src\utils\email_service.py
```
import os
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from flask import current_app

def send_verification_email(to_email: str, verification_token: str) -> bool:
    """Send verification email to user."""
    try:
        smtp_server = os.getenv('SMTP_SERVER', 'smtp.gmail.com')
        smtp_port = int(os.getenv('SMTP_PORT', '587'))
        smtp_username = os.getenv('SMTP_USERNAME')
        smtp_password = os.getenv('SMTP_PASSWORD')
        
        if not all([smtp_username, smtp_password]):
            current_app.logger.error("SMTP credentials not configured")
            return False

        verification_url = f"{os.getenv('FRONTEND_URL', 'http://localhost:3000')}/verify-email/{verification_token}"
        
        msg = MIMEMultipart()
        msg['From'] = smtp_username
        msg['To'] = to_email
        msg['Subject'] = "Verify your email address"

        html = f"""
        <html>
            <body>
                <h2>Welcome to Meeting App!</h2>
                <p>Please verify your email address by clicking the link below:</p>
                <p>
                    <a href="{verification_url}">Verify Email Address</a>
                </p>
                <p>If you didn't create an account, you can safely ignore this email.</p>
                <p>This link will expire in 24 hours.</p>
            </body>
        </html>
        """
        
        msg.attach(MIMEText(html, 'html'))

        with smtplib.SMTP(smtp_server, smtp_port) as server:
            server.starttls()
            server.login(smtp_username, smtp_password)
            server.send_message(msg)
            
        return True
    except Exception as e:
        current_app.logger.error(f"Failed to send verification email: {str(e)}")
        return False 
```


### FILE: backend\auth-service\src\utils\migrations_manager.py
```
import os
import sys
import logging
from flask import Flask
from flask_migrate import Migrate, upgrade
from sqlalchemy import text
from sqlalchemy.exc import OperationalError
import time

logger = logging.getLogger(__name__)

class MigrationsManager:
    def __init__(self, app: Flask, db, max_retries=5, retry_interval=5):
        self.app = app
        self.db = db
        self.migrate = Migrate(app, db)
        self.max_retries = max_retries
        self.retry_interval = retry_interval

    def wait_for_db(self):
        """Wait for database to be ready"""
        logger.info("Waiting for database...")
        for attempt in range(self.max_retries):
            try:
                with self.app.app_context():
                    self.db.session.execute(text('SELECT 1'))
                logger.info("Database is ready!")
                return True
            except OperationalError as e:
                if attempt == self.max_retries - 1:
                    logger.error(f"Database connection failed after {self.max_retries} attempts: {e}")
                    return False
                logger.warning(f"Database not ready (attempt {attempt + 1}/{self.max_retries}), waiting...")
                time.sleep(self.retry_interval)

    def run_migrations(self):
        """Run database migrations"""
        try:
            with self.app.app_context():
                logger.info("Starting database migrations...")
                upgrade()
                logger.info("Database migrations completed successfully!")
                return True
        except Exception as e:
            logger.error(f"Error running migrations: {e}")
            return False

    def verify_migrations(self):
        """Verify all migrations have been applied"""
        try:
            with self.app.app_context():
                for table in self.db.metadata.tables:
                    if not self.db.engine.dialect.has_table(self.db.engine, table):
                        logger.error(f"Table {table} does not exist!")
                        return False
                logger.info("All database tables verified!")
                return True
        except Exception as e:
            logger.error(f"Error verifying migrations: {e}")
            return False

    def initialize_database(self):
        """Initialize database with migrations and basic data"""
        if not self.wait_for_db():
            logger.error("Could not connect to database")
            sys.exit(1)

        if not self.run_migrations():
            logger.error("Failed to run migrations")
            sys.exit(1)

        if not self.verify_migrations():
            logger.error("Failed to verify migrations")
            sys.exit(1)

        logger.info("Database initialization completed successfully!") 
```


### FILE: backend\auth-service\src\utils\rate_limiter.py
```
"""
This module re-exports the shared rate limiter middleware to maintain
backward compatibility with code that imports from here.
"""

import logging
from functools import wraps
from meeting_shared.middleware.rate_limiter import RateLimiter, rate_limit as shared_rate_limit

logger = logging.getLogger(__name__)

# Add any auth-service specific rate limiting functionality here if needed

# For backward compatibility, re-export the get_client_identifier function
def get_client_identifier():
    """
    Create a unique client identifier based on IP and user agent
    This helps prevent rate limit circumvention
    """
    from flask import request
    import hashlib
    
    ip = request.remote_addr or 'unknown'
    user_agent = request.headers.get('User-Agent', 'unknown')
    
    # Create a hash of the combined values for privacy
    client_id = hashlib.md5(f"{ip}:{user_agent}".encode()).hexdigest()
    return client_id

# Re-export the shared rate_limit with potential customization
def rate_limit(limit: int, window: int, key_func=None):
    """
    Rate limiting decorator that uses the shared implementation
    but allows for custom key generation via key_func
    
    Args:
        limit: Number of requests allowed
        window: Time window in seconds
        key_func: Optional custom function to generate rate limit key
    """
    if key_func:
        # If a custom key_func is provided, wrap the shared implementation
        def custom_wrapper(f):
            @wraps(f)
            def wrapper(*args, **kwargs):
                # Use the shared implementation with our custom key function
                return shared_rate_limit(limit, window, key_func=key_func)(f)(*args, **kwargs)
            return wrapper
        return custom_wrapper
    else:
        # Otherwise, use the shared implementation directly
        return shared_rate_limit(limit, window)

# Alias for backward compatibility
custom_rate_limit = rate_limit 
```


### FILE: backend\auth-service\src\utils\service_integration.py
```
from typing import Optional, Dict, Any
from flask import current_app
import requests
from datetime import datetime
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from circuitbreaker import circuit
import logging
import json
from redis import Redis
from ..models.auth import AuthUser, UserSession
from ..database import db
from .database import transaction_context

logger = logging.getLogger(__name__)

class ServiceIntegrationError(Exception):
    """Base exception for service integration errors"""
    pass

class ServiceConnectionError(ServiceIntegrationError):
    """Raised when connection to service fails"""
    pass

class ServiceTimeoutError(ServiceIntegrationError):
    """Raised when service request times out"""
    pass

class ServiceResponseError(ServiceIntegrationError):
    """Raised when service returns unexpected response"""
    pass

class ServiceIntegration:
    def __init__(self):
        self.flask_service_url = current_app.config.get('FLASK_SERVICE_URL', 'http://backend:5000')
        self.timeout = current_app.config.get('SERVICE_TIMEOUT', 5)
        self.enabled = current_app.config.get('SERVICE_SYNC_ENABLED', True)
        # Initialize Redis for metrics
        self.redis_client = None
        try:
            redis_url = current_app.config.get('REDIS_URL')
            if redis_url:
                self.redis_client = Redis.from_url(redis_url)
        except Exception as e:
            logger.error(f"Failed to initialize Redis for service integration metrics: {e}")

    def _record_metric(self, name: str, success: bool, duration_ms: float):
        """Record service integration metrics in Redis"""
        if not self.redis_client:
            return
            
        try:
            # Record the outcome (success/failure)
            status = "success" if success else "failure"
            self.redis_client.hincrby(f"metrics:service_integration:{name}", status, 1)
            
            # Record the response time
            self.redis_client.lpush(f"metrics:service_integration:{name}:duration", duration_ms)
            self.redis_client.ltrim(f"metrics:service_integration:{name}:duration", 0, 99)  # Keep last 100
            
            # Calculate and update average response time
            durations = self.redis_client.lrange(f"metrics:service_integration:{name}:duration", 0, -1)
            if durations:
                avg_duration = sum(float(d) for d in durations) / len(durations)
                self.redis_client.hset(f"metrics:service_integration:{name}", "avg_duration_ms", avg_duration)
                
            # Set expiry for metrics
            self.redis_client.expire(f"metrics:service_integration:{name}", 86400 * 7)  # 7 days
            self.redis_client.expire(f"metrics:service_integration:{name}:duration", 86400 * 7)  # 7 days
        except Exception as e:
            logger.error(f"Failed to record metric: {e}")

    def _make_request(self, method: str, endpoint: str, **kwargs) -> requests.Response:
        """Make HTTP request with error handling"""
        start_time = datetime.utcnow()
        success = False
        
        try:
            # Add service key to headers if available
            service_key = current_app.config.get('SERVICE_KEY')
            if service_key and 'headers' not in kwargs:
                kwargs['headers'] = {'X-Service-Key': service_key}
            elif service_key and 'headers' in kwargs:
                kwargs['headers'].update({'X-Service-Key': service_key})
                
            response = requests.request(
                method,
                f"{self.flask_service_url}{endpoint}",
                timeout=self.timeout,
                **kwargs
            )
            response.raise_for_status()
            success = True
            return response
        except requests.ConnectionError as e:
            raise ServiceConnectionError(f"Failed to connect to service: {str(e)}")
        except requests.Timeout as e:
            raise ServiceTimeoutError(f"Service request timed out: {str(e)}")
        except requests.HTTPError as e:
            raise ServiceResponseError(f"Service returned error response: {str(e)}")
        except Exception as e:
            raise ServiceIntegrationError(f"Unexpected error in service request: {str(e)}")
        finally:
            # Record metrics
            duration_ms = (datetime.utcnow() - start_time).total_seconds() * 1000
            endpoint_name = endpoint.split('/')[-1]
            self._record_metric(f"{method}_{endpoint_name}", success, duration_ms)

    @retry(
        stop=stop_after_attempt(5),
        wait=wait_exponential(multiplier=1, min=4, max=60),
        retry=retry_if_exception_type((ServiceConnectionError, ServiceTimeoutError))
    )
    @circuit(failure_threshold=5, recovery_timeout=60)
    def sync_user_session(self, user_id: int, token: str, session_data: Dict[str, Any]) -> bool:
        """
        Synchronize user session with main service with retry logic and circuit breaker
        """
        if not self.enabled:
            logger.info("Service synchronization is disabled")
            return True

        try:
            # For bulk operations, add a bulk flag to optimize
            is_bulk = user_id is None and token is None
            
            response = self._make_request(
                'POST',
                '/api/auth/sync-session',
                json={
                    "user_id": user_id,
                    "token": token,
                    "session_data": session_data,
                    "is_bulk": is_bulk,
                    "timestamp": datetime.utcnow().isoformat()
                }
            )
            
            # For successful responses, record successful sync
            if self.redis_client and user_id:
                sync_key = f"last_sync:user:{user_id}"
                self.redis_client.hset(sync_key, "timestamp", datetime.utcnow().isoformat())
                self.redis_client.hset(sync_key, "status", "success")
                self.redis_client.expire(sync_key, 86400)  # 24 hours
                
            return response.status_code == 200
        except ServiceIntegrationError as e:
            logger.error(f"Failed to sync session: {str(e)}")
            
            # For failures, record the failed sync
            if self.redis_client and user_id:
                sync_key = f"last_sync:user:{user_id}"
                self.redis_client.hset(sync_key, "timestamp", datetime.utcnow().isoformat())
                self.redis_client.hset(sync_key, "status", "failure")
                self.redis_client.hset(sync_key, "error", str(e))
                self.redis_client.expire(sync_key, 86400)  # 24 hours
                
                # Queue for retry if appropriate
                if isinstance(e, (ServiceConnectionError, ServiceTimeoutError)):
                    retry_key = f"sync_retry:user:{user_id}"
                    self.redis_client.lpush(retry_key, json.dumps({
                        "user_id": user_id,
                        "token": token,
                        "session_data": session_data,
                        "timestamp": datetime.utcnow().isoformat()
                    }))
                    self.redis_client.expire(retry_key, 86400)  # 24 hours
            
            return False

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    @circuit(failure_threshold=5, recovery_timeout=60)
    def validate_token(self, token: str) -> Optional[dict]:
        """
        Validate token with main service with retry logic and circuit breaker
        """
        if not self.enabled:
            return None

        try:
            response = self._make_request(
                'POST',
                '/api/auth/validate-token',
                json={"token": token}
            )
            return response.json()
        except ServiceIntegrationError as e:
            logger.error(f"Failed to validate token: {str(e)}")
            return None

    @retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=4, max=30))
    def sync_user_data(self, user: AuthUser) -> bool:
        """
        Synchronize user data with main service with enhanced retry logic
        """
        if not self.enabled:
            return True

        try:
            user_data = {
                "id": user.id,
                "email": user.email,
                "is_active": not user.is_locked(),
                "is_email_verified": user.is_email_verified,
                "first_name": user.first_name,
                "last_name": user.last_name,
                "profile_picture": user.profile_picture,
                "last_sync": datetime.utcnow().isoformat()
            }

            response = self._make_request(
                'POST',
                '/api/auth/sync-user',
                json=user_data
            )
            
            # Record successful sync
            if self.redis_client:
                sync_key = f"last_sync:user:{user.id}"
                self.redis_client.hset(sync_key, "timestamp", datetime.utcnow().isoformat())
                self.redis_client.hset(sync_key, "status", "success")
                self.redis_client.expire(sync_key, 86400)  # 24 hours
                
            return response.status_code == 200
        except ServiceIntegrationError as e:
            logger.error(f"Failed to sync user data: {str(e)}")
            
            # Record failed sync
            if self.redis_client:
                sync_key = f"last_sync:user:{user.id}"
                self.redis_client.hset(sync_key, "timestamp", datetime.utcnow().isoformat())
                self.redis_client.hset(sync_key, "status", "failure")
                self.redis_client.hset(sync_key, "error", str(e))
                self.redis_client.expire(sync_key, 86400)  # 24 hours
            
            return False

    def verify_user_consistency(self, user_id: int) -> bool:
        """
        Verify user data consistency across services
        """
        if not self.enabled:
            return True

        try:
            # Get user data from auth service
            auth_user = AuthUser.query.get(user_id)
            if not auth_user:
                return False

            # Get user data from main service
            response = self._make_request('GET', f'/api/users/{user_id}')
            flask_user = response.json()

            # Compare critical fields
            return all([
                auth_user.email == flask_user.get('email'),
                auth_user.is_email_verified == flask_user.get('is_email_verified'),
                not auth_user.is_locked() == flask_user.get('is_active')
            ])
        except ServiceIntegrationError as e:
            logger.error(f"Failed to verify user consistency: {str(e)}")
            return False

    @retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=4, max=30))
    def revoke_user_sessions(self, user_id: int, reason: str = None) -> bool:
        """
        Revoke all user sessions in main service with enhanced retry logic
        """
        if not self.enabled:
            return True

        try:
            response = self._make_request(
                'POST',
                '/api/auth/revoke-user-sessions',
                json={
                    "user_id": user_id,
                    "reason": reason,
                    "timestamp": datetime.utcnow().isoformat()
                }
            )
            return response.status_code == 200
        except ServiceIntegrationError as e:
            logger.error(f"Failed to revoke sessions: {str(e)}")
            
            # Queue for retry if appropriate
            if isinstance(e, (ServiceConnectionError, ServiceTimeoutError)) and self.redis_client:
                retry_key = f"revoke_retry:user:{user_id}"
                self.redis_client.lpush(retry_key, json.dumps({
                    "user_id": user_id,
                    "reason": reason,
                    "timestamp": datetime.utcnow().isoformat()
                }))
                self.redis_client.expire(retry_key, 86400)  # 24 hours
            
            return False
            
    def process_pending_syncs(self) -> int:
        """
        Process any pending sync operations that failed previously
        Returns the number of operations processed
        """
        if not self.enabled or not self.redis_client:
            return 0
            
        try:
            # Get all retry keys
            retry_keys = self.redis_client.keys("sync_retry:user:*")
            processed = 0
            
            for key in retry_keys:
                # Process up to 5 pending operations per user
                for _ in range(5):
                    retry_data = self.redis_client.lpop(key)
                    if not retry_data:
                        break
                        
                    try:
                        data = json.loads(retry_data)
                        if self.sync_user_session(
                            data.get("user_id"), 
                            data.get("token"), 
                            data.get("session_data")
                        ):
                            processed += 1
                    except Exception as e:
                        logger.error(f"Failed to process pending sync: {e}")
                        # Push back to queue
                        self.redis_client.rpush(key, retry_data)
                        break
                        
            # Similar logic for revocation retries
            revoke_keys = self.redis_client.keys("revoke_retry:user:*")
            for key in revoke_keys:
                for _ in range(5):
                    retry_data = self.redis_client.lpop(key)
                    if not retry_data:
                        break
                        
                    try:
                        data = json.loads(retry_data)
                        if self.revoke_user_sessions(
                            data.get("user_id"),
                            data.get("reason")
                        ):
                            processed += 1
                    except Exception as e:
                        logger.error(f"Failed to process pending revocation: {e}")
                        self.redis_client.rpush(key, retry_data)
                        break
                        
            return processed
        except Exception as e:
            logger.error(f"Error processing pending syncs: {e}")
            return 0 
```


### FILE: backend\auth-service\src\utils\session_service.py
```
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Any
from flask import current_app
import logging
from ..models.auth import UserSession
from ..database import db
from .service_integration import ServiceIntegration
from .database import transaction_context, safe_commit

logger = logging.getLogger(__name__)

class SessionService:
    def __init__(self):
        self.service_integration = ServiceIntegration()

    def create_session(self, user_id: int, device_info: Optional[Dict[str, Any]] = None) -> Optional[UserSession]:
        """Create a new user session"""
        try:
            with transaction_context() as session:
                user_session = UserSession(
                    user_id=user_id,
                    device_info=device_info,
                    expires_at=datetime.utcnow() + timedelta(days=1)
                )
                session.add(user_session)
                session.flush()  # Get the session ID

                # Sync with main service
                if not self.service_integration.sync_user_session(
                    user_id, 
                    user_session.token,
                    {
                        'session_id': user_session.id,
                        'device_info': device_info,
                        'expires_at': user_session.expires_at.isoformat()
                    }
                ):
                    logger.error("Failed to sync session with main service")
                    raise Exception("Session sync failed")

                return user_session
        except Exception as e:
            logger.error(f"Error creating session: {str(e)}")
            return None

    def get_active_sessions(self, user_id: int) -> List[UserSession]:
        """Get all active sessions for a user"""
        return UserSession.query.filter(
            UserSession.user_id == user_id,
            UserSession.revoked == False,
            UserSession.expires_at > datetime.utcnow()
        ).all()

    def revoke_session(self, session_id: int, reason: str = None) -> bool:
        """Revoke a specific session"""
        try:
            with transaction_context() as session:
                user_session = UserSession.query.get(session_id)
                if not user_session:
                    return False

                user_session.revoke(reason)
                
                # Sync with main service
                if not self.service_integration.revoke_user_sessions(
                    user_session.user_id,
                    reason=f"Session {session_id} revoked: {reason}"
                ):
                    logger.error("Failed to sync session revocation with main service")
                    raise Exception("Session revocation sync failed")

                return True
        except Exception as e:
            logger.error(f"Error revoking session: {str(e)}")
            return False

    def revoke_all_user_sessions(self, user_id: int, reason: str = None) -> bool:
        """Revoke all sessions for a user"""
        try:
            with transaction_context() as session:
                UserSession.query.filter(
                    UserSession.user_id == user_id,
                    UserSession.revoked == False
                ).update({
                    'revoked': True,
                    'revoked_at': datetime.utcnow(),
                    'revocation_reason': reason
                })

                # Sync with main service
                if not self.service_integration.revoke_user_sessions(user_id, reason=reason):
                    logger.error("Failed to sync session revocations with main service")
                    raise Exception("Session revocations sync failed")

                return True
        except Exception as e:
            logger.error(f"Error revoking all sessions: {str(e)}")
            return False

    def cleanup_expired_sessions(self) -> int:
        """Clean up expired sessions"""
        try:
            with transaction_context() as session:
                result = UserSession.query.filter(
                    UserSession.expires_at < datetime.utcnow(),
                    UserSession.revoked == False
                ).update({
                    'revoked': True,
                    'revoked_at': datetime.utcnow(),
                    'revocation_reason': 'Expired'
                })

                # Sync cleanup with main service if any sessions were cleaned up
                if result > 0:
                    self.service_integration.sync_user_session(
                        None,
                        None,
                        {'cleanup_timestamp': datetime.utcnow().isoformat()}
                    )

                return result
        except Exception as e:
            logger.error(f"Error cleaning up sessions: {str(e)}")
            return 0

    def extend_session(self, session_id: int, duration: timedelta = None) -> bool:
        """Extend a session's expiration time"""
        if duration is None:
            duration = timedelta(days=1)

        try:
            with transaction_context() as session:
                user_session = UserSession.query.get(session_id)
                if not user_session or user_session.revoked:
                    return False

                new_expiry = datetime.utcnow() + duration
                user_session.expires_at = new_expiry

                # Sync with main service
                if not self.service_integration.sync_user_session(
                    user_session.user_id,
                    user_session.token,
                    {'expires_at': new_expiry.isoformat()}
                ):
                    logger.error("Failed to sync session extension with main service")
                    raise Exception("Session extension sync failed")

                return True
        except Exception as e:
            logger.error(f"Error extending session: {str(e)}")
            return False 
```


### FILE: backend\auth-service\src\utils\token_service.py
```
from datetime import datetime, timedelta
import jwt
from typing import Optional, Dict, Any
from flask import current_app
import logging
from .service_integration import ServiceIntegration

logger = logging.getLogger(__name__)

class TokenService:
    def __init__(self):
        self.secret_key = current_app.config['JWT_SECRET_KEY']
        self.algorithm = 'HS256'
        self.service_integration = ServiceIntegration()

    def generate_token(self, user_id: int, expires_delta: timedelta = None) -> str:
        """Generate a new JWT token"""
        if expires_delta is None:
            expires_delta = timedelta(days=1)

        data = {
            'user_id': user_id,
            'exp': datetime.utcnow() + expires_delta,
            'iat': datetime.utcnow(),
            'type': 'access'
        }
        
        return jwt.encode(data, self.secret_key, algorithm=self.algorithm)

    def generate_refresh_token(self, user_id: int, session_id: int) -> str:
        """Generate a refresh token"""
        data = {
            'user_id': user_id,
            'session_id': session_id,
            'exp': datetime.utcnow() + timedelta(days=30),
            'iat': datetime.utcnow(),
            'type': 'refresh'
        }
        
        return jwt.encode(data, self.secret_key, algorithm=self.algorithm)

    def validate_token(self, token: str, verify_type: str = None) -> Optional[Dict[str, Any]]:
        """Validate a JWT token"""
        try:
            payload = jwt.decode(token, self.secret_key, algorithms=[self.algorithm])
            
            if verify_type and payload.get('type') != verify_type:
                logger.warning(f"Invalid token type: expected {verify_type}, got {payload.get('type')}")
                return None

            # Sync validation with main service
            if not self.service_integration.validate_token(token):
                logger.warning("Token validation failed in main service")
                return None

            return payload
        except jwt.ExpiredSignatureError:
            logger.warning("Token has expired")
            return None
        except jwt.InvalidTokenError as e:
            logger.warning(f"Invalid token: {str(e)}")
            return None

    def refresh_access_token(self, refresh_token: str) -> Optional[str]:
        """Generate new access token from refresh token"""
        payload = self.validate_token(refresh_token, verify_type='refresh')
        if not payload:
            return None

        return self.generate_token(payload['user_id'])

    def revoke_token(self, token: str) -> bool:
        """Revoke a token"""
        try:
            payload = jwt.decode(token, self.secret_key, algorithms=[self.algorithm])
            user_id = payload.get('user_id')
            
            # Revoke in main service
            return self.service_integration.revoke_user_sessions(user_id, reason='Token revoked')
        except jwt.InvalidTokenError:
            return False 
```


### FILE: backend\flask-service\.dockerignore
```
# Git
.git
.gitignore

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
*.egg-info/
.installed.cfg
*.egg

# Docker
Dockerfile*
docker-compose*
.dockerignore

# IDE
.idea/
.vscode/
*.swp
*.swo

# Logs
logs/
*.log

# Data
data/
**/*.pyc
venv/
.pytest_cache/
.coverage

# Data
data/ 
```


### FILE: backend\flask-service\.env.example
```
# Flask Service Environment Variables

# Database Configuration
DATABASE_URL=postgresql://dev_user:dev-password-123@postgres:5432/meetingapp
BACKUP_DIR=/app/backups

# Security
JWT_SECRET_KEY=your-secret-key-here
SERVICE_KEY=your-service-key-here

# Redis Configuration
REDIS_URL=redis://redis:6379/0

# Service Integration
AUTH_SERVICE_URL=http://auth-service:5001
AUTH_SERVICE_KEY=your-auth-service-key

# Server Configuration
PORT=5000
FLASK_ENV=development  # development, testing, production
FLASK_APP=src/app.py

# CORS Configuration
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8080

# Logging
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s
LOG_FILE=/app/logs/flask-service.log

# Metrics (Prometheus)
ENABLE_METRICS=true
METRICS_PORT=9090 
```


### FILE: backend\flask-service\Dockerfile
```
FROM python:3.9-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    build-essential \
    curl \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# Copy shared package first and install it
COPY meeting_shared /app/meeting_shared/
RUN pip install -e /app/meeting_shared/

# Copy service files
COPY backend/flask-service/requirements.txt .
COPY backend/flask-service/src/ ./src/

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Set environment variables
ENV PYTHONPATH=/app/src:/app/meeting_shared
ENV FLASK_APP=src/app.py
ENV FLASK_ENV=production

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=15s --retries=3 \
    CMD curl -f http://localhost:5000/health || exit 1

EXPOSE 5000

# Run the application
CMD ["flask", "run", "--host=0.0.0.0"] 
```


### FILE: backend\flask-service\README.md
```
# Meeting API Service

## Overview

The Meeting API Service is a Flask-based backend for managing meetings in the Meeting App platform. It provides REST API endpoints for creating, updating, and managing meetings, integrates with the authentication service, and handles real-time updates via Redis and WebSockets.

## Architecture

The service follows a modular architecture with well-defined responsibilities:

```
backend/
â”œâ”€â”€ flask-service/         # Meeting API Service
â”‚   â”œâ”€â”€ src/               # Application code
â”‚   â”‚   â”œâ”€â”€ core/          # Core functionality
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py    # Logging and initialization
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py      # Environment-specific configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ errors.py      # Error handling
â”‚   â”‚   â”‚   â””â”€â”€ health.py      # Health checks
â”‚   â”‚   â”œâ”€â”€ routes/        # API routes and endpoints
â”‚   â”‚   â”œâ”€â”€ utils/         # Utility functions
â”‚   â”‚   â””â”€â”€ app.py         # Flask application factory
â”‚   â”œâ”€â”€ shared/            # Shared modules with auth service
â”‚   â”œâ”€â”€ migrations/        # Database migrations
â”‚   â””â”€â”€ tests/             # Unit and integration tests
```

## Enhanced Debugging

This service includes comprehensive logging and debugging capabilities:

1. **Centralized Logging**: All logging is handled through the `src.core` module, with appropriate log levels for each environment.

2. **Detailed Health Checks**: The `/health` endpoint provides detailed diagnostics for all dependencies and service components.

3. **Error Handling**: A robust error handling system provides consistent error responses and detailed logging of exceptions.

4. **Environment Diagnostics**: System information, environment variables, and configuration is logged at startup to aid in debugging deployment issues.

## Getting Started

### Prerequisites

- Python 3.10+
- PostgreSQL
- Redis

### Installation

1. Clone the repository
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Set up environment variables (see `.env.example`)

4. Initialize the database:
   ```bash
   flask db upgrade
   ```

5. Run the development server:
   ```bash
   flask run
   ```

### Docker

The service can be run with Docker using the provided Dockerfile:

```bash
# Build the image
docker build -t meeting-api-service .

# Run the container
docker run -p 5000:5000 --env-file .env meeting-api-service
```

Or with docker-compose:

```bash
docker-compose up -d backend
```

## API Endpoints

### Health Check

- **GET** `/health`
  - Returns detailed health information about the service and its dependencies
  - Response: 200 OK (healthy) or 503 Service Unavailable (unhealthy)

### Meeting Endpoints

- **GET** `/api/meetings`
  - Lists all meetings for the authenticated user
  - Response: 200 OK

- **POST** `/api/meetings`
  - Creates a new meeting
  - Response: 201 Created

- **GET** `/api/meetings/{id}`
  - Gets details of a specific meeting
  - Response: 200 OK

- **PUT** `/api/meetings/{id}`
  - Updates a meeting
  - Response: 200 OK

- **DELETE** `/api/meetings/{id}`
  - Deletes a meeting
  - Response: 204 No Content

## Debugging Guidance

### Common Issues

1. **Database Connection Errors**
   - Check PostgreSQL connection string in `.env`
   - Verify PostgreSQL service is running
   - Check database logs for connection rejections

2. **Redis Connection Issues**
   - Verify Redis is running and accessible
   - Check Redis connection string in `.env`
   - Check for authentication failures in Redis logs

3. **Auth Service Integration**
   - Ensure AUTH_SERVICE_URL is correct
   - Verify SERVICE_KEY matches between services
   - Check auth service logs for connection attempts

### Enhanced Logging

To enable detailed logging, set `LOG_LEVEL=DEBUG` in your environment. This will provide:

- Detailed request and response information
- SQL queries and execution times
- Redis operations
- Authentication flow details

Log files are stored in the `/app/logs` directory:
- `app.log` - All application logs
- `error.log` - Error logs only
- `error_TIMESTAMP.json` - Detailed error reports (in development)

## Testing

Run the test suite with pytest:

```bash
pytest
```

With coverage:

```bash
pytest --cov=src
```

## Error Handling

The service uses standardized error responses:

```json
{
  "error": true,
  "message": "Error message",
  "status_code": 400,
  "timestamp": "2023-01-01T12:00:00.000Z",
  "details": {
    "field": "Error details"
  }
}
```

Error types include:
- ValidationError (422)
- AuthenticationError (401)
- AuthorizationError (403)
- NotFoundError (404)
- ServiceError (500)
- ConfigurationError (500)

## Performance Monitoring

The service includes basic performance metrics:
- Response times for key endpoints
- Database query times
- Redis operation latency
- External service call durations

For production monitoring, consider integrating Prometheus or similar. 
```


### FILE: backend\flask-service\entrypoint.sh
```
#!/bin/bash

# Wait for postgres
echo "Waiting for postgres..."
while ! pg_isready -h postgres -p 5432 -U $POSTGRES_USER -d $POSTGRES_DB; do
    echo "Postgres is unavailable - sleeping"
    sleep 1
done
echo "Postgres is up - executing command"

# Print directory structure for debugging
echo "Directory structure in /app:"
ls -la /app
echo "Directory structure in /app/meeting_shared:"
ls -la /app/meeting_shared
echo "Directory structure in /app/src:"
ls -la /app/src

# Set Python path
echo "Setting PYTHONPATH to: /app:/app/meeting_shared"
export PYTHONPATH=/app:/app/meeting_shared
echo "Environment variables:"
env | grep -E 'FLASK|DATABASE|REDIS|JWT|SERVICE|AUTH|POSTGRES|PYTHONPATH'

# Run database migrations
echo "Running database migrations..."
cd /app
flask db upgrade || echo "Warning: Migrations failed, but continuing..."

# Create a simple Flask app instead of using the problematic one
echo "Starting application with enhanced logging..."
cat > /app/app_wrapper.py << 'EOF'
import sys
import os
import logging
import traceback

# Configure enhanced logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("app_wrapper")
logger.setLevel(logging.DEBUG)

# Log system information
logger.info(f"Python version: {sys.version}")
logger.info(f"Current working directory: {os.getcwd()}")
logger.info(f"Initial sys.path: {sys.path}")

# Ensure necessary paths are in sys.path
sys.path.insert(0, '/app')
sys.path.insert(0, '/app/meeting_shared')
logger.info(f"Updated sys.path: {sys.path}")

# Log environment variables
env_vars = {}
critical_vars = ['DATABASE_URL', 'JWT_SECRET_KEY', 'REDIS_URL', 'SERVICE_KEY', 'AUTH_SERVICE_URL', 
                'FLASK_APP', 'FLASK_DEBUG', 'PYTHONPATH']
for var in critical_vars:
    value = os.environ.get(var)
    if value:
        # Mask sensitive values
        if 'SECRET' in var or 'PASSWORD' in var:
            env_vars[var] = '***MASKED***'
        else:
            env_vars[var] = value
    else:
        env_vars[var] = 'NOT SET'

logger.info(f"Environment variables: {env_vars}")

try:
    logger.info("Attempting to import src.app...")
    # Import the create_app function
    import src.app
    logger.info("Successfully imported src.app")
    
    # Check modules in src.app
    logger.info(f"Available in src.app: {dir(src.app)}")
    logger.info(f"'os' in src.app globals: {'os' in dir(src.app)}")
    
    # Monkey patch os if needed
    if 'os' not in dir(src.app):
        logger.warning("'os' not in src.app namespace, adding it...")
        src.app.os = os
    
    # Create the Flask application
    logger.info("Creating Flask application...")
    app = src.app.create_app()
    logger.info("Flask application created successfully")
    
except ImportError as e:
    logger.error(f"Import error: {str(e)}")
    logger.error(f"Traceback: {traceback.format_exc()}")
    raise
except Exception as e:
    logger.error(f"Error creating app: {str(e)}")
    logger.error(f"Traceback: {traceback.format_exc()}")
    raise

if __name__ == '__main__':
    logger.info("Running Flask application...")
    app.run(host='0.0.0.0', port=5000)
EOF

# Start the application with the wrapper
echo "Starting Gunicorn with app_wrapper.py..."
exec gunicorn --bind 0.0.0.0:5000 --workers 2 --threads 4 --timeout 120 --log-level debug "app_wrapper:app" 
```


### FILE: backend\flask-service\fixed_app.py
```
import os
import sys
import logging
import traceback
from datetime import datetime, timedelta

from flask import Flask, jsonify
from flask_cors import CORS
from flask_migrate import Migrate
from flask_wtf.csrf import CSRFProtect
from redis import Redis

# Configure logging with more detailed format
logging.basicConfig(
    level=logging.DEBUG,  # Set to DEBUG for more verbose logging
    format='%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s'
)
logger = logging.getLogger(__name__)
logger.info("Initializing Flask application module")
logger.debug(f"Python version: {sys.version}")
logger.debug(f"Current working directory: {os.getcwd()}")
logger.debug(f"Initial sys.path: {sys.path}")

# Log current environment variables
env_vars = {}
critical_vars = ['DATABASE_URL', 'JWT_SECRET_KEY', 'REDIS_URL', 'SERVICE_KEY', 'AUTH_SERVICE_URL',
                'FLASK_APP', 'FLASK_DEBUG', 'PYTHONPATH']
for var in critical_vars:
    value = os.environ.get(var)
    if value:
        # Mask sensitive values
        if 'SECRET' in var or 'PASSWORD' in var:
            env_vars[var] = '***MASKED***'
        else:
            env_vars[var] = value
    else:
        env_vars[var] = 'NOT SET'

logger.info(f"Environment variables: {env_vars}")

# Add paths for shared modules - try multiple approaches for Windows compatibility
potential_paths = [
    os.path.abspath(os.path.dirname(__file__)),  # Current directory
    os.path.abspath(os.path.join(os.path.dirname(__file__), '../')),  # Parent directory
    os.path.abspath(os.path.join(os.path.dirname(__file__), '../../')),  # Grandparent directory
    '/app',  # Docker container path
    '/app/shared'  # Docker shared volume path
]

for path in potential_paths:
    if path not in sys.path:
        sys.path.append(path)
        logger.info(f"Added {path} to sys.path")

logger.info(f"Updated sys.path: {sys.path}")

# Try multiple import patterns to handle different environments
try:
    # Try absolute import first (when PYTHONPATH includes shared)
    logger.info("Attempting to import shared modules using absolute import...")
    from meeting_shared.database import db, init_db
    from meeting_shared.middleware.error_handler import handle_api_errors
    from meeting_shared.middleware.validation import validate_schema
    from meeting_shared.middleware.rate_limiter import RateLimiter
    from meeting_shared.config import config
    logger.info("Successfully imported shared modules using absolute import")
except ImportError as e:
    logger.warning(f"Absolute import failed: {e}, trying relative import")
    try:
        # Fallback to relative path
        logger.info("Attempting to import shared modules using relative import...")
        from meeting_shared.database import db, init_db
        from meeting_shared.middleware.error_handler import handle_api_errors
        from meeting_shared.middleware.validation import validate_schema
        from meeting_shared.middleware.rate_limiter import RateLimiter
        from meeting_shared.config import config
        logger.info("Successfully imported shared modules using relative import")
    except ImportError as e:
        logger.error(f"All import approaches failed: {e}")
        logger.error(f"Current sys.path: {sys.path}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        # We'll handle this in create_app() to provide a meaningful error message

# Import local modules
try:
    logger.info("Attempting to import local modules...")
    from .routes.meetings import meetings_bp
    from .routes.auth_integration import bp as auth_integration_bp
    from .routes.health import health_bp
    from .utils.migrations_manager import MigrationsManager
    from .utils.data_seeder import DataSeeder
    from .utils.auth_integration import AuthIntegration
    logger.info("Successfully imported local modules")
except ImportError as e:
    logger.error(f"Failed to import local modules: {e}")
    logger.error(f"Traceback: {traceback.format_exc()}")
    # We'll handle this in create_app()

# Try to import APScheduler, but continue if it's not available
try:
    logger.info("Attempting to import APScheduler...")
    from apscheduler.schedulers.background import BackgroundScheduler
    from apscheduler.triggers.interval import IntervalTrigger
    has_apscheduler = True
    logger.info("Successfully imported APScheduler")
except ImportError as e:
    has_apscheduler = False
    logger.warning(f"APScheduler not available, some features will be disabled: {e}")

# Initialize extensions
migrate = Migrate()
csrf = CSRFProtect()
rate_limiter = None
cors = CORS()
redis_client = None

def get_redis_client():
    """Get or create Redis client singleton"""
    global redis_client
    logger.debug("get_redis_client called")
    if redis_client is None:
        redis_url = os.environ.get("REDIS_URL", "redis://localhost:6379/0")
        logger.info(f"Initializing Redis client with URL: {redis_url.replace('redis://:', 'redis://***:')}")
        try:
            redis_client = Redis.from_url(redis_url)
            redis_client.ping()  # Test connection
            logger.info("Redis connection established successfully")
        except Exception as e:
            logger.error(f"Failed to connect to Redis: {str(e)}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            redis_client = None
    return redis_client

def create_app(config_name='development', initialize_db=True):
    """Create and configure the Flask application"""
    # Import os again to ensure it's available in this function's scope
    import os
    logger.info(f"create_app called with config_name={config_name}, initialize_db={initialize_db}")
    logger.debug(f"'os' module is available in create_app scope: {os is not None}")
    
    try:
        app = Flask(__name__)
        logger.info("Flask app instance created")
        
        # In case of import errors, return a minimal app that explains the issue
        import_errors = []
        
        # Check if critical modules were imported
        if 'db' not in globals():
            import_errors.append("Failed to import shared database module")
        if 'meetings_bp' not in globals():
            import_errors.append("Failed to import meetings blueprint")
        
        if import_errors:
            logger.error(f"Critical import errors detected: {import_errors}")
            @app.route('/')
            def import_error():
                return jsonify({
                    'status': 'error',
                    'message': 'Application failed to start due to import errors',
                    'errors': import_errors,
                    'python_path': sys.path
                }), 500
                
            @app.route('/health')
            def minimal_health():
                return jsonify({
                    'status': 'error',
                    'message': 'Application is running but with import errors',
                    'errors': import_errors
                }), 500
                
            return app

        # Ensure required environment variables are set
        required_env_vars = [
            'DATABASE_URL',
            'JWT_SECRET_KEY',
            'REDIS_URL',
            'SERVICE_KEY',
            'AUTH_SERVICE_URL'
        ]
        
        logger.info("Checking required environment variables...")
        
        # Check for missing environment variables
        missing_vars = []
        for var in required_env_vars:
            value = os.environ.get(var)
            if not value:
                missing_vars.append(var)
                logger.error(f"Required environment variable not set: {var}")
            else:
                if 'SECRET' in var or 'PASSWORD' in var:
                    logger.info(f"Environment variable {var} is set")
                else:
                    logger.info(f"Environment variable {var}={value}")
        
        if missing_vars:
            logger.error(f"Missing required environment variables: {', '.join(missing_vars)}")
            raise RuntimeError(f"Missing required environment variables: {', '.join(missing_vars)}")
        
        # Load configuration from shared config
        logger.info(f"Loading configuration from config[{config_name}]")
        app.config.from_object(config[config_name])
        
        # Ensure backup directory is configured
        backup_dir = os.environ.get('BACKUP_DIR', os.path.join(app.root_path, 'db_backups'))
        logger.info(f"Setting backup directory to: {backup_dir}")
        app.config['BACKUP_DIR'] = backup_dir
        
        # Initialize rate limiter
        logger.info("Initializing rate limiter...")
        global rate_limiter
        rate_limiter = RateLimiter(app.config['REDIS_URL'])
        
        # Initialize Redis client and store in app extensions
        logger.info("Initializing Redis client...")
        redis = get_redis_client()
        if redis:
            app.extensions['redis'] = redis
            logger.info("Redis client added to app extensions")
        else:
            logger.warning("Redis client initialization failed")
        
        # Configure cache settings
        logger.info("Configuring cache settings...")
        app.config['CACHE_TYPE'] = 'redis'
        app.config['CACHE_REDIS_URL'] = app.config['REDIS_URL']
        
        # CORS configuration from shared config
        logger.info("Configuring CORS...")
        CORS(app, resources={
            r"/api/*": {
                "origins": app.config['CORS_ORIGINS'],
                "methods": app.config['CORS_METHODS'],
                "allow_headers": app.config['CORS_HEADERS'],
                "supports_credentials": True
            }
        })
        logger.info(f"CORS configured with origins: {app.config['CORS_ORIGINS']}")
        
        # CSRF configuration
        logger.info("Configuring CSRF protection...")
        csrf.init_app(app)
        app.config['WTF_CSRF_TIME_LIMIT'] = 3600  # 1 hour
        app.config['WTF_CSRF_SSL_STRICT'] = True
        
        # Exempt non-browser endpoints from CSRF
        logger.info("Exempting auth_integration_bp from CSRF protection")
        csrf.exempt(auth_integration_bp)
        
        # Initialize database and migrations
        logger.info("Initializing database and migrations...")
        init_db(app)  # Using shared database initialization
        migrate.init_app(app, db)
        
        # Register error handlers
        logger.info("Registering error handlers...")
        handle_api_errors(app)
        
        # Initialize database if needed
        if initialize_db:
            logger.info("Initializing database...")
            with app.app_context():
                try:
                    migrations_manager = MigrationsManager(app, db)
                    migrations_manager.initialize_database()
                    logger.info("Database initialized successfully")

                    # Seed data in development
                    if app.config.get("FLASK_ENV") == "development":
                        logger.info("Seeding development data...")
                        data_seeder = DataSeeder(app, db)
                        if not data_seeder.run_all_seeders():
                            logger.error("Failed to seed data")
                        else:
                            logger.info("Data seeding completed successfully")
                except Exception as e:
                    logger.error(f"Database initialization error: {str(e)}")
                    logger.error(f"Traceback: {traceback.format_exc()}")
        
        # Register blueprints
        logger.info("Registering blueprints...")
        app.register_blueprint(meetings_bp, url_prefix='/api/meetings')
        app.register_blueprint(auth_integration_bp, url_prefix='/api')
        logger.info("Blueprints registered successfully")
        
        # Initialize background tasks if APScheduler is available
        if has_apscheduler:
            try:
                logger.info("Initializing background tasks...")
                from .tasks import initialize_tasks
                initialize_tasks(app)
                logger.info("Background tasks initialized successfully")
            except ImportError as e:
                logger.warning(f"Could not import tasks modules. Background tasks disabled: {e}")
        
        # Register health endpoint
        logger.info("Registering health endpoint...")
        @app.route("/health")
        def health_check():
            """Health check endpoint"""
            try:
                # Check database connection
                with app.app_context():
                    db.session.execute("SELECT 1")
                logger.debug("Database health check: OK")
                
                # Check Redis connection
                redis_status = "unavailable"
                if app.extensions.get("redis"):
                    try:
                        app.extensions["redis"].ping()
                        redis_status = "connected"
                        logger.debug("Redis health check: OK")
                    except Exception as e:
                        redis_status = f"error: {str(e)}"
                        logger.error(f"Redis health check failed: {str(e)}")
                
                health_data = {
                    "status": "healthy",
                    "service": "flask",
                    "database": "connected",
                    "redis": redis_status,
                    "apscheduler": "available" if has_apscheduler else "unavailable",
                    "timestamp": datetime.utcnow().isoformat()
                }
                logger.debug(f"Health check response: {health_data}")
                return health_data, 200
            except Exception as e:
                logger.error(f"Health check failed: {str(e)}")
                logger.error(f"Traceback: {traceback.format_exc()}")
                return {
                    "status": "unhealthy",
                    "service": "flask",
                    "error": str(e),
                    "timestamp": datetime.utcnow().isoformat()
                }, 500
        
        logger.info("Application initialized successfully")
        return app
        
    except Exception as e:
        logger.error(f"Error in create_app: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        raise 
```


### FILE: backend\flask-service\pytest.ini
```
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Environment variables for testing
env =
    FLASK_ENV=testing
    PYTHONPATH=src:../../meeting_shared
    TESTING=true
    DATABASE_URL=sqlite:///:memory:
    REDIS_URL=redis://localhost:6379/1
    JWT_SECRET_KEY=test-secret-key
    SERVICE_KEY=test-service-key

# Logging configuration
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)s] %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Test collection settings
addopts = -v --tb=short --strict-markers --cov=src --cov=meeting_shared --cov-report=term-missing --cov-report=html

# Coverage configuration
[coverage:run]
branch = True
source = src,meeting_shared

[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    if self.debug:
    raise NotImplementedError
    if __name__ == .__main__.:
    pass
    raise ImportError

[coverage:html]
directory = tests/coverage_html 
```


### FILE: backend\flask-service\requirements.txt
```
# Flask and extensions
Flask==2.2.5
Flask-SQLAlchemy==3.0.5
Flask-Migrate==4.0.4
Flask-Cors==4.0.0
Flask-WTF==1.1.1
Werkzeug==2.2.3

# Database
psycopg2-binary==2.9.7
SQLAlchemy==1.4.41

# Authentication
PyJWT==2.8.0
bcrypt==4.0.1

# Utilities
python-dotenv==1.0.0
requests==2.31.0
redis==5.0.0
pydantic>=2.5.2
marshmallow==3.20.1
APScheduler==3.10.4
psutil==5.9.5
gunicorn==21.2.0
bleach==6.0.0

# Monitoring and logging
sentry-sdk[flask]==1.28.1
structlog==23.1.0
logging-formatter-anticrlf==1.2.1
python-json-logger==2.0.7

# Service discovery and secrets
python-consul==1.1.0
kubernetes==28.1.0
hvac==1.1.1
boto3==1.29.6

# Testing
pytest==7.4.0
pytest-cov==4.1.0
pytest-flask==1.3.0
responses==0.23.3

# Local shared package - installed via Dockerfile
# -e ../../meeting_shared 
```


### FILE: backend\flask-service\migrations\alembic.ini
```
# A generic, single database configuration.

[alembic]
# path to migration scripts
script_location = migrations

# template used to generate migration files
# file_template = %%(rev)s_%%(slug)s

# sys.path path, will be prepended to sys.path if present.
# defaults to the current working directory.
prepend_sys_path = .

# timezone to use when rendering the date within the migration file
# as well as the filename.
# If specified, requires the python-dateutil library that can be
# installed by adding `alembic[tz]` to the pip requirements
# timezone =

# max length of characters to apply to the
# "slug" field
# truncate_slug_length = 40

# set to 'true' to run the environment during
# the 'revision' command, regardless of autogenerate
# revision_environment = false

# set to 'true' to allow .pyc and .pyo files without
# a source .py file to be detected as revisions in the
# versions/ directory
# sourceless = false

# version location specification; This defaults
# to migrations/versions.  When using multiple version
# directories, initial revisions must be specified with --version-path.
# The path separator used here should be the separator specified by "version_path_separator" below.
# version_locations = %(here)s/bar:%(here)s/bat:migrations/versions

# version path separator; As mentioned above, this is the character used to split
# version_locations. The default within new alembic.ini files is "os", which uses os.pathsep.
# If this key is omitted entirely, it falls back to the legacy behavior of splitting on spaces and/or colons.
# Valid values for version_path_separator are:
#
# version_path_separator = :
# version_path_separator = ;
# version_path_separator = space
version_path_separator = os  # Use os.pathsep. Default configuration used for new projects.

# the output encoding used when revision files
# are written from script.py.mako
# output_encoding = utf-8

# URL will be overridden by environment variable in env.py
sqlalchemy.url = driver://user:pass@localhost/dbname

[post_write_hooks]
# post_write_hooks defines scripts or Python functions that are run
# on newly generated revision scripts.  See the documentation for further
# detail and examples

# format using "black" - use the console_scripts runner, against the "black" entrypoint
# hooks = black
# black.type = console_scripts
# black.entrypoint = black
# black.options = -l 79 REVISION_SCRIPT_FILENAME

# Logging configuration
[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S 
```


### FILE: backend\flask-service\migrations\env.py
```
from logging.config import fileConfig
from sqlalchemy import engine_from_config
from sqlalchemy import pool
from alembic import context
import os

# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# Interpret the config file for Python logging.
# This line sets up loggers basically.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# Get database URL from environment
config.set_main_option('sqlalchemy.url', os.getenv('DATABASE_URL'))

# Import the Flask app and get the metadata
from src import app, db
with app.app_context():
    # add your model's MetaData object here
    # for 'autogenerate' support
    target_metadata = db.Model.metadata

def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.
    """
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()

def run_migrations_online() -> None:
    """Run migrations in 'online' mode.

    In this scenario we need to create an Engine
    and associate a connection with the context.
    """
    connectable = engine_from_config(
        config.get_section(config.config_ini_section, {}),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection, target_metadata=target_metadata
        )

        with context.begin_transaction():
            context.run_migrations()

if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online() 
```


### FILE: backend\flask-service\migrations\versions\initial_schema.py
```
"""Initial schema

Revision ID: initial_schema
Revises: None
Create Date: 2024-01-09 02:35:00.000000
"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects.postgresql import JSONB

# revision identifiers, used by Alembic
revision = 'initial_schema'
down_revision = None

def upgrade():
    # Create users table
    op.create_table(
        'users',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('email', sa.String(120), nullable=False),
        sa.Column('name', sa.String(100), nullable=False),
        sa.Column('password_hash', sa.String(128), nullable=False),
        sa.Column('created_at', sa.DateTime(), nullable=False, server_default=sa.func.now()),
        sa.Column('updated_at', sa.DateTime(), nullable=False, server_default=sa.func.now(), onupdate=sa.func.now()),
        
        # Security fields
        sa.Column('is_active', sa.Boolean(), nullable=False, server_default='true'),
        sa.Column('is_email_verified', sa.Boolean(), nullable=False, server_default='false'),
        sa.Column('email_verification_token', sa.String(100), nullable=True),
        sa.Column('email_verification_sent_at', sa.DateTime(), nullable=True),
        sa.Column('password_reset_token', sa.String(100), nullable=True),
        sa.Column('password_reset_sent_at', sa.DateTime(), nullable=True),
        sa.Column('last_login_at', sa.DateTime(), nullable=True),
        sa.Column('failed_login_attempts', sa.Integer(), nullable=False, server_default='0'),
        sa.Column('locked_until', sa.DateTime(), nullable=True),
        sa.Column('last_password_change', sa.DateTime(), nullable=False, server_default=sa.func.now()),
        sa.Column('last_login_ip', sa.String(45), nullable=True),
        sa.Column('login_count', sa.Integer(), nullable=False, server_default='0'),
        
        # User preferences
        sa.Column('preferences', JSONB(), nullable=False, server_default='{}'),
        
        sa.PrimaryKeyConstraint('id'),
        sa.UniqueConstraint('email'),
        sa.UniqueConstraint('name')
    )

    # Create meetings table
    op.create_table(
        'meetings',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('title', sa.String(200), nullable=False),
        sa.Column('description', sa.Text(), nullable=True),
        sa.Column('start_time', sa.DateTime(), nullable=False),
        sa.Column('end_time', sa.DateTime(), nullable=False),
        sa.Column('created_by', sa.Integer(), nullable=False),
        sa.Column('created_at', sa.DateTime(), nullable=False, server_default=sa.func.now()),
        sa.Column('updated_at', sa.DateTime(), nullable=False, server_default=sa.func.now(), onupdate=sa.func.now()),
        sa.Column('ended_at', sa.DateTime(), nullable=True),
        sa.Column('meeting_type', sa.String(20), nullable=False, server_default='regular'),
        sa.Column('max_participants', sa.Integer(), nullable=True),
        sa.Column('requires_approval', sa.Boolean(), nullable=False, server_default='false'),
        sa.Column('is_recorded', sa.Boolean(), nullable=False, server_default='false'),
        sa.Column('recording_url', sa.String(500), nullable=True),
        sa.Column('recurring_pattern', sa.String(50), nullable=True),
        sa.Column('parent_meeting_id', sa.Integer(), nullable=True),
        sa.ForeignKeyConstraint(['created_by'], ['users.id'], ondelete='CASCADE'),
        sa.ForeignKeyConstraint(['parent_meeting_id'], ['meetings.id'], ondelete='SET NULL'),
        sa.PrimaryKeyConstraint('id')
    )

    # Create meeting_participants table
    op.create_table(
        'meeting_participants',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('meeting_id', sa.Integer(), nullable=False),
        sa.Column('user_id', sa.Integer(), nullable=False),
        sa.Column('status', sa.String(20), nullable=False, server_default='pending'),
        sa.Column('role', sa.String(20), nullable=False, server_default='attendee'),
        sa.Column('joined_at', sa.DateTime(), nullable=True),
        sa.Column('left_at', sa.DateTime(), nullable=True),
        sa.Column('is_banned', sa.Boolean(), nullable=False, server_default='false'),
        sa.Column('created_at', sa.DateTime(), nullable=False, server_default=sa.func.now()),
        sa.Column('updated_at', sa.DateTime(), nullable=False, server_default=sa.func.now(), onupdate=sa.func.now()),
        sa.Column('total_time', sa.Integer(), nullable=True),
        sa.Column('connection_quality', sa.Float(), nullable=True),
        sa.Column('participation_score', sa.Float(), nullable=True),
        sa.Column('feedback', sa.Text(), nullable=True),
        sa.ForeignKeyConstraint(['meeting_id'], ['meetings.id'], ondelete='CASCADE'),
        sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id')
    )

    # Create meeting_co_hosts table
    op.create_table(
        'meeting_co_hosts',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('meeting_id', sa.Integer(), nullable=False),
        sa.Column('user_id', sa.Integer(), nullable=False),
        sa.Column('created_at', sa.DateTime(), nullable=False, server_default=sa.func.now()),
        sa.Column('updated_at', sa.DateTime(), nullable=False, server_default=sa.func.now(), onupdate=sa.func.now()),
        sa.ForeignKeyConstraint(['meeting_id'], ['meetings.id'], ondelete='CASCADE'),
        sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id'),
        sa.UniqueConstraint('meeting_id', 'user_id', name='uq_meeting_co_hosts')
    )

    # Create meeting_audit_logs table
    op.create_table(
        'meeting_audit_logs',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('meeting_id', sa.Integer(), nullable=False),
        sa.Column('user_id', sa.Integer(), nullable=False),
        sa.Column('action', sa.String(50), nullable=False),
        sa.Column('details', JSONB(), nullable=True),
        sa.Column('created_at', sa.DateTime(), nullable=False, server_default=sa.func.now()),
        sa.ForeignKeyConstraint(['meeting_id'], ['meetings.id'], ondelete='CASCADE'),
        sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id')
    )

    # Create indexes
    op.create_index('idx_users_email', 'users', ['email'])
    op.create_index('idx_users_name', 'users', ['name'])
    op.create_index('idx_users_is_active', 'users', ['is_active'])
    op.create_index('idx_users_is_email_verified', 'users', ['is_email_verified'])
    op.create_index('idx_users_email_verification_token', 'users', ['email_verification_token'])
    op.create_index('idx_users_password_reset_token', 'users', ['password_reset_token'])
    op.create_index('idx_users_preferences', 'users', ['preferences'], postgresql_using='gin')

    op.create_index('idx_meetings_created_by', 'meetings', ['created_by'])
    op.create_index('idx_meetings_start_time', 'meetings', ['start_time'])
    op.create_index('idx_meetings_end_time', 'meetings', ['end_time'])
    op.create_index('idx_meetings_meeting_type', 'meetings', ['meeting_type'])
    op.create_index('idx_meetings_parent_id', 'meetings', ['parent_meeting_id'])

    op.create_index('idx_meeting_participants_meeting_id', 'meeting_participants', ['meeting_id'])
    op.create_index('idx_meeting_participants_user_id', 'meeting_participants', ['user_id'])
    op.create_index('idx_meeting_participants_status', 'meeting_participants', ['status'])

    op.create_index('idx_meeting_co_hosts_meeting_id', 'meeting_co_hosts', ['meeting_id'])
    op.create_index('idx_meeting_co_hosts_user_id', 'meeting_co_hosts', ['user_id'])

    op.create_index('idx_meeting_audit_logs_meeting_id', 'meeting_audit_logs', ['meeting_id'])
    op.create_index('idx_meeting_audit_logs_user_id', 'meeting_audit_logs', ['user_id'])
    op.create_index('idx_meeting_audit_logs_created_at', 'meeting_audit_logs', ['created_at'])

def downgrade():
    # Drop indexes first
    op.drop_index('idx_meeting_audit_logs_created_at')
    op.drop_index('idx_meeting_audit_logs_user_id')
    op.drop_index('idx_meeting_audit_logs_meeting_id')
    op.drop_index('idx_meeting_co_hosts_user_id')
    op.drop_index('idx_meeting_co_hosts_meeting_id')
    op.drop_index('idx_meeting_participants_status')
    op.drop_index('idx_meeting_participants_user_id')
    op.drop_index('idx_meeting_participants_meeting_id')
    op.drop_index('idx_meetings_parent_id')
    op.drop_index('idx_meetings_meeting_type')
    op.drop_index('idx_meetings_end_time')
    op.drop_index('idx_meetings_start_time')
    op.drop_index('idx_meetings_created_by')
    op.drop_index('idx_users_preferences')
    op.drop_index('idx_users_password_reset_token')
    op.drop_index('idx_users_email_verification_token')
    op.drop_index('idx_users_is_email_verified')
    op.drop_index('idx_users_is_active')
    op.drop_index('idx_users_name')
    op.drop_index('idx_users_email')

    # Drop tables
    op.drop_table('meeting_audit_logs')
    op.drop_table('meeting_co_hosts')
    op.drop_table('meeting_participants')
    op.drop_table('meetings')
    op.drop_table('users') 
```


### FILE: backend\flask-service\scripts\create_migration.sh
```
#!/bin/bash

set -e  # Exit on error
set -u  # Exit on undefined variable

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Logging function
log() {
    echo -e "${2:-$NC}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}"
}

# Error handling
error_exit() {
    log "ERROR: $1" "$RED" >&2
    exit 1
}

# Check if message was provided
if [ "$#" -ne 1 ]; then
    error_exit "Usage: $0 \"migration message\""
fi

MIGRATION_MESSAGE="$1"

# Validate migration message format
if [[ ! $MIGRATION_MESSAGE =~ ^[a-z0-9_]+$ ]]; then
    error_exit "Migration message must contain only lowercase letters, numbers, and underscores"
fi

# Set environment variables
export FLASK_APP=src

# Create timestamp for filename
TIMESTAMP=$(date +'%Y_%m_%d_%H%M%S')
MIGRATION_NAME="${TIMESTAMP}_${MIGRATION_MESSAGE}"

# Create migration
log "Creating migration: $MIGRATION_MESSAGE" "$YELLOW"
if flask db revision --autogenerate -m "$MIGRATION_MESSAGE"; then
    log "Migration created successfully" "$GREEN"
    
    # Find the latest migration file
    LATEST_MIGRATION=$(ls -t migrations/versions/*.py | head -n 1)
    if [ -n "$LATEST_MIGRATION" ]; then
        log "Latest migration file: $LATEST_MIGRATION" "$YELLOW"
        
        # Validate the migration
        log "Validating migration..." "$YELLOW"
        if python scripts/migration_validator.py "migrations/versions"; then
            log "Migration validation successful" "$GREEN"
            
            # Show migration contents
            log "Migration contents:" "$YELLOW"
            echo "----------------------------------------"
            cat "$LATEST_MIGRATION"
            echo "----------------------------------------"
            
            # Reminder about testing
            log "IMPORTANT: Remember to:" "$YELLOW"
            log "1. Review the generated migration file" "$YELLOW"
            log "2. Test the upgrade path: flask db upgrade" "$YELLOW"
            log "3. Test the downgrade path: flask db downgrade" "$YELLOW"
            log "4. Commit both model changes and migration file" "$YELLOW"
        else
            error_exit "Migration validation failed. Please fix the issues and try again."
        fi
    else
        error_exit "Could not find the generated migration file"
    fi
else
    error_exit "Failed to create migration"
fi

# Make the migration file executable
chmod +x "$LATEST_MIGRATION"

# Success message
log "Migration creation completed successfully!" "$GREEN" 
```


### FILE: backend\flask-service\scripts\init_db.sh
```
#!/bin/bash

set -e  # Exit on error

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Logging function
log() {
    echo -e "${2:-$NC}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}"
}

# Error handling
error_exit() {
    log "ERROR: $1" "$RED" >&2
    exit 1
}

# Wait for PostgreSQL
wait_for_postgres() {
    local retries=30
    local count=0
    log "Waiting for PostgreSQL to be ready..." "$YELLOW"
    
    until pg_isready -h postgres -U dev_user -d meetingapp > /dev/null 2>&1; do
        count=$((count + 1))
        if [ $count -ge $retries ]; then
            error_exit "Timeout waiting for PostgreSQL"
        fi
        log "Waiting for PostgreSQL... ($count/$retries)" "$YELLOW"
        sleep 2
    done
    log "PostgreSQL is ready!" "$GREEN"
}

# Wait for Redis
wait_for_redis() {
    local retries=30
    local count=0
    log "Waiting for Redis to be ready..." "$YELLOW"
    
    until redis-cli -h redis -a dev-redis-123 ping > /dev/null 2>&1; do
        count=$((count + 1))
        if [ $count -ge $retries ]; then
            error_exit "Timeout waiting for Redis"
        fi
        log "Waiting for Redis... ($count/$retries)" "$YELLOW"
        sleep 2
    done
    log "Redis is ready!" "$GREEN"
}

# Initialize database
init_database() {
    log "Checking database initialization..." "$YELLOW"
    
    # Check if migrations directory exists
    if [ ! -d "migrations" ]; then
        log "Initializing migrations directory..." "$YELLOW"
        flask db init || error_exit "Failed to initialize migrations"
        log "Migrations directory initialized" "$GREEN"
    fi
    
    # Check current migration status
    log "Checking current migration status..." "$YELLOW"
    if ! flask db current > /dev/null 2>&1; then
        log "No migrations found, creating initial migration..." "$YELLOW"
        flask db migrate -m "initial" || error_exit "Failed to create initial migration"
        log "Initial migration created" "$GREEN"
    fi
}

# Apply migrations
apply_migrations() {
    log "Applying database migrations..." "$YELLOW"
    
    # Run migrations
    if flask db upgrade; then
        log "Database migrations completed successfully!" "$GREEN"
        # Show current version
        log "Current migration version:" "$YELLOW"
        flask db current
        # Show migration history
        log "Migration history:" "$YELLOW"
        flask db history
    else
        error_exit "Database migrations failed"
    fi
}

# Verify database
verify_database() {
    log "Running database verification..." "$YELLOW"
    
    # Test database connection
    if python -c "
from src import app, db
with app.app_context():
    try:
        db.session.execute('SELECT 1')
        print('Database verification successful')
    except Exception as e:
        print(f'Database verification failed: {str(e)}')
        exit(1)
"; then
        log "Database verification completed successfully!" "$GREEN"
    else
        error_exit "Database verification failed"
    fi
}

# Main execution
main() {
    export FLASK_APP=src
    
    # Wait for dependencies
    wait_for_postgres
    wait_for_redis
    
    # Initialize and migrate database
    init_database
    apply_migrations
    verify_database
    
    log "Database initialization and migration completed successfully!" "$GREEN"
}

# Run main function
main 
```


### FILE: backend\flask-service\scripts\migrate.sh
```
#!/bin/bash

set -e  # Exit on error
set -u  # Exit on undefined variable

# Configuration
MAX_WAIT=60
WAIT_COUNT=0

# Parse DATABASE_URL for connection details
if [ -z "${DATABASE_URL:-}" ]; then
    error_exit "DATABASE_URL environment variable is not set"
fi

# Extract connection details from DATABASE_URL
# Format: postgresql://user:password@host:port/dbname
DB_USER=$(echo $DATABASE_URL | sed -n 's/.*:\/\/\([^:]*\):.*/\1/p')
DB_HOST=$(echo $DATABASE_URL | sed -n 's/.*@\([^:]*\):.*/\1/p')
DB_PORT=$(echo $DATABASE_URL | sed -n 's/.*:\([^/]*\)\/.*/\1/p')
DB_NAME=$(echo $DATABASE_URL | sed -n 's/.*\/\(.*\)/\1/p')

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Logging function
log() {
    echo -e "${2:-$NC}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}"
}

# Error handling
error_exit() {
    log "ERROR: $1" "$RED" >&2
    exit 1
}

# Wait for database to be ready
log "Waiting for database to be ready..." "$YELLOW"
until pg_isready -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" > /dev/null 2>&1; do
    if [ $WAIT_COUNT -ge $MAX_WAIT ]; then
        error_exit "Timed out waiting for database to be ready"
    fi
    WAIT_COUNT=$((WAIT_COUNT + 1))
    log "Waiting for PostgreSQL... ($WAIT_COUNT/$MAX_WAIT seconds)" "$YELLOW"
    sleep 1
done

log "Database is ready!" "$GREEN"

cd /app

# Initialize migrations if needed
if [ ! -d "migrations" ]; then
    log "Initializing migrations directory..." "$YELLOW"
    alembic init migrations || error_exit "Failed to initialize migrations"
    log "Migrations directory initialized" "$GREEN"
fi

# Run migrations
log "Running database migrations..." "$YELLOW"

# First, try to merge heads if there are multiple
if alembic -c migrations/alembic.ini heads | grep -q ","; then
    log "Multiple migration heads detected, attempting to merge..." "$YELLOW"
    alembic -c migrations/alembic.ini merge heads || error_exit "Failed to merge migration heads"
fi

# Now run the upgrade
if alembic -c migrations/alembic.ini upgrade heads; then
    log "Database migrations completed successfully!" "$GREEN"
    # Show current version
    log "Current migration version:" "$YELLOW"
    alembic -c migrations/alembic.ini current
else
    error_exit "Database migrations failed"
fi 
```


### FILE: backend\flask-service\scripts\migration_validator.py
```
#!/usr/bin/env python
import os
import sys
import re
from pathlib import Path
import ast
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MigrationValidator:
    def __init__(self, migrations_dir):
        self.migrations_dir = Path(migrations_dir)
        self.errors = []
        self.warnings = []

    def validate_migration_files(self):
        """Validate all migration files in the directory"""
        migration_files = sorted(self.migrations_dir.glob('*.py'))
        
        for migration_file in migration_files:
            logger.info(f"Validating migration file: {migration_file.name}")
            self.validate_single_migration(migration_file)

        return len(self.errors) == 0

    def validate_single_migration(self, file_path):
        """Validate a single migration file"""
        try:
            with open(file_path, 'r') as f:
                content = f.read()
                
            # Parse the Python file
            tree = ast.parse(content)
            
            # Check for basic requirements
            self._check_revision(tree, file_path)
            self._check_upgrade_downgrade(tree, file_path)
            self._check_dangerous_operations(content, file_path)
            self._check_transaction_safety(content, file_path)
            
        except Exception as e:
            self.errors.append(f"Error parsing {file_path.name}: {str(e)}")

    def _check_revision(self, tree, file_path):
        """Check if revision and dependencies are properly defined"""
        revision_found = False
        for node in ast.walk(tree):
            if isinstance(node, ast.Assign):
                for target in node.targets:
                    if isinstance(target, ast.Name) and target.id == 'revision':
                        revision_found = True
                        if not isinstance(node.value, ast.Str):
                            self.errors.append(f"{file_path.name}: revision should be a string")
        
        if not revision_found:
            self.errors.append(f"{file_path.name}: missing revision identifier")

    def _check_upgrade_downgrade(self, tree, file_path):
        """Check if upgrade and downgrade functions are defined"""
        functions = set()
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                functions.add(node.name)
        
        if 'upgrade' not in functions:
            self.errors.append(f"{file_path.name}: missing upgrade function")
        if 'downgrade' not in functions:
            self.warnings.append(f"{file_path.name}: missing downgrade function")

    def _check_dangerous_operations(self, content, file_path):
        """Check for potentially dangerous operations"""
        dangerous_patterns = [
            (r'drop\s+table', 'table drop'),
            (r'truncate\s+table', 'table truncate'),
            (r'delete\s+from', 'delete without where clause'),
            (r'alter\s+table\s+\w+\s+drop\s+column', 'column drop')
        ]
        
        for pattern, operation in dangerous_patterns:
            if re.search(pattern, content, re.IGNORECASE):
                self.warnings.append(
                    f"{file_path.name}: contains potentially dangerous operation: {operation}"
                )

    def _check_transaction_safety(self, content, file_path):
        """Check for transaction safety"""
        if 'op.execute' in content and 'op.get_bind().execute' not in content:
            self.warnings.append(
                f"{file_path.name}: uses raw execute - ensure statements are transaction-safe"
            )

    def print_report(self):
        """Print validation report"""
        if self.errors:
            logger.error("Validation Errors:")
            for error in self.errors:
                logger.error(f"  - {error}")
        
        if self.warnings:
            logger.warning("Validation Warnings:")
            for warning in self.warnings:
                logger.warning(f"  - {warning}")
        
        if not self.errors and not self.warnings:
            logger.info("All migrations validated successfully!")

def main():
    if len(sys.argv) != 2:
        print("Usage: python migration_validator.py <migrations_directory>")
        sys.exit(1)

    migrations_dir = sys.argv[1]
    if not os.path.exists(migrations_dir):
        print(f"Error: Directory {migrations_dir} does not exist")
        sys.exit(1)

    validator = MigrationValidator(migrations_dir)
    is_valid = validator.validate_migration_files()
    validator.print_report()

    sys.exit(0 if is_valid else 1)

if __name__ == '__main__':
    main() 
```


### FILE: backend\flask-service\scripts\show_migration_chain.py
```
#!/usr/bin/env python
import os
import sys
import re
from datetime import datetime
import graphviz
import logging
from pathlib import Path

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MigrationChainVisualizer:
    def __init__(self, migrations_dir):
        self.migrations_dir = Path(migrations_dir)
        self.migrations = {}
        self.graph = graphviz.Digraph(comment='Migration Chain')
        self.graph.attr(rankdir='LR')

    def parse_migration_files(self):
        """Parse all migration files to extract revision information"""
        for migration_file in sorted(self.migrations_dir.glob('*.py')):
            if migration_file.name.startswith('__'):
                continue

            with open(migration_file, 'r') as f:
                content = f.read()

            # Extract revision and dependencies
            revision_match = re.search(r"revision = '([^']*)'", content)
            down_revision_match = re.search(r"down_revision = '([^']*)'", content)
            
            if revision_match:
                revision = revision_match.group(1)
                down_revision = down_revision_match.group(1) if down_revision_match else None
                
                # Extract timestamp and description from filename
                timestamp_match = re.match(r'(\d{14})_(.+)\.py', migration_file.name)
                if timestamp_match:
                    timestamp = datetime.strptime(timestamp_match.group(1), '%Y%m%d%H%M%S')
                    description = timestamp_match.group(2).replace('_', ' ').title()
                else:
                    timestamp = None
                    description = migration_file.stem

                self.migrations[revision] = {
                    'down_revision': down_revision,
                    'file': migration_file.name,
                    'timestamp': timestamp,
                    'description': description
                }

    def create_graph(self, output_file='migration_chain'):
        """Create a visual representation of the migration chain"""
        self.parse_migration_files()

        # Add nodes
        for revision, info in self.migrations.items():
            label = f"{info['description']}\n{info['timestamp'].strftime('%Y-%m-%d %H:%M') if info['timestamp'] else ''}"
            self.graph.node(revision, label=label)

        # Add edges
        for revision, info in self.migrations.items():
            if info['down_revision']:
                self.graph.edge(info['down_revision'], revision)

        # Save the graph
        try:
            self.graph.render(output_file, view=True, format='png')
            logger.info(f"Migration chain visualization saved to {output_file}.png")
        except Exception as e:
            logger.error(f"Failed to create visualization: {e}")

    def print_chain(self):
        """Print text representation of the migration chain"""
        self.parse_migration_files()

        # Find head revision(s)
        heads = set(self.migrations.keys()) - {
            m['down_revision'] for m in self.migrations.values() if m['down_revision']
        }

        def print_branch(revision, level=0):
            """Recursively print migration chain"""
            if revision not in self.migrations:
                return

            info = self.migrations[revision]
            indent = '  ' * level
            timestamp = info['timestamp'].strftime('%Y-%m-%d %H:%M') if info['timestamp'] else 'N/A'
            print(f"{indent}â”œâ”€â”€ {info['description']} ({timestamp})")
            
            # Find children
            children = [
                rev for rev, data in self.migrations.items()
                if data['down_revision'] == revision
            ]
            
            for child in sorted(children):
                print_branch(child, level + 1)

        print("\nMigration Chain:")
        print("---------------")
        for head in sorted(heads):
            print_branch(head)

def main():
    if len(sys.argv) != 2:
        print("Usage: python show_migration_chain.py <migrations_directory>")
        sys.exit(1)

    migrations_dir = sys.argv[1]
    if not os.path.exists(migrations_dir):
        print(f"Error: Directory {migrations_dir} does not exist")
        sys.exit(1)

    visualizer = MigrationChainVisualizer(migrations_dir)
    visualizer.print_chain()
    visualizer.create_graph()

if __name__ == '__main__':
    main() 
```


### FILE: backend\flask-service\scripts\test_migrations.py
```
#!/usr/bin/env python
import os
import sys
import logging
import subprocess
import docker
import psycopg2
from datetime import datetime
import time

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MigrationTester:
    def __init__(self, migrations_dir, app_dir):
        self.migrations_dir = migrations_dir
        self.app_dir = app_dir
        self.docker_client = docker.from_env()
        self.test_db_name = f"test_migrations_{int(time.time())}"
        self.container = None

    def setup_test_database(self):
        """Create a temporary PostgreSQL container for testing"""
        try:
            logger.info("Setting up test database container...")
            self.container = self.docker_client.containers.run(
                'postgres:15-alpine',
                environment={
                    'POSTGRES_DB': self.test_db_name,
                    'POSTGRES_USER': 'test_user',
                    'POSTGRES_PASSWORD': 'test_password'
                },
                ports={'5432/tcp': None},
                detach=True
            )

            # Wait for container to be ready
            time.sleep(5)
            port = self.container.ports['5432/tcp'][0]['HostPort']
            
            return f"postgresql://test_user:test_password@localhost:{port}/{self.test_db_name}"
        except Exception as e:
            logger.error(f"Failed to setup test database: {e}")
            self.cleanup()
            sys.exit(1)

    def test_migration(self, migration_id):
        """Test a specific migration"""
        try:
            # Set up test environment
            database_url = self.setup_test_database()
            os.environ['DATABASE_URL'] = database_url

            logger.info(f"Testing migration: {migration_id}")

            # Run migrations up to the target
            result = subprocess.run(
                ['flask', 'db', 'upgrade', migration_id],
                cwd=self.app_dir,
                capture_output=True,
                text=True
            )

            if result.returncode != 0:
                logger.error(f"Migration upgrade failed: {result.stderr}")
                return False

            # Test downgrade
            result = subprocess.run(
                ['flask', 'db', 'downgrade', '-1'],
                cwd=self.app_dir,
                capture_output=True,
                text=True
            )

            if result.returncode != 0:
                logger.error(f"Migration downgrade failed: {result.stderr}")
                return False

            # Test upgrade again
            result = subprocess.run(
                ['flask', 'db', 'upgrade'],
                cwd=self.app_dir,
                capture_output=True,
                text=True
            )

            if result.returncode != 0:
                logger.error(f"Second migration upgrade failed: {result.stderr}")
                return False

            logger.info(f"Migration {migration_id} tested successfully!")
            return True

        except Exception as e:
            logger.error(f"Error testing migration: {e}")
            return False
        finally:
            self.cleanup()

    def test_all_migrations(self):
        """Test all migrations in sequence"""
        try:
            database_url = self.setup_test_database()
            os.environ['DATABASE_URL'] = database_url

            logger.info("Testing all migrations in sequence...")

            # Get list of migrations
            result = subprocess.run(
                ['flask', 'db', 'history'],
                cwd=self.app_dir,
                capture_output=True,
                text=True
            )

            if result.returncode != 0:
                logger.error(f"Failed to get migration history: {result.stderr}")
                return False

            migrations = [
                line.split(' ')[0] 
                for line in result.stdout.split('\n') 
                if line.strip() and not line.startswith('>')
            ]

            # Test each migration
            for migration_id in migrations:
                logger.info(f"Testing migration {migration_id}...")
                
                # Upgrade to this migration
                result = subprocess.run(
                    ['flask', 'db', 'upgrade', migration_id],
                    cwd=self.app_dir,
                    capture_output=True,
                    text=True
                )

                if result.returncode != 0:
                    logger.error(f"Failed to upgrade to {migration_id}: {result.stderr}")
                    return False

                # Verify database state
                if not self.verify_database_state():
                    logger.error(f"Database verification failed after migration {migration_id}")
                    return False

            logger.info("All migrations tested successfully!")
            return True

        except Exception as e:
            logger.error(f"Error testing migrations: {e}")
            return False
        finally:
            self.cleanup()

    def verify_database_state(self):
        """Verify database state after migration"""
        try:
            # Run application's verification logic
            result = subprocess.run(
                ['python', '-c', 'from src.app import create_app; app = create_app(); app.test_client()'],
                cwd=self.app_dir,
                capture_output=True,
                text=True
            )
            return result.returncode == 0
        except Exception as e:
            logger.error(f"Database verification failed: {e}")
            return False

    def cleanup(self):
        """Clean up test environment"""
        if self.container:
            try:
                self.container.stop()
                self.container.remove()
                logger.info("Test database container cleaned up")
            except Exception as e:
                logger.error(f"Error cleaning up container: {e}")

def main():
    if len(sys.argv) < 2:
        print("Usage: python test_migrations.py <app_directory> [migration_id]")
        sys.exit(1)

    app_dir = sys.argv[1]
    migrations_dir = os.path.join(app_dir, 'migrations')

    if not os.path.exists(migrations_dir):
        print(f"Error: Migrations directory not found in {app_dir}")
        sys.exit(1)

    tester = MigrationTester(migrations_dir, app_dir)

    if len(sys.argv) > 2:
        # Test specific migration
        success = tester.test_migration(sys.argv[2])
    else:
        # Test all migrations
        success = tester.test_all_migrations()

    sys.exit(0 if success else 1)

if __name__ == '__main__':
    main() 
```


### FILE: backend\flask-service\src\__init__.py
```
from flask import Flask, jsonify
from flask_cors import CORS
from flask_sqlalchemy import SQLAlchemy
from flask_migrate import Migrate
import os
import redis
import logging

# Import from shared modules
from meeting_shared.database import db

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Required environment variables
REQUIRED_ENV_VARS = [
    'DATABASE_URL',
    'JWT_SECRET_KEY',
    'REDIS_URL'
]

# Check for required environment variables
missing_vars = [var for var in REQUIRED_ENV_VARS if not os.getenv(var)]
if missing_vars:
    raise RuntimeError(f"Missing required environment variables: {', '.join(missing_vars)}")

app = Flask(__name__)

# Configure CORS
CORS(app, resources={
    r"/api/*": {
        "origins": os.getenv('CORS_ORIGINS', 'http://localhost:3000').split(","),
        "methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
        "allow_headers": ["Content-Type", "Authorization"],
        "supports_credentials": True
    }
})

# Database configuration
app.config['SQLALCHEMY_DATABASE_URI'] = os.getenv('DATABASE_URL')
app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False
app.config['JWT_SECRET_KEY'] = os.getenv('JWT_SECRET_KEY')

try:
    # Initialize extensions
    migrate = Migrate(app, db)
    logger.info("Database initialized successfully")
except Exception as e:
    logger.error(f"Failed to initialize database: {str(e)}")
    raise

try:
    # Initialize Redis
    redis_client = redis.from_url(os.getenv('REDIS_URL'))
    redis_client.ping()  # Test connection
    logger.info("Redis connection established successfully")
except Exception as e:
    logger.error(f"Failed to connect to Redis: {str(e)}")
    raise

# Health check endpoints
@app.route('/health')
def health_check():
    return jsonify({'status': 'healthy'}), 200

@app.route('/health/db')
def db_health_check():
    try:
        # Execute a simple query
        db.session.execute('SELECT 1')
        return jsonify({'status': 'healthy', 'message': 'Database connection successful'}), 200
    except Exception as e:
        return jsonify({'status': 'unhealthy', 'message': str(e)}), 500

@app.route('/health/redis')
def redis_health_check():
    try:
        # Try to ping Redis
        redis_client.ping()
        return jsonify({'status': 'healthy', 'message': 'Redis connection successful'}), 200
    except Exception as e:
        return jsonify({'status': 'unhealthy', 'message': str(e)}), 500

# Import and register blueprints
from .routes.auth import auth_bp
from .routes.meetings import meetings_bp

app.register_blueprint(auth_bp, url_prefix='/api/auth')
app.register_blueprint(meetings_bp, url_prefix='/api/meetings')

# Error handlers
@app.errorhandler(500)
def internal_error(error):
    logger.error(f"Internal Server Error: {str(error)}")
    return jsonify({'error': 'Internal Server Error'}), 500

@app.errorhandler(404)
def not_found_error(error):
    return jsonify({'error': 'Not Found'}), 404

logger.info("Application initialized successfully") 
```


### FILE: backend\flask-service\src\app.py
```
"""
Flask service application factory.
"""

import os
import logging
import random
import string

# Patch werkzeug.security.gen_salt to avoid secrets.choice issue
import werkzeug.security
def patched_gen_salt(length):
    """Generate a random string of SALT_CHARS with specified length."""
    if length <= 0:
        raise ValueError('Salt length must be positive')
    return ''.join(random.choice(werkzeug.security.SALT_CHARS) for _ in range(length))
werkzeug.security.gen_salt = patched_gen_salt

from flask import Flask, jsonify, g, current_app
from meeting_shared.config import get_config
from meeting_shared.shared_logging import setup_logging
from meeting_shared.middleware import register_middleware
from meeting_shared.database import init_db, db

# Import routes
from .routes.health import health_bp

logger = logging.getLogger(__name__)

def create_app(config_name=None):
    """Create Flask application."""
    app = Flask(__name__)
    
    # Load configuration
    config = get_config(config_name or os.getenv('FLASK_ENV', 'default'))
    app.config.from_object(config)
    logger.info(f"Initialized with configuration: {config_name or 'default'}")
    
    # Setup logging first
    setup_logging(app)
    logger.info("Logging configured")
    
    # Register middleware (before routes)
    register_middleware(app)
    logger.info("Middleware registered")
    
    # Initialize database
    init_db(app)  # This initializes the global db instance
    app.db = db   # Also store it on the app for easy access
    logger.info("Database initialized")
    
    # Register error handlers
    try:
        from .core.errors import register_error_handlers
        register_error_handlers(app)
    except ImportError as e:
        logger.error(f"Error importing error handlers: {str(e)}")
    
    # Initialize services
    try:
        from .services import init_services
        init_services(app)
    except ImportError as e:
        logger.error(f"Error importing services: {str(e)}")
    
    # Register API routes
    try:
        from .routes import register_routes
        register_routes(app)
    except ImportError as e:
        logger.error(f"Error importing routes: {str(e)}")
    
    # Register health check endpoint
    @app.route('/health')
    def health_check():
        """Health check endpoint with database verification."""
        status = "healthy"
        database_status = "available"
        
        # Verify database connection
        try:
            db.session.execute('SELECT 1')
            status_code = 200
        except Exception as e:
            logger.error(f"Health check database error: {str(e)}")
            database_status = "unavailable"
            status = "degraded"
            status_code = 500
            
        return jsonify({
            'status': status,
            'service': app.config.get('APP_NAME', 'flask-service'),
            'database': database_status,
            'request_id': g.get('request_id', 'none')
        }), status_code
    
    logger.info("Flask application initialization sequence complete")
    logger.info(f"Registered routes: {[rule.rule for rule in app.url_map.iter_rules()]}")
    
    return app 
```


### FILE: backend\flask-service\src\fixed_app.py
```
import os
import sys
import logging
from datetime import datetime, timedelta

from flask import Flask, jsonify
from flask_cors import CORS
from flask_migrate import Migrate
from flask_wtf.csrf import CSRFProtect
from redis import Redis

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Add paths for shared modules - try multiple approaches for Windows compatibility
potential_paths = [
    os.path.abspath(os.path.dirname(__file__)),  # Current directory
    os.path.abspath(os.path.join(os.path.dirname(__file__), '../')),  # Parent directory
    os.path.abspath(os.path.join(os.path.dirname(__file__), '../../')),  # Grandparent directory
    '/app',  # Docker container path
    '/app/meeting_shared'  # Docker shared volume path
]

for path in potential_paths:
    if path not in sys.path:
        sys.path.append(path)
        logger.info(f"Added {path} to sys.path")

# Try multiple import patterns to handle different environments
try:
    # Try absolute import first (when PYTHONPATH includes shared)
    from meeting_shared.database import db, init_db
    from meeting_shared.middleware.error_handler import handle_api_errors
    from meeting_shared.middleware.validation import validate_schema
    from meeting_shared.middleware.rate_limiter import RateLimiter
    from meeting_shared.config import config
    logger.info("Successfully imported shared modules using absolute import")
except ImportError as e:
    logger.warning(f"Absolute import failed: {e}, trying relative import")
    try:
        # Fallback to relative path
        from backend.meeting_shared.database import db, init_db
        from backend.meeting_shared.middleware.error_handler import handle_api_errors
        from backend.meeting_shared.middleware.validation import validate_schema
        from backend.meeting_shared.middleware.rate_limiter import RateLimiter
        from backend.meeting_shared.config import config
        logger.info("Successfully imported shared modules using relative import")
    except ImportError as e:
        logger.error(f"All import approaches failed: {e}")
        logger.error(f"Current sys.path: {sys.path}")
        # We'll handle this in create_app() to provide a meaningful error message

# Import local modules
try:
    from .routes.meetings import meetings_bp
    from .routes.auth_integration import bp as auth_integration_bp
    from .routes.health import health_bp
    from .utils.migrations_manager import MigrationsManager
    from .utils.data_seeder import DataSeeder
    from .utils.auth_integration import AuthIntegration
except ImportError as e:
    logger.error(f"Failed to import local modules: {e}")
    # We'll handle this in create_app()

# Try to import APScheduler, but continue if it's not available
try:
    from apscheduler.schedulers.background import BackgroundScheduler
    from apscheduler.triggers.interval import IntervalTrigger
    has_apscheduler = True
    logger.info("Successfully imported APScheduler")
except ImportError:
    has_apscheduler = False
    logger.warning("APScheduler not available, some features will be disabled")

# Initialize extensions
migrate = Migrate()
csrf = CSRFProtect()
rate_limiter = None
cors = CORS()
redis_client = None

def get_redis_client():
    """Get or create Redis client singleton"""
    global redis_client
    if redis_client is None:
        redis_url = os.environ.get("REDIS_URL", "redis://localhost:6379/0")
        try:
            redis_client = Redis.from_url(redis_url)
            redis_client.ping()  # Test connection
            logger.info("Redis connection established successfully")
        except Exception as e:
            logger.error(f"Failed to connect to Redis: {str(e)}")
            redis_client = None
    return redis_client

def create_app(config_name='development', initialize_db=True):
    """Create and configure the Flask application"""
    # Import os again to ensure it's available in this function's scope
    import os
    
    app = Flask(__name__)
    
    # In case of import errors, return a minimal app that explains the issue
    import_errors = []
    
    # Check if critical modules were imported
    if 'db' not in globals():
        import_errors.append("Failed to import shared database module")
    if 'meetings_bp' not in globals():
        import_errors.append("Failed to import meetings blueprint")
    
    if import_errors:
        @app.route('/')
        def import_error():
            return jsonify({
                'status': 'error',
                'message': 'Application failed to start due to import errors',
                'errors': import_errors,
                'python_path': sys.path
            }), 500
            
        @app.route('/health')
        def minimal_health():
            return jsonify({
                'status': 'error',
                'message': 'Application is running but with import errors',
                'errors': import_errors
            }), 500
            
        return app

    # Ensure required environment variables are set
    required_env_vars = [
        'DATABASE_URL',
        'JWT_SECRET_KEY',
        'REDIS_URL',
        'SERVICE_KEY',
        'AUTH_SERVICE_URL'
    ]
    
    # Check for missing environment variables
    missing_vars = []
    for var in required_env_vars:
        if not os.environ.get(var):
            missing_vars.append(var)
    
    if missing_vars:
        raise RuntimeError(f"Missing required environment variables: {', '.join(missing_vars)}")
    
    # Load configuration from shared config
    app.config.from_object(config[config_name])
    
    # Ensure backup directory is configured
    app.config['BACKUP_DIR'] = os.environ.get('BACKUP_DIR', os.path.join(app.root_path, 'db_backups'))
    
    # Initialize rate limiter
    global rate_limiter
    rate_limiter = RateLimiter(app.config['REDIS_URL'])
    
    # Initialize Redis client and store in app extensions
    redis = get_redis_client()
    if redis:
        app.extensions['redis'] = redis
    
    # Configure cache settings
    app.config['CACHE_TYPE'] = 'redis'
    app.config['CACHE_REDIS_URL'] = app.config['REDIS_URL']
    
    # CORS configuration from shared config
    CORS(app, resources={
        r"/api/*": {
            "origins": app.config['CORS_ORIGINS'],
            "methods": app.config['CORS_METHODS'],
            "allow_headers": app.config['CORS_HEADERS'],
            "supports_credentials": True
        }
    })
    
    # CSRF configuration
    csrf.init_app(app)
    app.config['WTF_CSRF_TIME_LIMIT'] = 3600  # 1 hour
    app.config['WTF_CSRF_SSL_STRICT'] = True
    
    # Exempt non-browser endpoints from CSRF
    csrf.exempt(auth_integration_bp)
    
    # Initialize database and migrations
    init_db(app)  # Using shared database initialization
    migrate.init_app(app, db)
    
    # Register error handlers
    handle_api_errors(app)
    
    # Initialize database if needed
    if initialize_db:
        with app.app_context():
            migrations_manager = MigrationsManager(app, db)
            migrations_manager.initialize_database()

            # Seed data in development
            if app.config.get("FLASK_ENV") == "development":
                data_seeder = DataSeeder(app, db)
                if not data_seeder.run_all_seeders():
                    logger.error("Failed to seed data")
    
    # Register blueprints
    app.register_blueprint(meetings_bp, url_prefix='/api/meetings')
    app.register_blueprint(auth_integration_bp, url_prefix='/api')
    
    # Initialize background tasks if APScheduler is available
    if has_apscheduler:
        try:
            from .tasks import initialize_tasks
            initialize_tasks(app)
        except ImportError:
            logger.warning("Could not import tasks modules. Background tasks disabled.")
    
    # Register health endpoint
    @app.route("/health")
    def health_check():
        """Health check endpoint"""
        try:
            # Check database connection
            with app.app_context():
                db.session.execute("SELECT 1")
            
            # Check Redis connection
            redis_status = "unavailable"
            if app.extensions.get("redis"):
                try:
                    app.extensions["redis"].ping()
                    redis_status = "connected"
                except Exception as e:
                    redis_status = f"error: {str(e)}"
            
            return {
                "status": "healthy",
                "service": "flask",
                "database": "connected",
                "redis": redis_status,
                "apscheduler": "available" if has_apscheduler else "unavailable",
                "timestamp": datetime.utcnow().isoformat()
            }, 200
        except Exception as e:
            logger.error(f"Health check failed: {str(e)}")
            return {
                "status": "unhealthy",
                "service": "flask",
                "error": str(e),
                "timestamp": datetime.utcnow().isoformat()
            }, 500
    
    logger.info("Application initialized successfully")
    return app 
```


### FILE: backend\flask-service\src\core\__init__.py
```
"""
Core module for Flask service functionality and initialization.
Provides centralized logging, error handling, and configuration.
"""

import logging
import os
import sys
import json
from pathlib import Path

# Try to import shared modules
try:
    from meeting_shared.shared_logging import configure_logging, get_logger
    from meeting_shared.middleware.request_id import RequestIdMiddleware, get_request_id
    SHARED_MODULES_AVAILABLE = True
except ImportError:
    SHARED_MODULES_AVAILABLE = False

# Configure application-wide logging
def setup_logging(log_level=None):
    """
    Configure application-wide logging with appropriate handlers and formatters.
    
    Args:
        log_level: Optional override for log level (default is from environment or INFO)
        
    Returns:
        logging.Logger: Logger instance
    """
    if not log_level:
        log_level = os.environ.get('LOG_LEVEL', 'INFO').upper()
    
    # Use shared logging if available
    if SHARED_MODULES_AVAILABLE:
        # Configure using shared module
        config = {
            'level': log_level,
            'service_name': 'flask-service',
            'json_enabled': os.environ.get('JSON_LOGS', 'true').lower() == 'true',
            'file_enabled': os.environ.get('LOG_TO_FILE', 'false').lower() == 'true',
            'file_path': os.environ.get('LOG_FILE', 'logs/flask-service.log'),
        }
        configure_logging(config)
        logger = get_logger(__name__)
    else:
        # Fall back to basic logging
        logging_format = os.environ.get(
            'LOG_FORMAT', 
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        # Configure root logger
        root_logger = logging.getLogger()
        root_logger.setLevel(getattr(logging, log_level))
        
        # Remove existing handlers
        for handler in list(root_logger.handlers):
            root_logger.removeHandler(handler)
        
        # Add console handler
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(getattr(logging, log_level))
        console_formatter = logging.Formatter(logging_format)
        console_handler.setFormatter(console_formatter)
        root_logger.addHandler(console_handler)
        
        # Add file handler if requested
        if os.environ.get('LOG_TO_FILE', 'false').lower() == 'true':
            log_file = os.environ.get('LOG_FILE', 'logs/flask-service.log')
            os.makedirs(os.path.dirname(log_file), exist_ok=True)
            
            file_handler = logging.FileHandler(log_file)
            file_handler.setLevel(getattr(logging, log_level))
            file_formatter = logging.Formatter(logging_format)
            file_handler.setFormatter(file_formatter)
            root_logger.addHandler(file_handler)
        
        logger = logging.getLogger(__name__)
    
    logger.info(f"Logging initialized at level {log_level}")
    
    return logger

def log_system_info():
    """
    Log system and environment information for debugging purposes.
    """
    import platform
    import socket
    from datetime import datetime
    
    logger = logging.getLogger(__name__)
    
    # Collect system information
    system_info = {
        'timestamp': datetime.utcnow().isoformat() + 'Z',
        'hostname': socket.gethostname(),
        'platform': platform.platform(),
        'python_version': platform.python_version(),
        'environment': os.environ.get('FLASK_ENV', 'production'),
        'debug': os.environ.get('DEBUG', 'false').lower() == 'true',
    }
    
    # Log system information
    logger.info(f"System info: {json.dumps(system_info)}")
    
    # Log environment variables (filtered)
    safe_vars = {k: v for k, v in os.environ.items() 
                if not any(secret in k.lower() 
                        for secret in ['key', 'secret', 'token', 'password', 'auth'])}
    
    logger.debug(f"Environment variables: {json.dumps(safe_vars)}")

def log_directory_structure(base_path='/app', max_depth=2):
    """
    Log the directory structure for debugging purposes.
    """
    logger = logging.getLogger(__name__)
    logger.info(f"Directory structure of {base_path} (max depth: {max_depth})")
    
    def _log_dir(path, depth=0):
        if depth > max_depth:
            return
        
        try:
            path_obj = Path(path)
            
            # Skip if path doesn't exist
            if not path_obj.exists():
                logger.warning(f"Path does not exist: {path}")
                return
            
            # Log directory entries
            if path_obj.is_dir():
                indent = '  ' * depth
                
                # Get directory contents
                try:
                    contents = list(path_obj.iterdir())
                    
                    # Log count of items
                    logger.info(f"{indent}{path} ({len(contents)} items)")
                    
                    # Sort contents (directories first)
                    contents.sort(key=lambda p: (0 if p.is_dir() else 1, p.name))
                    
                    # Log each item
                    for item in contents:
                        if item.is_dir():
                            _log_dir(item, depth + 1)
                        else:
                            try:
                                stat = item.stat()
                                size_kb = stat.st_size / 1024
                                logger.info(f"{indent}  {item.name} ({size_kb:.1f} KB)")
                            except Exception as e:
                                logger.info(f"{indent}  {item.name} (error: {str(e)})")
                except Exception as e:
                    logger.error(f"Error listing directory {path}: {str(e)}")
        except Exception as e:
            logger.error(f"Error logging directory structure: {str(e)}")
    
    # Start logging directory structure
    _log_dir(base_path)

def register_extensions(app):
    """
    Register Flask extensions with the app.
    
    Args:
        app: Flask application instance
    """
    # Register request ID middleware if available
    if SHARED_MODULES_AVAILABLE:
        RequestIdMiddleware(app)
        app.logger.info("Registered RequestIdMiddleware")

def init_app(app):
    """
    Initialize the Flask application with core functionality.
    
    Args:
        app: Flask application instance
    """
    # Set up logging
    setup_logging()
    
    # Register extensions
    register_extensions(app)
    
    # Log system information
    log_system_info()
    
    # Log directory structure for debugging
    if app.debug:
        log_directory_structure()
    
    # Register error handlers
    from .errors import register_error_handlers
    register_error_handlers(app)
    
    app.logger.info("Core initialization complete") 
```


### FILE: backend\flask-service\src\core\config.py
```
"""
Centralized configuration management for the application.
Handles environment variables and provides environment-specific settings.
"""

import os
import logging
from pathlib import Path

logger = logging.getLogger(__name__)

class BaseConfig:
    """Base configuration settings shared across all environments"""
    # Application settings
    APP_NAME = "Meeting API Service"
    API_PREFIX = "/api"
    
    # Environment settings
    DEBUG = False
    TESTING = False
    
    # Security settings
    SECRET_KEY = os.environ.get("JWT_SECRET_KEY")
    SERVICE_KEY = os.environ.get("SERVICE_KEY")
    
    # Database settings 
    SQLALCHEMY_DATABASE_URI = os.environ.get("DATABASE_URL")
    SQLALCHEMY_TRACK_MODIFICATIONS = False
    
    # Redis settings
    REDIS_URL = os.environ.get("REDIS_URL", "redis://localhost:6379/0")
    
    # CORS settings
    CORS_ORIGINS = os.environ.get("CORS_ORIGINS", "http://localhost:3000").split(",")
    CORS_METHODS = ["GET", "POST", "PUT", "DELETE", "OPTIONS"]
    CORS_HEADERS = ["Content-Type", "Authorization", "X-Service-Key"]
    
    # Auth Service integration
    AUTH_SERVICE_URL = os.environ.get("AUTH_SERVICE_URL", "http://auth-service:5001")
    
    # File paths
    ROOT_DIR = Path("/app")
    LOG_DIR = ROOT_DIR / "logs"
    BACKUP_DIR = ROOT_DIR / "backups"
    
    # Ensure directories exist
    LOG_DIR.mkdir(exist_ok=True)
    BACKUP_DIR.mkdir(exist_ok=True)

    # Healthcheck settings
    HEALTH_DATABASE_TIMEOUT = 3  # seconds
    HEALTH_REDIS_TIMEOUT = 2     # seconds

class DevelopmentConfig(BaseConfig):
    """Development environment specific configuration"""
    DEBUG = True
    LOG_LEVEL = "DEBUG"
    
    # Enable detailed error messages and SQL query logging
    SQLALCHEMY_ECHO = True
    
    # Development-specific settings
    PRESERVE_CONTEXT_ON_EXCEPTION = False
    
    # Extended CORS settings for development
    CORS_ORIGINS = os.environ.get("CORS_ORIGINS", 
                                 "http://localhost:3000,http://localhost:3001,http://localhost:5000").split(",")

class TestingConfig(BaseConfig):
    """Testing environment specific configuration"""
    TESTING = True
    DEBUG = True
    
    # Use in-memory database for testing
    SQLALCHEMY_DATABASE_URI = os.environ.get("TEST_DATABASE_URL", "sqlite:///:memory:")
    
    # Disable CSRF protection for testing
    WTF_CSRF_ENABLED = False
    
    # Mock external services
    AUTH_SERVICE_URL = os.environ.get("TEST_AUTH_SERVICE_URL", "http://localhost:5001")
    REDIS_URL = os.environ.get("TEST_REDIS_URL", "redis://localhost:6379/1")

class ProductionConfig(BaseConfig):
    """Production environment specific configuration"""
    LOG_LEVEL = "INFO"
    
    # Production security settings
    WTF_CSRF_SSL_STRICT = True
    
    # Set stricter CORS
    CORS_ORIGINS = os.environ.get("CORS_ORIGINS", "https://yourdomain.com").split(",")

# Dictionary of available configurations
config = {
    "development": DevelopmentConfig,
    "testing": TestingConfig,
    "production": ProductionConfig,
    # Default to development
    "default": DevelopmentConfig
}

def get_config(config_name=None):
    """
    Get the configuration for the current environment.
    
    Args:
        config_name: Optional configuration name override
        
    Returns:
        Configuration class
    """
    if not config_name:
        config_name = os.environ.get("FLASK_ENV", "development").lower()
    
    selected_config = config.get(config_name, config["default"])
    logger.info(f"Using '{config_name}' configuration")
    
    # Validate critical settings
    if not selected_config.SECRET_KEY and config_name == "production":
        logger.critical("SECRET_KEY not set in production environment!")
    
    if not selected_config.SQLALCHEMY_DATABASE_URI:
        logger.critical("DATABASE_URL not set! Application may fail to start")
    
    return selected_config 
```


### FILE: backend\flask-service\src\core\errors.py
```
"""
Centralized error handling for the Flask service.
Provides standardized error responses and detailed logging of exceptions.
"""

import traceback
import logging
import json
import os
from datetime import datetime
from flask import jsonify, request, current_app

logger = logging.getLogger(__name__)

# Try to import standardized errors from shared module
try:
    # Try to import from backend.meeting_shared first
    from backend.meeting_shared.errors import (
        APIError, ValidationError, AuthenticationError, AuthorizationError,
        UserExistsError, UserNotFoundError, TokenError, ResourceNotFoundError,
        ResourceExistsError, ServiceError, ConfigurationError, DependencyError,
        RateLimitError, EmailError, HAS_REQUEST_ID
    )
    SHARED_ERRORS_AVAILABLE = True
    logger.info("Successfully imported shared error classes")
except ImportError:
    try:
        # Try to import from meeting_shared as fallback
        from meeting_shared.errors import (
            APIError, ValidationError, AuthenticationError, AuthorizationError,
            UserExistsError, UserNotFoundError, TokenError, ResourceNotFoundError,
            ResourceExistsError, ServiceError, ConfigurationError, DependencyError,
            RateLimitError, EmailError, HAS_REQUEST_ID
        )
        SHARED_ERRORS_AVAILABLE = True
        logger.info("Successfully imported shared error classes using fallback path")
    except ImportError:
        SHARED_ERRORS_AVAILABLE = False
        logger.warning("Could not import shared error classes, using local definitions")
        
        # Try to import request ID functionality
        try:
            from backend.meeting_shared.middleware.request_id import get_request_id
            HAS_REQUEST_ID = True
        except ImportError:
            try:
                from meeting_shared.middleware.request_id import get_request_id
                HAS_REQUEST_ID = True
            except ImportError:
                HAS_REQUEST_ID = False

        # Define error classes locally if shared module is not available
        class APIError(Exception):
            """Base exception class for API errors with status code and message"""
            
            def __init__(self, message, status_code=400, details=None):
                self.message = message
                self.status_code = status_code
                self.details = details or {}
                self.timestamp = datetime.utcnow().isoformat() + 'Z'
                
                # Add request ID if available
                if HAS_REQUEST_ID:
                    self.request_id = get_request_id()
                else:
                    self.request_id = None
            
            def to_dict(self):
                """Convert exception to dictionary representation"""
                error_dict = {
                    'error': True,
                    'status_code': self.status_code,
                    'message': self.message,
                    'timestamp': self.timestamp
                }
                
                # Include request ID if available
                if hasattr(self, 'request_id') and self.request_id:
                    error_dict['request_id'] = self.request_id
                
                # Include request URL and method if in a request context
                try:
                    error_dict['path'] = request.path
                    error_dict['method'] = request.method
                except RuntimeError:
                    # Not in a request context
                    pass
                
                # Include additional details if provided
                if self.details:
                    error_dict['details'] = self.details
                
                return error_dict

        class ValidationError(APIError):
            """Exception for data validation errors"""
            
            def __init__(self, message="Validation error", details=None):
                super().__init__(message, status_code=422, details=details)

        class AuthenticationError(APIError):
            """Exception for authentication failures"""
            
            def __init__(self, message="Authentication required", details=None):
                super().__init__(message, status_code=401, details=details)

        class AuthorizationError(APIError):
            """Exception for authorization failures"""
            
            def __init__(self, message="Not authorized", details=None):
                super().__init__(message, status_code=403, details=details)

        class ResourceNotFoundError(APIError):
            """Exception for resource not found"""
            
            def __init__(self, message="Resource not found", details=None):
                super().__init__(message, status_code=404, details=details)

        class ResourceExistsError(APIError):
            """Exception for duplicate resource"""
            
            def __init__(self, message="Resource already exists", details=None):
                super().__init__(message, status_code=409, details=details)

        class RateLimitError(APIError):
            """Exception for rate limiting"""
            
            def __init__(self, message="Rate limit exceeded", details=None):
                super().__init__(message, status_code=429, details=details)

        class ServiceError(APIError):
            """Exception for service failures"""
            
            def __init__(self, message="Service error", details=None):
                super().__init__(message, status_code=500, details=details)

        class ConfigurationError(APIError):
            """Exception for configuration errors"""
            
            def __init__(self, message="Configuration error", details=None):
                super().__init__(message, status_code=500, details=details)

        class DependencyError(APIError):
            """Exception for dependency failures"""
            
            def __init__(self, message="Dependency error", details=None):
                super().__init__(message, status_code=503, details=details)
                
        class UserExistsError(APIError):
            """Exception for duplicate user registration"""
            
            def __init__(self, message="User already exists", details=None):
                super().__init__(message, status_code=409, details=details)
                
        class UserNotFoundError(APIError):
            """Exception for user not found"""
            
            def __init__(self, message="User not found", details=None):
                super().__init__(message, status_code=404, details=details)
                
        class TokenError(APIError):
            """Exception for token validation failures"""
            
            def __init__(self, message="Invalid or expired token", details=None):
                super().__init__(message, status_code=401, details=details)
                
        class EmailError(APIError):
            """Exception for email sending failures"""
            
            def __init__(self, message="Failed to send email", details=None):
                super().__init__(message, status_code=500, details=details)

def register_error_handlers(app):
    """
    Register all error handlers with the Flask app.
    
    Args:
        app: Flask application instance
    """
    # Custom exceptions
    app.register_error_handler(APIError, handle_api_error)
    app.register_error_handler(ValidationError, handle_api_error)
    app.register_error_handler(AuthenticationError, handle_api_error)
    app.register_error_handler(AuthorizationError, handle_api_error)
    app.register_error_handler(ResourceNotFoundError, handle_api_error)
    app.register_error_handler(ResourceExistsError, handle_api_error)
    app.register_error_handler(RateLimitError, handle_api_error)
    app.register_error_handler(ServiceError, handle_api_error)
    app.register_error_handler(ConfigurationError, handle_api_error)
    app.register_error_handler(DependencyError, handle_api_error)
    app.register_error_handler(UserExistsError, handle_api_error)
    app.register_error_handler(UserNotFoundError, handle_api_error)
    app.register_error_handler(TokenError, handle_api_error)
    app.register_error_handler(EmailError, handle_api_error)
    
    # Standard HTTP errors
    app.register_error_handler(400, handle_bad_request)
    app.register_error_handler(401, handle_unauthorized)
    app.register_error_handler(403, handle_forbidden)
    app.register_error_handler(404, handle_not_found)
    app.register_error_handler(405, handle_method_not_allowed)
    app.register_error_handler(422, handle_unprocessable_entity)
    app.register_error_handler(429, handle_rate_limit_exceeded)
    app.register_error_handler(500, handle_server_error)
    
    # Catch-all for any other exceptions
    app.register_error_handler(Exception, handle_exception)
    
    logger.info("Registered error handlers")

def handle_api_error(error):
    """
    Handler for API errors.
    
    Args:
        error: APIError instance
        
    Returns:
        JSON response with error details
    """
    response = jsonify(error.to_dict())
    response.status_code = error.status_code
    
    # Add request ID header if available
    if hasattr(error, 'request_id') and error.request_id:
        response.headers['X-Request-ID'] = error.request_id
    
    # Log the error
    if error.status_code >= 500:
        logger.error(f"API Error: {error.message}", extra={'status_code': error.status_code})
    else:
        logger.info(f"API Error: {error.message}", extra={'status_code': error.status_code})
    
    return response

def handle_bad_request(error):
    """
    Handler for 400 Bad Request errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = APIError("Bad request", status_code=400)
    return handle_api_error(api_error)

def handle_unauthorized(error):
    """
    Handler for 401 Unauthorized errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = AuthenticationError("Authentication required")
    return handle_api_error(api_error)

def handle_forbidden(error):
    """
    Handler for 403 Forbidden errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = AuthorizationError("Access forbidden")
    return handle_api_error(api_error)

def handle_not_found(error):
    """
    Handler for 404 Not Found errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = ResourceNotFoundError("Resource not found")
    return handle_api_error(api_error)

def handle_method_not_allowed(error):
    """
    Handler for 405 Method Not Allowed errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = APIError("Method not allowed", status_code=405)
    return handle_api_error(api_error)

def handle_unprocessable_entity(error):
    """
    Handler for 422 Unprocessable Entity errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    # Extract validation errors from WTForms if available
    details = {}
    if hasattr(error, 'data') and 'errors' in error.data:
        details = {'fields': error.data['errors']}
    
    api_error = ValidationError("Validation error", details=details)
    return handle_api_error(api_error)

def handle_rate_limit_exceeded(error):
    """
    Handler for 429 Too Many Requests errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    api_error = RateLimitError("Rate limit exceeded")
    return handle_api_error(api_error)

def handle_server_error(error):
    """
    Handler for 500 Internal Server Error errors.
    
    Args:
        error: Error instance
        
    Returns:
        JSON response with error details
    """
    # Log the full stack trace
    logger.error(f"Server error: {str(error)}", exc_info=True)
    
    # Create a more detailed error in development
    is_development = current_app.config.get('ENV') == 'development'
    
    details = None
    if is_development:
        details = {
            'traceback': traceback.format_exc(),
            'error_type': error.__class__.__name__
        }
    
    api_error = ServiceError("Internal server error", details=details)
    return handle_api_error(api_error)

def handle_exception(error):
    """
    Catch-all handler for uncaught exceptions.
    
    Args:
        error: Exception instance
        
    Returns:
        JSON response with error details
    """
    # Log the full stack trace
    logger.error(f"Uncaught exception: {str(error)}", exc_info=True)
    
    # Create a more detailed error in development
    is_development = current_app.config.get('ENV') == 'development'
    
    details = None
    if is_development:
        details = {
            'traceback': traceback.format_exc(),
            'error_type': error.__class__.__name__
        }
    
    message = str(error) if is_development else "An unexpected error occurred"
    
    api_error = ServiceError(message, details=details)
    return handle_api_error(api_error) 
```


### FILE: backend\flask-service\src\core\health.py
```
"""
Health check module for service health monitoring and diagnostics.
Provides comprehensive health checks for all service dependencies.
"""

import logging
import time
import os
import socket
import platform
import psutil
from datetime import datetime
from flask import Blueprint, jsonify, current_app

from .config import get_config

logger = logging.getLogger(__name__)

# Create health blueprint
health_bp = Blueprint('health', __name__)

@health_bp.route('/health', methods=['GET'])
def health_check():
    """
    Comprehensive health check endpoint for the service.
    Checks database, Redis, auth service, and system resources.
    """
    start_time = time.time()
    health_data = {
        "service": "Meeting API Service",
        "timestamp": datetime.utcnow().isoformat(),
        "uptime": _get_uptime(),
        "status": "checking",
        "checks": {},
        "system": _get_system_info()
    }
    
    # Perform all health checks
    try:
        # Check database
        db_status = _check_database()
        health_data["checks"]["database"] = db_status
        
        # Check Redis
        redis_status = _check_redis()
        health_data["checks"]["redis"] = redis_status
        
        # Check Auth Service connection
        auth_status = _check_auth_service()
        health_data["checks"]["auth_service"] = auth_status
        
        # Determine overall status (healthy only if all checks pass)
        critical_services = [db_status, redis_status]
        if all(service.get('status') == 'healthy' for service in critical_services):
            health_data["status"] = "healthy"
        else:
            health_data["status"] = "unhealthy"
            
    except Exception as e:
        logger.error(f"Error performing health check: {str(e)}")
        health_data["status"] = "error"
        health_data["error"] = str(e)
    
    # Add response time
    health_data["response_time_ms"] = round((time.time() - start_time) * 1000, 2)
    
    # Determine response status code
    status_code = 200 if health_data["status"] == "healthy" else 503
    
    return jsonify(health_data), status_code


def _check_database():
    """
    Check database connectivity and health
    """
    from flask_sqlalchemy import SQLAlchemy
    
    try:
        start_time = time.time()
        db = SQLAlchemy(current_app)
        
        # Execute a simple query to verify connection
        result = db.session.execute("SELECT 1").fetchone()
        response_time = round((time.time() - start_time) * 1000, 2)
        
        if result and result[0] == 1:
            return {
                "status": "healthy",
                "response_time_ms": response_time,
                "details": {
                    "connection_string": _mask_connection_string(current_app.config.get('SQLALCHEMY_DATABASE_URI', 'unknown'))
                }
            }
        else:
            return {
                "status": "unhealthy",
                "response_time_ms": response_time,
                "error": "Database query did not return expected result"
            }
    except Exception as e:
        logger.error(f"Database health check failed: {str(e)}")
        return {
            "status": "unhealthy",
            "error": str(e)
        }


def _check_redis():
    """
    Check Redis connectivity and health
    """
    from redis import Redis
    
    try:
        start_time = time.time()
        redis_url = current_app.config.get('REDIS_URL')
        redis_client = Redis.from_url(redis_url)
        
        # Ping Redis to verify connection
        if redis_client.ping():
            # Get Redis info
            info = redis_client.info()
            response_time = round((time.time() - start_time) * 1000, 2)
            
            return {
                "status": "healthy",
                "response_time_ms": response_time,
                "details": {
                    "redis_version": info.get('redis_version', 'unknown'),
                    "connected_clients": info.get('connected_clients', 'unknown'),
                    "used_memory_human": info.get('used_memory_human', 'unknown')
                }
            }
        else:
            return {
                "status": "unhealthy",
                "error": "Redis ping failed"
            }
    except Exception as e:
        logger.error(f"Redis health check failed: {str(e)}")
        return {
            "status": "unhealthy",
            "error": str(e)
        }


def _check_auth_service():
    """
    Check Auth Service connectivity
    """
    import requests
    
    try:
        start_time = time.time()
        auth_url = current_app.config.get('AUTH_SERVICE_URL')
        health_url = f"{auth_url}/health"
        
        # Set a short timeout for the request
        timeout = current_app.config.get('HEALTH_TIMEOUT', 3)
        
        # Make request to auth service health endpoint
        response = requests.get(health_url, timeout=timeout)
        response_time = round((time.time() - start_time) * 1000, 2)
        
        if response.status_code == 200:
            try:
                auth_data = response.json()
                return {
                    "status": "healthy",
                    "response_time_ms": response_time,
                    "details": {
                        "auth_service_status": auth_data.get('status', 'unknown'),
                        "auth_service_version": auth_data.get('version', 'unknown')
                    }
                }
            except:
                return {
                    "status": "degraded",
                    "response_time_ms": response_time,
                    "error": "Invalid JSON response from auth service"
                }
        else:
            return {
                "status": "unhealthy",
                "response_time_ms": response_time,
                "error": f"Auth service returned status code {response.status_code}"
            }
    except requests.Timeout:
        return {
            "status": "unhealthy",
            "error": "Auth service connection timeout"
        }
    except requests.ConnectionError:
        return {
            "status": "unhealthy",
            "error": "Could not connect to auth service"
        }
    except Exception as e:
        logger.error(f"Auth service health check failed: {str(e)}")
        return {
            "status": "unhealthy",
            "error": str(e)
        }


def _get_system_info():
    """
    Get system information for diagnostics
    """
    try:
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        return {
            "hostname": socket.gethostname(),
            "platform": platform.platform(),
            "python_version": platform.python_version(),
            "cpu_count": os.cpu_count(),
            "memory": {
                "total_gb": round(memory.total / (1024**3), 2),
                "available_gb": round(memory.available / (1024**3), 2),
                "used_percent": memory.percent
            },
            "disk": {
                "total_gb": round(disk.total / (1024**3), 2),
                "free_gb": round(disk.free / (1024**3), 2),
                "used_percent": disk.percent
            },
            "load_avg": _get_load_avg()
        }
    except Exception as e:
        logger.error(f"Error getting system info: {str(e)}")
        return {"error": "Could not retrieve system information"}


def _get_load_avg():
    """
    Get system load average, with Windows compatibility
    """
    try:
        if hasattr(os, 'getloadavg'):
            # Unix systems
            load1, load5, load15 = os.getloadavg()
            return {"1min": round(load1, 2), "5min": round(load5, 2), "15min": round(load15, 2)}
        else:
            # Windows systems
            return {"cpu_percent": psutil.cpu_percent(interval=0.1)}
    except:
        return {"error": "Could not retrieve load average"}


def _get_uptime():
    """
    Get service uptime
    """
    try:
        # Get process start time
        p = psutil.Process(os.getpid())
        start_time = datetime.fromtimestamp(p.create_time())
        uptime = datetime.now() - start_time
        
        # Format uptime as days, hours, minutes, seconds
        days, remainder = divmod(uptime.total_seconds(), 86400)
        hours, remainder = divmod(remainder, 3600)
        minutes, seconds = divmod(remainder, 60)
        
        return {
            "days": int(days),
            "hours": int(hours),
            "minutes": int(minutes),
            "seconds": int(seconds),
            "total_seconds": int(uptime.total_seconds())
        }
    except Exception as e:
        logger.error(f"Error getting uptime: {str(e)}")
        return {"error": "Could not determine uptime"}


def _mask_connection_string(conn_string):
    """
    Mask sensitive information in database connection string
    """
    if not conn_string or '://' not in conn_string:
        return 'invalid-connection-string'
    
    try:
        # Split connection string into parts
        protocol_part, rest = conn_string.split('://')
        
        # Mask username and password if present
        if '@' in rest:
            auth_part, host_part = rest.split('@')
            
            # Replace password with asterisks if present
            if ':' in auth_part:
                username, password = auth_part.split(':')
                masked_auth = f"{username}:***"
            else:
                masked_auth = auth_part
                
            return f"{protocol_part}://{masked_auth}@{host_part}"
        else:
            # No auth part
            return conn_string
    except:
        # If parsing fails, return a generic masked string
        return f"{conn_string.split('://')[0]}://***" 
```


### FILE: backend\flask-service\src\models\__init__.py
```
from .. import db
from .user import User
from .meeting import Meeting
from .meeting_participant import MeetingParticipant
from .meeting_co_host import MeetingCoHost
from .meeting_audit_log import MeetingAuditLog

__all__ = ['db', 'User', 'Meeting', 'MeetingParticipant', 'MeetingCoHost', 'MeetingAuditLog'] 
```


### FILE: backend\flask-service\src\models\meeting.py
```
from datetime import datetime, timezone
from .. import db
from ..schemas.meeting import MeetingCreate, MeetingUpdate, MeetingResponse

class Meeting(db.Model):
    __tablename__ = 'meetings'
    
    id = db.Column(db.Integer, primary_key=True)
    title = db.Column(db.String(200), nullable=False)
    description = db.Column(db.Text)
    start_time = db.Column(db.DateTime, nullable=False)
    end_time = db.Column(db.DateTime, nullable=False)
    created_by = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=False)
    created_at = db.Column(db.DateTime, nullable=False, default=lambda: datetime.now(timezone.utc))
    updated_at = db.Column(db.DateTime, nullable=False, default=lambda: datetime.now(timezone.utc), onupdate=lambda: datetime.now(timezone.utc))
    ended_at = db.Column(db.DateTime, nullable=True)
    
    # New fields
    meeting_type = db.Column(db.String(20), nullable=False, default='regular')  # regular, recurring, private
    max_participants = db.Column(db.Integer, nullable=True)
    requires_approval = db.Column(db.Boolean, nullable=False, default=False)
    is_recorded = db.Column(db.Boolean, nullable=False, default=False)
    recording_url = db.Column(db.String(500), nullable=True)
    recurring_pattern = db.Column(db.String(50), nullable=True)  # daily, weekly, monthly, custom
    parent_meeting_id = db.Column(db.Integer, db.ForeignKey('meetings.id'), nullable=True)  # For recurring meetings

    # Relationships
    creator = db.relationship('User', backref=db.backref('created_meetings', lazy=True))
    participants = db.relationship('MeetingParticipant', backref='meeting', lazy=True, cascade='all, delete-orphan')
    co_hosts = db.relationship('MeetingCoHost', backref='meeting', lazy=True, cascade='all, delete-orphan')
    child_meetings = db.relationship('Meeting', backref=db.backref('parent_meeting', remote_side=[id]))

    def __init__(self, title, description, start_time, end_time, created_by, meeting_type='regular', 
                 max_participants=None, requires_approval=False, is_recorded=False):
        self.title = title
        self.description = description
        self.start_time = start_time
        self.end_time = end_time
        self.created_by = created_by
        self.meeting_type = meeting_type
        self.max_participants = max_participants
        self.requires_approval = requires_approval
        self.is_recorded = is_recorded

    def to_dict(self):
        return {
            'id': self.id,
            'title': self.title,
            'description': self.description,
            'start_time': self.start_time.isoformat(),
            'end_time': self.end_time.isoformat(),
            'created_by': self.created_by,
            'created_at': self.created_at.isoformat(),
            'updated_at': self.updated_at.isoformat(),
            'ended_at': self.ended_at.isoformat() if self.ended_at else None,
            'meeting_type': self.meeting_type,
            'max_participants': self.max_participants,
            'requires_approval': self.requires_approval,
            'is_recorded': self.is_recorded,
            'recording_url': self.recording_url,
            'recurring_pattern': self.recurring_pattern,
            'parent_meeting_id': self.parent_meeting_id
        }

    @classmethod
    def from_schema(cls, meeting_create: MeetingCreate, created_by: int):
        """Create a new meeting from a MeetingCreate schema"""
        return cls(
            title=meeting_create.title,
            description=meeting_create.description,
            start_time=meeting_create.start_time,
            end_time=meeting_create.end_time,
            created_by=created_by,
            meeting_type=meeting_create.meeting_type,
            max_participants=meeting_create.max_participants,
            requires_approval=meeting_create.requires_approval,
            is_recorded=meeting_create.is_recorded,
            recurring_pattern=meeting_create.recurring_pattern,
            parent_meeting_id=meeting_create.parent_meeting_id
        )

    def update_from_schema(self, meeting_update: MeetingUpdate):
        """Update meeting from a MeetingUpdate schema"""
        for field, value in meeting_update.model_dump(exclude_unset=True).items():
            setattr(self, field, value)

    def to_schema(self) -> MeetingResponse:
        """Convert meeting model to MeetingResponse schema"""
        response_data = {
            'id': self.id,
            'title': self.title,
            'description': self.description,
            'start_time': self.start_time,
            'end_time': self.end_time,
            'created_by': self.created_by,
            'created_at': self.created_at,
            'updated_at': self.updated_at,
            'ended_at': self.ended_at,
            'meeting_type': self.meeting_type,
            'max_participants': self.max_participants,
            'requires_approval': self.requires_approval,
            'is_recorded': self.is_recorded,
            'recording_url': self.recording_url,
            'recurring_pattern': self.recurring_pattern,
            'parent_meeting_id': self.parent_meeting_id,
            'participant_count': len(self.participants),
            'co_hosts': [co_host.user_id for co_host in self.co_hosts]
        }
        return MeetingResponse.model_validate(response_data) 
```


### FILE: backend\flask-service\src\models\meeting_audit_log.py
```
from datetime import datetime, timezone
from .. import db

class MeetingAuditLog(db.Model):
    __tablename__ = 'meeting_audit_logs'
    
    id = db.Column(db.Integer, primary_key=True)
    meeting_id = db.Column(db.Integer, db.ForeignKey('meetings.id'), nullable=False)
    user_id = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=True)
    action = db.Column(db.String(50), nullable=False)  # created, joined, left, ended, etc.
    details = db.Column(db.Text, nullable=True)
    timestamp = db.Column(db.DateTime, nullable=False, default=lambda: datetime.now(timezone.utc))
    
    # Relationships
    meeting = db.relationship('Meeting', backref=db.backref('audit_logs', lazy=True))
    user = db.relationship('User', backref=db.backref('meeting_actions', lazy=True))
    
    def __init__(self, meeting_id, user_id, action, details=None):
        self.meeting_id = meeting_id
        self.user_id = user_id
        self.action = action
        self.details = details
        
    def to_dict(self):
        return {
            'id': self.id,
            'meeting_id': self.meeting_id,
            'user_id': self.user_id,
            'action': self.action,
            'details': self.details,
            'timestamp': self.timestamp.isoformat()
        } 
```


### FILE: backend\flask-service\src\models\meeting_co_host.py
```
from datetime import datetime, timezone
from .. import db

class MeetingCoHost(db.Model):
    __tablename__ = 'meeting_co_hosts'
    
    id = db.Column(db.Integer, primary_key=True)
    meeting_id = db.Column(db.Integer, db.ForeignKey('meetings.id'), nullable=False)
    user_id = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=False)
    permissions = db.Column(db.String(255), nullable=True)  # comma-separated list of permissions
    created_at = db.Column(db.DateTime, nullable=False, default=lambda: datetime.now(timezone.utc))
    updated_at = db.Column(db.DateTime, nullable=False, default=lambda: datetime.now(timezone.utc), onupdate=lambda: datetime.now(timezone.utc))
    
    # Relationships
    user = db.relationship('User', backref=db.backref('co_hosted_meetings', lazy=True))
    
    def __init__(self, meeting_id, user_id):
        self.meeting_id = meeting_id
        self.user_id = user_id
        
    def to_dict(self):
        return {
            'id': self.id,
            'meeting_id': self.meeting_id,
            'user_id': self.user_id,
            'created_at': self.created_at.isoformat(),
            'updated_at': self.updated_at.isoformat()
        } 
```


### FILE: backend\flask-service\src\models\meeting_participant.py
```
from datetime import datetime, timezone
from .. import db
from ..schemas.participant import ParticipantCreate, ParticipantUpdate, ParticipantResponse

class MeetingParticipant(db.Model):
    __tablename__ = 'meeting_participants'
    
    id = db.Column(db.Integer, primary_key=True)
    meeting_id = db.Column(db.Integer, db.ForeignKey('meetings.id'), nullable=False)
    user_id = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=False)
    status = db.Column(db.String(20), nullable=False, default='pending')  # pending, approved, declined, banned
    role = db.Column(db.String(20), nullable=False, default='attendee')  # attendee, presenter, moderator
    joined_at = db.Column(db.DateTime, nullable=True)
    left_at = db.Column(db.DateTime, nullable=True)
    is_banned = db.Column(db.Boolean, nullable=False, default=False)
    created_at = db.Column(db.DateTime, nullable=False, default=lambda: datetime.now(timezone.utc))
    updated_at = db.Column(db.DateTime, nullable=False, default=lambda: datetime.now(timezone.utc), onupdate=lambda: datetime.now(timezone.utc))
    
    # Additional fields for participation tracking
    total_time = db.Column(db.Integer, nullable=True)  # Total time spent in meeting in seconds
    connection_quality = db.Column(db.Float, nullable=True)  # Average connection quality
    participation_score = db.Column(db.Float, nullable=True)  # Engagement score
    feedback = db.Column(db.Text, nullable=True)  # Participant feedback
    
    # Relationships
    user = db.relationship('User', backref=db.backref('meeting_participations', lazy=True))
    
    @classmethod
    def from_schema(cls, participant_create: ParticipantCreate):
        """Create a new participant from a ParticipantCreate schema"""
        return cls(
            meeting_id=participant_create.meeting_id,
            user_id=participant_create.user_id,
            status=participant_create.status,
            role=participant_create.role
        )

    def update_from_schema(self, participant_update: ParticipantUpdate):
        """Update participant from a ParticipantUpdate schema"""
        for field, value in participant_update.model_dump(exclude_unset=True).items():
            setattr(self, field, value)

    def to_schema(self) -> ParticipantResponse:
        """Convert participant model to ParticipantResponse schema"""
        response_data = {
            'id': self.id,
            'meeting_id': self.meeting_id,
            'user_id': self.user_id,
            'status': self.status,
            'role': self.role,
            'joined_at': self.joined_at,
            'left_at': self.left_at,
            'is_banned': self.is_banned,
            'created_at': self.created_at,
            'updated_at': self.updated_at,
            'total_time': self.total_time,
            'connection_quality': self.connection_quality,
            'participation_score': self.participation_score,
            'feedback': self.feedback,
            'user_name': self.user.name if self.user else None,
            'user_email': self.user.email if self.user else None
        }
        return ParticipantResponse.model_validate(response_data)

    def record_join(self, connection_quality: float = None):
        """Record participant joining the meeting"""
        self.joined_at = datetime.now(timezone.utc)
        self.connection_quality = connection_quality
        db.session.commit()

    def record_leave(self, total_time: int, participation_score: float, feedback: str = None):
        """Record participant leaving the meeting"""
        self.left_at = datetime.now(timezone.utc)
        self.total_time = total_time
        self.participation_score = participation_score
        self.feedback = feedback
        db.session.commit()

    def __init__(self, meeting_id, user_id, status='pending', role='attendee'):
        self.meeting_id = meeting_id
        self.user_id = user_id
        self.status = status
        self.role = role
        
    def to_dict(self):
        return {
            'id': self.id,
            'meeting_id': self.meeting_id,
            'user_id': self.user_id,
            'status': self.status,
            'role': self.role,
            'joined_at': self.joined_at.isoformat() if self.joined_at else None,
            'left_at': self.left_at.isoformat() if self.left_at else None,
            'is_banned': self.is_banned,
            'created_at': self.created_at.isoformat(),
            'updated_at': self.updated_at.isoformat(),
            'total_time': self.total_time,
            'connection_quality': self.connection_quality,
            'participation_score': self.participation_score,
            'feedback': self.feedback
        } 
```


### FILE: backend\flask-service\src\models\user.py
```
from datetime import datetime, timezone
from .. import db

class User(db.Model):
    """Simplified user model that mirrors essential user data from auth service"""
    __tablename__ = 'users'

    id = db.Column(db.Integer, primary_key=True)
    email = db.Column(db.String(120), unique=True, nullable=False, index=True)
    name = db.Column(db.String(100), nullable=False)
    is_active = db.Column(db.Boolean, nullable=False, default=True)
    is_email_verified = db.Column(db.Boolean, nullable=False, default=False)
    last_login_at = db.Column(db.DateTime, nullable=True)
    created_at = db.Column(db.DateTime, nullable=False, default=lambda: datetime.now(timezone.utc))
    updated_at = db.Column(db.DateTime, nullable=False, default=lambda: datetime.now(timezone.utc), onupdate=lambda: datetime.now(timezone.utc))

    # Relationships
    hosted_meetings = db.relationship('Meeting', back_populates='host')

    def to_dict(self):
        return {
            'id': self.id,
            'email': self.email,
            'name': self.name,
            'is_active': self.is_active,
            'is_email_verified': self.is_email_verified,
            'last_login_at': self.last_login_at.isoformat() if self.last_login_at else None,
            'created_at': self.created_at.isoformat(),
            'updated_at': self.updated_at.isoformat()
        } 
```


### FILE: backend\flask-service\src\routes\__init__.py
```
from .auth import auth_bp
from .meetings import meetings_bp
from .health import health_bp
from .auth_integration import bp as auth_integration_bp

def register_routes(app):
    """Register all route blueprints with the Flask application.
    
    Args:
        app: The Flask application instance
    """
    # Register blueprints with appropriate URL prefixes
    app.register_blueprint(health_bp)
    app.register_blueprint(auth_bp, url_prefix='/api/auth')
    app.register_blueprint(meetings_bp, url_prefix='/api/meetings')
    app.register_blueprint(auth_integration_bp, url_prefix='/api')
    
    return app
```


### FILE: backend\flask-service\src\routes\auth.py
```
from flask import Blueprint, request, jsonify
from werkzeug.security import generate_password_hash
import jwt
import datetime
from datetime import timezone
import os
import re
from sqlalchemy.exc import IntegrityError

from ..models import db, User

auth_bp = Blueprint('auth', __name__)

def validate_email(email):
    if not email or len(email) > 120:
        return False
    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    return re.match(pattern, email) is not None

def validate_password(password):
    if not password or len(password) > 72:  # bcrypt max length is 72 bytes
        return False
    # At least 8 chars, 1 uppercase, 1 lowercase, 1 number, 1 special char
    if len(password) < 8:
        return False
    if not re.search(r'[A-Z]', password):
        return False
    if not re.search(r'[a-z]', password):
        return False
    if not re.search(r'[0-9]', password):
        return False
    if not re.search(r'[!@#$%^&*(),.?":{}|<>]', password):
        return False
    return True

def validate_name(name):
    if not name or len(name) > 100:
        return False
    # Allow letters, numbers, spaces, dots, and hyphens
    return bool(re.match(r'^[a-zA-Z0-9\s.-]{3,100}$', name))

def get_failed_login_attempts(email):
    # You should implement rate limiting using Redis or similar
    # This is a placeholder
    return 0

def is_ip_blocked(ip):
    # You should implement IP blocking using Redis or similar
    # This is a placeholder
    return False

@auth_bp.route('/register', methods=['POST'])
def register():
    try:
        # Check IP blocking first
        if is_ip_blocked(request.remote_addr):
            return jsonify({'error': 'Too many requests', 'code': 'ip_blocked'}), 429

        data = request.get_json()
        
        if not data:
            return jsonify({'error': 'No data provided'}), 400
            
        if not all(k in data for k in ['email', 'name', 'password']):
            return jsonify({'error': 'Missing required fields'}), 400
            
        # Sanitize inputs
        email = data['email'].strip().lower()
        name = data['name'].strip()
        password = data['password']
            
        # Enhanced validations
        if not validate_email(email):
            return jsonify({
                'error': 'Invalid email format or length',
                'requirements': 'Valid email format and maximum 120 characters'
            }), 400
            
        if not validate_password(password):
            return jsonify({
                'error': 'Password does not meet requirements',
                'requirements': 'At least 8 characters, 1 uppercase, 1 lowercase, 1 number, 1 special character'
            }), 400
            
        if not validate_name(name):
            return jsonify({
                'error': 'Invalid name format or length',
                'requirements': 'Between 3-100 characters, letters, numbers, spaces, dots, and hyphens only'
            }), 400
            
        # Check for existing user with case-insensitive email
        if User.query.filter(User.email.ilike(email)).first():
            return jsonify({'error': 'Email already registered'}), 400
            
        # Check for existing user with case-insensitive name
        if User.query.filter(User.name.ilike(name)).first():
            return jsonify({'error': 'Name already taken'}), 400
        
        user = User(
            email=email,
            name=name,
            password=password
        )
        
        try:
            db.session.add(user)
            db.session.commit()
        except IntegrityError:
            db.session.rollback()
            return jsonify({'error': 'Database constraint violation'}), 400
        
        # Generate JWT token with limited expiry
        token_expiry = int(os.getenv('JWT_EXPIRY_DAYS', '1'))
        token = jwt.encode({
            'user_id': user.id,
            'email': user.email,
            'exp': datetime.datetime.now(timezone.utc) + datetime.timedelta(days=token_expiry),
            'iat': datetime.datetime.now(timezone.utc),
            'type': 'access'
        }, os.getenv('JWT_SECRET_KEY'), algorithm='HS256')
        
        return jsonify({
            'message': 'User registered successfully',
            'token': token,
            'user': user.to_dict()
        }), 201
        
    except Exception as e:
        db.session.rollback()
        return jsonify({'error': 'Server error occurred during registration'}), 500

@auth_bp.route('/login', methods=['POST'])
def login():
    try:
        # Check IP blocking first
        if is_ip_blocked(request.remote_addr):
            return jsonify({'error': 'Too many requests', 'code': 'ip_blocked'}), 429

        data = request.get_json()
        
        if not data:
            return jsonify({'error': 'No data provided'}), 400
        
        if not all(k in data for k in ['email', 'password']):
            return jsonify({'error': 'Missing required fields'}), 400
        
        email = data['email'].strip().lower()
        
        # Check failed login attempts
        attempts = get_failed_login_attempts(email)
        if attempts >= 5:  # Lock after 5 failed attempts
            return jsonify({
                'error': 'Account temporarily locked',
                'code': 'account_locked',
                'retry_after': '15 minutes'
            }), 429
        
        user = User.query.filter(User.email.ilike(email)).first()
        
        if not user or not user.check_password(data['password']):
            # Increment failed attempts counter (implement in Redis)
            return jsonify({
                'error': 'Invalid credentials',
                'remaining_attempts': 5 - (attempts + 1)
            }), 401
        
        # Reset failed attempts counter on successful login
        
        # Generate JWT token with all necessary claims
        token_expiry = int(os.getenv('JWT_EXPIRY_DAYS', '1'))
        token = jwt.encode({
            'user_id': user.id,
            'email': user.email,
            'exp': datetime.datetime.now(timezone.utc) + datetime.timedelta(days=token_expiry),
            'iat': datetime.datetime.now(timezone.utc),
            'type': 'access'
        }, os.getenv('JWT_SECRET_KEY'), algorithm='HS256')
        
        return jsonify({
            'token': token,
            'user': user.to_dict()
        }), 200
        
    except Exception as e:
        return jsonify({'error': 'Server error occurred during login'}), 500

@auth_bp.route('/verify-token', methods=['POST'])
def verify_token():
    try:
        token = request.headers.get('Authorization')
        
        if not token or not token.startswith('Bearer '):
            return jsonify({'error': 'Invalid token format', 'code': 'invalid_token_format'}), 401
            
        token = token.split('Bearer ')[1]
        
        try:
            data = jwt.decode(token, os.getenv('JWT_SECRET_KEY'), algorithms=['HS256'])
            user = User.query.get(data['user_id'])
            
            if not user:
                return jsonify({'error': 'User not found', 'code': 'user_not_found'}), 401
                
            return jsonify({
                'valid': True,
                'user': user.to_dict()
            })
            
        except jwt.ExpiredSignatureError:
            return jsonify({'error': 'Token has expired', 'code': 'token_expired'}), 401
        except jwt.InvalidTokenError:
            return jsonify({'error': 'Invalid token', 'code': 'token_invalid'}), 401
            
    except Exception as e:
        return jsonify({'error': 'Server error occurred during token verification', 'code': 'verification_error'}), 500 
```


### FILE: backend\flask-service\src\routes\auth_integration.py
```
from flask import Blueprint, request, jsonify, current_app
from functools import wraps
from ..utils.auth_integration import AuthIntegration
from meeting_shared.middleware.auth import service_auth_required
from meeting_shared.middleware.validation import validate_schema
from meeting_shared.schemas.base import ErrorResponse, SuccessResponse
from meeting_shared.database import transaction_context
import logging

logger = logging.getLogger(__name__)
bp = Blueprint('auth_integration', __name__)

def require_service_key(f):
    @wraps(f)
    def decorated(*args, **kwargs):
        service_key = request.headers.get('X-Service-Key')
        if not service_key or service_key != current_app.config['AUTH_SERVICE_KEY']:
            return jsonify({'error': 'Invalid service key'}), 403
        return f(*args, **kwargs)
    return decorated

@bp.route('/auth/validate-token', methods=['POST'])
@service_auth_required
def validate_token():
    """Validate JWT token"""
    try:
        data = request.get_json()
        token = data.get('token')
        if not token:
            return jsonify(ErrorResponse(
                error="Validation Error",
                message="Token is required"
            ).model_dump()), 400

        auth_integration = AuthIntegration()
        payload = auth_integration.validate_token(token)
        
        if payload:
            return jsonify(SuccessResponse(data=payload).model_dump())
        return jsonify(ErrorResponse(
            error="Authentication Error",
            message="Invalid token"
        ).model_dump()), 401
    except Exception as e:
        logger.error(f"Error validating token: {str(e)}")
        return jsonify(ErrorResponse(
            error="Internal Server Error",
            message="Failed to validate token"
        ).model_dump()), 500

@bp.route('/auth/sync-session', methods=['POST'])
@service_auth_required
def sync_session():
    """Synchronize session data from auth service"""
    try:
        data = request.get_json()
        auth_integration = AuthIntegration()
        
        with transaction_context() as session:
            if auth_integration.sync_user_session(data):
                return jsonify(SuccessResponse(
                    message="Session synchronized successfully"
                ).model_dump())
            
            return jsonify(ErrorResponse(
                error="Sync Error",
                message="Failed to sync session"
            ).model_dump()), 400
            
    except Exception as e:
        logger.error(f"Error syncing session: {str(e)}")
        return jsonify(ErrorResponse(
            error="Internal Server Error",
            message="Failed to process sync request"
        ).model_dump()), 500

@bp.route('/auth/sync-user', methods=['POST'])
@service_auth_required
def sync_user():
    """Synchronize user data from auth service"""
    try:
        data = request.get_json()
        auth_integration = AuthIntegration()
        
        with transaction_context() as session:
            if auth_integration.sync_user_data(data):
                return jsonify(SuccessResponse(
                    message="User data synchronized successfully"
                ).model_dump())
            return jsonify(ErrorResponse(
                error="Sync Error",
                message="Failed to sync user data"
            ).model_dump()), 400
    except Exception as e:
        logger.error(f"Error syncing user data: {str(e)}")
        return jsonify(ErrorResponse(
            error="Internal Server Error",
            message="Failed to sync user data"
        ).model_dump()), 500

@bp.route('/auth/revoke-user-sessions', methods=['POST'])
@service_auth_required
def revoke_sessions():
    """Handle session revocation from auth service"""
    try:
        data = request.get_json()
        user_id = data.get('user_id')
        reason = data.get('reason')
        
        if not user_id:
            return jsonify(ErrorResponse(
                error="Validation Error",
                message="User ID is required"
            ).model_dump()), 400

        auth_integration = AuthIntegration()
        with transaction_context() as session:
            if auth_integration.revoke_user_sessions(user_id, reason):
                return jsonify(SuccessResponse(
                    message="User sessions revoked successfully"
                ).model_dump())
            return jsonify(ErrorResponse(
                error="Revocation Error",
                message="Failed to revoke sessions"
            ).model_dump()), 400
    except Exception as e:
        logger.error(f"Error revoking sessions: {str(e)}")
        return jsonify(ErrorResponse(
            error="Internal Server Error",
            message="Failed to revoke sessions"
        ).model_dump()), 500 
```


### FILE: backend\flask-service\src\routes\health.py
```
from flask import Blueprint, jsonify, current_app
import requests
import time
import os
import sys
from datetime import datetime, timezone
import logging
import platform
from sqlalchemy import text
from sqlalchemy.exc import SQLAlchemyError

# Handle import based on whether we're using the application db or directly importing
try:
    from ..utils.database import db
except ImportError:
    try:
        from meeting_shared.database import db
    except ImportError:
        db = None
        logging.error("Failed to import database module")

logger = logging.getLogger(__name__)
health_bp = Blueprint('health', __name__)

@health_bp.route('/health', methods=['GET'])
def health_check():
    """Basic health check endpoint that provides essential system information"""
    health_info = {
        'status': 'healthy',
        'service': 'backend',
        'timestamp': datetime.now(timezone.utc).isoformat(),
        'environment': os.environ.get('FLASK_ENV', 'unknown'),
        'system_info': {
            'python_version': sys.version,
            'platform': platform.platform(),
            'node': platform.node()
        }
    }
    
    # Basic database check
    try:
        if db is not None:
            db.session.execute(text('SELECT 1'))
        else:
            health_info['status'] = 'degraded'
            health_info['message'] = 'Database module not available'
    except Exception as e:
        health_info['status'] = 'unhealthy'
        health_info['error'] = str(e)
    
    return jsonify(health_info)

@health_bp.route('/health/detailed', methods=['GET'])
def detailed_health_check():
    """Detailed health check that verifies all dependencies"""
    start_time = time.time()
    health_status = {
        'service': 'backend',
        'timestamp': datetime.now(timezone.utc).isoformat(),
        'dependencies': {},
        'status': 'healthy'  # Will be updated if any dependency is unhealthy
    }
    
    # Check database
    try:
        db.session.execute(text('SELECT 1'))
        health_status['dependencies']['database'] = {
            'status': 'healthy',
            'type': 'postgres'
        }
    except Exception as e:
        logger.error(f"Database health check failed: {str(e)}")
        health_status['dependencies']['database'] = {
            'status': 'unhealthy',
            'error': str(e),
            'type': 'postgres'
        }
        health_status['status'] = 'unhealthy'
    
    # Check Redis
    try:
        redis_client = current_app.extensions.get('redis')
        if redis_client:
            redis_client.ping()
            health_status['dependencies']['redis'] = {
                'status': 'healthy'
            }
        else:
            health_status['dependencies']['redis'] = {
                'status': 'unavailable',
                'error': 'Redis client not initialized'
            }
            health_status['status'] = 'degraded'
    except Exception as e:
        logger.error(f"Redis health check failed: {str(e)}")
        health_status['dependencies']['redis'] = {
            'status': 'unhealthy',
            'error': str(e)
        }
        health_status['status'] = 'unhealthy'
    
    # Check auth service
    try:
        auth_service_url = current_app.config.get('AUTH_SERVICE_URL')
        response = requests.get(
            f"{auth_service_url}/health", 
            timeout=5
        )
        if response.status_code == 200:
            health_status['dependencies']['auth_service'] = {
                'status': 'healthy',
                'url': auth_service_url
            }
        else:
            health_status['dependencies']['auth_service'] = {
                'status': 'unhealthy',
                'error': f"Unexpected status code: {response.status_code}",
                'url': auth_service_url
            }
            health_status['status'] = 'unhealthy'
    except requests.RequestException as e:
        logger.error(f"Auth service health check failed: {str(e)}")
        health_status['dependencies']['auth_service'] = {
            'status': 'unhealthy',
            'error': str(e),
            'url': current_app.config.get('AUTH_SERVICE_URL')
        }
        health_status['status'] = 'unhealthy'
    
    # Check token validation
    try:
        # Try a basic token validation with a dummy token (should fail but connection should work)
        auth_service_url = current_app.config.get('AUTH_SERVICE_URL')
        service_key = current_app.config.get('SERVICE_KEY')
        
        response = requests.post(
            f"{auth_service_url}/api/auth/validate-token",
            json={"token": "dummy_test_token"},
            headers={"X-Service-Key": service_key},
            timeout=5
        )
        
        if response.status_code in [401, 400]:  # Expected for invalid token
            health_status['dependencies']['token_validation'] = {
                'status': 'healthy',
                'message': 'Token validation endpoint accessible'
            }
        else:
            health_status['dependencies']['token_validation'] = {
                'status': 'degraded',
                'error': f"Unexpected status code: {response.status_code}",
                'message': 'Token validation endpoint is accessible but not working as expected'
            }
            if health_status['status'] == 'healthy':
                health_status['status'] = 'degraded'
    except requests.RequestException as e:
        logger.error(f"Token validation health check failed: {str(e)}")
        health_status['dependencies']['token_validation'] = {
            'status': 'unhealthy',
            'error': str(e)
        }
        health_status['status'] = 'unhealthy'
    
    # Add response time
    health_status['response_time_ms'] = round((time.time() - start_time) * 1000, 2)
    
    # Return appropriate status code based on health
    status_code = 200
    if health_status['status'] == 'degraded':
        status_code = 200  # Still operational but with issues
    elif health_status['status'] == 'unhealthy':
        status_code = 503  # Service unavailable
        
    return jsonify(health_status), status_code 
```


### FILE: backend\flask-service\src\routes\meetings.py
```
from flask import Blueprint, request, jsonify, current_app
from sqlalchemy.exc import SQLAlchemyError
from datetime import datetime, timezone
import bleach
import json
import time
from meeting_shared.middleware.auth import jwt_required
from meeting_shared.middleware.error_handler import error_handler, APIError
from meeting_shared.middleware.validation import validate_schema
from meeting_shared.schemas.base import ErrorResponse, SuccessResponse
from ..schemas.meeting import MeetingCreate, MeetingResponse, MeetingUpdate
from ..models import db, User, Meeting, MeetingParticipant, MeetingCoHost, MeetingAuditLog
from ..utils.auth_integration import enhanced_token_required

meetings_bp = Blueprint('meetings', __name__)

def get_cache_client():
    """Get Redis client from app extensions"""
    return current_app.extensions.get('redis')

def get_cached_meetings(cache_key):
    """Get meetings from cache if available"""
    redis_client = get_cache_client()
    if not redis_client:
        return None
        
    cached = redis_client.get(cache_key)
    if cached:
        try:
            return json.loads(cached)
        except Exception as e:
            current_app.logger.error(f"Error parsing cached meetings: {e}")
    return None

def cache_meetings(cache_key, meetings, expiry=300):
    """Cache meetings in Redis"""
    redis_client = get_cache_client()
    if not redis_client:
        return
        
    try:
        redis_client.setex(cache_key, expiry, json.dumps(meetings))
    except Exception as e:
        current_app.logger.error(f"Error caching meetings: {e}")

@meetings_bp.route('/create', methods=['POST'])
@enhanced_token_required
@error_handler
def create_meeting(current_user):
    """Create a new meeting."""
    data = request.get_json()
    
    if not data:
        raise APIError('No data provided', 400)
        
    required_fields = ['title', 'description', 'start_time', 'end_time']
    if not all(field in data for field in required_fields):
        raise APIError('Missing required fields', 400, 
                       {'required': required_fields})
        
    # Validate title and description
    title = bleach.clean(data['title'].strip())
    description = bleach.clean(data['description'].strip())
    
    if not title:
        raise APIError('Meeting title cannot be empty', 400)
        
    if len(title) > 200:
        raise APIError('Meeting title too long (max 200 characters)', 400)
        
    if len(description) > 2000:
        raise APIError('Meeting description too long (max 2000 characters)', 400)

    try:
        start_time = datetime.fromisoformat(data['start_time'].replace('Z', '+00:00'))
        end_time = datetime.fromisoformat(data['end_time'].replace('Z', '+00:00'))
        
        if not start_time.tzinfo or not end_time.tzinfo:
            raise APIError('Timezone information is required', 400)
            
    except ValueError:
        raise APIError('Invalid datetime format. Please use ISO format', 400)

    current_time = datetime.now(timezone.utc)
    
    # Enhanced time validations
    if start_time < current_time:
        raise APIError('Meeting cannot start in the past', 400)
        
    if start_time >= end_time:
        raise APIError('Start time must be before end time', 400)
        
    # Validate reasonable time ranges
    duration = end_time - start_time
    if duration.total_seconds() < 300:  # 5 minutes minimum
        raise APIError('Meeting must be at least 5 minutes long', 400)
        
    if duration.total_seconds() > 86400:  # 24 hours maximum
        raise APIError('Meeting cannot be longer than 24 hours', 400)
        
    # Check if start time is too far in the future
    if (start_time - current_time).days > 365:
        raise APIError('Cannot schedule meetings more than 1 year in advance', 400)
        
    # Validate meeting type and settings
    meeting_type = data.get('meeting_type', 'regular')
    if meeting_type not in ['regular', 'recurring', 'private']:
        raise APIError('Invalid meeting type', 400, {'valid_types': ['regular', 'recurring', 'private']})
        
    max_participants = data.get('max_participants')
    if max_participants is not None:
        if not isinstance(max_participants, int) or max_participants <= 0:
            raise APIError('Invalid maximum participants value', 400)
            
    requires_approval = data.get('requires_approval', False)
    is_recorded = data.get('is_recorded', False)
    
    # Handle recurring meeting pattern
    recurring_pattern = None
    if meeting_type == 'recurring':
        recurring_pattern = data.get('recurring_pattern')
        if not recurring_pattern or recurring_pattern not in ['daily', 'weekly', 'monthly', 'custom']:
            raise APIError('Invalid recurring pattern for recurring meeting', 400, 
                           {'valid_patterns': ['daily', 'weekly', 'monthly', 'custom']})
    
    # Check for overlapping meetings for the user
    user_meetings = Meeting.query.filter(
        Meeting.created_by == current_user.id,
        Meeting.ended_at.is_(None),
        Meeting.end_time > start_time,
        Meeting.start_time < end_time
    ).first()
    
    if user_meetings:
        raise APIError('You have another meeting scheduled during this time', 400)
        
    # Check total number of active meetings for user
    active_meetings_count = Meeting.query.filter(
        Meeting.created_by == current_user.id,
        Meeting.ended_at.is_(None)
    ).count()
    
    if active_meetings_count >= 50:
        raise APIError('You have reached the maximum limit of active meetings', 400)
    
    # Create the meeting
    meeting = Meeting(
        title=title,
        description=description,
        start_time=start_time,
        end_time=end_time,
        created_by=current_user.id,
        meeting_type=meeting_type,
        max_participants=max_participants,
        requires_approval=requires_approval,
        is_recorded=is_recorded
    )
    
    if recurring_pattern:
        meeting.recurring_pattern = recurring_pattern
        
    db.session.add(meeting)
    
    # Add co-hosts if specified
    co_host_ids = data.get('co_hosts', [])
    for co_host_id in co_host_ids:
        if co_host_id != current_user.id:
            co_host = MeetingCoHost(meeting_id=meeting.id, user_id=co_host_id)
            db.session.add(co_host)
            
    # Log the creation
    audit_log = MeetingAuditLog(
        meeting_id=meeting.id,
        user_id=current_user.id,
        action='created',
        details={
            'meeting_type': meeting_type,
            'requires_approval': requires_approval,
            'is_recorded': is_recorded,
            'recurring_pattern': recurring_pattern
        }
    )
    db.session.add(audit_log)
    
    # Invalidate cache for this user's meetings
    redis_client = get_cache_client()
    if redis_client:
        cache_key = f"meetings:user:{current_user.id}"
        redis_client.delete(cache_key)
    
    db.session.commit()
    
    response = MeetingResponse.from_orm(meeting)
    return jsonify(response.model_dump()), 201

@meetings_bp.route('/join/<int:id>', methods=['GET'])
@enhanced_token_required
def join_meeting(current_user, id):
    try:
        if id <= 0:
            return jsonify({'error': 'Invalid meeting ID'}), 400
            
        meeting = Meeting.query.get(id)
        
        if not meeting:
            return jsonify({'error': 'Meeting not found'}), 404
            
        # Check if meeting has ended
        if meeting.ended_at:
            return jsonify({'error': 'Meeting has already ended'}), 400

        # Check if meeting hasn't started yet
        current_time = datetime.now(timezone.utc)
        if current_time < meeting.start_time:
            time_until_start = (meeting.start_time - current_time).total_seconds()
            if time_until_start > 300:  # More than 5 minutes before start
                return jsonify({
                    'error': 'Meeting has not started yet',
                    'starts_in_minutes': round(time_until_start / 60)
                }), 400

        # Check if meeting has exceeded its end time
        if current_time > meeting.end_time:
            return jsonify({'error': 'Meeting has exceeded its scheduled end time'}), 400

        # Check maximum participants limit
        current_participants = MeetingParticipant.query.filter_by(
            meeting_id=meeting.id,
            left_at=None
        ).count()
        if meeting.max_participants and current_participants >= meeting.max_participants:
            return jsonify({'error': 'Meeting has reached maximum participants'}), 400

        # Check if user is banned
        participant = MeetingParticipant.query.filter_by(
            meeting_id=meeting.id,
            user_id=current_user.id
        ).first()
        
        if participant and participant.is_banned:
            return jsonify({'error': 'You have been banned from this meeting'}), 403

        # Check concurrent meetings
        active_participation = MeetingParticipant.query.join(Meeting).filter(
            MeetingParticipant.user_id == current_user.id,
            Meeting.ended_at.is_(None),
            Meeting.id != meeting.id,
            MeetingParticipant.left_at.is_(None)
        ).first()
        
        if active_participation:
            return jsonify({'error': 'You are already in another active meeting'}), 400

        # Determine participant role
        participant_role = 'attendee'
        if meeting.created_by == current_user.id:
            participant_role = 'host'
        elif MeetingCoHost.query.filter_by(meeting_id=meeting.id, user_id=current_user.id).first():
            participant_role = 'co-host'

        # Handle participant joining
        if meeting.created_by != current_user.id:
            if not participant:
                participant = MeetingParticipant(
                    meeting_id=meeting.id,
                    user_id=current_user.id,
                    status='pending' if meeting.requires_approval else 'approved',
                    role=participant_role,
                    joined_at=current_time if not meeting.requires_approval else None
                )
                db.session.add(participant)
            else:
                # Update rejoin time if they previously left
                participant.joined_at = current_time if not meeting.requires_approval else None
                participant.left_at = None
                participant.role = participant_role
                
            db.session.commit()

            # If waiting room is enabled
            if meeting.requires_approval and participant.status == 'pending':
                return jsonify({
                    'message': 'Waiting for host approval',
                    'status': 'waiting'
                }), 202

        # Log the join attempt
        audit_log = MeetingAuditLog(
            meeting_id=meeting.id,
            user_id=current_user.id,
            action='joined',
            details={
                'role': participant_role,
                'status': participant.status if participant else 'host'
            }
        )
        db.session.add(audit_log)
        db.session.commit()

        # Return meeting details with participant info
        meeting_dict = meeting.to_dict()
        meeting_dict.update({
            'is_creator': meeting.created_by == current_user.id,
            'is_co_host': participant_role == 'co-host',
            'role': participant_role,
            'participant_count': current_participants,
            'time_remaining_minutes': round((meeting.end_time - current_time).total_seconds() / 60)
        })
        return jsonify(meeting_dict), 200
        
    except Exception as e:
        db.session.rollback()
        return jsonify({'error': 'Server error occurred while joining meeting'}), 500

@meetings_bp.route('/list', methods=['GET'])
@enhanced_token_required
@error_handler
def list_meetings(current_user):
    """Get list of meetings for the current user with caching."""
    # Get query parameters for filtering
    active_only = request.args.get('active_only', type=lambda v: v.lower() == 'true', default=True)
    force_refresh = request.args.get('refresh', type=lambda v: v.lower() == 'true', default=False)
    
    # Generate cache key based on user and filters
    cache_key = f"meetings:user:{current_user.id}:active:{active_only}"
    
    # Try to get from cache if not forcing refresh
    if not force_refresh:
        cached_meetings = get_cached_meetings(cache_key)
        if cached_meetings is not None:
            return jsonify(cached_meetings)
    
    # Track performance
    start_time = time.time()
    
    # First, get meetings where user is creator
    creator_meetings = Meeting.query.filter(Meeting.created_by == current_user.id)
    if active_only:
        creator_meetings = creator_meetings.filter(Meeting.ended_at.is_(None))
    creator_meetings = creator_meetings.all()

    # Then, get meetings where user is participant
    participant_meetings = Meeting.query.join(MeetingParticipant).filter(
        MeetingParticipant.user_id == current_user.id
    )
    if active_only:
        participant_meetings = participant_meetings.filter(Meeting.ended_at.is_(None))
    participant_meetings = participant_meetings.all()

    # Combine and sort meetings
    all_meetings = sorted(
        set(creator_meetings + participant_meetings),
        key=lambda m: m.start_time,
        reverse=True
    )
    
    # Convert to response format
    response_meetings = [MeetingResponse.from_orm(meeting).model_dump() for meeting in all_meetings]
    
    # Calculate query time for optimization metrics
    query_time = time.time() - start_time
    
    # Cache the results (only if query is slow enough to warrant caching)
    if query_time > 0.1:  # Only cache if query takes more than 100ms
        cache_meetings(cache_key, response_meetings)
    
    # Log performance metrics
    current_app.logger.debug(f"Meeting list query took {query_time:.3f}s for user {current_user.id}")
    
    return jsonify(response_meetings)

@meetings_bp.route('/<int:id>', methods=['GET'])
@enhanced_token_required
@error_handler
def get_meeting(current_user, id):
    """Get a specific meeting by ID."""
    meeting = Meeting.query.get(id)
    
    if not meeting:
        raise APIError('Meeting not found', 404)
        
    # Check if user has access to the meeting
    if meeting.created_by != current_user.id and current_user.id not in [p.user_id for p in meeting.participants]:
        raise APIError('Access denied', 403)
        
    response = MeetingResponse.from_orm(meeting)
    return jsonify(response.model_dump())

@meetings_bp.route('/<int:id>', methods=['DELETE'])
@enhanced_token_required
@error_handler
def delete_meeting(current_user, id):
    """Delete/cancel a meeting."""
    meeting = Meeting.query.get(id)
    
    if not meeting:
        raise APIError('Meeting not found', 404)
        
    # Only the creator can delete a meeting
    if meeting.created_by != current_user.id:
        raise APIError('You do not have permission to delete this meeting', 403)
        
    # If meeting has started, mark as ended instead of deleting
    current_time = datetime.now(timezone.utc)
    if meeting.start_time <= current_time:
        meeting.ended_at = current_time
        
        # Log early termination
        audit_log = MeetingAuditLog(
            meeting_id=meeting.id,
            user_id=current_user.id,
            action='ended_early',
            details={"ended_at": current_time.isoformat()}
        )
    else:
        # Log cancellation
        audit_log = MeetingAuditLog(
            meeting_id=meeting.id,
            user_id=current_user.id,
            action='cancelled',
            details={"cancelled_at": current_time.isoformat()}
        )
        
        # Mark as cancelled
        meeting.is_cancelled = True
        meeting.cancelled_at = current_time
        
    db.session.add(audit_log)
    
    # Invalidate cache for this user's meetings and other participants
    redis_client = get_cache_client()
    if redis_client:
        # Invalidate creator's cache
        redis_client.delete(f"meetings:user:{meeting.created_by}")
        redis_client.delete(f"meetings:user:{meeting.created_by}:active:true")
        redis_client.delete(f"meetings:user:{meeting.created_by}:active:false")
        
        # Invalidate participant caches
        for participant in meeting.participants:
            redis_client.delete(f"meetings:user:{participant.user_id}")
            redis_client.delete(f"meetings:user:{participant.user_id}:active:true")
            redis_client.delete(f"meetings:user:{participant.user_id}:active:false")
    
    db.session.commit()
    
    return jsonify(SuccessResponse(
        message="Meeting cancelled successfully" if meeting.is_cancelled else "Meeting ended successfully"
    ).model_dump())

@meetings_bp.route('/stats', methods=['GET'])
@enhanced_token_required
@error_handler
def get_meeting_stats(current_user):
    """Get meeting statistics for the current user."""
    # Try to get from cache first
    cache_key = f"meeting_stats:user:{current_user.id}"
    cached_stats = get_cached_meetings(cache_key)
    if cached_stats is not None:
        return jsonify(cached_stats)
        
    # Calculate stats
    current_time = datetime.now(timezone.utc)
    
    # Active meetings where user is creator
    active_hosted = Meeting.query.filter(
        Meeting.created_by == current_user.id,
        Meeting.ended_at.is_(None),
        Meeting.is_cancelled == False
    ).count()
    
    # Upcoming meetings where user is creator
    upcoming_hosted = Meeting.query.filter(
        Meeting.created_by == current_user.id,
        Meeting.start_time > current_time,
        Meeting.is_cancelled == False
    ).count()
    
    # Active meetings where user is participant
    active_participating = db.session.query(Meeting).join(MeetingParticipant).filter(
        MeetingParticipant.user_id == current_user.id,
        Meeting.ended_at.is_(None),
        Meeting.is_cancelled == False
    ).count()
    
    # Upcoming meetings where user is participant
    upcoming_participating = db.session.query(Meeting).join(MeetingParticipant).filter(
        MeetingParticipant.user_id == current_user.id,
        Meeting.start_time > current_time,
        Meeting.is_cancelled == False
    ).count()
    
    # All past meetings as host
    past_hosted = Meeting.query.filter(
        Meeting.created_by == current_user.id,
        Meeting.ended_at.isnot(None)
    ).count()
    
    # All past meetings as participant
    past_participating = db.session.query(Meeting).join(MeetingParticipant).filter(
        MeetingParticipant.user_id == current_user.id,
        Meeting.ended_at.isnot(None)
    ).count()
    
    # Calculate total meeting hours
    total_hours_query = db.session.query(
        db.func.sum(db.func.extract('epoch', Meeting.end_time - Meeting.start_time) / 3600)
    ).filter(
        Meeting.created_by == current_user.id,
        Meeting.ended_at.isnot(None)
    ).scalar()
    
    total_meeting_hours = round(float(total_hours_query or 0), 1)
    
    stats = {
        "active_hosted": active_hosted,
        "upcoming_hosted": upcoming_hosted,
        "active_participating": active_participating,
        "upcoming_participating": upcoming_participating,
        "past_hosted": past_hosted,
        "past_participating": past_participating,
        "total_meeting_hours": total_meeting_hours,
        "total_meetings": past_hosted + active_hosted
    }
    
    # Cache for 10 minutes
    cache_meetings(cache_key, stats, 600)
    
    return jsonify(stats) 
```


### FILE: backend\flask-service\src\schemas\audit_log.py
```
from datetime import datetime
from typing import Optional, Any, Literal
from pydantic import BaseModel, Field
from .base import BaseSchema

class AuditLogBase(BaseSchema):
    meeting_id: int
    user_id: Optional[int] = None
    action: Literal[
        'meeting_created',
        'meeting_updated',
        'meeting_started',
        'meeting_ended',
        'participant_joined',
        'participant_left',
        'participant_approved',
        'participant_declined',
        'participant_banned',
        'co_host_added',
        'co_host_removed',
        'recording_started',
        'recording_stopped',
        'chat_disabled',
        'chat_enabled',
        'screen_share_started',
        'screen_share_stopped'
    ]
    details: Optional[dict[str, Any]] = None
    ip_address: Optional[str] = Field(None, max_length=45)

class AuditLogCreate(BaseModel):
    meeting_id: int
    user_id: Optional[int] = None
    action: Literal[
        'meeting_created',
        'meeting_updated',
        'meeting_started',
        'meeting_ended',
        'participant_joined',
        'participant_left',
        'participant_approved',
        'participant_declined',
        'participant_banned',
        'co_host_added',
        'co_host_removed',
        'recording_started',
        'recording_stopped',
        'chat_disabled',
        'chat_enabled',
        'screen_share_started',
        'screen_share_stopped'
    ]
    details: Optional[dict[str, Any]] = None
    ip_address: Optional[str] = Field(None, max_length=45)

class AuditLogResponse(AuditLogBase):
    user_name: Optional[str] = None
    meeting_title: Optional[str] = None 
```


### FILE: backend\flask-service\src\schemas\base.py
```
"""
This module re-exports the shared schema base classes to maintain
backward compatibility with code that imports from here.
"""

from meeting_shared.schemas.base import ErrorResponse
from pydantic import BaseModel as SharedBaseSchema
from typing import Optional, Dict, Any

# Define a SuccessResponse class for backward compatibility
class SuccessResponse(dict):
    """Standard success response model."""
    def __init__(self, data=None, message=None):
        super().__init__(
            success=True,
            data=data or {},
            message=message or "Operation completed successfully"
        )

# For backward compatibility, provide a marshmallow-based BaseSchema
from marshmallow import Schema, fields, EXCLUDE

class BaseSchema(Schema):
    """Base schema class with common configuration."""
    
    class Meta:
        unknown = EXCLUDE
        ordered = True

    id = fields.Integer(dump_only=True)
    created_at = fields.DateTime(dump_only=True)
    updated_at = fields.DateTime(dump_only=True)

    def __init__(self, *args, **kwargs):
        """Initialize schema with strict validation by default."""
        kwargs['strict'] = kwargs.get('strict', True)
        super().__init__(*args, **kwargs) 
```


### FILE: backend\flask-service\src\schemas\co_host.py
```
from datetime import datetime
from typing import Optional, List
from pydantic import BaseModel
from .base import BaseSchema

class CoHostBase(BaseSchema):
    meeting_id: int
    user_id: int
    can_manage_participants: bool = True
    can_edit_meeting: bool = False
    can_end_meeting: bool = False

class CoHostCreate(BaseModel):
    meeting_id: int
    user_id: int
    can_manage_participants: bool = True
    can_edit_meeting: bool = False
    can_end_meeting: bool = False

class CoHostUpdate(BaseModel):
    can_manage_participants: Optional[bool] = None
    can_edit_meeting: Optional[bool] = None
    can_end_meeting: Optional[bool] = None

class CoHostResponse(CoHostBase):
    user_name: Optional[str] = None
    user_email: Optional[str] = None

class CoHostBulkCreate(BaseModel):
    meeting_id: int
    co_hosts: List[int]  # List of user IDs
    can_manage_participants: bool = True
    can_edit_meeting: bool = False
    can_end_meeting: bool = False 
```


### FILE: backend\flask-service\src\schemas\meeting.py
```
from datetime import datetime
from typing import Optional, List, Literal
from pydantic import BaseModel, Field, validator
from .base import BaseSchema

class MeetingBase(BaseSchema):
    title: str = Field(..., min_length=1, max_length=200)
    description: Optional[str] = None
    start_time: datetime
    end_time: datetime
    meeting_type: Literal['regular', 'recurring', 'private'] = 'regular'
    max_participants: Optional[int] = Field(None, gt=0)
    requires_approval: bool = False
    is_recorded: bool = False
    recording_url: Optional[str] = None
    recurring_pattern: Optional[Literal['daily', 'weekly', 'monthly', 'custom']] = None
    parent_meeting_id: Optional[int] = None
    ended_at: Optional[datetime] = None

    @validator('end_time')
    def end_time_must_be_after_start_time(cls, v, values):
        if 'start_time' in values and v <= values['start_time']:
            raise ValueError('end_time must be after start_time')
        return v

class MeetingCreate(BaseModel):
    title: str = Field(..., min_length=1, max_length=200)
    description: Optional[str] = None
    start_time: datetime
    end_time: datetime
    meeting_type: Literal['regular', 'recurring', 'private'] = 'regular'
    max_participants: Optional[int] = Field(None, gt=0)
    requires_approval: bool = False
    is_recorded: bool = False
    recurring_pattern: Optional[Literal['daily', 'weekly', 'monthly', 'custom']] = None
    parent_meeting_id: Optional[int] = None

    @validator('end_time')
    def end_time_must_be_after_start_time(cls, v, values):
        if 'start_time' in values and v <= values['start_time']:
            raise ValueError('end_time must be after start_time')
        return v

class MeetingUpdate(BaseModel):
    title: Optional[str] = Field(None, min_length=1, max_length=200)
    description: Optional[str] = None
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    max_participants: Optional[int] = Field(None, gt=0)
    requires_approval: Optional[bool] = None
    is_recorded: Optional[bool] = None
    recording_url: Optional[str] = None

    @validator('end_time')
    def end_time_must_be_after_start_time(cls, v, values):
        if v and 'start_time' in values and values['start_time'] and v <= values['start_time']:
            raise ValueError('end_time must be after start_time')
        return v

class MeetingResponse(MeetingBase):
    id: int
    created_by: int
    participant_count: Optional[int] = None
    co_hosts: Optional[List[int]] = None 
```


### FILE: backend\flask-service\src\schemas\participant.py
```
from datetime import datetime
from typing import Optional, Literal
from pydantic import BaseModel, Field, validator, confloat
from .base import BaseSchema

class ParticipantBase(BaseSchema):
    meeting_id: int
    user_id: int
    status: Literal['pending', 'approved', 'declined', 'banned'] = 'pending'
    role: Literal['attendee', 'presenter', 'moderator'] = 'attendee'
    joined_at: Optional[datetime] = None
    left_at: Optional[datetime] = None
    is_banned: bool = False
    total_time: Optional[int] = Field(None, ge=0)  # in seconds
    connection_quality: Optional[confloat(ge=0, le=1)] = None
    participation_score: Optional[confloat(ge=0, le=1)] = None
    feedback: Optional[str] = None

class ParticipantCreate(BaseModel):
    meeting_id: int
    user_id: int
    status: Literal['pending', 'approved', 'declined', 'banned'] = 'pending'
    role: Literal['attendee', 'presenter', 'moderator'] = 'attendee'

class ParticipantUpdate(BaseModel):
    status: Optional[Literal['pending', 'approved', 'declined', 'banned']] = None
    role: Optional[Literal['attendee', 'presenter', 'moderator']] = None
    is_banned: Optional[bool] = None
    feedback: Optional[str] = None

class ParticipantJoin(BaseModel):
    meeting_id: int
    user_id: int
    connection_quality: Optional[confloat(ge=0, le=1)] = None

    @validator('connection_quality')
    def validate_connection_quality(cls, v):
        if v is not None and (v < 0 or v > 1):
            raise ValueError('Connection quality must be between 0 and 1')
        return v

class ParticipantLeave(BaseModel):
    meeting_id: int
    user_id: int
    total_time: int = Field(..., ge=0)
    participation_score: confloat(ge=0, le=1)
    feedback: Optional[str] = None

class ParticipantResponse(ParticipantBase):
    user_name: Optional[str] = None
    user_email: Optional[str] = None 
```


### FILE: backend\flask-service\src\services\__init__.py
```
"""
Service initialization for the Flask backend.
"""

import logging

logger = logging.getLogger(__name__)

def init_services(app):
    """Initialize all services for the Flask application.
    
    Args:
        app: The Flask application instance
    """
    logger.info("Initializing services")
    
    # You can initialize your services here
    
    logger.info("Services initialized successfully") 
```


### FILE: backend\flask-service\src\tasks\__init__.py
```
"""
Background tasks for the application.
This package contains modules for scheduled tasks like:
- Data cleanup
- System metrics collection
- Cache maintenance
""" 
```


### FILE: backend\flask-service\src\tasks\cleanup.py
```
import logging
from datetime import datetime, timedelta, timezone
from flask import current_app
from sqlalchemy import text
from ..database import db
from ..models.meeting import Meeting
from ..models.meeting_audit_log import MeetingAuditLog

logger = logging.getLogger(__name__)

def cleanup_expired_meetings():
    """
    Cleanup meetings that have ended but not marked as ended.
    Also cleans up stale meeting resources.
    """
    try:
        logger.info("Starting cleanup of expired meetings")
        start_time = datetime.now(timezone.utc)
        
        with current_app.app_context():
            # Find meetings that have passed their end time but not marked as ended
            current_time = datetime.now(timezone.utc)
            cutoff_time = current_time - timedelta(minutes=30)  # Give 30 minute grace period
            
            # Find meetings to mark as ended
            expired_meetings = Meeting.query.filter(
                Meeting.end_time < cutoff_time,
                Meeting.ended_at.is_(None),
                Meeting.is_cancelled == False
            ).all()
            
            if expired_meetings:
                logger.info(f"Found {len(expired_meetings)} expired meetings to cleanup")
                
                for meeting in expired_meetings:
                    meeting.ended_at = meeting.end_time  # Use the scheduled end time
                    
                    # Log the auto-end
                    audit_log = MeetingAuditLog(
                        meeting_id=meeting.id,
                        user_id=meeting.created_by,
                        action='auto_ended',
                        details={
                            'reason': 'Meeting ended automatically after scheduled end time',
                            'ended_at': meeting.end_time.isoformat(),
                            'cleanup_time': current_time.isoformat()
                        }
                    )
                    db.session.add(audit_log)
                
                db.session.commit()
                logger.info(f"Successfully marked {len(expired_meetings)} meetings as ended")
                
                # Invalidate caches for affected users
                redis_client = current_app.extensions.get('redis')
                if redis_client:
                    for meeting in expired_meetings:
                        redis_client.delete(f"meetings:user:{meeting.created_by}")
                        redis_client.delete(f"meetings:user:{meeting.created_by}:active:true")
                        redis_client.delete(f"meetings:user:{meeting.created_by}:active:false")
            else:
                logger.info("No expired meetings to cleanup")
            
            # Archive old meetings (older than 6 months)
            archive_cutoff = current_time - timedelta(days=180)
            meetings_to_archive = Meeting.query.filter(
                Meeting.ended_at < archive_cutoff,
                Meeting.is_archived == False
            ).all()
            
            if meetings_to_archive:
                logger.info(f"Found {len(meetings_to_archive)} old meetings to archive")
                
                for meeting in meetings_to_archive:
                    meeting.is_archived = True
                    meeting.archived_at = current_time
                    
                    # Log the archiving
                    audit_log = MeetingAuditLog(
                        meeting_id=meeting.id,
                        user_id=meeting.created_by,
                        action='archived',
                        details={
                            'reason': 'Meeting archived automatically after 6 months',
                            'archived_at': current_time.isoformat()
                        }
                    )
                    db.session.add(audit_log)
                
                db.session.commit()
                logger.info(f"Successfully archived {len(meetings_to_archive)} meetings")
            else:
                logger.info("No old meetings to archive")
            
            # Calculate duration for monitoring
            duration = (datetime.now(timezone.utc) - start_time).total_seconds()
            logger.info(f"Meeting cleanup completed in {duration:.2f} seconds")
            
            # Store metrics in Redis
            try:
                redis_client = current_app.extensions.get('redis')
                if redis_client:
                    metrics = {
                        'expired_meetings': len(expired_meetings),
                        'archived_meetings': len(meetings_to_archive),
                        'duration_seconds': duration,
                        'timestamp': current_time.isoformat()
                    }
                    redis_client.hmset('metrics:last_meeting_cleanup', metrics)
                    redis_client.expire('metrics:last_meeting_cleanup', 86400)  # 24 hours
            except Exception as e:
                logger.error(f"Failed to store cleanup metrics: {str(e)}")
                
            return {
                'expired_meetings': len(expired_meetings),
                'archived_meetings': len(meetings_to_archive),
                'duration_seconds': duration
            }
    
    except Exception as e:
        logger.error(f"Error during meeting cleanup: {str(e)}")
        if 'db' in locals() and db.session:
            db.session.rollback()
        return {'error': str(e)} 
```


### FILE: backend\flask-service\src\tasks\metrics.py
```
import logging
import json
import os
import platform
import time
from datetime import datetime, timezone
from sqlalchemy import text
from flask import current_app
from ..database import db
from ..models.meeting import Meeting

logger = logging.getLogger(__name__)

def update_system_metrics():
    """
    Collect and store system metrics for monitoring
    """
    try:
        logger.info("Starting metrics collection")
        start_time = time.time()
        
        with current_app.app_context():
            metrics = {}
            
            # DB metrics
            db_metrics = collect_database_metrics()
            if db_metrics:
                metrics.update(db_metrics)
            
            # Application metrics
            app_metrics = collect_application_metrics()
            if app_metrics:
                metrics.update(app_metrics)
            
            # System metrics
            sys_metrics = collect_system_metrics()
            if sys_metrics:
                metrics.update(sys_metrics)
            
            # Store metrics in Redis
            redis_client = current_app.extensions.get('redis')
            if redis_client:
                # Add timestamp
                metrics['timestamp'] = datetime.now(timezone.utc).isoformat()
                metrics['collection_duration_ms'] = int((time.time() - start_time) * 1000)
                
                # Store latest metrics
                for key, value in metrics.items():
                    redis_client.hset('metrics:system:latest', key, _serialize_value(value))
                
                # Set expiry for latest metrics
                redis_client.expire('metrics:system:latest', 86400)  # 24 hours
                
                # Store historical data points for time-series metrics
                store_time_series_metrics(redis_client, metrics)
                
                logger.info(f"Metrics collection completed in {(time.time() - start_time):.2f} seconds")
                return metrics
            else:
                logger.warning("Redis client not available, metrics not stored")
                return metrics
    
    except Exception as e:
        logger.error(f"Error during metrics collection: {str(e)}")
        return {'error': str(e)}

def _serialize_value(value):
    """Serialize value for Redis storage"""
    if isinstance(value, (dict, list)):
        return json.dumps(value)
    return str(value)

def collect_database_metrics():
    """Collect database metrics"""
    try:
        metrics = {}
        
        # Count active meetings
        active_meetings = Meeting.query.filter(
            Meeting.ended_at.is_(None),
            Meeting.is_cancelled == False
        ).count()
        metrics['active_meetings'] = active_meetings
        
        # Count total meetings
        total_meetings = Meeting.query.count()
        metrics['total_meetings'] = total_meetings
        
        # Count today's meetings
        today = datetime.now(timezone.utc).replace(hour=0, minute=0, second=0, microsecond=0)
        todays_meetings = Meeting.query.filter(
            Meeting.start_time >= today
        ).count()
        metrics['todays_meetings'] = todays_meetings
        
        # Get database size (PostgreSQL)
        try:
            db_name = current_app.config.get('SQLALCHEMY_DATABASE_URI').split('/')[-1]
            query = text("""
                SELECT pg_database_size(:db_name) as db_size
            """)
            result = db.session.execute(query, {'db_name': db_name}).first()
            if result:
                metrics['database_size_bytes'] = result.db_size
        except Exception as e:
            logger.warning(f"Could not get database size: {e}")
        
        # Get table statistics
        try:
            query = text("""
                SELECT 
                    relname as table_name,
                    n_live_tup as row_count
                FROM 
                    pg_stat_user_tables
                ORDER BY 
                    n_live_tup DESC
            """)
            results = db.session.execute(query).fetchall()
            table_stats = {r.table_name: r.row_count for r in results}
            metrics['table_row_counts'] = table_stats
        except Exception as e:
            logger.warning(f"Could not get table statistics: {e}")
        
        return metrics
    except Exception as e:
        logger.error(f"Error collecting database metrics: {e}")
        return {}

def collect_application_metrics():
    """Collect application metrics"""
    try:
        metrics = {}
        
        # Application version/build info
        metrics['app_version'] = os.environ.get('APP_VERSION', 'unknown')
        metrics['flask_env'] = current_app.config.get('FLASK_ENV', 'unknown')
        
        # Cache hit ratio if available
        redis_client = current_app.extensions.get('redis')
        if redis_client:
            try:
                # Get cache statistics from Redis INFO
                info = redis_client.info()
                metrics['redis_hit_ratio'] = (info['keyspace_hits'] / (info['keyspace_hits'] + info['keyspace_misses'] + 0.001)) * 100
                metrics['redis_used_memory'] = info['used_memory']
                metrics['redis_connected_clients'] = info['connected_clients']
            except Exception as e:
                logger.warning(f"Could not get Redis stats: {e}")
        
        return metrics
    except Exception as e:
        logger.error(f"Error collecting application metrics: {e}")
        return {}

def collect_system_metrics():
    """Collect system metrics"""
    try:
        metrics = {}
        
        # System information
        metrics['python_version'] = platform.python_version()
        metrics['os_name'] = platform.system()
        metrics['os_version'] = platform.version()
        
        # Process information
        metrics['process_id'] = os.getpid()
        
        # Memory usage
        try:
            import psutil
            process = psutil.Process(os.getpid())
            
            # Memory usage for this process
            memory_info = process.memory_info()
            metrics['process_memory_rss'] = memory_info.rss
            metrics['process_memory_vms'] = memory_info.vms
            
            # CPU usage
            metrics['process_cpu_percent'] = process.cpu_percent(interval=0.1)
            metrics['system_cpu_percent'] = psutil.cpu_percent(interval=0.1)
            
            # System memory
            system_memory = psutil.virtual_memory()
            metrics['system_memory_available'] = system_memory.available
            metrics['system_memory_total'] = system_memory.total
            metrics['system_memory_percent'] = system_memory.percent
            
            # Disk usage
            disk_usage = psutil.disk_usage('/')
            metrics['disk_usage_percent'] = disk_usage.percent
            metrics['disk_free'] = disk_usage.free
        except ImportError:
            logger.warning("psutil not available, skipping detailed system metrics")
        
        return metrics
    except Exception as e:
        logger.error(f"Error collecting system metrics: {e}")
        return {}

def store_time_series_metrics(redis_client, metrics):
    """Store time-series metrics for historical analysis"""
    try:
        timestamp = int(time.time())
        
        # Define which metrics to track historically
        time_series_metrics = [
            'active_meetings',
            'process_memory_rss',
            'system_cpu_percent',
            'system_memory_percent',
            'redis_hit_ratio'
        ]
        
        # For each metric, store a data point
        for metric_name in time_series_metrics:
            if metric_name in metrics:
                # Store as a sorted set with timestamp as score
                # This allows efficient time range queries
                redis_client.zadd(
                    f'metrics:timeseries:{metric_name}',
                    {f"{timestamp}:{metrics[metric_name]}": timestamp}
                )
                
                # Trim to last 1000 points to avoid unlimited growth
                redis_client.zremrangebyrank(
                    f'metrics:timeseries:{metric_name}',
                    0, -1001
                )
    except Exception as e:
        logger.error(f"Error storing time-series metrics: {e}") 
```


### FILE: backend\flask-service\src\utils\auth_integration.py
```
from typing import Optional, Dict, Any, Tuple
from flask import current_app, request, g
from meeting_shared.database import db, transaction_context
from meeting_shared.middleware.auth import jwt_required
from meeting_shared.schemas.base import ErrorResponse
from ..models.user import User
import jwt
import logging
import requests
import json
from datetime import datetime, timedelta
from functools import wraps

logger = logging.getLogger(__name__)

class AuthIntegration:
    def __init__(self):
        self.jwt_secret = current_app.config['JWT_SECRET_KEY']
        self.algorithm = 'HS256'
        self.auth_service_url = current_app.config.get('AUTH_SERVICE_URL', 'http://auth-service:5001')
        self.service_key = current_app.config.get('SERVICE_KEY')
        self.token_cache = {}  # Simple in-memory cache for token validation results
        self.token_cache_expiry = {}  # Expiry times for cache entries
        self.cache_ttl = 300  # 5 minutes cache TTL

    def validate_token(self, token: str) -> Optional[Dict[str, Any]]:
        """Validate JWT token and return payload if valid"""
        try:
            # Check cache first to avoid repeated decoding
            if token in self.token_cache:
                # Check if cache entry is still valid
                if datetime.now().timestamp() < self.token_cache_expiry.get(token, 0):
                    return self.token_cache[token]
                else:
                    # Remove expired entry
                    self.token_cache.pop(token, None)
                    self.token_cache_expiry.pop(token, None)
            
            # First try local validation
            try:
                payload = jwt.decode(token, self.jwt_secret, algorithms=[self.algorithm])
                
                # Check if the user exists in our database
                user = User.query.get(payload.get('user_id'))
                if not user:
                    logger.warning(f"User {payload.get('user_id')} not found in database during token validation")
                    return self._verify_with_auth_service(token)
                
                # Cache the successful result
                self.token_cache[token] = payload
                self.token_cache_expiry[token] = datetime.now().timestamp() + self.cache_ttl
                return payload
            except jwt.InvalidTokenError as e:
                # If local validation fails, verify with auth service
                logger.info(f"Local token validation failed: {str(e)}, trying auth service")
                return self._verify_with_auth_service(token)
        except Exception as e:
            logger.error(f"Token validation error: {str(e)}")
            return None

    def _verify_with_auth_service(self, token: str) -> Optional[Dict[str, Any]]:
        """Verify token with auth service"""
        try:
            headers = {'X-Service-Key': self.service_key}
            response = requests.post(
                f"{self.auth_service_url}/api/auth/validate-token",
                json={"token": token},
                headers=headers,
                timeout=5
            )
            
            if response.status_code == 200:
                payload = response.json().get('data', {})
                
                # Cache the successful result
                self.token_cache[token] = payload
                self.token_cache_expiry[token] = datetime.now().timestamp() + self.cache_ttl
                return payload
            else:
                logger.warning(f"Auth service rejected token: {response.status_code}, {response.text}")
                return None
        except requests.RequestException as e:
            logger.error(f"Error connecting to auth service: {str(e)}")
            # Fall back to local validation as a last resort
            try:
                return jwt.decode(token, self.jwt_secret, algorithms=[self.algorithm])
            except:
                return None

    def get_user_from_token(self, token: str) -> Tuple[Optional[User], Optional[str]]:
        """
        Get user from token and handle error messages
        Returns (user, error_message)
        """
        try:
            payload = self.validate_token(token)
            if not payload:
                return None, "Invalid or expired token"
            
            user_id = payload.get('user_id')
            if not user_id:
                return None, "Token missing user ID"
            
            user = User.query.get(user_id)
            if not user:
                return None, "User not found"
            
            if not user.is_active:
                return None, "Account is inactive"
            
            return user, None
        except Exception as e:
            logger.error(f"Error getting user from token: {str(e)}")
            return None, f"Authentication error: {str(e)}"

    def sync_user_session(self, data: Dict[str, Any]) -> bool:
        """
        Synchronize user session data from auth service
        """
        try:
            with transaction_context() as session:
                user_id = data.get('user_id')
                if not user_id:
                    return True  # Skip for cleanup notifications
                
                user = User.query.get(user_id)
                if not user:
                    logger.warning(f"User {user_id} not found during session sync")
                    return False

                # Update user's session state
                session_data = data.get('session_data', {})
                user.last_login_at = datetime.fromisoformat(session_data.get('expires_at')) if session_data.get('expires_at') else None
                user.is_active = session_data.get('is_active', True)
                
                # Clear any cached tokens for this user
                self._clear_user_token_cache(user_id)
                
                return True
                
        except Exception as e:
            logger.error(f"Error syncing user session: {str(e)}")
            return False
            
    def _clear_user_token_cache(self, user_id: int) -> None:
        """Clear cached tokens for a specific user"""
        try:
            # Find all tokens in cache that belong to this user
            tokens_to_remove = []
            for token, payload in self.token_cache.items():
                if payload.get('user_id') == user_id:
                    tokens_to_remove.append(token)
            
            # Remove tokens from cache
            for token in tokens_to_remove:
                self.token_cache.pop(token, None)
                self.token_cache_expiry.pop(token, None)
                
            logger.debug(f"Cleared {len(tokens_to_remove)} cached tokens for user {user_id}")
        except Exception as e:
            logger.error(f"Error clearing user token cache: {str(e)}")
            
    def cleanup_token_cache(self) -> int:
        """
        Clean up expired token cache entries
        Returns number of entries removed
        """
        try:
            now = datetime.now().timestamp()
            tokens_to_remove = [
                token for token, expiry in self.token_cache_expiry.items()
                if expiry < now
            ]
            
            for token in tokens_to_remove:
                self.token_cache.pop(token, None)
                self.token_cache_expiry.pop(token, None)
                
            return len(tokens_to_remove)
        except Exception as e:
            logger.error(f"Error cleaning up token cache: {str(e)}")
            return 0

def enhanced_token_required(f):
    """
    Enhanced decorator to require JWT token for route access
    Uses AuthIntegration for validation with caching and auth service fallback
    """
    @wraps(f)
    def decorated(*args, **kwargs):
        auth_header = request.headers.get('Authorization', '')
        
        if not auth_header or not auth_header.startswith('Bearer '):
            return ErrorResponse(
                error="Authentication Error",
                message="Missing or invalid Authorization header"
            ).to_response(401)
        
        token = auth_header.split(' ')[1]
        
        # Get auth integration instance
        auth_integration = AuthIntegration()
        
        # Try to get user from token
        user, error = auth_integration.get_user_from_token(token)
        if not user:
            return ErrorResponse(
                error="Authentication Error",
                message=error or "Invalid token"
            ).to_response(401)
        
        # Store in flask g object for route access
        g.current_user = user
        g.current_token = token
        
        return f(user, *args, **kwargs)
    
    return decorated

    def sync_user_data(self, data: Dict[str, Any]) -> bool:
        """
        Synchronize user data from auth service
        """
        try:
            with transaction_context() as session:
                user_id = data.get('id')
                if not user_id:
                    return False

                user = User.query.get(user_id)
                if not user:
                    # Create user if doesn't exist
                    user = User(
                        id=user_id,
                        email=data['email'],
                        name=f"{data.get('first_name', '')} {data.get('last_name', '')}".strip(),
                        is_active=data['is_active'],
                        is_email_verified=data['is_email_verified']
                    )
                    session.add(user)
                else:
                    # Update existing user
                    user.email = data['email']
                    user.name = f"{data.get('first_name', '')} {data.get('last_name', '')}".strip()
                    user.is_active = data['is_active']
                    user.is_email_verified = data['is_email_verified']

                return True
        except Exception as e:
            logger.error(f"Error syncing user data: {str(e)}")
            return False

    def revoke_user_sessions(self, user_id: int, reason: str = None) -> bool:
        """
        Handle session revocation from auth service
        """
        try:
            with transaction_context() as session:
                user = User.query.get(user_id)
                if user:
                    user.last_login_at = None
                return True
        except Exception as e:
            logger.error(f"Error revoking user sessions: {str(e)}")
            return False

    def get_current_user(self) -> Optional[User]:
        """Get current authenticated user"""
        try:
            token = request.headers.get('Authorization', '').split(' ')[1]
            payload = self.validate_token(token)
            if not payload:
                return None
                
            return User.query.get(payload.get('user_id'))
            
        except Exception as e:
            logger.error(f"Error getting current user: {str(e)}")
            return None 
```


### FILE: backend\flask-service\src\utils\data_seeder.py
```
from meeting_shared.utils.data_seeder import DataSeeder

# Re-export the shared DataSeeder
__all__ = ['DataSeeder'] 
```


### FILE: backend\flask-service\src\utils\database.py
```
from meeting_shared.database import transaction_context
from meeting_shared.utils.database import with_transaction, DatabaseManager
from meeting_shared.middleware.validation import validate_schema
from flask import current_app
from sqlalchemy.exc import SQLAlchemyError
import logging
from meeting_shared.database import db

logger = logging.getLogger(__name__)

# Re-export shared database utilities
__all__ = ['transaction_context', 'with_transaction', 'DatabaseManager']

# Initialize database manager
db_manager = None

def get_db_manager():
    """Get or create database manager instance"""
    global db_manager
    if db_manager is None:
        db_manager = DatabaseManager(db)
    return db_manager

def safe_commit():
    """Safely commit database changes"""
    return get_db_manager().safe_commit()

def safe_add(obj, auto_commit=True):
    """Safely add an object to the database"""
    return get_db_manager().safe_add(obj, auto_commit)

def safe_delete(obj, auto_commit=True):
    """Safely delete an object from the database"""
    return get_db_manager().safe_delete(obj, auto_commit)

def safe_bulk_add(objects, auto_commit=True):
    """Safely add multiple objects to the database"""
    return get_db_manager().safe_bulk_add(objects, auto_commit)

def safe_bulk_delete(objects, auto_commit=True):
    """Safely delete multiple objects from the database"""
    return get_db_manager().safe_bulk_delete(objects, auto_commit) 
```


### FILE: backend\flask-service\src\utils\logger.py
```
import logging
import logging.handlers
import os
from typing import Optional
from pathlib import Path

def setup_logging(
    app_name: str,
    log_level: Optional[str] = None,
    log_format: Optional[str] = None,
    log_file: Optional[str] = None
) -> logging.Logger:
    """
    Configure logging for the application
    
    Args:
        app_name: Name of the application
        log_level: Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
        log_format: Log message format
        log_file: Path to log file
    """
    # Get configuration from environment or use defaults
    level = getattr(logging, (log_level or os.getenv('LOG_LEVEL', 'INFO')).upper())
    fmt = log_format or os.getenv('LOG_FORMAT', '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    log_path = log_file or os.getenv('LOG_FILE')

    # Create logger
    logger = logging.getLogger(app_name)
    logger.setLevel(level)

    # Create formatters and handlers
    formatter = logging.Formatter(fmt)
    
    # Console handler
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

    # File handler (if log path is specified)
    if log_path:
        # Ensure log directory exists
        log_dir = os.path.dirname(log_path)
        if log_dir:
            Path(log_dir).mkdir(parents=True, exist_ok=True)

        # Create rotating file handler
        file_handler = logging.handlers.RotatingFileHandler(
            log_path,
            maxBytes=10485760,  # 10MB
            backupCount=5
        )
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)

    # Prevent propagation to root logger
    logger.propagate = False

    logger.info(f"Logging configured for {app_name} at level {level}")
    return logger 
```


### FILE: backend\flask-service\src\utils\metrics.py
```
from prometheus_client import Counter, Histogram, Gauge, start_http_server
from functools import wraps
import time
from typing import Optional
from flask import request, Flask
import os
import threading
import logging

logger = logging.getLogger(__name__)

# Define metrics
http_requests_total = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

http_request_duration_seconds = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration in seconds',
    ['method', 'endpoint']
)

db_connections_current = Gauge(
    'db_connections_current',
    'Current number of database connections'
)

redis_connections_current = Gauge(
    'redis_connections_current',
    'Current number of Redis connections'
)

class MetricsManager:
    def __init__(self, app: Optional[Flask] = None):
        self.app = app
        if app is not None:
            self.init_app(app)

    def init_app(self, app: Flask):
        """Initialize metrics with Flask app"""
        self.app = app
        
        if os.getenv('ENABLE_METRICS', 'false').lower() == 'true':
            # Start metrics server in a separate thread
            metrics_port = int(os.getenv('METRICS_PORT', 9090))
            threading.Thread(
                target=start_http_server,
                args=(metrics_port,),
                daemon=True
            ).start()
            logger.info(f"Metrics server started on port {metrics_port}")

            # Register metrics middleware
            app.before_request(self._before_request)
            app.after_request(self._after_request)

    def _before_request(self):
        """Store start time for request duration calculation"""
        request._prometheus_metrics_start_time = time.time()

    def _after_request(self, response):
        """Record request duration and update metrics"""
        if hasattr(request, '_prometheus_metrics_start_time'):
            duration = time.time() - request._prometheus_metrics_start_time
            endpoint = request.endpoint or 'unknown'
            
            # Record request duration
            http_request_duration_seconds.labels(
                method=request.method,
                endpoint=endpoint
            ).observe(duration)
            
            # Count total requests
            http_requests_total.labels(
                method=request.method,
                endpoint=endpoint,
                status=response.status_code
            ).inc()
            
        return response

def track_db_connections(f):
    """Decorator to track database connections"""
    @wraps(f)
    def wrapped(*args, **kwargs):
        db_connections_current.inc()
        try:
            return f(*args, **kwargs)
        finally:
            db_connections_current.dec()
    return wrapped

def track_redis_connections(f):
    """Decorator to track Redis connections"""
    @wraps(f)
    def wrapped(*args, **kwargs):
        redis_connections_current.inc()
        try:
            return f(*args, **kwargs)
        finally:
            redis_connections_current.dec()
    return wrapped 
```


### FILE: backend\flask-service\src\utils\migrations_manager.py
```
import os
import sys
import logging
from flask import Flask
from flask_migrate import Migrate, upgrade, downgrade, current
from sqlalchemy import text
from sqlalchemy.exc import OperationalError
import time
from datetime import datetime
from meeting_shared.utils.migrations_manager import MigrationsManager as SharedMigrationsManager

logger = logging.getLogger(__name__)

class MigrationsManager(SharedMigrationsManager):
    def __init__(self, app: Flask, db, max_retries=5, retry_interval=5):
        self.app = app
        self.db = db
        self.migrate = Migrate(app, db)
        self.max_retries = max_retries
        self.retry_interval = retry_interval
        self.migration_history = []

    def wait_for_db(self):
        """Wait for database to be ready"""
        logger.info("Waiting for database...")
        for attempt in range(self.max_retries):
            try:
                with self.app.app_context():
                    self.db.session.execute(text('SELECT 1'))
                logger.info("Database is ready!")
                return True
            except OperationalError as e:
                if attempt == self.max_retries - 1:
                    logger.error(f"Database connection failed after {self.max_retries} attempts: {e}")
                    return False
                logger.warning(f"Database not ready (attempt {attempt + 1}/{self.max_retries}), waiting...")
                time.sleep(self.retry_interval)

    def backup_database(self):
        """Create a database backup before migrations"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_file = f"backup_{timestamp}.sql"
            backup_path = os.path.join(self.app.config['BACKUP_DIR'], backup_file)
            
            # Ensure backup directory exists
            os.makedirs(self.app.config['BACKUP_DIR'], exist_ok=True)
            
            # Create backup using pg_dump
            os.system(f"pg_dump {self.app.config['SQLALCHEMY_DATABASE_URI']} > {backup_path}")
            logger.info(f"Database backup created: {backup_file}")
            return backup_path
        except Exception as e:
            logger.error(f"Failed to create database backup: {e}")
            return None

    def restore_database(self, backup_path):
        """Restore database from backup"""
        try:
            os.system(f"psql {self.app.config['SQLALCHEMY_DATABASE_URI']} < {backup_path}")
            logger.info("Database restored from backup")
            return True
        except Exception as e:
            logger.error(f"Failed to restore database: {e}")
            return False

    def run_migrations(self):
        """Run database migrations with safety checks"""
        try:
            with self.app.app_context():
                # Get current migration version
                current_version = current(self.app)
                logger.info(f"Current migration version: {current_version}")

                # Create backup before migrations
                backup_path = self.backup_database()
                if not backup_path:
                    logger.error("Failed to create backup, aborting migrations")
                    return False

                # Run migrations
                logger.info("Starting database migrations...")
                upgrade()
                
                # Verify migrations
                if not self.verify_migrations():
                    logger.error("Migration verification failed, initiating rollback...")
                    if self.restore_database(backup_path):
                        logger.info("Successfully rolled back to previous state")
                    else:
                        logger.error("Failed to rollback, manual intervention required")
                    return False

                logger.info("Database migrations completed successfully!")
                return True
        except Exception as e:
            logger.error(f"Error running migrations: {e}")
            return False

    def verify_migrations(self):
        """Verify all migrations have been applied correctly"""
        try:
            with self.app.app_context():
                # Check if all tables exist
                for table in self.db.metadata.tables:
                    if not self.db.engine.dialect.has_table(self.db.engine, table):
                        logger.error(f"Table {table} does not exist!")
                        return False

                # Verify table constraints
                for table_name in self.db.metadata.tables:
                    result = self.db.session.execute(
                        text(f"SELECT conname FROM pg_constraint WHERE conrelid = '{table_name}'::regclass")
                    ).fetchall()
                    if not result:
                        logger.warning(f"No constraints found for table {table_name}")

                logger.info("All database tables and constraints verified!")
                return True
        except Exception as e:
            logger.error(f"Error verifying migrations: {e}")
            return False

    def check_migration_status(self):
        """Check and log migration status"""
        try:
            with self.app.app_context():
                current_version = current(self.app)
                logger.info(f"Current migration version: {current_version}")
                
                # Get all migration versions
                migrations_dir = os.path.join(os.path.dirname(self.app.root_path), 'migrations', 'versions')
                available_migrations = [f for f in os.listdir(migrations_dir) if f.endswith('.py')]
                
                logger.info(f"Available migrations: {len(available_migrations)}")
                return True
        except Exception as e:
            logger.error(f"Error checking migration status: {e}")
            return False

    def initialize_database(self):
        """Initialize database with migrations and verify integrity"""
        if not self.wait_for_db():
            logger.error("Could not connect to database")
            sys.exit(1)

        if not self.check_migration_status():
            logger.error("Failed to check migration status")
            sys.exit(1)

        if not self.run_migrations():
            logger.error("Failed to run migrations")
            sys.exit(1)

        logger.info("Database initialization completed successfully!")

# Re-export the shared MigrationsManager
__all__ = ['MigrationsManager'] 
```


### FILE: backend\flask-service\src\utils\responses.py
```
from flask import jsonify
from typing import Any, Dict, Optional, Tuple, Union

def api_response(
    data: Optional[Dict[str, Any]] = None,
    message: Optional[str] = None,
    error: Optional[str] = None,
    code: Optional[str] = None,
    status_code: int = 200
) -> Tuple[Dict[str, Any], int]:
    """
    Create a standardized API response.
    
    Args:
        data: Optional dictionary of response data
        message: Optional success message
        error: Optional error message
        code: Optional error code
        status_code: HTTP status code (default: 200)
    
    Returns:
        Tuple of (response_dict, status_code)
    """
    response = {}
    
    if data is not None:
        response.update(data)
    
    if message is not None:
        response['message'] = message
        
    if error is not None:
        response['error'] = error
        
    if code is not None:
        response['code'] = code
        
    return jsonify(response), status_code

def error_response(
    error: str,
    code: str,
    status_code: int = 400
) -> Tuple[Dict[str, Any], int]:
    """
    Create a standardized error response.
    
    Args:
        error: Error message
        code: Error code
        status_code: HTTP status code (default: 400)
    
    Returns:
        Tuple of (response_dict, status_code)
    """
    return api_response(error=error, code=code, status_code=status_code)

def success_response(
    data: Optional[Dict[str, Any]] = None,
    message: Optional[str] = None,
    status_code: int = 200
) -> Tuple[Dict[str, Any], int]:
    """
    Create a standardized success response.
    
    Args:
        data: Optional dictionary of response data
        message: Optional success message
        status_code: HTTP status code (default: 200)
    
    Returns:
        Tuple of (response_dict, status_code)
    """
    return api_response(data=data, message=message, status_code=status_code) 
```


### FILE: backend\flask-service\src\utils\socket_events.py
```
from flask_socketio import emit, join_room, leave_room
from functools import wraps
import jwt
import os

def socket_auth_required(f):
    @wraps(f)
    def decorated(data, *args, **kwargs):
        token = data.get('token')
        
        if not token:
            return emit('error', {'message': 'Token is missing'})
            
        try:
            token_data = jwt.decode(token, os.getenv('JWT_SECRET_KEY'), algorithms=['HS256'])
            data['user_id'] = token_data['user_id']
        except:
            return emit('error', {'message': 'Invalid token'})
            
        return f(data, *args, **kwargs)
        
    return decorated

def register_socket_events(socketio):
    @socketio.on('join')
    @socket_auth_required
    def handle_join(data):
        room = data.get('meeting_code')
        if room:
            join_room(room)
            emit('user_joined', {
                'user_id': data['user_id']
            }, room=room)

    @socketio.on('leave')
    @socket_auth_required
    def handle_leave(data):
        room = data.get('meeting_code')
        if room:
            leave_room(room)
            emit('user_left', {
                'user_id': data['user_id']
            }, room=room)

    @socketio.on('offer')
    @socket_auth_required
    def handle_offer(data):
        target_user = data.get('target_user')
        if target_user:
            emit('offer', {
                'sdp': data['sdp'],
                'user_id': data['user_id']
            }, room=target_user)

    @socketio.on('answer')
    @socket_auth_required
    def handle_answer(data):
        target_user = data.get('target_user')
        if target_user:
            emit('answer', {
                'sdp': data['sdp'],
                'user_id': data['user_id']
            }, room=target_user)

    @socketio.on('ice_candidate')
    @socket_auth_required
    def handle_ice_candidate(data):
        target_user = data.get('target_user')
        if target_user:
            emit('ice_candidate', {
                'candidate': data['candidate'],
                'user_id': data['user_id']
            }, room=target_user)

    @socketio.on('chat_message')
    @socket_auth_required
    def handle_chat_message(data):
        room = data.get('meeting_code')
        if room:
            emit('chat_message', {
                'user_id': data['user_id'],
                'message': data['message'],
                'timestamp': data['timestamp']
            }, room=room) 
```


### FILE: backend\node-service\.dockerignore
```
# Git
.git
.gitignore

# Node.js
node_modules/
npm-debug.log
yarn-debug.log
yarn-error.log
.npm/
.yarn/
*.tgz

# Docker
Dockerfile*
docker-compose*
.dockerignore

# IDE
.idea/
.vscode/
*.swp
*.swo

# Logs
logs/
*.log

# Data
data/ 
```


### FILE: backend\node-service\.env.example
```
# Server Configuration
PORT=3001
HOST=0.0.0.0
NODE_ENV=development

# CORS Configuration
CORS_ORIGINS=http://localhost:3000,http://localhost:8080

# Redis Configuration
REDIS_URL=redis://localhost:6379

# JWT Configuration
JWT_SECRET=your-secret-key-here
JWT_EXPIRES_IN=24h

# WebRTC Configuration
STUN_SERVERS=stun:stun.l.google.com:19302,stun:stun1.l.google.com:19302
TURN_SERVERS=turn:your-turn-server:3478
TURN_USERNAME=your-turn-username
TURN_CREDENTIAL=your-turn-password

# Metrics Configuration
ENABLE_METRICS=true

# Logging Configuration
LOG_LEVEL=info
LOG_FORMAT=json

# File Sharing Configuration
MAX_FILE_SIZE=10485760
ALLOWED_FILE_TYPES=image/*,application/pdf,application/msword,application/vnd.openxmlformats-officedocument.wordprocessingml.document,text/plain

# Room Configuration
MAX_ROOM_PARTICIPANTS=12
ROOM_TIMEOUT=1800000 
```


### FILE: backend\node-service\Dockerfile
```
FROM node:18-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    curl \
    jq \
    && rm -rf /var/lib/apt/lists/*

# Copy package files
COPY package*.json ./

# Install all dependencies from package.json
RUN npm install && \
    npm cache clean --force

# Create directories
RUN mkdir -p /app/logs /app/src

# Copy source code separately to avoid permission issues
COPY src/ /app/src/
COPY *.js /app/

# Create healthcheck script that tests Redis connection
RUN echo '#!/bin/sh\n\
\n\
# Test HTTP endpoint\n\
RESPONSE=$(curl -s http://localhost:3001/health)\n\
if [ $? -ne 0 ]; then\n\
  echo "Healthcheck failed: Could not connect to service"\n\
  exit 1\n\
fi\n\
\n\
# Extract status from response\n\
STATUS=$(echo $RESPONSE | jq -r .status 2>/dev/null)\n\
\n\
# Handle "degraded" status as healthy to allow container time to fully connect\n\
if [ "$STATUS" = "degraded" ]; then\n\
  echo "Service is degraded but operational..."\n\
  exit 0\n\
fi\n\
\n\
# Require "healthy" status for fully operational service\n\
if [ "$STATUS" != "healthy" ]; then\n\
  echo "Healthcheck failed: Service returned status $STATUS"\n\
  exit 1\n\
fi\n\
\n\
exit 0\n\
' > /healthcheck.sh && \
chmod +x /healthcheck.sh

# Set environment
ENV NODE_ENV=production
ENV PORT=3001

# Expose port
EXPOSE 3001

# Health check with more lenient parameters
HEALTHCHECK --interval=30s --timeout=30s --start-period=30s --retries=3 \
    CMD /healthcheck.sh

# Start the application with error handling
CMD ["node", "src/server.js"] 
```


### FILE: backend\node-service\package-lock.json
```
{
  "name": "meeting-app-websocket",
  "version": "1.0.0",
  "lockfileVersion": 3,
  "requires": true,
  "packages": {
    "": {
      "name": "meeting-app-websocket",
      "version": "1.0.0",
      "dependencies": {
        "compression": "^1.7.4",
        "cors": "^2.8.5",
        "dotenv": "^16.3.1",
        "express": "^4.18.2",
        "helmet": "^7.0.0",
        "ioredis": "^5.3.2",
        "jsonwebtoken": "^9.0.2",
        "morgan": "^1.10.0",
        "prom-client": "^14.2.0",
        "socket.io": "^4.7.2",
        "winston": "^3.10.0"
      },
      "devDependencies": {
        "jest": "^29.6.4",
        "nodemon": "^3.0.1"
      }
    },
    "node_modules/@ampproject/remapping": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/@ampproject/remapping/-/remapping-2.3.0.tgz",
      "integrity": "sha512-30iZtAPgz+LTIYoeivqYo853f02jBYSd5uGnGpkFV0M3xOt9aN73erkgYAmZU43x4VfqcnLxW9Kpg3R5LC4YYw==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@jridgewell/gen-mapping": "^0.3.5",
        "@jridgewell/trace-mapping": "^0.3.24"
      },
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@babel/code-frame": {
      "version": "7.26.2",
      "resolved": "https://registry.npmjs.org/@babel/code-frame/-/code-frame-7.26.2.tgz",
      "integrity": "sha512-RJlIHRueQgwWitWgF8OdFYGZX328Ax5BCemNGlqHfplnRT9ESi8JkFlvaVYbS+UubVY6dpv87Fs2u5M29iNFVQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-validator-identifier": "^7.25.9",
        "js-tokens": "^4.0.0",
        "picocolors": "^1.0.0"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/compat-data": {
      "version": "7.26.8",
      "resolved": "https://registry.npmjs.org/@babel/compat-data/-/compat-data-7.26.8.tgz",
      "integrity": "sha512-oH5UPLMWR3L2wEFLnFJ1TZXqHufiTKAiLfqw5zkhS4dKXLJ10yVztfil/twG8EDTA4F/tvVNw9nOl4ZMslB8rQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/core": {
      "version": "7.26.9",
      "resolved": "https://registry.npmjs.org/@babel/core/-/core-7.26.9.tgz",
      "integrity": "sha512-lWBYIrF7qK5+GjY5Uy+/hEgp8OJWOD/rpy74GplYRhEauvbHDeFB8t5hPOZxCZ0Oxf4Cc36tK51/l3ymJysrKw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@ampproject/remapping": "^2.2.0",
        "@babel/code-frame": "^7.26.2",
        "@babel/generator": "^7.26.9",
        "@babel/helper-compilation-targets": "^7.26.5",
        "@babel/helper-module-transforms": "^7.26.0",
        "@babel/helpers": "^7.26.9",
        "@babel/parser": "^7.26.9",
        "@babel/template": "^7.26.9",
        "@babel/traverse": "^7.26.9",
        "@babel/types": "^7.26.9",
        "convert-source-map": "^2.0.0",
        "debug": "^4.1.0",
        "gensync": "^1.0.0-beta.2",
        "json5": "^2.2.3",
        "semver": "^6.3.1"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/babel"
      }
    },
    "node_modules/@babel/core/node_modules/debug": {
      "version": "4.4.0",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.4.0.tgz",
      "integrity": "sha512-6WTZ/IxCY/T6BALoZHaE4ctp9xm+Z5kY/pzYaCHRFeyVhojxlrm+46y68HA6hr0TcwEssoxNiDEUJQjfPZ/RYA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/@babel/core/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@babel/generator": {
      "version": "7.26.9",
      "resolved": "https://registry.npmjs.org/@babel/generator/-/generator-7.26.9.tgz",
      "integrity": "sha512-kEWdzjOAUMW4hAyrzJ0ZaTOu9OmpyDIQicIh0zg0EEcEkYXZb2TjtBhnHi2ViX7PKwZqF4xwqfAm299/QMP3lg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/parser": "^7.26.9",
        "@babel/types": "^7.26.9",
        "@jridgewell/gen-mapping": "^0.3.5",
        "@jridgewell/trace-mapping": "^0.3.25",
        "jsesc": "^3.0.2"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-compilation-targets": {
      "version": "7.26.5",
      "resolved": "https://registry.npmjs.org/@babel/helper-compilation-targets/-/helper-compilation-targets-7.26.5.tgz",
      "integrity": "sha512-IXuyn5EkouFJscIDuFF5EsiSolseme1s0CZB+QxVugqJLYmKdxI1VfIBOst0SUu4rnk2Z7kqTwmoO1lp3HIfnA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/compat-data": "^7.26.5",
        "@babel/helper-validator-option": "^7.25.9",
        "browserslist": "^4.24.0",
        "lru-cache": "^5.1.1",
        "semver": "^6.3.1"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-module-imports": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/helper-module-imports/-/helper-module-imports-7.25.9.tgz",
      "integrity": "sha512-tnUA4RsrmflIM6W6RFTLFSXITtl0wKjgpnLgXyowocVPrbYrLUXSBXDgTs8BlbmIzIdlBySRQjINYs2BAkiLtw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/traverse": "^7.25.9",
        "@babel/types": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-module-transforms": {
      "version": "7.26.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-module-transforms/-/helper-module-transforms-7.26.0.tgz",
      "integrity": "sha512-xO+xu6B5K2czEnQye6BHA7DolFFmS3LB7stHZFaOLb1pAwO1HWLS8fXA+eh0A2yIvltPVmx3eNNDBJA2SLHXFw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-module-imports": "^7.25.9",
        "@babel/helper-validator-identifier": "^7.25.9",
        "@babel/traverse": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/@babel/helper-plugin-utils": {
      "version": "7.26.5",
      "resolved": "https://registry.npmjs.org/@babel/helper-plugin-utils/-/helper-plugin-utils-7.26.5.tgz",
      "integrity": "sha512-RS+jZcRdZdRFzMyr+wcsaqOmld1/EqTghfaBGQQd/WnRdzdlvSZ//kF7U8VQTxf1ynZ4cjUcYgjVGx13ewNPMg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-string-parser": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/helper-string-parser/-/helper-string-parser-7.25.9.tgz",
      "integrity": "sha512-4A/SCr/2KLd5jrtOMFzaKjVtAei3+2r/NChoBNoZ3EyP/+GlhoaEGoWOZUmFmoITP7zOJyHIMm+DYRd8o3PvHA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-validator-identifier": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/helper-validator-identifier/-/helper-validator-identifier-7.25.9.tgz",
      "integrity": "sha512-Ed61U6XJc3CVRfkERJWDz4dJwKe7iLmmJsbOGu9wSloNSFttHV0I8g6UAgb7qnK5ly5bGLPd4oXZlxCdANBOWQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-validator-option": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/helper-validator-option/-/helper-validator-option-7.25.9.tgz",
      "integrity": "sha512-e/zv1co8pp55dNdEcCynfj9X7nyUKUXoUEwfXqaZt0omVOmDe9oOTdKStH4GmAw6zxMFs50ZayuMfHDKlO7Tfw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helpers": {
      "version": "7.26.9",
      "resolved": "https://registry.npmjs.org/@babel/helpers/-/helpers-7.26.9.tgz",
      "integrity": "sha512-Mz/4+y8udxBKdmzt/UjPACs4G3j5SshJJEFFKxlCGPydG4JAHXxjWjAwjd09tf6oINvl1VfMJo+nB7H2YKQ0dA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/template": "^7.26.9",
        "@babel/types": "^7.26.9"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/parser": {
      "version": "7.26.9",
      "resolved": "https://registry.npmjs.org/@babel/parser/-/parser-7.26.9.tgz",
      "integrity": "sha512-81NWa1njQblgZbQHxWHpxxCzNsa3ZwvFqpUg7P+NNUU6f3UU2jBEg4OlF/J6rl8+PQGh1q6/zWScd001YwcA5A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/types": "^7.26.9"
      },
      "bin": {
        "parser": "bin/babel-parser.js"
      },
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@babel/plugin-syntax-async-generators": {
      "version": "7.8.4",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-async-generators/-/plugin-syntax-async-generators-7.8.4.tgz",
      "integrity": "sha512-tycmZxkGfZaxhMRbXlPXuVFpdWlXpir2W4AMhSJgRKzk/eDlIXOhb2LHWoLpDF7TEHylV5zNhykX6KAgHJmTNw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.8.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-bigint": {
      "version": "7.8.3",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-bigint/-/plugin-syntax-bigint-7.8.3.tgz",
      "integrity": "sha512-wnTnFlG+YxQm3vDxpGE57Pj0srRU4sHE/mDkt1qv2YJJSeUAec2ma4WLUnUPeKjyrfntVwe/N6dCXpU+zL3Npg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.8.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-class-properties": {
      "version": "7.12.13",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-class-properties/-/plugin-syntax-class-properties-7.12.13.tgz",
      "integrity": "sha512-fm4idjKla0YahUNgFNLCB0qySdsoPiZP3iQE3rky0mBUtMZ23yDJ9SJdg6dXTSDnulOVqiF3Hgr9nbXvXTQZYA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.12.13"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-class-static-block": {
      "version": "7.14.5",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-class-static-block/-/plugin-syntax-class-static-block-7.14.5.tgz",
      "integrity": "sha512-b+YyPmr6ldyNnM6sqYeMWE+bgJcJpO6yS4QD7ymxgH34GBPNDM/THBh8iunyvKIZztiwLH4CJZ0RxTk9emgpjw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.14.5"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-import-attributes": {
      "version": "7.26.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-import-attributes/-/plugin-syntax-import-attributes-7.26.0.tgz",
      "integrity": "sha512-e2dttdsJ1ZTpi3B9UYGLw41hifAubg19AtCu/2I/F1QNVclOBr1dYpTdmdyZ84Xiz43BS/tCUkMAZNLv12Pi+A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-import-meta": {
      "version": "7.10.4",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-import-meta/-/plugin-syntax-import-meta-7.10.4.tgz",
      "integrity": "sha512-Yqfm+XDx0+Prh3VSeEQCPU81yC+JWZ2pDPFSS4ZdpfZhp4MkFMaDC1UqseovEKwSUpnIL7+vK+Clp7bfh0iD7g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.10.4"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-json-strings": {
      "version": "7.8.3",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-json-strings/-/plugin-syntax-json-strings-7.8.3.tgz",
      "integrity": "sha512-lY6kdGpWHvjoe2vk4WrAapEuBR69EMxZl+RoGRhrFGNYVK8mOPAW8VfbT/ZgrFbXlDNiiaxQnAtgVCZ6jv30EA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.8.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-jsx": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-jsx/-/plugin-syntax-jsx-7.25.9.tgz",
      "integrity": "sha512-ld6oezHQMZsZfp6pWtbjaNDF2tiiCYYDqQszHt5VV437lewP9aSi2Of99CK0D0XB21k7FLgnLcmQKyKzynfeAA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-logical-assignment-operators": {
      "version": "7.10.4",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-logical-assignment-operators/-/plugin-syntax-logical-assignment-operators-7.10.4.tgz",
      "integrity": "sha512-d8waShlpFDinQ5MtvGU9xDAOzKH47+FFoney2baFIoMr952hKOLp1HR7VszoZvOsV/4+RRszNY7D17ba0te0ig==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.10.4"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-nullish-coalescing-operator": {
      "version": "7.8.3",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-nullish-coalescing-operator/-/plugin-syntax-nullish-coalescing-operator-7.8.3.tgz",
      "integrity": "sha512-aSff4zPII1u2QD7y+F8oDsz19ew4IGEJg9SVW+bqwpwtfFleiQDMdzA/R+UlWDzfnHFCxxleFT0PMIrR36XLNQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.8.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-numeric-separator": {
      "version": "7.10.4",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-numeric-separator/-/plugin-syntax-numeric-separator-7.10.4.tgz",
      "integrity": "sha512-9H6YdfkcK/uOnY/K7/aA2xpzaAgkQn37yzWUMRK7OaPOqOpGS1+n0H5hxT9AUw9EsSjPW8SVyMJwYRtWs3X3ug==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.10.4"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-object-rest-spread": {
      "version": "7.8.3",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-object-rest-spread/-/plugin-syntax-object-rest-spread-7.8.3.tgz",
      "integrity": "sha512-XoqMijGZb9y3y2XskN+P1wUGiVwWZ5JmoDRwx5+3GmEplNyVM2s2Dg8ILFQm8rWM48orGy5YpI5Bl8U1y7ydlA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.8.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-optional-catch-binding": {
      "version": "7.8.3",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-optional-catch-binding/-/plugin-syntax-optional-catch-binding-7.8.3.tgz",
      "integrity": "sha512-6VPD0Pc1lpTqw0aKoeRTMiB+kWhAoT24PA+ksWSBrFtl5SIRVpZlwN3NNPQjehA2E/91FV3RjLWoVTglWcSV3Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.8.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-optional-chaining": {
      "version": "7.8.3",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-optional-chaining/-/plugin-syntax-optional-chaining-7.8.3.tgz",
      "integrity": "sha512-KoK9ErH1MBlCPxV0VANkXW2/dw4vlbGDrFgz8bmUsBGYkFRcbRwMh6cIJubdPrkxRwuGdtCk0v/wPTKbQgBjkg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.8.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-private-property-in-object": {
      "version": "7.14.5",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-private-property-in-object/-/plugin-syntax-private-property-in-object-7.14.5.tgz",
      "integrity": "sha512-0wVnp9dxJ72ZUJDV27ZfbSj6iHLoytYZmh3rFcxNnvsJF3ktkzLDZPy/mA17HGsaQT3/DQsWYX1f1QGWkCoVUg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.14.5"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-top-level-await": {
      "version": "7.14.5",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-top-level-await/-/plugin-syntax-top-level-await-7.14.5.tgz",
      "integrity": "sha512-hx++upLv5U1rgYfwe1xBQUhRmU41NEvpUvrp8jkrSCdvGSnM5/qdRMtylJ6PG5OFkBaHkbTAKTnd3/YyESRHFw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.14.5"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-typescript": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-typescript/-/plugin-syntax-typescript-7.25.9.tgz",
      "integrity": "sha512-hjMgRy5hb8uJJjUcdWunWVcoi9bGpJp8p5Ol1229PoN6aytsLwNMgmdftO23wnCLMfVmTwZDWMPNq/D1SY60JQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/template": {
      "version": "7.26.9",
      "resolved": "https://registry.npmjs.org/@babel/template/-/template-7.26.9.tgz",
      "integrity": "sha512-qyRplbeIpNZhmzOysF/wFMuP9sctmh2cFzRAZOn1YapxBsE1i9bJIY586R/WBLfLcmcBlM8ROBiQURnnNy+zfA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/code-frame": "^7.26.2",
        "@babel/parser": "^7.26.9",
        "@babel/types": "^7.26.9"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/traverse": {
      "version": "7.26.9",
      "resolved": "https://registry.npmjs.org/@babel/traverse/-/traverse-7.26.9.tgz",
      "integrity": "sha512-ZYW7L+pL8ahU5fXmNbPF+iZFHCv5scFak7MZ9bwaRPLUhHh7QQEMjZUg0HevihoqCM5iSYHN61EyCoZvqC+bxg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/code-frame": "^7.26.2",
        "@babel/generator": "^7.26.9",
        "@babel/parser": "^7.26.9",
        "@babel/template": "^7.26.9",
        "@babel/types": "^7.26.9",
        "debug": "^4.3.1",
        "globals": "^11.1.0"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/traverse/node_modules/debug": {
      "version": "4.4.0",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.4.0.tgz",
      "integrity": "sha512-6WTZ/IxCY/T6BALoZHaE4ctp9xm+Z5kY/pzYaCHRFeyVhojxlrm+46y68HA6hr0TcwEssoxNiDEUJQjfPZ/RYA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/@babel/traverse/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@babel/types": {
      "version": "7.26.9",
      "resolved": "https://registry.npmjs.org/@babel/types/-/types-7.26.9.tgz",
      "integrity": "sha512-Y3IR1cRnOxOCDvMmNiym7XpXQ93iGDDPHx+Zj+NM+rg0fBaShfQLkg+hKPaZCEvg5N/LeCo4+Rj/i3FuJsIQaw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-string-parser": "^7.25.9",
        "@babel/helper-validator-identifier": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@bcoe/v8-coverage": {
      "version": "0.2.3",
      "resolved": "https://registry.npmjs.org/@bcoe/v8-coverage/-/v8-coverage-0.2.3.tgz",
      "integrity": "sha512-0hYQ8SB4Db5zvZB4axdMHGwEaQjkZzFjQiN9LVYvIFB2nSUHW9tYpxWriPrWDASIxiaXax83REcLxuSdnGPZtw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@colors/colors": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/@colors/colors/-/colors-1.6.0.tgz",
      "integrity": "sha512-Ir+AOibqzrIsL6ajt3Rz3LskB7OiMVHqltZmspbW/TJuTVuyOMirVqAkjfY6JISiLHgyNqicAC8AyHHGzNd/dA==",
      "license": "MIT",
      "engines": {
        "node": ">=0.1.90"
      }
    },
    "node_modules/@dabh/diagnostics": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/@dabh/diagnostics/-/diagnostics-2.0.3.tgz",
      "integrity": "sha512-hrlQOIi7hAfzsMqlGSFyVucrx38O+j6wiGOf//H2ecvIEqYN4ADBSS2iLMh5UFyDunCNniUIPk/q3riFv45xRA==",
      "license": "MIT",
      "dependencies": {
        "colorspace": "1.1.x",
        "enabled": "2.0.x",
        "kuler": "^2.0.0"
      }
    },
    "node_modules/@ioredis/commands": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/@ioredis/commands/-/commands-1.2.0.tgz",
      "integrity": "sha512-Sx1pU8EM64o2BrqNpEO1CNLtKQwyhuXuqyfH7oGKCk+1a33d2r5saW8zNwm3j6BTExtjrv2BxTgzzkMwts6vGg==",
      "license": "MIT"
    },
    "node_modules/@istanbuljs/load-nyc-config": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@istanbuljs/load-nyc-config/-/load-nyc-config-1.1.0.tgz",
      "integrity": "sha512-VjeHSlIzpv/NyD3N0YuHfXOPDIixcA1q2ZV98wsMqcYlPmv2n3Yb2lYP9XMElnaFVXg5A7YLTeLu6V84uQDjmQ==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "camelcase": "^5.3.1",
        "find-up": "^4.1.0",
        "get-package-type": "^0.1.0",
        "js-yaml": "^3.13.1",
        "resolve-from": "^5.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/@istanbuljs/schema": {
      "version": "0.1.3",
      "resolved": "https://registry.npmjs.org/@istanbuljs/schema/-/schema-0.1.3.tgz",
      "integrity": "sha512-ZXRY4jNvVgSVQ8DL3LTcakaAtXwTVUxE81hslsyD2AtoXW/wVob10HkOJ1X/pAlcI7D+2YoZKg5do8G/w6RYgA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/@jest/console": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/console/-/console-29.7.0.tgz",
      "integrity": "sha512-5Ni4CU7XHQi32IJ398EEP4RrB8eV09sXP2ROqD4bksHrnTree52PsxvX8tpL8LvTZ3pFzXyPbNQReSN41CAhOg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "chalk": "^4.0.0",
        "jest-message-util": "^29.7.0",
        "jest-util": "^29.7.0",
        "slash": "^3.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/core": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/core/-/core-29.7.0.tgz",
      "integrity": "sha512-n7aeXWKMnGtDA48y8TLWJPJmLmmZ642Ceo78cYWEpiD7FzDgmNDV/GCVRorPABdXLJZ/9wzzgZAlHjXjxDHGsg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/console": "^29.7.0",
        "@jest/reporters": "^29.7.0",
        "@jest/test-result": "^29.7.0",
        "@jest/transform": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "ansi-escapes": "^4.2.1",
        "chalk": "^4.0.0",
        "ci-info": "^3.2.0",
        "exit": "^0.1.2",
        "graceful-fs": "^4.2.9",
        "jest-changed-files": "^29.7.0",
        "jest-config": "^29.7.0",
        "jest-haste-map": "^29.7.0",
        "jest-message-util": "^29.7.0",
        "jest-regex-util": "^29.6.3",
        "jest-resolve": "^29.7.0",
        "jest-resolve-dependencies": "^29.7.0",
        "jest-runner": "^29.7.0",
        "jest-runtime": "^29.7.0",
        "jest-snapshot": "^29.7.0",
        "jest-util": "^29.7.0",
        "jest-validate": "^29.7.0",
        "jest-watcher": "^29.7.0",
        "micromatch": "^4.0.4",
        "pretty-format": "^29.7.0",
        "slash": "^3.0.0",
        "strip-ansi": "^6.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "node-notifier": "^8.0.1 || ^9.0.0 || ^10.0.0"
      },
      "peerDependenciesMeta": {
        "node-notifier": {
          "optional": true
        }
      }
    },
    "node_modules/@jest/environment": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/environment/-/environment-29.7.0.tgz",
      "integrity": "sha512-aQIfHDq33ExsN4jP1NWGXhxgQ/wixs60gDiKO+XVMd8Mn0NWPWgc34ZQDTb2jKaUWQ7MuwoitXAsN2XVXNMpAw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/fake-timers": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "jest-mock": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/expect": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/expect/-/expect-29.7.0.tgz",
      "integrity": "sha512-8uMeAMycttpva3P1lBHB8VciS9V0XAr3GymPpipdyQXbBcuhkLQOSe8E/p92RyAdToS6ZD1tFkX+CkhoECE0dQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "expect": "^29.7.0",
        "jest-snapshot": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/expect-utils": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/expect-utils/-/expect-utils-29.7.0.tgz",
      "integrity": "sha512-GlsNBWiFQFCVi9QVSx7f5AgMeLxe9YCCs5PuP2O2LdjDAA8Jh9eX7lA1Jq/xdXw3Wb3hyvlFNfZIfcRetSzYcA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "jest-get-type": "^29.6.3"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/fake-timers": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/fake-timers/-/fake-timers-29.7.0.tgz",
      "integrity": "sha512-q4DH1Ha4TTFPdxLsqDXK1d3+ioSL7yL5oCMJZgDYm6i+6CygW5E5xVr/D1HdsGxjt1ZWSfUAs9OxSB/BNelWrQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "@sinonjs/fake-timers": "^10.0.2",
        "@types/node": "*",
        "jest-message-util": "^29.7.0",
        "jest-mock": "^29.7.0",
        "jest-util": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/globals": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/globals/-/globals-29.7.0.tgz",
      "integrity": "sha512-mpiz3dutLbkW2MNFubUGUEVLkTGiqW6yLVTA+JbP6fI6J5iL9Y0Nlg8k95pcF8ctKwCS7WVxteBs29hhfAotzQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/environment": "^29.7.0",
        "@jest/expect": "^29.7.0",
        "@jest/types": "^29.6.3",
        "jest-mock": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/reporters": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/reporters/-/reporters-29.7.0.tgz",
      "integrity": "sha512-DApq0KJbJOEzAFYjHADNNxAE3KbhxQB1y5Kplb5Waqw6zVbuWatSnMjE5gs8FUgEPmNsnZA3NCWl9NG0ia04Pg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@bcoe/v8-coverage": "^0.2.3",
        "@jest/console": "^29.7.0",
        "@jest/test-result": "^29.7.0",
        "@jest/transform": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@jridgewell/trace-mapping": "^0.3.18",
        "@types/node": "*",
        "chalk": "^4.0.0",
        "collect-v8-coverage": "^1.0.0",
        "exit": "^0.1.2",
        "glob": "^7.1.3",
        "graceful-fs": "^4.2.9",
        "istanbul-lib-coverage": "^3.0.0",
        "istanbul-lib-instrument": "^6.0.0",
        "istanbul-lib-report": "^3.0.0",
        "istanbul-lib-source-maps": "^4.0.0",
        "istanbul-reports": "^3.1.3",
        "jest-message-util": "^29.7.0",
        "jest-util": "^29.7.0",
        "jest-worker": "^29.7.0",
        "slash": "^3.0.0",
        "string-length": "^4.0.1",
        "strip-ansi": "^6.0.0",
        "v8-to-istanbul": "^9.0.1"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "node-notifier": "^8.0.1 || ^9.0.0 || ^10.0.0"
      },
      "peerDependenciesMeta": {
        "node-notifier": {
          "optional": true
        }
      }
    },
    "node_modules/@jest/schemas": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/@jest/schemas/-/schemas-29.6.3.tgz",
      "integrity": "sha512-mo5j5X+jIZmJQveBKeS/clAueipV7KgiX1vMgCxam1RNYiqE1w62n0/tJJnHtjW8ZHcQco5gY85jA3mi0L+nSA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@sinclair/typebox": "^0.27.8"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/source-map": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/@jest/source-map/-/source-map-29.6.3.tgz",
      "integrity": "sha512-MHjT95QuipcPrpLM+8JMSzFx6eHp5Bm+4XeFDJlwsvVBjmKNiIAvasGK2fxz2WbGRlnvqehFbh07MMa7n3YJnw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/trace-mapping": "^0.3.18",
        "callsites": "^3.0.0",
        "graceful-fs": "^4.2.9"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/test-result": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/test-result/-/test-result-29.7.0.tgz",
      "integrity": "sha512-Fdx+tv6x1zlkJPcWXmMDAG2HBnaR9XPSd5aDWQVsfrZmLVT3lU1cwyxLgRmXR9yrq4NBoEm9BMsfgFzTQAbJYA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/console": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/istanbul-lib-coverage": "^2.0.0",
        "collect-v8-coverage": "^1.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/test-sequencer": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/test-sequencer/-/test-sequencer-29.7.0.tgz",
      "integrity": "sha512-GQwJ5WZVrKnOJuiYiAF52UNUJXgTZx1NHjFSEB0qEMmSZKAkdMoIzw/Cj6x6NF4AvV23AUqDpFzQkN/eYCYTxw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/test-result": "^29.7.0",
        "graceful-fs": "^4.2.9",
        "jest-haste-map": "^29.7.0",
        "slash": "^3.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/transform": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/transform/-/transform-29.7.0.tgz",
      "integrity": "sha512-ok/BTPFzFKVMwO5eOHRrvnBVHdRy9IrsrW1GpMaQ9MCnilNLXQKmAX8s1YXDFaai9xJpac2ySzV0YeRRECr2Vw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/core": "^7.11.6",
        "@jest/types": "^29.6.3",
        "@jridgewell/trace-mapping": "^0.3.18",
        "babel-plugin-istanbul": "^6.1.1",
        "chalk": "^4.0.0",
        "convert-source-map": "^2.0.0",
        "fast-json-stable-stringify": "^2.1.0",
        "graceful-fs": "^4.2.9",
        "jest-haste-map": "^29.7.0",
        "jest-regex-util": "^29.6.3",
        "jest-util": "^29.7.0",
        "micromatch": "^4.0.4",
        "pirates": "^4.0.4",
        "slash": "^3.0.0",
        "write-file-atomic": "^4.0.2"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/types": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/@jest/types/-/types-29.6.3.tgz",
      "integrity": "sha512-u3UPsIilWKOM3F9CXtrG8LEJmNxwoCQC/XVj4IKYXvvpx7QIi/Kg1LI5uDmDpKlac62NUtX7eLjRh+jVZcLOzw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/schemas": "^29.6.3",
        "@types/istanbul-lib-coverage": "^2.0.0",
        "@types/istanbul-reports": "^3.0.0",
        "@types/node": "*",
        "@types/yargs": "^17.0.8",
        "chalk": "^4.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jridgewell/gen-mapping": {
      "version": "0.3.8",
      "resolved": "https://registry.npmjs.org/@jridgewell/gen-mapping/-/gen-mapping-0.3.8.tgz",
      "integrity": "sha512-imAbBGkb+ebQyxKgzv5Hu2nmROxoDOXHh80evxdoXNOrvAnVx7zimzc1Oo5h9RlfV4vPXaE2iM5pOFbvOCClWA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/set-array": "^1.2.1",
        "@jridgewell/sourcemap-codec": "^1.4.10",
        "@jridgewell/trace-mapping": "^0.3.24"
      },
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/resolve-uri": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/@jridgewell/resolve-uri/-/resolve-uri-3.1.2.tgz",
      "integrity": "sha512-bRISgCIjP20/tbWSPWMEi54QVPRZExkuD9lJL+UIxUKtwVJA8wW1Trb1jMs1RFXo1CBTNZ/5hpC9QvmKWdopKw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/set-array": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/@jridgewell/set-array/-/set-array-1.2.1.tgz",
      "integrity": "sha512-R8gLRTZeyp03ymzP/6Lil/28tGeGEzhx1q2k703KGWRAI1VdvPIXdG70VJc2pAMw3NA6JKL5hhFu1sJX0Mnn/A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/sourcemap-codec": {
      "version": "1.5.0",
      "resolved": "https://registry.npmjs.org/@jridgewell/sourcemap-codec/-/sourcemap-codec-1.5.0.tgz",
      "integrity": "sha512-gv3ZRaISU3fjPAgNsriBRqGWQL6quFx04YMPW/zD8XMLsU32mhCCbfbO6KZFLjvYpCZ8zyDEgqsgf+PwPaM7GQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@jridgewell/trace-mapping": {
      "version": "0.3.25",
      "resolved": "https://registry.npmjs.org/@jridgewell/trace-mapping/-/trace-mapping-0.3.25.tgz",
      "integrity": "sha512-vNk6aEwybGtawWmy/PzwnGDOjCkLWSD2wqvjGGAgOAwCGWySYXfYoxt00IJkTF+8Lb57DwOb3Aa0o9CApepiYQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/resolve-uri": "^3.1.0",
        "@jridgewell/sourcemap-codec": "^1.4.14"
      }
    },
    "node_modules/@sinclair/typebox": {
      "version": "0.27.8",
      "resolved": "https://registry.npmjs.org/@sinclair/typebox/-/typebox-0.27.8.tgz",
      "integrity": "sha512-+Fj43pSMwJs4KRrH/938Uf+uAELIgVBmQzg/q1YG10djyfA3TnrU8N8XzqCh/okZdszqBQTZf96idMfE5lnwTA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@sinonjs/commons": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/@sinonjs/commons/-/commons-3.0.1.tgz",
      "integrity": "sha512-K3mCHKQ9sVh8o1C9cxkwxaOmXoAMlDxC1mYyHrjqOWEcBjYr76t96zL2zlj5dUGZ3HSw240X1qgH3Mjf1yJWpQ==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "type-detect": "4.0.8"
      }
    },
    "node_modules/@sinonjs/fake-timers": {
      "version": "10.3.0",
      "resolved": "https://registry.npmjs.org/@sinonjs/fake-timers/-/fake-timers-10.3.0.tgz",
      "integrity": "sha512-V4BG07kuYSUkTCSBHG8G8TNhM+F19jXFWnQtzj+we8DrkpSBCee9Z3Ms8yiGer/dlmhe35/Xdgyo3/0rQKg7YA==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "@sinonjs/commons": "^3.0.0"
      }
    },
    "node_modules/@socket.io/component-emitter": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/@socket.io/component-emitter/-/component-emitter-3.1.2.tgz",
      "integrity": "sha512-9BCxFwvbGg/RsZK9tjXd8s4UcwR0MWeFQ1XEKIQVVvAGJyINdrqKMcTRyLoK8Rse1GjzLV9cwjWV1olXRWEXVA==",
      "license": "MIT"
    },
    "node_modules/@types/babel__core": {
      "version": "7.20.5",
      "resolved": "https://registry.npmjs.org/@types/babel__core/-/babel__core-7.20.5.tgz",
      "integrity": "sha512-qoQprZvz5wQFJwMDqeseRXWv3rqMvhgpbXFfVyWhbx9X47POIA6i/+dXefEmZKoAgOaTdaIgNSMqMIU61yRyzA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/parser": "^7.20.7",
        "@babel/types": "^7.20.7",
        "@types/babel__generator": "*",
        "@types/babel__template": "*",
        "@types/babel__traverse": "*"
      }
    },
    "node_modules/@types/babel__generator": {
      "version": "7.6.8",
      "resolved": "https://registry.npmjs.org/@types/babel__generator/-/babel__generator-7.6.8.tgz",
      "integrity": "sha512-ASsj+tpEDsEiFr1arWrlN6V3mdfjRMZt6LtK/Vp/kreFLnr5QH5+DhvD5nINYZXzwJvXeGq+05iUXcAzVrqWtw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/types": "^7.0.0"
      }
    },
    "node_modules/@types/babel__template": {
      "version": "7.4.4",
      "resolved": "https://registry.npmjs.org/@types/babel__template/-/babel__template-7.4.4.tgz",
      "integrity": "sha512-h/NUaSyG5EyxBIp8YRxo4RMe2/qQgvyowRwVMzhYhBCONbW8PUsg4lkFMrhgZhUe5z3L3MiLDuvyJ/CaPa2A8A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/parser": "^7.1.0",
        "@babel/types": "^7.0.0"
      }
    },
    "node_modules/@types/babel__traverse": {
      "version": "7.20.6",
      "resolved": "https://registry.npmjs.org/@types/babel__traverse/-/babel__traverse-7.20.6.tgz",
      "integrity": "sha512-r1bzfrm0tomOI8g1SzvCaQHo6Lcv6zu0EA+W2kHrt8dyrHQxGzBBL4kdkzIS+jBMV+EYcMAEAqXqYaLJq5rOZg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/types": "^7.20.7"
      }
    },
    "node_modules/@types/cors": {
      "version": "2.8.17",
      "resolved": "https://registry.npmjs.org/@types/cors/-/cors-2.8.17.tgz",
      "integrity": "sha512-8CGDvrBj1zgo2qE+oS3pOCyYNqCPryMWY2bGfwA0dcfopWGgxs+78df0Rs3rc9THP4JkOhLsAa+15VdpAqkcUA==",
      "license": "MIT",
      "dependencies": {
        "@types/node": "*"
      }
    },
    "node_modules/@types/graceful-fs": {
      "version": "4.1.9",
      "resolved": "https://registry.npmjs.org/@types/graceful-fs/-/graceful-fs-4.1.9.tgz",
      "integrity": "sha512-olP3sd1qOEe5dXTSaFvQG+02VdRXcdytWLAZsAq1PecU8uqQAhkrnbli7DagjtXKW/Bl7YJbUsa8MPcuc8LHEQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/node": "*"
      }
    },
    "node_modules/@types/istanbul-lib-coverage": {
      "version": "2.0.6",
      "resolved": "https://registry.npmjs.org/@types/istanbul-lib-coverage/-/istanbul-lib-coverage-2.0.6.tgz",
      "integrity": "sha512-2QF/t/auWm0lsy8XtKVPG19v3sSOQlJe/YHZgfjb/KBBHOGSV+J2q/S671rcq9uTBrLAXmZpqJiaQbMT+zNU1w==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@types/istanbul-lib-report": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/@types/istanbul-lib-report/-/istanbul-lib-report-3.0.3.tgz",
      "integrity": "sha512-NQn7AHQnk/RSLOxrBbGyJM/aVQ+pjj5HCgasFxc0K/KhoATfQ/47AyUl15I2yBUpihjmas+a+VJBOqecrFH+uA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/istanbul-lib-coverage": "*"
      }
    },
    "node_modules/@types/istanbul-reports": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/@types/istanbul-reports/-/istanbul-reports-3.0.4.tgz",
      "integrity": "sha512-pk2B1NWalF9toCRu6gjBzR69syFjP4Od8WRAX+0mmf9lAjCRicLOWc+ZrxZHx/0XRjotgkF9t6iaMJ+aXcOdZQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/istanbul-lib-report": "*"
      }
    },
    "node_modules/@types/node": {
      "version": "22.13.10",
      "resolved": "https://registry.npmjs.org/@types/node/-/node-22.13.10.tgz",
      "integrity": "sha512-I6LPUvlRH+O6VRUqYOcMudhaIdUVWfsjnZavnsraHvpBwaEyMN29ry+0UVJhImYL16xsscu0aske3yA+uPOWfw==",
      "license": "MIT",
      "dependencies": {
        "undici-types": "~6.20.0"
      }
    },
    "node_modules/@types/stack-utils": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/@types/stack-utils/-/stack-utils-2.0.3.tgz",
      "integrity": "sha512-9aEbYZ3TbYMznPdcdr3SmIrLXwC/AKZXQeCf9Pgao5CKb8CyHuEX5jzWPTkvregvhRJHcpRO6BFoGW9ycaOkYw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@types/triple-beam": {
      "version": "1.3.5",
      "resolved": "https://registry.npmjs.org/@types/triple-beam/-/triple-beam-1.3.5.tgz",
      "integrity": "sha512-6WaYesThRMCl19iryMYP7/x2OVgCtbIVflDGFpWnb9irXI3UjYE4AzmYuiUKY1AJstGijoY+MgUszMgRxIYTYw==",
      "license": "MIT"
    },
    "node_modules/@types/yargs": {
      "version": "17.0.33",
      "resolved": "https://registry.npmjs.org/@types/yargs/-/yargs-17.0.33.tgz",
      "integrity": "sha512-WpxBCKWPLr4xSsHgz511rFJAM+wS28w2zEO1QDNY5zM/S8ok70NNfztH0xwhqKyaK0OHCbN98LDAZuy1ctxDkA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/yargs-parser": "*"
      }
    },
    "node_modules/@types/yargs-parser": {
      "version": "21.0.3",
      "resolved": "https://registry.npmjs.org/@types/yargs-parser/-/yargs-parser-21.0.3.tgz",
      "integrity": "sha512-I4q9QU9MQv4oEOz4tAHJtNz1cwuLxn2F3xcc2iV5WdqLPpUnj30aUuxt1mAxYTG+oe8CZMV/+6rU4S4gRDzqtQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/accepts": {
      "version": "1.3.8",
      "resolved": "https://registry.npmjs.org/accepts/-/accepts-1.3.8.tgz",
      "integrity": "sha512-PYAthTa2m2VKxuvSD3DPC/Gy+U+sOA1LAuT8mkmRuvw+NACSaeXEQ+NHcVF7rONl6qcaxV3Uuemwawk+7+SJLw==",
      "license": "MIT",
      "dependencies": {
        "mime-types": "~2.1.34",
        "negotiator": "0.6.3"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/accepts/node_modules/negotiator": {
      "version": "0.6.3",
      "resolved": "https://registry.npmjs.org/negotiator/-/negotiator-0.6.3.tgz",
      "integrity": "sha512-+EUsqGPLsM+j/zdChZjsnX51g4XrHFOIXwfnCVPGlQk/k5giakcKsuxCObBRu6DSm9opw/O6slWbJdghQM4bBg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/ansi-escapes": {
      "version": "4.3.2",
      "resolved": "https://registry.npmjs.org/ansi-escapes/-/ansi-escapes-4.3.2.tgz",
      "integrity": "sha512-gKXj5ALrKWQLsYG9jlTRmR/xKluxHV+Z9QEwNIgCfM1/uwPMCuzVVnh5mwTd+OuBZcwSIMbqssNWRm1lE51QaQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "type-fest": "^0.21.3"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/ansi-regex": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-5.0.1.tgz",
      "integrity": "sha512-quJQXlTSUGL2LH9SUXo8VwsY4soanhgo6LNSm84E1LBcE8s3O0wpdiRzyR9z/ZZJMlMWv37qOOb9pdJlMUEKFQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/ansi-styles": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-4.3.0.tgz",
      "integrity": "sha512-zbB9rCJAT1rbjiVDb2hqKFHNYLxgtk8NURxZ3IZwD3F6NtxbXZQCnnSi1Lkx+IDohdPlFp222wVALIheZJQSEg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "color-convert": "^2.0.1"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/anymatch": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/anymatch/-/anymatch-3.1.3.tgz",
      "integrity": "sha512-KMReFUr0B4t+D+OBkjR3KYqvocp2XaSzO55UcB6mgQMd3KbcE+mWTyvVV7D/zsdEbNnV6acZUutkiHQXvTr1Rw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "normalize-path": "^3.0.0",
        "picomatch": "^2.0.4"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/argparse": {
      "version": "1.0.10",
      "resolved": "https://registry.npmjs.org/argparse/-/argparse-1.0.10.tgz",
      "integrity": "sha512-o5Roy6tNG4SL/FOkCAN6RzjiakZS25RLYFrcMttJqbdd8BWrnA+fGz57iN5Pb06pvBGvl5gQ0B48dJlslXvoTg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "sprintf-js": "~1.0.2"
      }
    },
    "node_modules/array-flatten": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/array-flatten/-/array-flatten-1.1.1.tgz",
      "integrity": "sha512-PCVAQswWemu6UdxsDFFX/+gVeYqKAod3D3UVm91jHwynguOwAvYPhx8nNlM++NqRcK6CxxpUafjmhIdKiHibqg==",
      "license": "MIT"
    },
    "node_modules/async": {
      "version": "3.2.6",
      "resolved": "https://registry.npmjs.org/async/-/async-3.2.6.tgz",
      "integrity": "sha512-htCUDlxyyCLMgaM3xXg0C0LW2xqfuQ6p05pCEIsXuyQ+a1koYKTuBMzRNwmybfLgvJDMd0r1LTn4+E0Ti6C2AA==",
      "license": "MIT"
    },
    "node_modules/babel-jest": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/babel-jest/-/babel-jest-29.7.0.tgz",
      "integrity": "sha512-BrvGY3xZSwEcCzKvKsCi2GgHqDqsYkOP4/by5xCgIwGXQxIEh+8ew3gmrE1y7XRR6LHZIj6yLYnUi/mm2KXKBg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/transform": "^29.7.0",
        "@types/babel__core": "^7.1.14",
        "babel-plugin-istanbul": "^6.1.1",
        "babel-preset-jest": "^29.6.3",
        "chalk": "^4.0.0",
        "graceful-fs": "^4.2.9",
        "slash": "^3.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.8.0"
      }
    },
    "node_modules/babel-plugin-istanbul": {
      "version": "6.1.1",
      "resolved": "https://registry.npmjs.org/babel-plugin-istanbul/-/babel-plugin-istanbul-6.1.1.tgz",
      "integrity": "sha512-Y1IQok9821cC9onCx5otgFfRm7Lm+I+wwxOx738M/WLPZ9Q42m4IG5W0FNX8WLL2gYMZo3JkuXIH2DOpWM+qwA==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@istanbuljs/load-nyc-config": "^1.0.0",
        "@istanbuljs/schema": "^0.1.2",
        "istanbul-lib-instrument": "^5.0.4",
        "test-exclude": "^6.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/babel-plugin-istanbul/node_modules/istanbul-lib-instrument": {
      "version": "5.2.1",
      "resolved": "https://registry.npmjs.org/istanbul-lib-instrument/-/istanbul-lib-instrument-5.2.1.tgz",
      "integrity": "sha512-pzqtp31nLv/XFOzXGuvhCb8qhjmTVo5vjVk19XE4CRlSWz0KoeJ3bw9XsA7nOp9YBf4qHjwBxkDzKcME/J29Yg==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "@babel/core": "^7.12.3",
        "@babel/parser": "^7.14.7",
        "@istanbuljs/schema": "^0.1.2",
        "istanbul-lib-coverage": "^3.2.0",
        "semver": "^6.3.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/babel-plugin-jest-hoist": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/babel-plugin-jest-hoist/-/babel-plugin-jest-hoist-29.6.3.tgz",
      "integrity": "sha512-ESAc/RJvGTFEzRwOTT4+lNDk/GNHMkKbNzsvT0qKRfDyyYTskxB5rnU2njIDYVxXCBHHEI1c0YwHob3WaYujOg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/template": "^7.3.3",
        "@babel/types": "^7.3.3",
        "@types/babel__core": "^7.1.14",
        "@types/babel__traverse": "^7.0.6"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/babel-preset-current-node-syntax": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/babel-preset-current-node-syntax/-/babel-preset-current-node-syntax-1.1.0.tgz",
      "integrity": "sha512-ldYss8SbBlWva1bs28q78Ju5Zq1F+8BrqBZZ0VFhLBvhh6lCpC2o3gDJi/5DRLs9FgYZCnmPYIVFU4lRXCkyUw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/plugin-syntax-async-generators": "^7.8.4",
        "@babel/plugin-syntax-bigint": "^7.8.3",
        "@babel/plugin-syntax-class-properties": "^7.12.13",
        "@babel/plugin-syntax-class-static-block": "^7.14.5",
        "@babel/plugin-syntax-import-attributes": "^7.24.7",
        "@babel/plugin-syntax-import-meta": "^7.10.4",
        "@babel/plugin-syntax-json-strings": "^7.8.3",
        "@babel/plugin-syntax-logical-assignment-operators": "^7.10.4",
        "@babel/plugin-syntax-nullish-coalescing-operator": "^7.8.3",
        "@babel/plugin-syntax-numeric-separator": "^7.10.4",
        "@babel/plugin-syntax-object-rest-spread": "^7.8.3",
        "@babel/plugin-syntax-optional-catch-binding": "^7.8.3",
        "@babel/plugin-syntax-optional-chaining": "^7.8.3",
        "@babel/plugin-syntax-private-property-in-object": "^7.14.5",
        "@babel/plugin-syntax-top-level-await": "^7.14.5"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/babel-preset-jest": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/babel-preset-jest/-/babel-preset-jest-29.6.3.tgz",
      "integrity": "sha512-0B3bhxR6snWXJZtR/RliHTDPRgn1sNHOR0yVtq/IiQFyuOVjFS+wuio/R4gSNkyYmKmJB4wGZv2NZanmKmTnNA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "babel-plugin-jest-hoist": "^29.6.3",
        "babel-preset-current-node-syntax": "^1.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/balanced-match": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/balanced-match/-/balanced-match-1.0.2.tgz",
      "integrity": "sha512-3oSeUO0TMV67hN1AmbXsK4yaqU7tjiHlbxRDZOpH0KW9+CeX4bRAaX0Anxt0tx2MrpRpWwQaPwIlISEJhYU5Pw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/base64id": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/base64id/-/base64id-2.0.0.tgz",
      "integrity": "sha512-lGe34o6EHj9y3Kts9R4ZYs/Gr+6N7MCaMlIFA3F1R2O5/m7K06AxfSeO5530PEERE6/WyEg3lsuyw4GHlPZHog==",
      "license": "MIT",
      "engines": {
        "node": "^4.5.0 || >= 5.9"
      }
    },
    "node_modules/basic-auth": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/basic-auth/-/basic-auth-2.0.1.tgz",
      "integrity": "sha512-NF+epuEdnUYVlGuhaxbbq+dvJttwLnGY+YixlXlME5KpQ5W3CnXA5cVTneY3SPbPDRkcjMbifrwmFYcClgOZeg==",
      "license": "MIT",
      "dependencies": {
        "safe-buffer": "5.1.2"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/basic-auth/node_modules/safe-buffer": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/safe-buffer/-/safe-buffer-5.1.2.tgz",
      "integrity": "sha512-Gd2UZBJDkXlY7GbJxfsE8/nvKkUEU1G38c1siN6QP6a9PT9MmHB8GnpscSmMJSoF8LOIrt8ud/wPtojys4G6+g==",
      "license": "MIT"
    },
    "node_modules/binary-extensions": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/binary-extensions/-/binary-extensions-2.3.0.tgz",
      "integrity": "sha512-Ceh+7ox5qe7LJuLHoY0feh3pHuUDHAcRUeyL2VYghZwfpkNIy/+8Ocg0a3UuSoYzavmylwuLWQOf3hl0jjMMIw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/bintrees": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/bintrees/-/bintrees-1.0.2.tgz",
      "integrity": "sha512-VOMgTMwjAaUG580SXn3LacVgjurrbMme7ZZNYGSSV7mmtY6QQRh0Eg3pwIcntQ77DErK1L0NxkbetjcoXzVwKw==",
      "license": "MIT"
    },
    "node_modules/body-parser": {
      "version": "1.20.3",
      "resolved": "https://registry.npmjs.org/body-parser/-/body-parser-1.20.3.tgz",
      "integrity": "sha512-7rAxByjUMqQ3/bHJy7D6OGXvx/MMc4IqBn/X0fcM1QUcAItpZrBEYhWGem+tzXH90c+G01ypMcYJBO9Y30203g==",
      "license": "MIT",
      "dependencies": {
        "bytes": "3.1.2",
        "content-type": "~1.0.5",
        "debug": "2.6.9",
        "depd": "2.0.0",
        "destroy": "1.2.0",
        "http-errors": "2.0.0",
        "iconv-lite": "0.4.24",
        "on-finished": "2.4.1",
        "qs": "6.13.0",
        "raw-body": "2.5.2",
        "type-is": "~1.6.18",
        "unpipe": "1.0.0"
      },
      "engines": {
        "node": ">= 0.8",
        "npm": "1.2.8000 || >= 1.4.16"
      }
    },
    "node_modules/brace-expansion": {
      "version": "1.1.11",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.11.tgz",
      "integrity": "sha512-iCuPHDFgrHX7H2vEI/5xpz07zSHB00TpugqhmYtVmMO6518mCuRMoOYFldEBl0g187ufozdaHgWKcYFb61qGiA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "node_modules/braces": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/braces/-/braces-3.0.3.tgz",
      "integrity": "sha512-yQbXgO/OSZVD2IsiLlro+7Hf6Q18EJrKSEsdoMzKePKXct3gvD8oLcOQdIzGupr5Fj+EDe8gO/lxc1BzfMpxvA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fill-range": "^7.1.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/browserslist": {
      "version": "4.24.4",
      "resolved": "https://registry.npmjs.org/browserslist/-/browserslist-4.24.4.tgz",
      "integrity": "sha512-KDi1Ny1gSePi1vm0q4oxSF8b4DR44GF4BbmS2YdhPLOEqd8pDviZOGH/GsmRwoWJ2+5Lr085X7naowMwKHDG1A==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/browserslist"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "caniuse-lite": "^1.0.30001688",
        "electron-to-chromium": "^1.5.73",
        "node-releases": "^2.0.19",
        "update-browserslist-db": "^1.1.1"
      },
      "bin": {
        "browserslist": "cli.js"
      },
      "engines": {
        "node": "^6 || ^7 || ^8 || ^9 || ^10 || ^11 || ^12 || >=13.7"
      }
    },
    "node_modules/bser": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/bser/-/bser-2.1.1.tgz",
      "integrity": "sha512-gQxTNE/GAfIIrmHLUE3oJyp5FO6HRBfhjnw4/wMmA63ZGDJnWBmgY/lyQBpnDUkGmAhbSe39tx2d/iTOAfglwQ==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "node-int64": "^0.4.0"
      }
    },
    "node_modules/buffer-equal-constant-time": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/buffer-equal-constant-time/-/buffer-equal-constant-time-1.0.1.tgz",
      "integrity": "sha512-zRpUiDwd/xk6ADqPMATG8vc9VPrkck7T07OIx0gnjmJAnHnTVXNQG3vfvWNuiZIkwu9KrKdA1iJKfsfTVxE6NA==",
      "license": "BSD-3-Clause"
    },
    "node_modules/buffer-from": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/buffer-from/-/buffer-from-1.1.2.tgz",
      "integrity": "sha512-E+XQCRwSbaaiChtv6k6Dwgc+bx+Bs6vuKJHHl5kox/BaKbhiXzqQOwK4cO22yElGp2OCmjwVhT3HmxgyPGnJfQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/bytes": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/bytes/-/bytes-3.1.2.tgz",
      "integrity": "sha512-/Nf7TyzTx6S3yRJObOAV7956r8cr2+Oj8AC5dt8wSP3BQAoeX58NoHyCU8P8zGkNXStjTSi6fzO6F0pBdcYbEg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/call-bind-apply-helpers": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/call-bind-apply-helpers/-/call-bind-apply-helpers-1.0.2.tgz",
      "integrity": "sha512-Sp1ablJ0ivDkSzjcaJdxEunN5/XvksFJ2sMBFfq6x0ryhQV/2b/KwFe21cMpmHtPOSij8K99/wSfoEuTObmuMQ==",
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/call-bound": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/call-bound/-/call-bound-1.0.4.tgz",
      "integrity": "sha512-+ys997U96po4Kx/ABpBCqhA9EuxJaQWDQg7295H4hBphv3IZg0boBKuwYpt4YXp6MZ5AmZQnU/tyMTlRpaSejg==",
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.2",
        "get-intrinsic": "^1.3.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/callsites": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/callsites/-/callsites-3.1.0.tgz",
      "integrity": "sha512-P8BjAsXvZS+VIDUI11hHCQEv74YT67YUi5JJFNWIqL235sBmjX4+qx9Muvls5ivyNENctx46xQLQ3aTuE7ssaQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/camelcase": {
      "version": "5.3.1",
      "resolved": "https://registry.npmjs.org/camelcase/-/camelcase-5.3.1.tgz",
      "integrity": "sha512-L28STB170nwWS63UjtlEOE3dldQApaJXZkOI1uMFfzf3rRuPegHaHesyee+YxQ+W6SvRDQV6UrdOdRiR153wJg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/caniuse-lite": {
      "version": "1.0.30001702",
      "resolved": "https://registry.npmjs.org/caniuse-lite/-/caniuse-lite-1.0.30001702.tgz",
      "integrity": "sha512-LoPe/D7zioC0REI5W73PeR1e1MLCipRGq/VkovJnd6Df+QVqT+vT33OXCp8QUd7kA7RZrHWxb1B36OQKI/0gOA==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/caniuse-lite"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "CC-BY-4.0"
    },
    "node_modules/chalk": {
      "version": "4.1.2",
      "resolved": "https://registry.npmjs.org/chalk/-/chalk-4.1.2.tgz",
      "integrity": "sha512-oKnbhFyRIXpUuez8iBMmyEa4nbj4IOQyuhc/wy9kY7/WVPcwIO9VA668Pu8RkO7+0G76SLROeyw9CpQ061i4mA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^4.1.0",
        "supports-color": "^7.1.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/chalk?sponsor=1"
      }
    },
    "node_modules/char-regex": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/char-regex/-/char-regex-1.0.2.tgz",
      "integrity": "sha512-kWWXztvZ5SBQV+eRgKFeh8q5sLuZY2+8WUIzlxWVTg+oGwY14qylx1KbKzHd8P6ZYkAg0xyIDU9JMHhyJMZ1jw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/chokidar": {
      "version": "3.6.0",
      "resolved": "https://registry.npmjs.org/chokidar/-/chokidar-3.6.0.tgz",
      "integrity": "sha512-7VT13fmjotKpGipCW9JEQAusEPE+Ei8nl6/g4FBAmIm0GOOLMua9NDDo/DWp0ZAxCr3cPq5ZpBqmPAQgDda2Pw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "anymatch": "~3.1.2",
        "braces": "~3.0.2",
        "glob-parent": "~5.1.2",
        "is-binary-path": "~2.1.0",
        "is-glob": "~4.0.1",
        "normalize-path": "~3.0.0",
        "readdirp": "~3.6.0"
      },
      "engines": {
        "node": ">= 8.10.0"
      },
      "funding": {
        "url": "https://paulmillr.com/funding/"
      },
      "optionalDependencies": {
        "fsevents": "~2.3.2"
      }
    },
    "node_modules/ci-info": {
      "version": "3.9.0",
      "resolved": "https://registry.npmjs.org/ci-info/-/ci-info-3.9.0.tgz",
      "integrity": "sha512-NIxF55hv4nSqQswkAeiOi1r83xy8JldOFDTWiug55KBu9Jnblncd2U6ViHmYgHf01TPZS77NJBhBMKdWj9HQMQ==",
      "dev": true,
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/sibiraj-s"
        }
      ],
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/cjs-module-lexer": {
      "version": "1.4.3",
      "resolved": "https://registry.npmjs.org/cjs-module-lexer/-/cjs-module-lexer-1.4.3.tgz",
      "integrity": "sha512-9z8TZaGM1pfswYeXrUpzPrkx8UnWYdhJclsiYMm6x/w5+nN+8Tf/LnAgfLGQCm59qAOxU8WwHEq2vNwF6i4j+Q==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/cliui": {
      "version": "8.0.1",
      "resolved": "https://registry.npmjs.org/cliui/-/cliui-8.0.1.tgz",
      "integrity": "sha512-BSeNnyus75C4//NQ9gQt1/csTXyo/8Sb+afLAkzAptFuMsod9HFokGNudZpi/oQV73hnVK+sR+5PVRMd+Dr7YQ==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "string-width": "^4.2.0",
        "strip-ansi": "^6.0.1",
        "wrap-ansi": "^7.0.0"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/cluster-key-slot": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/cluster-key-slot/-/cluster-key-slot-1.1.2.tgz",
      "integrity": "sha512-RMr0FhtfXemyinomL4hrWcYJxmX6deFdCxpJzhDttxgO1+bcCnkk+9drydLVDmAMG7NE6aN/fl4F7ucU/90gAA==",
      "license": "Apache-2.0",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/co": {
      "version": "4.6.0",
      "resolved": "https://registry.npmjs.org/co/-/co-4.6.0.tgz",
      "integrity": "sha512-QVb0dM5HvG+uaxitm8wONl7jltx8dqhfU33DcqtOZcLSVIKSDDLDi7+0LbAKiyI8hD9u42m2YxXSkMGWThaecQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "iojs": ">= 1.0.0",
        "node": ">= 0.12.0"
      }
    },
    "node_modules/collect-v8-coverage": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/collect-v8-coverage/-/collect-v8-coverage-1.0.2.tgz",
      "integrity": "sha512-lHl4d5/ONEbLlJvaJNtsF/Lz+WvB07u2ycqTYbdrq7UypDXailES4valYb2eWiJFxZlVmpGekfqoxQhzyFdT4Q==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/color": {
      "version": "3.2.1",
      "resolved": "https://registry.npmjs.org/color/-/color-3.2.1.tgz",
      "integrity": "sha512-aBl7dZI9ENN6fUGC7mWpMTPNHmWUSNan9tuWN6ahh5ZLNk9baLJOnSMlrQkHcrfFgz2/RigjUVAjdx36VcemKA==",
      "license": "MIT",
      "dependencies": {
        "color-convert": "^1.9.3",
        "color-string": "^1.6.0"
      }
    },
    "node_modules/color-convert": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/color-convert/-/color-convert-2.0.1.tgz",
      "integrity": "sha512-RRECPsj7iu/xb5oKYcsFHSppFNnsj/52OVTRKb4zP5onXwVF3zVmmToNcOfGC+CRDpfK/U584fMg38ZHCaElKQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "color-name": "~1.1.4"
      },
      "engines": {
        "node": ">=7.0.0"
      }
    },
    "node_modules/color-name": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/color-name/-/color-name-1.1.4.tgz",
      "integrity": "sha512-dOy+3AuW3a2wNbZHIuMZpTcgjGuLU/uBL/ubcZF9OXbDo8ff4O8yVp5Bf0efS8uEoYo5q4Fx7dY9OgQGXgAsQA==",
      "license": "MIT"
    },
    "node_modules/color-string": {
      "version": "1.9.1",
      "resolved": "https://registry.npmjs.org/color-string/-/color-string-1.9.1.tgz",
      "integrity": "sha512-shrVawQFojnZv6xM40anx4CkoDP+fZsw/ZerEMsW/pyzsRbElpsL/DBVW7q3ExxwusdNXI3lXpuhEZkzs8p5Eg==",
      "license": "MIT",
      "dependencies": {
        "color-name": "^1.0.0",
        "simple-swizzle": "^0.2.2"
      }
    },
    "node_modules/color/node_modules/color-convert": {
      "version": "1.9.3",
      "resolved": "https://registry.npmjs.org/color-convert/-/color-convert-1.9.3.tgz",
      "integrity": "sha512-QfAUtd+vFdAtFQcC8CCyYt1fYWxSqAiK2cSD6zDB8N3cpsEBAvRxp9zOGg6G/SHHJYAT88/az/IuDGALsNVbGg==",
      "license": "MIT",
      "dependencies": {
        "color-name": "1.1.3"
      }
    },
    "node_modules/color/node_modules/color-name": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/color-name/-/color-name-1.1.3.tgz",
      "integrity": "sha512-72fSenhMw2HZMTVHeCA9KCmpEIbzWiQsjN+BHcBbS9vr1mtt+vJjPdksIBNUmKAW8TFUDPJK5SUU3QhE9NEXDw==",
      "license": "MIT"
    },
    "node_modules/colorspace": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/colorspace/-/colorspace-1.1.4.tgz",
      "integrity": "sha512-BgvKJiuVu1igBUF2kEjRCZXol6wiiGbY5ipL/oVPwm0BL9sIpMIzM8IK7vwuxIIzOXMV3Ey5w+vxhm0rR/TN8w==",
      "license": "MIT",
      "dependencies": {
        "color": "^3.1.3",
        "text-hex": "1.0.x"
      }
    },
    "node_modules/compressible": {
      "version": "2.0.18",
      "resolved": "https://registry.npmjs.org/compressible/-/compressible-2.0.18.tgz",
      "integrity": "sha512-AF3r7P5dWxL8MxyITRMlORQNaOA2IkAFaTr4k7BUumjPtRpGDTZpl0Pb1XCO6JeDCBdp126Cgs9sMxqSjgYyRg==",
      "license": "MIT",
      "dependencies": {
        "mime-db": ">= 1.43.0 < 2"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/compression": {
      "version": "1.8.0",
      "resolved": "https://registry.npmjs.org/compression/-/compression-1.8.0.tgz",
      "integrity": "sha512-k6WLKfunuqCYD3t6AsuPGvQWaKwuLLh2/xHNcX4qE+vIfDNXpSqnrhwA7O53R7WVQUnt8dVAIW+YHr7xTgOgGA==",
      "license": "MIT",
      "dependencies": {
        "bytes": "3.1.2",
        "compressible": "~2.0.18",
        "debug": "2.6.9",
        "negotiator": "~0.6.4",
        "on-headers": "~1.0.2",
        "safe-buffer": "5.2.1",
        "vary": "~1.1.2"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/concat-map": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/concat-map/-/concat-map-0.0.1.tgz",
      "integrity": "sha512-/Srv4dswyQNBfohGpz9o6Yb3Gz3SrUDqBH5rTuhGR7ahtlbYKnVxw2bCFMRljaA7EXHaXZ8wsHdodFvbkhKmqg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/content-disposition": {
      "version": "0.5.4",
      "resolved": "https://registry.npmjs.org/content-disposition/-/content-disposition-0.5.4.tgz",
      "integrity": "sha512-FveZTNuGw04cxlAiWbzi6zTAL/lhehaWbTtgluJh4/E95DqMwTmha3KZN1aAWA8cFIhHzMZUvLevkw5Rqk+tSQ==",
      "license": "MIT",
      "dependencies": {
        "safe-buffer": "5.2.1"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/content-type": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/content-type/-/content-type-1.0.5.tgz",
      "integrity": "sha512-nTjqfcBFEipKdXCv4YDQWCfmcLZKm81ldF0pAopTvyrFGVbcR6P/VAAd5G7N+0tTr8QqiU0tFadD6FK4NtJwOA==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/convert-source-map": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/convert-source-map/-/convert-source-map-2.0.0.tgz",
      "integrity": "sha512-Kvp459HrV2FEJ1CAsi1Ku+MY3kasH19TFykTz2xWmMeq6bk2NU3XXvfJ+Q61m0xktWwt+1HSYf3JZsTms3aRJg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/cookie": {
      "version": "0.7.1",
      "resolved": "https://registry.npmjs.org/cookie/-/cookie-0.7.1.tgz",
      "integrity": "sha512-6DnInpx7SJ2AK3+CTUE/ZM0vWTUboZCegxhC2xiIydHR9jNuTAASBrfEpHhiGOZw/nX51bHt6YQl8jsGo4y/0w==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/cookie-signature": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/cookie-signature/-/cookie-signature-1.0.6.tgz",
      "integrity": "sha512-QADzlaHc8icV8I7vbaJXJwod9HWYp8uCqf1xa4OfNu1T7JVxQIrUgOWtHdNDtPiywmFbiS12VjotIXLrKM3orQ==",
      "license": "MIT"
    },
    "node_modules/cors": {
      "version": "2.8.5",
      "resolved": "https://registry.npmjs.org/cors/-/cors-2.8.5.tgz",
      "integrity": "sha512-KIHbLJqu73RGr/hnbrO9uBeixNGuvSQjul/jdFvS/KFSIH1hWVd1ng7zOHx+YrEfInLG7q4n6GHQ9cDtxv/P6g==",
      "license": "MIT",
      "dependencies": {
        "object-assign": "^4",
        "vary": "^1"
      },
      "engines": {
        "node": ">= 0.10"
      }
    },
    "node_modules/create-jest": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/create-jest/-/create-jest-29.7.0.tgz",
      "integrity": "sha512-Adz2bdH0Vq3F53KEMJOoftQFutWCukm6J24wbPWRO4k1kMY7gS7ds/uoJkNuV8wDCtWWnuwGcJwpWcih+zEW1Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "chalk": "^4.0.0",
        "exit": "^0.1.2",
        "graceful-fs": "^4.2.9",
        "jest-config": "^29.7.0",
        "jest-util": "^29.7.0",
        "prompts": "^2.0.1"
      },
      "bin": {
        "create-jest": "bin/create-jest.js"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/cross-spawn": {
      "version": "7.0.6",
      "resolved": "https://registry.npmjs.org/cross-spawn/-/cross-spawn-7.0.6.tgz",
      "integrity": "sha512-uV2QOWP2nWzsy2aMp8aRibhi9dlzF5Hgh5SHaB9OiTGEyDTiJJyx0uy51QXdyWbtAHNua4XJzUKca3OzKUd3vA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "path-key": "^3.1.0",
        "shebang-command": "^2.0.0",
        "which": "^2.0.1"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/debug": {
      "version": "2.6.9",
      "resolved": "https://registry.npmjs.org/debug/-/debug-2.6.9.tgz",
      "integrity": "sha512-bC7ElrdJaJnPbAP+1EotYvqZsb3ecl5wi6Bfi6BJTUcNowp6cvspg0jXznRTKDjm/E7AdgFBVeAPVMNcKGsHMA==",
      "license": "MIT",
      "dependencies": {
        "ms": "2.0.0"
      }
    },
    "node_modules/dedent": {
      "version": "1.5.3",
      "resolved": "https://registry.npmjs.org/dedent/-/dedent-1.5.3.tgz",
      "integrity": "sha512-NHQtfOOW68WD8lgypbLA5oT+Bt0xXJhiYvoR6SmmNXZfpzOGXwdKWmcwG8N7PwVVWV3eF/68nmD9BaJSsTBhyQ==",
      "dev": true,
      "license": "MIT",
      "peerDependencies": {
        "babel-plugin-macros": "^3.1.0"
      },
      "peerDependenciesMeta": {
        "babel-plugin-macros": {
          "optional": true
        }
      }
    },
    "node_modules/deepmerge": {
      "version": "4.3.1",
      "resolved": "https://registry.npmjs.org/deepmerge/-/deepmerge-4.3.1.tgz",
      "integrity": "sha512-3sUqbMEc77XqpdNO7FRyRog+eW3ph+GYCbj+rK+uYyRMuwsVy0rMiVtPn+QJlKFvWP/1PYpapqYn0Me2knFn+A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/denque": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/denque/-/denque-2.1.0.tgz",
      "integrity": "sha512-HVQE3AAb/pxF8fQAoiqpvg9i3evqug3hoiwakOyZAwJm+6vZehbkYXZ0l4JxS+I3QxM97v5aaRNhj8v5oBhekw==",
      "license": "Apache-2.0",
      "engines": {
        "node": ">=0.10"
      }
    },
    "node_modules/depd": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/depd/-/depd-2.0.0.tgz",
      "integrity": "sha512-g7nH6P6dyDioJogAAGprGpCtVImJhpPk/roCzdb3fIh61/s/nPsfR6onyMwkCAR/OlC3yBC0lESvUoQEAssIrw==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/destroy": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/destroy/-/destroy-1.2.0.tgz",
      "integrity": "sha512-2sJGJTaXIIaR1w4iJSNoN0hnMY7Gpc/n8D4qSCJw8QqFWXf7cuAgnEHxBpweaVcPevC2l3KpjYCx3NypQQgaJg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.8",
        "npm": "1.2.8000 || >= 1.4.16"
      }
    },
    "node_modules/detect-newline": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/detect-newline/-/detect-newline-3.1.0.tgz",
      "integrity": "sha512-TLz+x/vEXm/Y7P7wn1EJFNLxYpUD4TgMosxY6fAVJUnJMbupHBOncxyWUG9OpTaH9EBD7uFI5LfEgmMOc54DsA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/diff-sequences": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/diff-sequences/-/diff-sequences-29.6.3.tgz",
      "integrity": "sha512-EjePK1srD3P08o2j4f0ExnylqRs5B9tJjcp9t1krH2qRi8CCdsYfwe9JgSLurFBWwq4uOlipzfk5fHNvwFKr8Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/dotenv": {
      "version": "16.4.7",
      "resolved": "https://registry.npmjs.org/dotenv/-/dotenv-16.4.7.tgz",
      "integrity": "sha512-47qPchRCykZC03FhkYAhrvwU4xDBFIj1QPqaarj6mdM/hgUzfPHcpkHJOn3mJAufFeeAxAzeGsr5X0M4k6fLZQ==",
      "license": "BSD-2-Clause",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://dotenvx.com"
      }
    },
    "node_modules/dunder-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/dunder-proto/-/dunder-proto-1.0.1.tgz",
      "integrity": "sha512-KIN/nDJBQRcXw0MLVhZE9iQHmG68qAVIBg9CqmUYjmQIhgij9U5MFvrqkUL5FbtyyzZuOeOt0zdeRe4UY7ct+A==",
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.1",
        "es-errors": "^1.3.0",
        "gopd": "^1.2.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/ecdsa-sig-formatter": {
      "version": "1.0.11",
      "resolved": "https://registry.npmjs.org/ecdsa-sig-formatter/-/ecdsa-sig-formatter-1.0.11.tgz",
      "integrity": "sha512-nagl3RYrbNv6kQkeJIpt6NJZy8twLB/2vtz6yN9Z4vRKHN4/QZJIEbqohALSgwKdnksuY3k5Addp5lg8sVoVcQ==",
      "license": "Apache-2.0",
      "dependencies": {
        "safe-buffer": "^5.0.1"
      }
    },
    "node_modules/ee-first": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/ee-first/-/ee-first-1.1.1.tgz",
      "integrity": "sha512-WMwm9LhRUo+WUaRN+vRuETqG89IgZphVSNkdFgeb6sS/E4OrDIN7t48CAewSHXc6C8lefD8KKfr5vY61brQlow==",
      "license": "MIT"
    },
    "node_modules/electron-to-chromium": {
      "version": "1.5.113",
      "resolved": "https://registry.npmjs.org/electron-to-chromium/-/electron-to-chromium-1.5.113.tgz",
      "integrity": "sha512-wjT2O4hX+wdWPJ76gWSkMhcHAV2PTMX+QetUCPYEdCIe+cxmgzzSSiGRCKW8nuh4mwKZlpv0xvoW7OF2X+wmHg==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/emittery": {
      "version": "0.13.1",
      "resolved": "https://registry.npmjs.org/emittery/-/emittery-0.13.1.tgz",
      "integrity": "sha512-DeWwawk6r5yR9jFgnDKYt4sLS0LmHJJi3ZOnb5/JdbYwj3nW+FxQnHIjhBKz8YLC7oRNPVM9NQ47I3CVx34eqQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sindresorhus/emittery?sponsor=1"
      }
    },
    "node_modules/emoji-regex": {
      "version": "8.0.0",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz",
      "integrity": "sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/enabled": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/enabled/-/enabled-2.0.0.tgz",
      "integrity": "sha512-AKrN98kuwOzMIdAizXGI86UFBoo26CL21UM763y1h/GMSJ4/OHU9k2YlsmBpyScFo/wbLzWQJBMCW4+IO3/+OQ==",
      "license": "MIT"
    },
    "node_modules/encodeurl": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/encodeurl/-/encodeurl-2.0.0.tgz",
      "integrity": "sha512-Q0n9HRi4m6JuGIV1eFlmvJB7ZEVxu93IrMyiMsGC0lrMJMWzRgx6WGquyfQgZVb31vhGgXnfmPNNXmxnOkRBrg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/engine.io": {
      "version": "6.6.4",
      "resolved": "https://registry.npmjs.org/engine.io/-/engine.io-6.6.4.tgz",
      "integrity": "sha512-ZCkIjSYNDyGn0R6ewHDtXgns/Zre/NT6Agvq1/WobF7JXgFff4SeDroKiCO3fNJreU9YG429Sc81o4w5ok/W5g==",
      "license": "MIT",
      "dependencies": {
        "@types/cors": "^2.8.12",
        "@types/node": ">=10.0.0",
        "accepts": "~1.3.4",
        "base64id": "2.0.0",
        "cookie": "~0.7.2",
        "cors": "~2.8.5",
        "debug": "~4.3.1",
        "engine.io-parser": "~5.2.1",
        "ws": "~8.17.1"
      },
      "engines": {
        "node": ">=10.2.0"
      }
    },
    "node_modules/engine.io-parser": {
      "version": "5.2.3",
      "resolved": "https://registry.npmjs.org/engine.io-parser/-/engine.io-parser-5.2.3.tgz",
      "integrity": "sha512-HqD3yTBfnBxIrbnM1DoD6Pcq8NECnh8d4As1Qgh0z5Gg3jRRIqijury0CL3ghu/edArpUYiYqQiDUQBIs4np3Q==",
      "license": "MIT",
      "engines": {
        "node": ">=10.0.0"
      }
    },
    "node_modules/engine.io/node_modules/cookie": {
      "version": "0.7.2",
      "resolved": "https://registry.npmjs.org/cookie/-/cookie-0.7.2.tgz",
      "integrity": "sha512-yki5XnKuf750l50uGTllt6kKILY4nQ1eNIQatoXEByZ5dWgnKqbnqmTrBE5B4N7lrMJKQ2ytWMiTO2o0v6Ew/w==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/engine.io/node_modules/debug": {
      "version": "4.3.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.3.7.tgz",
      "integrity": "sha512-Er2nc/H7RrMXZBFCEim6TCmMk02Z8vLC2Rbi1KEBggpo0fS6l0S1nnapwmIi3yW/+GOJap1Krg4w0Hg80oCqgQ==",
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/engine.io/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "license": "MIT"
    },
    "node_modules/error-ex": {
      "version": "1.3.2",
      "resolved": "https://registry.npmjs.org/error-ex/-/error-ex-1.3.2.tgz",
      "integrity": "sha512-7dFHNmqeFSEt2ZBsCriorKnn3Z2pj+fd9kmI6QoWw4//DL+icEBfc0U7qJCisqrTsKTjw4fNFy2pW9OqStD84g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-arrayish": "^0.2.1"
      }
    },
    "node_modules/es-define-property": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/es-define-property/-/es-define-property-1.0.1.tgz",
      "integrity": "sha512-e3nRfgfUZ4rNGL232gUgX06QNyyez04KdjFrF+LTRoOXmrOgFKDg4BCdsjW8EnT69eqdYGmRpJwiPVYNrCaW3g==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-errors": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/es-errors/-/es-errors-1.3.0.tgz",
      "integrity": "sha512-Zf5H2Kxt2xjTvbJvP2ZWLEICxA6j+hAmMzIlypy4xcBg1vKVnx89Wy0GbS+kf5cwCVFFzdCFh2XSCFNULS6csw==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-object-atoms": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/es-object-atoms/-/es-object-atoms-1.1.1.tgz",
      "integrity": "sha512-FGgH2h8zKNim9ljj7dankFPcICIK9Cp5bm+c2gQSYePhpaG5+esrLODihIorn+Pe6FGJzWhXQotPv73jTaldXA==",
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/escalade": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/escalade/-/escalade-3.2.0.tgz",
      "integrity": "sha512-WUj2qlxaQtO4g6Pq5c29GTcWGDyd8itL8zTlipgECz3JesAiiOKotd8JU6otB3PACgG6xkJUyVhboMS+bje/jA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/escape-html": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/escape-html/-/escape-html-1.0.3.tgz",
      "integrity": "sha512-NiSupZ4OeuGwr68lGIeym/ksIZMJodUGOSCZ/FSnTxcrekbvqrgdUxlJOMpijaKZVjAJrWrGs/6Jy8OMuyj9ow==",
      "license": "MIT"
    },
    "node_modules/escape-string-regexp": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/escape-string-regexp/-/escape-string-regexp-2.0.0.tgz",
      "integrity": "sha512-UpzcLCXolUWcNu5HtVMHYdXJjArjsF9C0aNnquZYY4uW/Vu0miy5YoWvbV345HauVvcAUnpRuhMMcqTcGOY2+w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/esprima": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/esprima/-/esprima-4.0.1.tgz",
      "integrity": "sha512-eGuFFw7Upda+g4p+QHvnW0RyTX/SVeJBDM/gCtMARO0cLuT2HcEKnTPvhjV6aGeqrCB/sbNop0Kszm0jsaWU4A==",
      "dev": true,
      "license": "BSD-2-Clause",
      "bin": {
        "esparse": "bin/esparse.js",
        "esvalidate": "bin/esvalidate.js"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/etag": {
      "version": "1.8.1",
      "resolved": "https://registry.npmjs.org/etag/-/etag-1.8.1.tgz",
      "integrity": "sha512-aIL5Fx7mawVa300al2BnEE4iNvo1qETxLrPI/o05L7z6go7fCw1J6EQmbK4FmJ2AS7kgVF/KEZWufBfdClMcPg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/execa": {
      "version": "5.1.1",
      "resolved": "https://registry.npmjs.org/execa/-/execa-5.1.1.tgz",
      "integrity": "sha512-8uSpZZocAZRBAPIEINJj3Lo9HyGitllczc27Eh5YYojjMFMn8yHMDMaUHE2Jqfq05D/wucwI4JGURyXt1vchyg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "cross-spawn": "^7.0.3",
        "get-stream": "^6.0.0",
        "human-signals": "^2.1.0",
        "is-stream": "^2.0.0",
        "merge-stream": "^2.0.0",
        "npm-run-path": "^4.0.1",
        "onetime": "^5.1.2",
        "signal-exit": "^3.0.3",
        "strip-final-newline": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sindresorhus/execa?sponsor=1"
      }
    },
    "node_modules/exit": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/exit/-/exit-0.1.2.tgz",
      "integrity": "sha512-Zk/eNKV2zbjpKzrsQ+n1G6poVbErQxJ0LBOJXaKZ1EViLzH+hrLu9cdXI4zw9dBQJslwBEpbQ2P1oS7nDxs6jQ==",
      "dev": true,
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/expect": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/expect/-/expect-29.7.0.tgz",
      "integrity": "sha512-2Zks0hf1VLFYI1kbh0I5jP3KHHyCHpkfyHBzsSXRFgl/Bg9mWYfMW8oD+PdMPlEwy5HNsR9JutYy6pMeOh61nw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/expect-utils": "^29.7.0",
        "jest-get-type": "^29.6.3",
        "jest-matcher-utils": "^29.7.0",
        "jest-message-util": "^29.7.0",
        "jest-util": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/express": {
      "version": "4.21.2",
      "resolved": "https://registry.npmjs.org/express/-/express-4.21.2.tgz",
      "integrity": "sha512-28HqgMZAmih1Czt9ny7qr6ek2qddF4FclbMzwhCREB6OFfH+rXAnuNCwo1/wFvrtbgsQDb4kSbX9de9lFbrXnA==",
      "license": "MIT",
      "dependencies": {
        "accepts": "~1.3.8",
        "array-flatten": "1.1.1",
        "body-parser": "1.20.3",
        "content-disposition": "0.5.4",
        "content-type": "~1.0.4",
        "cookie": "0.7.1",
        "cookie-signature": "1.0.6",
        "debug": "2.6.9",
        "depd": "2.0.0",
        "encodeurl": "~2.0.0",
        "escape-html": "~1.0.3",
        "etag": "~1.8.1",
        "finalhandler": "1.3.1",
        "fresh": "0.5.2",
        "http-errors": "2.0.0",
        "merge-descriptors": "1.0.3",
        "methods": "~1.1.2",
        "on-finished": "2.4.1",
        "parseurl": "~1.3.3",
        "path-to-regexp": "0.1.12",
        "proxy-addr": "~2.0.7",
        "qs": "6.13.0",
        "range-parser": "~1.2.1",
        "safe-buffer": "5.2.1",
        "send": "0.19.0",
        "serve-static": "1.16.2",
        "setprototypeof": "1.2.0",
        "statuses": "2.0.1",
        "type-is": "~1.6.18",
        "utils-merge": "1.0.1",
        "vary": "~1.1.2"
      },
      "engines": {
        "node": ">= 0.10.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/express"
      }
    },
    "node_modules/fast-json-stable-stringify": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/fast-json-stable-stringify/-/fast-json-stable-stringify-2.1.0.tgz",
      "integrity": "sha512-lhd/wF+Lk98HZoTCtlVraHtfh5XYijIjalXck7saUtuanSDyLMxnHhSXEDJqHxD7msR8D0uCmqlkwjCV8xvwHw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fb-watchman": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/fb-watchman/-/fb-watchman-2.0.2.tgz",
      "integrity": "sha512-p5161BqbuCaSnB8jIbzQHOlpgsPmK5rJVDfDKO91Axs5NC1uu3HRQm6wt9cd9/+GtQQIO53JdGXXoyDpTAsgYA==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "bser": "2.1.1"
      }
    },
    "node_modules/fecha": {
      "version": "4.2.3",
      "resolved": "https://registry.npmjs.org/fecha/-/fecha-4.2.3.tgz",
      "integrity": "sha512-OP2IUU6HeYKJi3i0z4A19kHMQoLVs4Hc+DPqqxI2h/DPZHTm/vjsfC6P0b4jCMy14XizLBqvndQ+UilD7707Jw==",
      "license": "MIT"
    },
    "node_modules/fill-range": {
      "version": "7.1.1",
      "resolved": "https://registry.npmjs.org/fill-range/-/fill-range-7.1.1.tgz",
      "integrity": "sha512-YsGpe3WHLK8ZYi4tWDg2Jy3ebRz2rXowDxnld4bkQB00cc/1Zw9AWnC0i9ztDJitivtQvaI9KaLyKrc+hBW0yg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "to-regex-range": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/finalhandler": {
      "version": "1.3.1",
      "resolved": "https://registry.npmjs.org/finalhandler/-/finalhandler-1.3.1.tgz",
      "integrity": "sha512-6BN9trH7bp3qvnrRyzsBz+g3lZxTNZTbVO2EV1CS0WIcDbawYVdYvGflME/9QP0h0pYlCDBCTjYa9nZzMDpyxQ==",
      "license": "MIT",
      "dependencies": {
        "debug": "2.6.9",
        "encodeurl": "~2.0.0",
        "escape-html": "~1.0.3",
        "on-finished": "2.4.1",
        "parseurl": "~1.3.3",
        "statuses": "2.0.1",
        "unpipe": "~1.0.0"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/find-up": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/find-up/-/find-up-4.1.0.tgz",
      "integrity": "sha512-PpOwAdQ/YlXQ2vj8a3h8IipDuYRi3wceVQQGYWxNINccq40Anw7BlsEXCMbt1Zt+OLA6Fq9suIpIWD0OsnISlw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "locate-path": "^5.0.0",
        "path-exists": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/fn.name": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/fn.name/-/fn.name-1.1.0.tgz",
      "integrity": "sha512-GRnmB5gPyJpAhTQdSZTSp9uaPSvl09KoYcMQtsB9rQoOmzs9dH6ffeccH+Z+cv6P68Hu5bC6JjRh4Ah/mHSNRw==",
      "license": "MIT"
    },
    "node_modules/forwarded": {
      "version": "0.2.0",
      "resolved": "https://registry.npmjs.org/forwarded/-/forwarded-0.2.0.tgz",
      "integrity": "sha512-buRG0fpBtRHSTCOASe6hD258tEubFoRLb4ZNA6NxMVHNw2gOcwHo9wyablzMzOA5z9xA9L1KNjk/Nt6MT9aYow==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/fresh": {
      "version": "0.5.2",
      "resolved": "https://registry.npmjs.org/fresh/-/fresh-0.5.2.tgz",
      "integrity": "sha512-zJ2mQYM18rEFOudeV4GShTGIQ7RbzA7ozbU9I/XBpm7kqgMywgmylMwXHxZJmkVoYkna9d2pVXVXPdYTP9ej8Q==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/fs.realpath": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/fs.realpath/-/fs.realpath-1.0.0.tgz",
      "integrity": "sha512-OO0pH2lK6a0hZnAdau5ItzHPI6pUlvI7jMVnxUQRtw4owF2wk8lOSabtGDCTP4Ggrg2MbGnWO9X8K1t4+fGMDw==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/fsevents": {
      "version": "2.3.3",
      "resolved": "https://registry.npmjs.org/fsevents/-/fsevents-2.3.3.tgz",
      "integrity": "sha512-5xoDfX+fL7faATnagmWPpbFtwh/R77WmMMqqHGS65C3vvB0YHrgF+B1YmZ3441tMj5n63k0212XNoJwzlhffQw==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": "^8.16.0 || ^10.6.0 || >=11.0.0"
      }
    },
    "node_modules/function-bind": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/function-bind/-/function-bind-1.1.2.tgz",
      "integrity": "sha512-7XHNxH7qX9xG5mIwxkhumTox/MIRNcOgDrxWsMt2pAr23WHp6MrRlN7FBSFpCpr+oVO0F744iUgR82nJMfG2SA==",
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/gensync": {
      "version": "1.0.0-beta.2",
      "resolved": "https://registry.npmjs.org/gensync/-/gensync-1.0.0-beta.2.tgz",
      "integrity": "sha512-3hN7NaskYvMDLQY55gnW3NQ+mesEAepTqlg+VEbj7zzqEMBVNhzcGYYeqFo/TlYz6eQiFcp1HcsCZO+nGgS8zg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/get-caller-file": {
      "version": "2.0.5",
      "resolved": "https://registry.npmjs.org/get-caller-file/-/get-caller-file-2.0.5.tgz",
      "integrity": "sha512-DyFP3BM/3YHTQOCUL/w0OZHR0lpKeGrxotcHWcqNEdnltqFwXVfhEBQ94eIo34AfQpo0rGki4cyIiftY06h2Fg==",
      "dev": true,
      "license": "ISC",
      "engines": {
        "node": "6.* || 8.* || >= 10.*"
      }
    },
    "node_modules/get-intrinsic": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/get-intrinsic/-/get-intrinsic-1.3.0.tgz",
      "integrity": "sha512-9fSjSaos/fRIVIp+xSJlE6lfwhES7LNtKaCBIamHsjr2na1BiABJPo0mOjjz8GJDURarmCPGqaiVg5mfjb98CQ==",
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.2",
        "es-define-property": "^1.0.1",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.1.1",
        "function-bind": "^1.1.2",
        "get-proto": "^1.0.1",
        "gopd": "^1.2.0",
        "has-symbols": "^1.1.0",
        "hasown": "^2.0.2",
        "math-intrinsics": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-package-type": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/get-package-type/-/get-package-type-0.1.0.tgz",
      "integrity": "sha512-pjzuKtY64GYfWizNAJ0fr9VqttZkNiK2iS430LtIHzjBEr6bX8Am2zm4sW4Ro5wjWW5cAlRL1qAMTcXbjNAO2Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8.0.0"
      }
    },
    "node_modules/get-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/get-proto/-/get-proto-1.0.1.tgz",
      "integrity": "sha512-sTSfBjoXBp89JvIKIefqw7U2CCebsc74kiY6awiGogKtoSGbgjYE/G/+l9sF3MWFPNc9IcoOC4ODfKHfxFmp0g==",
      "license": "MIT",
      "dependencies": {
        "dunder-proto": "^1.0.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/get-stream": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/get-stream/-/get-stream-6.0.1.tgz",
      "integrity": "sha512-ts6Wi+2j3jQjqi70w5AlN8DFnkSwC+MqmxEzdEALB2qXZYV3X/b1CTfgPLGJNMeAWxdPfU8FO1ms3NUfaHCPYg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/glob": {
      "version": "7.2.3",
      "resolved": "https://registry.npmjs.org/glob/-/glob-7.2.3.tgz",
      "integrity": "sha512-nFR0zLpU2YCaRxwoCJvL6UvCH2JFyFVIvwTLsIf21AuHlMskA1hhTdk+LlYJtOlYt9v6dvszD2BGRqBL+iQK9Q==",
      "deprecated": "Glob versions prior to v9 are no longer supported",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "fs.realpath": "^1.0.0",
        "inflight": "^1.0.4",
        "inherits": "2",
        "minimatch": "^3.1.1",
        "once": "^1.3.0",
        "path-is-absolute": "^1.0.0"
      },
      "engines": {
        "node": "*"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/glob-parent": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-5.1.2.tgz",
      "integrity": "sha512-AOIgSQCepiJYwP3ARnGx+5VnTu2HBYdzbGP45eLw1vr3zB3vZLeyed1sC9hnbcOc9/SrMyM5RPQrkGz4aS9Zow==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "is-glob": "^4.0.1"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/globals": {
      "version": "11.12.0",
      "resolved": "https://registry.npmjs.org/globals/-/globals-11.12.0.tgz",
      "integrity": "sha512-WOBp/EEGUiIsJSp7wcv/y6MO+lV9UoncWqxuFfm8eBwzWNgyfBd6Gz+IeKQ9jCmyhoH99g15M3T+QaVHFjizVA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/gopd": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/gopd/-/gopd-1.2.0.tgz",
      "integrity": "sha512-ZUKRh6/kUFoAiTAtTYPZJ3hw9wNxx+BIBOijnlG9PnrJsCcSjs1wyyD6vJpaYtgnzDrKYRSqf3OO6Rfa93xsRg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/graceful-fs": {
      "version": "4.2.11",
      "resolved": "https://registry.npmjs.org/graceful-fs/-/graceful-fs-4.2.11.tgz",
      "integrity": "sha512-RbJ5/jmFcNNCcDV5o9eTnBLJ/HszWV0P73bc+Ff4nS/rJj+YaS6IGyiOL0VoBYX+l1Wrl3k63h/KrH+nhJ0XvQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/has-flag": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/has-flag/-/has-flag-4.0.0.tgz",
      "integrity": "sha512-EykJT/Q1KjTWctppgIAgfSO0tKVuZUjhgMr17kqTumMl6Afv3EISleU7qZUzoXDFTAHTDC4NOoG/ZxU3EvlMPQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/has-symbols": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/has-symbols/-/has-symbols-1.1.0.tgz",
      "integrity": "sha512-1cDNdwJ2Jaohmb3sg4OmKaMBwuC48sYni5HUw2DvsC8LjGTLK9h+eb1X6RyuOHe4hT0ULCW68iomhjUoKUqlPQ==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/hasown": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/hasown/-/hasown-2.0.2.tgz",
      "integrity": "sha512-0hJU9SCPvmMzIBdZFqNPXWa6dqh7WdH0cII9y+CyS8rG3nL48Bclra9HmKhVVUHyPWNH5Y7xDwAB7bfgSjkUMQ==",
      "license": "MIT",
      "dependencies": {
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/helmet": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/helmet/-/helmet-7.2.0.tgz",
      "integrity": "sha512-ZRiwvN089JfMXokizgqEPXsl2Guk094yExfoDXR0cBYWxtBbaSww/w+vT4WEJsBW2iTUi1GgZ6swmoug3Oy4Xw==",
      "license": "MIT",
      "engines": {
        "node": ">=16.0.0"
      }
    },
    "node_modules/html-escaper": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/html-escaper/-/html-escaper-2.0.2.tgz",
      "integrity": "sha512-H2iMtd0I4Mt5eYiapRdIDjp+XzelXQ0tFE4JS7YFwFevXXMmOp9myNrUvCg0D6ws8iqkRPBfKHgbwig1SmlLfg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/http-errors": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/http-errors/-/http-errors-2.0.0.tgz",
      "integrity": "sha512-FtwrG/euBzaEjYeRqOgly7G0qviiXoJWnvEH2Z1plBdXgbyjv34pHTSb9zoeHMyDy33+DWy5Wt9Wo+TURtOYSQ==",
      "license": "MIT",
      "dependencies": {
        "depd": "2.0.0",
        "inherits": "2.0.4",
        "setprototypeof": "1.2.0",
        "statuses": "2.0.1",
        "toidentifier": "1.0.1"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/human-signals": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/human-signals/-/human-signals-2.1.0.tgz",
      "integrity": "sha512-B4FFZ6q/T2jhhksgkbEW3HBvWIfDW85snkQgawt07S7J5QXTk6BkNV+0yAeZrM5QpMAdYlocGoljn0sJ/WQkFw==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">=10.17.0"
      }
    },
    "node_modules/iconv-lite": {
      "version": "0.4.24",
      "resolved": "https://registry.npmjs.org/iconv-lite/-/iconv-lite-0.4.24.tgz",
      "integrity": "sha512-v3MXnZAcvnywkTUEZomIActle7RXXeedOR31wwl7VlyoXO4Qi9arvSenNQWne1TcRwhCL1HwLI21bEqdpj8/rA==",
      "license": "MIT",
      "dependencies": {
        "safer-buffer": ">= 2.1.2 < 3"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/ignore-by-default": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/ignore-by-default/-/ignore-by-default-1.0.1.tgz",
      "integrity": "sha512-Ius2VYcGNk7T90CppJqcIkS5ooHUZyIQK+ClZfMfMNFEF9VSE73Fq+906u/CWu92x4gzZMWOwfFYckPObzdEbA==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/import-local": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/import-local/-/import-local-3.2.0.tgz",
      "integrity": "sha512-2SPlun1JUPWoM6t3F0dw0FkCF/jWY8kttcY4f599GLTSjh2OCuuhdTkJQsEcZzBqbXZGKMK2OqW1oZsjtf/gQA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "pkg-dir": "^4.2.0",
        "resolve-cwd": "^3.0.0"
      },
      "bin": {
        "import-local-fixture": "fixtures/cli.js"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/imurmurhash": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/imurmurhash/-/imurmurhash-0.1.4.tgz",
      "integrity": "sha512-JmXMZ6wuvDmLiHEml9ykzqO6lwFbof0GG4IkcGaENdCRDDmMVnny7s5HsIgHCbaq0w2MyPhDqkhTUgS2LU2PHA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.8.19"
      }
    },
    "node_modules/inflight": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/inflight/-/inflight-1.0.6.tgz",
      "integrity": "sha512-k92I/b08q4wvFscXCLvqfsHCrjrF7yiXsQuIVvVE7N82W3+aqpzuUdBbfhWcy/FZR3/4IgflMgKLOsvPDrGCJA==",
      "deprecated": "This module is not supported, and leaks memory. Do not use it. Check out lru-cache if you want a good and tested way to coalesce async requests by a key value, which is much more comprehensive and powerful.",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "once": "^1.3.0",
        "wrappy": "1"
      }
    },
    "node_modules/inherits": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/inherits/-/inherits-2.0.4.tgz",
      "integrity": "sha512-k/vGaX4/Yla3WzyMCvTQOXYeIHvqOKtnqBduzTHpzpQZzAskKMhZ2K+EnBiSM9zGSoIFeMpXKxa4dYeZIQqewQ==",
      "license": "ISC"
    },
    "node_modules/ioredis": {
      "version": "5.6.0",
      "resolved": "https://registry.npmjs.org/ioredis/-/ioredis-5.6.0.tgz",
      "integrity": "sha512-tBZlIIWbndeWBWCXWZiqtOF/yxf6yZX3tAlTJ7nfo5jhd6dctNxF7QnYlZLZ1a0o0pDoen7CgZqO+zjNaFbJAg==",
      "license": "MIT",
      "dependencies": {
        "@ioredis/commands": "^1.1.1",
        "cluster-key-slot": "^1.1.0",
        "debug": "^4.3.4",
        "denque": "^2.1.0",
        "lodash.defaults": "^4.2.0",
        "lodash.isarguments": "^3.1.0",
        "redis-errors": "^1.2.0",
        "redis-parser": "^3.0.0",
        "standard-as-callback": "^2.1.0"
      },
      "engines": {
        "node": ">=12.22.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/ioredis"
      }
    },
    "node_modules/ioredis/node_modules/debug": {
      "version": "4.4.0",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.4.0.tgz",
      "integrity": "sha512-6WTZ/IxCY/T6BALoZHaE4ctp9xm+Z5kY/pzYaCHRFeyVhojxlrm+46y68HA6hr0TcwEssoxNiDEUJQjfPZ/RYA==",
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/ioredis/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "license": "MIT"
    },
    "node_modules/ipaddr.js": {
      "version": "1.9.1",
      "resolved": "https://registry.npmjs.org/ipaddr.js/-/ipaddr.js-1.9.1.tgz",
      "integrity": "sha512-0KI/607xoxSToH7GjN1FfSbLoU0+btTicjsQSWQlh/hZykN8KpmMf7uYwPW3R+akZ6R/w18ZlXSHBYXiYUPO3g==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.10"
      }
    },
    "node_modules/is-arrayish": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/is-arrayish/-/is-arrayish-0.2.1.tgz",
      "integrity": "sha512-zz06S8t0ozoDXMG+ube26zeCTNXcKIPJZJi8hBrF4idCLms4CG9QtK7qBl1boi5ODzFpjswb5JPmHCbMpjaYzg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/is-binary-path": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/is-binary-path/-/is-binary-path-2.1.0.tgz",
      "integrity": "sha512-ZMERYes6pDydyuGidse7OsHxtbI7WVeUEozgR/g7rd0xUimYNlvZRE/K2MgZTjWy725IfelLeVcEM97mmtRGXw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "binary-extensions": "^2.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-core-module": {
      "version": "2.16.1",
      "resolved": "https://registry.npmjs.org/is-core-module/-/is-core-module-2.16.1.tgz",
      "integrity": "sha512-UfoeMA6fIJ8wTYFEUjelnaGI67v6+N7qXJEvQuIGa99l4xsCruSYOVSQ0uPANn4dAzm8lkYPaKLrrijLq7x23w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-extglob": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/is-extglob/-/is-extglob-2.1.1.tgz",
      "integrity": "sha512-SbKbANkN603Vi4jEZv49LeVJMn4yGwsbzZworEoyEiutsN3nJYdbO36zfhGJ6QEDpOZIFkDtnq5JRxmvl3jsoQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/is-fullwidth-code-point": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/is-fullwidth-code-point/-/is-fullwidth-code-point-3.0.0.tgz",
      "integrity": "sha512-zymm5+u+sCsSWyD9qNaejV3DFvhCKclKdizYaJUuHA83RLjb7nSuGnddCHGv0hk+KY7BMAlsWeK4Ueg6EV6XQg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-generator-fn": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/is-generator-fn/-/is-generator-fn-2.1.0.tgz",
      "integrity": "sha512-cTIB4yPYL/Grw0EaSzASzg6bBy9gqCofvWN8okThAYIxKJZC+udlRAmGbM0XLeniEJSs8uEgHPGuHSe1XsOLSQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/is-glob": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/is-glob/-/is-glob-4.0.3.tgz",
      "integrity": "sha512-xelSayHH36ZgE7ZWhli7pW34hNbNl8Ojv5KVmkJD4hBdD3th8Tfk9vYasLM+mXWOZhFkgZfxhLSnrwRr4elSSg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-extglob": "^2.1.1"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/is-number": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/is-number/-/is-number-7.0.0.tgz",
      "integrity": "sha512-41Cifkg6e8TylSpdtTpeLVMqvSBEVzTttHvERD741+pnZ8ANv0004MRL43QKPDlK9cGvNp6NZWZUBlbGXYxxng==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.12.0"
      }
    },
    "node_modules/is-stream": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/is-stream/-/is-stream-2.0.1.tgz",
      "integrity": "sha512-hFoiJiTl63nn+kstHGBtewWSKnQLpyb155KHheA1l39uvtO9nWIop1p3udqPcUd/xbF1VLMO4n7OI6p7RbngDg==",
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/isexe": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/isexe/-/isexe-2.0.0.tgz",
      "integrity": "sha512-RHxMLp9lnKHGHRng9QFhRCMbYAcVpn69smSGcq3f36xjgVVWThj4qqLbTLlq7Ssj8B+fIQ1EuCEGI2lKsyQeIw==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/istanbul-lib-coverage": {
      "version": "3.2.2",
      "resolved": "https://registry.npmjs.org/istanbul-lib-coverage/-/istanbul-lib-coverage-3.2.2.tgz",
      "integrity": "sha512-O8dpsF+r0WV/8MNRKfnmrtCWhuKjxrq2w+jpzBL5UZKTi2LeVWnWOmWRxFlesJONmc+wLAGvKQZEOanko0LFTg==",
      "dev": true,
      "license": "BSD-3-Clause",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/istanbul-lib-instrument": {
      "version": "6.0.3",
      "resolved": "https://registry.npmjs.org/istanbul-lib-instrument/-/istanbul-lib-instrument-6.0.3.tgz",
      "integrity": "sha512-Vtgk7L/R2JHyyGW07spoFlB8/lpjiOLTjMdms6AFMraYt3BaJauod/NGrfnVG/y4Ix1JEuMRPDPEj2ua+zz1/Q==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "@babel/core": "^7.23.9",
        "@babel/parser": "^7.23.9",
        "@istanbuljs/schema": "^0.1.3",
        "istanbul-lib-coverage": "^3.2.0",
        "semver": "^7.5.4"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/istanbul-lib-instrument/node_modules/semver": {
      "version": "7.7.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-7.7.1.tgz",
      "integrity": "sha512-hlq8tAfn0m/61p4BVRcPzIGr6LKiMwo4VM6dGi6pt4qcRkmNzTcWq6eCEjEh+qXjkMDvPlOFFSGwQjoEa6gyMA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/istanbul-lib-report": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/istanbul-lib-report/-/istanbul-lib-report-3.0.1.tgz",
      "integrity": "sha512-GCfE1mtsHGOELCU8e/Z7YWzpmybrx/+dSTfLrvY8qRmaY6zXTKWn6WQIjaAFw069icm6GVMNkgu0NzI4iPZUNw==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "istanbul-lib-coverage": "^3.0.0",
        "make-dir": "^4.0.0",
        "supports-color": "^7.1.0"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/istanbul-lib-source-maps": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/istanbul-lib-source-maps/-/istanbul-lib-source-maps-4.0.1.tgz",
      "integrity": "sha512-n3s8EwkdFIJCG3BPKBYvskgXGoy88ARzvegkitk60NxRdwltLOTaH7CUiMRXvwYorl0Q712iEjcWB+fK/MrWVw==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "debug": "^4.1.1",
        "istanbul-lib-coverage": "^3.0.0",
        "source-map": "^0.6.1"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/istanbul-lib-source-maps/node_modules/debug": {
      "version": "4.4.0",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.4.0.tgz",
      "integrity": "sha512-6WTZ/IxCY/T6BALoZHaE4ctp9xm+Z5kY/pzYaCHRFeyVhojxlrm+46y68HA6hr0TcwEssoxNiDEUJQjfPZ/RYA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/istanbul-lib-source-maps/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/istanbul-reports": {
      "version": "3.1.7",
      "resolved": "https://registry.npmjs.org/istanbul-reports/-/istanbul-reports-3.1.7.tgz",
      "integrity": "sha512-BewmUXImeuRk2YY0PVbxgKAysvhRPUQE0h5QRM++nVWyubKGV0l8qQ5op8+B2DOmwSe63Jivj0BjkPQVf8fP5g==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "html-escaper": "^2.0.0",
        "istanbul-lib-report": "^3.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/jest": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest/-/jest-29.7.0.tgz",
      "integrity": "sha512-NIy3oAFp9shda19hy4HK0HRTWKtPJmGdnvywu01nOqNC2vZg+Z+fvJDxpMQA88eb2I9EcafcdjYgsDthnYTvGw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/core": "^29.7.0",
        "@jest/types": "^29.6.3",
        "import-local": "^3.0.2",
        "jest-cli": "^29.7.0"
      },
      "bin": {
        "jest": "bin/jest.js"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "node-notifier": "^8.0.1 || ^9.0.0 || ^10.0.0"
      },
      "peerDependenciesMeta": {
        "node-notifier": {
          "optional": true
        }
      }
    },
    "node_modules/jest-changed-files": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-changed-files/-/jest-changed-files-29.7.0.tgz",
      "integrity": "sha512-fEArFiwf1BpQ+4bXSprcDc3/x4HSzL4al2tozwVpDFpsxALjLYdyiIK4e5Vz66GQJIbXJ82+35PtysofptNX2w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "execa": "^5.0.0",
        "jest-util": "^29.7.0",
        "p-limit": "^3.1.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-circus": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-circus/-/jest-circus-29.7.0.tgz",
      "integrity": "sha512-3E1nCMgipcTkCocFwM90XXQab9bS+GMsjdpmPrlelaxwD93Ad8iVEjX/vvHPdLPnFf+L40u+5+iutRdA1N9myw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/environment": "^29.7.0",
        "@jest/expect": "^29.7.0",
        "@jest/test-result": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "chalk": "^4.0.0",
        "co": "^4.6.0",
        "dedent": "^1.0.0",
        "is-generator-fn": "^2.0.0",
        "jest-each": "^29.7.0",
        "jest-matcher-utils": "^29.7.0",
        "jest-message-util": "^29.7.0",
        "jest-runtime": "^29.7.0",
        "jest-snapshot": "^29.7.0",
        "jest-util": "^29.7.0",
        "p-limit": "^3.1.0",
        "pretty-format": "^29.7.0",
        "pure-rand": "^6.0.0",
        "slash": "^3.0.0",
        "stack-utils": "^2.0.3"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-cli": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-cli/-/jest-cli-29.7.0.tgz",
      "integrity": "sha512-OVVobw2IubN/GSYsxETi+gOe7Ka59EFMR/twOU3Jb2GnKKeMGJB5SGUUrEz3SFVmJASUdZUzy83sLNNQ2gZslg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/core": "^29.7.0",
        "@jest/test-result": "^29.7.0",
        "@jest/types": "^29.6.3",
        "chalk": "^4.0.0",
        "create-jest": "^29.7.0",
        "exit": "^0.1.2",
        "import-local": "^3.0.2",
        "jest-config": "^29.7.0",
        "jest-util": "^29.7.0",
        "jest-validate": "^29.7.0",
        "yargs": "^17.3.1"
      },
      "bin": {
        "jest": "bin/jest.js"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "node-notifier": "^8.0.1 || ^9.0.0 || ^10.0.0"
      },
      "peerDependenciesMeta": {
        "node-notifier": {
          "optional": true
        }
      }
    },
    "node_modules/jest-config": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-config/-/jest-config-29.7.0.tgz",
      "integrity": "sha512-uXbpfeQ7R6TZBqI3/TxCU4q4ttk3u0PJeC+E0zbfSoSjq6bJ7buBPxzQPL0ifrkY4DNu4JUdk0ImlBUYi840eQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/core": "^7.11.6",
        "@jest/test-sequencer": "^29.7.0",
        "@jest/types": "^29.6.3",
        "babel-jest": "^29.7.0",
        "chalk": "^4.0.0",
        "ci-info": "^3.2.0",
        "deepmerge": "^4.2.2",
        "glob": "^7.1.3",
        "graceful-fs": "^4.2.9",
        "jest-circus": "^29.7.0",
        "jest-environment-node": "^29.7.0",
        "jest-get-type": "^29.6.3",
        "jest-regex-util": "^29.6.3",
        "jest-resolve": "^29.7.0",
        "jest-runner": "^29.7.0",
        "jest-util": "^29.7.0",
        "jest-validate": "^29.7.0",
        "micromatch": "^4.0.4",
        "parse-json": "^5.2.0",
        "pretty-format": "^29.7.0",
        "slash": "^3.0.0",
        "strip-json-comments": "^3.1.1"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "@types/node": "*",
        "ts-node": ">=9.0.0"
      },
      "peerDependenciesMeta": {
        "@types/node": {
          "optional": true
        },
        "ts-node": {
          "optional": true
        }
      }
    },
    "node_modules/jest-diff": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-diff/-/jest-diff-29.7.0.tgz",
      "integrity": "sha512-LMIgiIrhigmPrs03JHpxUh2yISK3vLFPkAodPeo0+BuF7wA2FoQbkEg1u8gBYBThncu7e1oEDUfIXVuTqLRUjw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "chalk": "^4.0.0",
        "diff-sequences": "^29.6.3",
        "jest-get-type": "^29.6.3",
        "pretty-format": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-docblock": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-docblock/-/jest-docblock-29.7.0.tgz",
      "integrity": "sha512-q617Auw3A612guyaFgsbFeYpNP5t2aoUNLwBUbc/0kD1R4t9ixDbyFTHd1nok4epoVFpr7PmeWHrhvuV3XaJ4g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "detect-newline": "^3.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-each": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-each/-/jest-each-29.7.0.tgz",
      "integrity": "sha512-gns+Er14+ZrEoC5fhOfYCY1LOHHr0TI+rQUHZS8Ttw2l7gl+80eHc/gFf2Ktkw0+SIACDTeWvpFcv3B04VembQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "chalk": "^4.0.0",
        "jest-get-type": "^29.6.3",
        "jest-util": "^29.7.0",
        "pretty-format": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-environment-node": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-environment-node/-/jest-environment-node-29.7.0.tgz",
      "integrity": "sha512-DOSwCRqXirTOyheM+4d5YZOrWcdu0LNZ87ewUoywbcb2XR4wKgqiG8vNeYwhjFMbEkfju7wx2GYH0P2gevGvFw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/environment": "^29.7.0",
        "@jest/fake-timers": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "jest-mock": "^29.7.0",
        "jest-util": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-get-type": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/jest-get-type/-/jest-get-type-29.6.3.tgz",
      "integrity": "sha512-zrteXnqYxfQh7l5FHyL38jL39di8H8rHoecLH3JNxH3BwOrBsNeabdap5e0I23lD4HHI8W5VFBZqG4Eaq5LNcw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-haste-map": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-haste-map/-/jest-haste-map-29.7.0.tgz",
      "integrity": "sha512-fP8u2pyfqx0K1rGn1R9pyE0/KTn+G7PxktWidOBTqFPLYX0b9ksaMFkhK5vrS3DVun09pckLdlx90QthlW7AmA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "@types/graceful-fs": "^4.1.3",
        "@types/node": "*",
        "anymatch": "^3.0.3",
        "fb-watchman": "^2.0.0",
        "graceful-fs": "^4.2.9",
        "jest-regex-util": "^29.6.3",
        "jest-util": "^29.7.0",
        "jest-worker": "^29.7.0",
        "micromatch": "^4.0.4",
        "walker": "^1.0.8"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "optionalDependencies": {
        "fsevents": "^2.3.2"
      }
    },
    "node_modules/jest-leak-detector": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-leak-detector/-/jest-leak-detector-29.7.0.tgz",
      "integrity": "sha512-kYA8IJcSYtST2BY9I+SMC32nDpBT3J2NvWJx8+JCuCdl/CR1I4EKUJROiP8XtCcxqgTTBGJNdbB1A8XRKbTetw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "jest-get-type": "^29.6.3",
        "pretty-format": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-matcher-utils": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-matcher-utils/-/jest-matcher-utils-29.7.0.tgz",
      "integrity": "sha512-sBkD+Xi9DtcChsI3L3u0+N0opgPYnCRPtGcQYrgXmR+hmt/fYfWAL0xRXYU8eWOdfuLgBe0YCW3AFtnRLagq/g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "chalk": "^4.0.0",
        "jest-diff": "^29.7.0",
        "jest-get-type": "^29.6.3",
        "pretty-format": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-message-util": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-message-util/-/jest-message-util-29.7.0.tgz",
      "integrity": "sha512-GBEV4GRADeP+qtB2+6u61stea8mGcOT4mCtrYISZwfu9/ISHFJ/5zOMXYbpBE9RsS5+Gb63DW4FgmnKJ79Kf6w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/code-frame": "^7.12.13",
        "@jest/types": "^29.6.3",
        "@types/stack-utils": "^2.0.0",
        "chalk": "^4.0.0",
        "graceful-fs": "^4.2.9",
        "micromatch": "^4.0.4",
        "pretty-format": "^29.7.0",
        "slash": "^3.0.0",
        "stack-utils": "^2.0.3"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-mock": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-mock/-/jest-mock-29.7.0.tgz",
      "integrity": "sha512-ITOMZn+UkYS4ZFh83xYAOzWStloNzJFO2s8DWrE4lhtGD+AorgnbkiKERe4wQVBydIGPx059g6riW5Btp6Llnw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "jest-util": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-pnp-resolver": {
      "version": "1.2.3",
      "resolved": "https://registry.npmjs.org/jest-pnp-resolver/-/jest-pnp-resolver-1.2.3.tgz",
      "integrity": "sha512-+3NpwQEnRoIBtx4fyhblQDPgJI0H1IEIkX7ShLUjPGA7TtUTvI1oiKi3SR4oBR0hQhQR80l4WAe5RrXBwWMA8w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      },
      "peerDependencies": {
        "jest-resolve": "*"
      },
      "peerDependenciesMeta": {
        "jest-resolve": {
          "optional": true
        }
      }
    },
    "node_modules/jest-regex-util": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/jest-regex-util/-/jest-regex-util-29.6.3.tgz",
      "integrity": "sha512-KJJBsRCyyLNWCNBOvZyRDnAIfUiRJ8v+hOBQYGn8gDyF3UegwiP4gwRR3/SDa42g1YbVycTidUF3rKjyLFDWbg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-resolve": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-resolve/-/jest-resolve-29.7.0.tgz",
      "integrity": "sha512-IOVhZSrg+UvVAshDSDtHyFCCBUl/Q3AAJv8iZ6ZjnZ74xzvwuzLXid9IIIPgTnY62SJjfuupMKZsZQRsCvxEgA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "chalk": "^4.0.0",
        "graceful-fs": "^4.2.9",
        "jest-haste-map": "^29.7.0",
        "jest-pnp-resolver": "^1.2.2",
        "jest-util": "^29.7.0",
        "jest-validate": "^29.7.0",
        "resolve": "^1.20.0",
        "resolve.exports": "^2.0.0",
        "slash": "^3.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-resolve-dependencies": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-resolve-dependencies/-/jest-resolve-dependencies-29.7.0.tgz",
      "integrity": "sha512-un0zD/6qxJ+S0et7WxeI3H5XSe9lTBBR7bOHCHXkKR6luG5mwDDlIzVQ0V5cZCuoTgEdcdwzTghYkTWfubi+nA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "jest-regex-util": "^29.6.3",
        "jest-snapshot": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-runner": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-runner/-/jest-runner-29.7.0.tgz",
      "integrity": "sha512-fsc4N6cPCAahybGBfTRcq5wFR6fpLznMg47sY5aDpsoejOcVYFb07AHuSnR0liMcPTgBsA3ZJL6kFOjPdoNipQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/console": "^29.7.0",
        "@jest/environment": "^29.7.0",
        "@jest/test-result": "^29.7.0",
        "@jest/transform": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "chalk": "^4.0.0",
        "emittery": "^0.13.1",
        "graceful-fs": "^4.2.9",
        "jest-docblock": "^29.7.0",
        "jest-environment-node": "^29.7.0",
        "jest-haste-map": "^29.7.0",
        "jest-leak-detector": "^29.7.0",
        "jest-message-util": "^29.7.0",
        "jest-resolve": "^29.7.0",
        "jest-runtime": "^29.7.0",
        "jest-util": "^29.7.0",
        "jest-watcher": "^29.7.0",
        "jest-worker": "^29.7.0",
        "p-limit": "^3.1.0",
        "source-map-support": "0.5.13"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-runtime": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-runtime/-/jest-runtime-29.7.0.tgz",
      "integrity": "sha512-gUnLjgwdGqW7B4LvOIkbKs9WGbn+QLqRQQ9juC6HndeDiezIwhDP+mhMwHWCEcfQ5RUXa6OPnFF8BJh5xegwwQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/environment": "^29.7.0",
        "@jest/fake-timers": "^29.7.0",
        "@jest/globals": "^29.7.0",
        "@jest/source-map": "^29.6.3",
        "@jest/test-result": "^29.7.0",
        "@jest/transform": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "chalk": "^4.0.0",
        "cjs-module-lexer": "^1.0.0",
        "collect-v8-coverage": "^1.0.0",
        "glob": "^7.1.3",
        "graceful-fs": "^4.2.9",
        "jest-haste-map": "^29.7.0",
        "jest-message-util": "^29.7.0",
        "jest-mock": "^29.7.0",
        "jest-regex-util": "^29.6.3",
        "jest-resolve": "^29.7.0",
        "jest-snapshot": "^29.7.0",
        "jest-util": "^29.7.0",
        "slash": "^3.0.0",
        "strip-bom": "^4.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-snapshot": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-snapshot/-/jest-snapshot-29.7.0.tgz",
      "integrity": "sha512-Rm0BMWtxBcioHr1/OX5YCP8Uov4riHvKPknOGs804Zg9JGZgmIBkbtlxJC/7Z4msKYVbIJtfU+tKb8xlYNfdkw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/core": "^7.11.6",
        "@babel/generator": "^7.7.2",
        "@babel/plugin-syntax-jsx": "^7.7.2",
        "@babel/plugin-syntax-typescript": "^7.7.2",
        "@babel/types": "^7.3.3",
        "@jest/expect-utils": "^29.7.0",
        "@jest/transform": "^29.7.0",
        "@jest/types": "^29.6.3",
        "babel-preset-current-node-syntax": "^1.0.0",
        "chalk": "^4.0.0",
        "expect": "^29.7.0",
        "graceful-fs": "^4.2.9",
        "jest-diff": "^29.7.0",
        "jest-get-type": "^29.6.3",
        "jest-matcher-utils": "^29.7.0",
        "jest-message-util": "^29.7.0",
        "jest-util": "^29.7.0",
        "natural-compare": "^1.4.0",
        "pretty-format": "^29.7.0",
        "semver": "^7.5.3"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-snapshot/node_modules/semver": {
      "version": "7.7.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-7.7.1.tgz",
      "integrity": "sha512-hlq8tAfn0m/61p4BVRcPzIGr6LKiMwo4VM6dGi6pt4qcRkmNzTcWq6eCEjEh+qXjkMDvPlOFFSGwQjoEa6gyMA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/jest-util": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-util/-/jest-util-29.7.0.tgz",
      "integrity": "sha512-z6EbKajIpqGKU56y5KBUgy1dt1ihhQJgWzUlZHArA/+X2ad7Cb5iF+AK1EWVL/Bo7Rz9uurpqw6SiBCefUbCGA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "chalk": "^4.0.0",
        "ci-info": "^3.2.0",
        "graceful-fs": "^4.2.9",
        "picomatch": "^2.2.3"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-validate": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-validate/-/jest-validate-29.7.0.tgz",
      "integrity": "sha512-ZB7wHqaRGVw/9hST/OuFUReG7M8vKeq0/J2egIGLdvjHCmYqGARhzXmtgi+gVeZ5uXFF219aOc3Ls2yLg27tkw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "camelcase": "^6.2.0",
        "chalk": "^4.0.0",
        "jest-get-type": "^29.6.3",
        "leven": "^3.1.0",
        "pretty-format": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-validate/node_modules/camelcase": {
      "version": "6.3.0",
      "resolved": "https://registry.npmjs.org/camelcase/-/camelcase-6.3.0.tgz",
      "integrity": "sha512-Gmy6FhYlCY7uOElZUSbxo2UCDH8owEk996gkbrpsgGtrJLM3J7jGxl9Ic7Qwwj4ivOE5AWZWRMecDdF7hqGjFA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/jest-watcher": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-watcher/-/jest-watcher-29.7.0.tgz",
      "integrity": "sha512-49Fg7WXkU3Vl2h6LbLtMQ/HyB6rXSIX7SqvBLQmssRBGN9I0PNvPmAmCWSOY6SOvrjhI/F7/bGAv9RtnsPA03g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/test-result": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "ansi-escapes": "^4.2.1",
        "chalk": "^4.0.0",
        "emittery": "^0.13.1",
        "jest-util": "^29.7.0",
        "string-length": "^4.0.1"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-worker": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-worker/-/jest-worker-29.7.0.tgz",
      "integrity": "sha512-eIz2msL/EzL9UFTFFx7jBTkeZfku0yUAyZZZmJ93H2TYEiroIx2PQjEXcwYtYl8zXCxb+PAmA2hLIt/6ZEkPHw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/node": "*",
        "jest-util": "^29.7.0",
        "merge-stream": "^2.0.0",
        "supports-color": "^8.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-worker/node_modules/supports-color": {
      "version": "8.1.1",
      "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-8.1.1.tgz",
      "integrity": "sha512-MpUEN2OodtUzxvKQl72cUF7RQ5EiHsGvSsVG0ia9c5RbWGL2CI4C7EpPS8UTBIplnlzZiNuV56w+FuNxy3ty2Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "has-flag": "^4.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/supports-color?sponsor=1"
      }
    },
    "node_modules/js-tokens": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/js-tokens/-/js-tokens-4.0.0.tgz",
      "integrity": "sha512-RdJUflcE3cUzKiMqQgsCu06FPu9UdIJO0beYbPhHN4k6apgJtifcoCtT9bcxOpYBtpD2kCM6Sbzg4CausW/PKQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/js-yaml": {
      "version": "3.14.1",
      "resolved": "https://registry.npmjs.org/js-yaml/-/js-yaml-3.14.1.tgz",
      "integrity": "sha512-okMH7OXXJ7YrN9Ok3/SXrnu4iX9yOk+25nqX4imS2npuvTYDmo/QEZoqwZkYaIDk3jVvBOTOIEgEhaLOynBS9g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "argparse": "^1.0.7",
        "esprima": "^4.0.0"
      },
      "bin": {
        "js-yaml": "bin/js-yaml.js"
      }
    },
    "node_modules/jsesc": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/jsesc/-/jsesc-3.1.0.tgz",
      "integrity": "sha512-/sM3dO2FOzXjKQhJuo0Q173wf2KOo8t4I8vHy6lF9poUp7bKT0/NHE8fPX23PwfhnykfqnC2xRxOnVw5XuGIaA==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "jsesc": "bin/jsesc"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/json-parse-even-better-errors": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/json-parse-even-better-errors/-/json-parse-even-better-errors-2.3.1.tgz",
      "integrity": "sha512-xyFwyhro/JEof6Ghe2iz2NcXoj2sloNsWr/XsERDK/oiPCfaNhl5ONfp+jQdAZRQQ0IJWNzH9zIZF7li91kh2w==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json5": {
      "version": "2.2.3",
      "resolved": "https://registry.npmjs.org/json5/-/json5-2.2.3.tgz",
      "integrity": "sha512-XmOWe7eyHYH14cLdVPoyg+GOH3rYX++KpzrylJwSW98t3Nk+U8XOl8FWKOgwtzdb8lXGf6zYwDUzeHMWfxasyg==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "json5": "lib/cli.js"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/jsonwebtoken": {
      "version": "9.0.2",
      "resolved": "https://registry.npmjs.org/jsonwebtoken/-/jsonwebtoken-9.0.2.tgz",
      "integrity": "sha512-PRp66vJ865SSqOlgqS8hujT5U4AOgMfhrwYIuIhfKaoSCZcirrmASQr8CX7cUg+RMih+hgznrjp99o+W4pJLHQ==",
      "license": "MIT",
      "dependencies": {
        "jws": "^3.2.2",
        "lodash.includes": "^4.3.0",
        "lodash.isboolean": "^3.0.3",
        "lodash.isinteger": "^4.0.4",
        "lodash.isnumber": "^3.0.3",
        "lodash.isplainobject": "^4.0.6",
        "lodash.isstring": "^4.0.1",
        "lodash.once": "^4.0.0",
        "ms": "^2.1.1",
        "semver": "^7.5.4"
      },
      "engines": {
        "node": ">=12",
        "npm": ">=6"
      }
    },
    "node_modules/jsonwebtoken/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "license": "MIT"
    },
    "node_modules/jsonwebtoken/node_modules/semver": {
      "version": "7.7.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-7.7.1.tgz",
      "integrity": "sha512-hlq8tAfn0m/61p4BVRcPzIGr6LKiMwo4VM6dGi6pt4qcRkmNzTcWq6eCEjEh+qXjkMDvPlOFFSGwQjoEa6gyMA==",
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/jwa": {
      "version": "1.4.1",
      "resolved": "https://registry.npmjs.org/jwa/-/jwa-1.4.1.tgz",
      "integrity": "sha512-qiLX/xhEEFKUAJ6FiBMbes3w9ATzyk5W7Hvzpa/SLYdxNtng+gcurvrI7TbACjIXlsJyr05/S1oUhZrc63evQA==",
      "license": "MIT",
      "dependencies": {
        "buffer-equal-constant-time": "1.0.1",
        "ecdsa-sig-formatter": "1.0.11",
        "safe-buffer": "^5.0.1"
      }
    },
    "node_modules/jws": {
      "version": "3.2.2",
      "resolved": "https://registry.npmjs.org/jws/-/jws-3.2.2.tgz",
      "integrity": "sha512-YHlZCB6lMTllWDtSPHz/ZXTsi8S00usEV6v1tjq8tOUZzw7DpSDWVXjXDre6ed1w/pd495ODpHZYSdkRTsa0HA==",
      "license": "MIT",
      "dependencies": {
        "jwa": "^1.4.1",
        "safe-buffer": "^5.0.1"
      }
    },
    "node_modules/kleur": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/kleur/-/kleur-3.0.3.tgz",
      "integrity": "sha512-eTIzlVOSUR+JxdDFepEYcBMtZ9Qqdef+rnzWdRZuMbOywu5tO2w2N7rqjoANZ5k9vywhL6Br1VRjUIgTQx4E8w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/kuler": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/kuler/-/kuler-2.0.0.tgz",
      "integrity": "sha512-Xq9nH7KlWZmXAtodXDDRE7vs6DU1gTU8zYDHDiWLSip45Egwq3plLHzPn27NgvzL2r1LMPC1vdqh98sQxtqj4A==",
      "license": "MIT"
    },
    "node_modules/leven": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/leven/-/leven-3.1.0.tgz",
      "integrity": "sha512-qsda+H8jTaUaN/x5vzW2rzc+8Rw4TAQ/4KjB46IwK5VH+IlVeeeje/EoZRpiXvIqjFgK84QffqPztGI3VBLG1A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/lines-and-columns": {
      "version": "1.2.4",
      "resolved": "https://registry.npmjs.org/lines-and-columns/-/lines-and-columns-1.2.4.tgz",
      "integrity": "sha512-7ylylesZQ/PV29jhEDl3Ufjo6ZX7gCqJr5F7PKrqc93v7fzSymt1BpwEU8nAUXs8qzzvqhbjhK5QZg6Mt/HkBg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/locate-path": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/locate-path/-/locate-path-5.0.0.tgz",
      "integrity": "sha512-t7hw9pI+WvuwNJXwk5zVHpyhIqzg2qTlklJOf0mVxGSbe3Fp2VieZcduNYjaLDoy6p9uGpQEGWG87WpMKlNq8g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-locate": "^4.1.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/lodash.defaults": {
      "version": "4.2.0",
      "resolved": "https://registry.npmjs.org/lodash.defaults/-/lodash.defaults-4.2.0.tgz",
      "integrity": "sha512-qjxPLHd3r5DnsdGacqOMU6pb/avJzdh9tFX2ymgoZE27BmjXrNy/y4LoaiTeAb+O3gL8AfpJGtqfX/ae2leYYQ==",
      "license": "MIT"
    },
    "node_modules/lodash.includes": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/lodash.includes/-/lodash.includes-4.3.0.tgz",
      "integrity": "sha512-W3Bx6mdkRTGtlJISOvVD/lbqjTlPPUDTMnlXZFnVwi9NKJ6tiAk6LVdlhZMm17VZisqhKcgzpO5Wz91PCt5b0w==",
      "license": "MIT"
    },
    "node_modules/lodash.isarguments": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/lodash.isarguments/-/lodash.isarguments-3.1.0.tgz",
      "integrity": "sha512-chi4NHZlZqZD18a0imDHnZPrDeBbTtVN7GXMwuGdRH9qotxAjYs3aVLKc7zNOG9eddR5Ksd8rvFEBc9SsggPpg==",
      "license": "MIT"
    },
    "node_modules/lodash.isboolean": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/lodash.isboolean/-/lodash.isboolean-3.0.3.tgz",
      "integrity": "sha512-Bz5mupy2SVbPHURB98VAcw+aHh4vRV5IPNhILUCsOzRmsTmSQ17jIuqopAentWoehktxGd9e/hbIXq980/1QJg==",
      "license": "MIT"
    },
    "node_modules/lodash.isinteger": {
      "version": "4.0.4",
      "resolved": "https://registry.npmjs.org/lodash.isinteger/-/lodash.isinteger-4.0.4.tgz",
      "integrity": "sha512-DBwtEWN2caHQ9/imiNeEA5ys1JoRtRfY3d7V9wkqtbycnAmTvRRmbHKDV4a0EYc678/dia0jrte4tjYwVBaZUA==",
      "license": "MIT"
    },
    "node_modules/lodash.isnumber": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/lodash.isnumber/-/lodash.isnumber-3.0.3.tgz",
      "integrity": "sha512-QYqzpfwO3/CWf3XP+Z+tkQsfaLL/EnUlXWVkIk5FUPc4sBdTehEqZONuyRt2P67PXAk+NXmTBcc97zw9t1FQrw==",
      "license": "MIT"
    },
    "node_modules/lodash.isplainobject": {
      "version": "4.0.6",
      "resolved": "https://registry.npmjs.org/lodash.isplainobject/-/lodash.isplainobject-4.0.6.tgz",
      "integrity": "sha512-oSXzaWypCMHkPC3NvBEaPHf0KsA5mvPrOPgQWDsbg8n7orZ290M0BmC/jgRZ4vcJ6DTAhjrsSYgdsW/F+MFOBA==",
      "license": "MIT"
    },
    "node_modules/lodash.isstring": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/lodash.isstring/-/lodash.isstring-4.0.1.tgz",
      "integrity": "sha512-0wJxfxH1wgO3GrbuP+dTTk7op+6L41QCXbGINEmD+ny/G/eCqGzxyCsh7159S+mgDDcoarnBw6PC1PS5+wUGgw==",
      "license": "MIT"
    },
    "node_modules/lodash.once": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/lodash.once/-/lodash.once-4.1.1.tgz",
      "integrity": "sha512-Sb487aTOCr9drQVL8pIxOzVhafOjZN9UU54hiN8PU3uAiSV7lx1yYNpbNmex2PK6dSJoNTSJUUswT651yww3Mg==",
      "license": "MIT"
    },
    "node_modules/logform": {
      "version": "2.7.0",
      "resolved": "https://registry.npmjs.org/logform/-/logform-2.7.0.tgz",
      "integrity": "sha512-TFYA4jnP7PVbmlBIfhlSe+WKxs9dklXMTEGcBCIvLhE/Tn3H6Gk1norupVW7m5Cnd4bLcr08AytbyV/xj7f/kQ==",
      "license": "MIT",
      "dependencies": {
        "@colors/colors": "1.6.0",
        "@types/triple-beam": "^1.3.2",
        "fecha": "^4.2.0",
        "ms": "^2.1.1",
        "safe-stable-stringify": "^2.3.1",
        "triple-beam": "^1.3.0"
      },
      "engines": {
        "node": ">= 12.0.0"
      }
    },
    "node_modules/logform/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "license": "MIT"
    },
    "node_modules/lru-cache": {
      "version": "5.1.1",
      "resolved": "https://registry.npmjs.org/lru-cache/-/lru-cache-5.1.1.tgz",
      "integrity": "sha512-KpNARQA3Iwv+jTA0utUVVbrh+Jlrr1Fv0e56GGzAFOXN7dk/FviaDW8LHmK52DlcH4WP2n6gI8vN1aesBFgo9w==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "yallist": "^3.0.2"
      }
    },
    "node_modules/make-dir": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/make-dir/-/make-dir-4.0.0.tgz",
      "integrity": "sha512-hXdUTZYIVOt1Ex//jAQi+wTZZpUpwBj/0QsOzqegb3rGMMeJiSEu5xLHnYfBrRV4RH2+OCSOO95Is/7x1WJ4bw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "semver": "^7.5.3"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/make-dir/node_modules/semver": {
      "version": "7.7.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-7.7.1.tgz",
      "integrity": "sha512-hlq8tAfn0m/61p4BVRcPzIGr6LKiMwo4VM6dGi6pt4qcRkmNzTcWq6eCEjEh+qXjkMDvPlOFFSGwQjoEa6gyMA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/makeerror": {
      "version": "1.0.12",
      "resolved": "https://registry.npmjs.org/makeerror/-/makeerror-1.0.12.tgz",
      "integrity": "sha512-JmqCvUhmt43madlpFzG4BQzG2Z3m6tvQDNKdClZnO3VbIudJYmxsT0FNJMeiB2+JTSlTQTSbU8QdesVmwJcmLg==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "tmpl": "1.0.5"
      }
    },
    "node_modules/math-intrinsics": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/math-intrinsics/-/math-intrinsics-1.1.0.tgz",
      "integrity": "sha512-/IXtbwEk5HTPyEwyKX6hGkYXxM9nbj64B+ilVJnC/R6B0pH5G4V3b0pVbL7DBj4tkhBAppbQUlf6F6Xl9LHu1g==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/media-typer": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/media-typer/-/media-typer-0.3.0.tgz",
      "integrity": "sha512-dq+qelQ9akHpcOl/gUVRTxVIOkAJ1wR3QAvb4RsVjS8oVoFjDGTc679wJYmUmknUF5HwMLOgb5O+a3KxfWapPQ==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/merge-descriptors": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/merge-descriptors/-/merge-descriptors-1.0.3.tgz",
      "integrity": "sha512-gaNvAS7TZ897/rVaZ0nMtAyxNyi/pdbjbAwUpFQpN70GqnVfOiXpeUUMKRBmzXaSQ8DdTX4/0ms62r2K+hE6mQ==",
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/merge-stream": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/merge-stream/-/merge-stream-2.0.0.tgz",
      "integrity": "sha512-abv/qOcuPfk3URPfDzmZU1LKmuw8kT+0nIHvKrKgFrwifol/doWcdA4ZqsWQ8ENrFKkd67Mfpo/LovbIUsbt3w==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/methods": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/methods/-/methods-1.1.2.tgz",
      "integrity": "sha512-iclAHeNqNm68zFtnZ0e+1L2yUIdvzNoauKU4WBA3VvH/vPFieF7qfRlwUZU+DA9P9bPXIS90ulxoUoCH23sV2w==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/micromatch": {
      "version": "4.0.8",
      "resolved": "https://registry.npmjs.org/micromatch/-/micromatch-4.0.8.tgz",
      "integrity": "sha512-PXwfBhYu0hBCPw8Dn0E+WDYb7af3dSLVWKi3HGv84IdF4TyFoC0ysxFd0Goxw7nSv4T/PzEJQxsYsEiFCKo2BA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "braces": "^3.0.3",
        "picomatch": "^2.3.1"
      },
      "engines": {
        "node": ">=8.6"
      }
    },
    "node_modules/mime": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/mime/-/mime-1.6.0.tgz",
      "integrity": "sha512-x0Vn8spI+wuJ1O6S7gnbaQg8Pxh4NNHb7KSINmEWKiPE4RKOplvijn+NkmYmmRgP68mc70j2EbeTFRsrswaQeg==",
      "license": "MIT",
      "bin": {
        "mime": "cli.js"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/mime-db": {
      "version": "1.53.0",
      "resolved": "https://registry.npmjs.org/mime-db/-/mime-db-1.53.0.tgz",
      "integrity": "sha512-oHlN/w+3MQ3rba9rqFr6V/ypF10LSkdwUysQL7GkXoTgIWeV+tcXGA852TBxH+gsh8UWoyhR1hKcoMJTuWflpg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/mime-types": {
      "version": "2.1.35",
      "resolved": "https://registry.npmjs.org/mime-types/-/mime-types-2.1.35.tgz",
      "integrity": "sha512-ZDY+bPm5zTTF+YpCrAU9nK0UgICYPT0QtT1NZWFv4s++TNkcgVaT0g6+4R2uI4MjQjzysHB1zxuWL50hzaeXiw==",
      "license": "MIT",
      "dependencies": {
        "mime-db": "1.52.0"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/mime-types/node_modules/mime-db": {
      "version": "1.52.0",
      "resolved": "https://registry.npmjs.org/mime-db/-/mime-db-1.52.0.tgz",
      "integrity": "sha512-sPU4uV7dYlvtWJxwwxHD0PuihVNiE7TyAbQ5SWxDCB9mUYvOgroQOwYQQOKPJ8CIbE+1ETVlOoK1UC2nU3gYvg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/mimic-fn": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/mimic-fn/-/mimic-fn-2.1.0.tgz",
      "integrity": "sha512-OqbOk5oEQeAZ8WXWydlu9HJjz9WVdEIvamMCcXmuqUYjTknH/sqsWvhQ3vgwKFRR1HpjvNBKQ37nbJgYzGqGcg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/minimatch": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz",
      "integrity": "sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^1.1.7"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/morgan": {
      "version": "1.10.0",
      "resolved": "https://registry.npmjs.org/morgan/-/morgan-1.10.0.tgz",
      "integrity": "sha512-AbegBVI4sh6El+1gNwvD5YIck7nSA36weD7xvIxG4in80j/UoK8AEGaWnnz8v1GxonMCltmlNs5ZKbGvl9b1XQ==",
      "license": "MIT",
      "dependencies": {
        "basic-auth": "~2.0.1",
        "debug": "2.6.9",
        "depd": "~2.0.0",
        "on-finished": "~2.3.0",
        "on-headers": "~1.0.2"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/morgan/node_modules/on-finished": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/on-finished/-/on-finished-2.3.0.tgz",
      "integrity": "sha512-ikqdkGAAyf/X/gPhXGvfgAytDZtDbr+bkNUJ0N9h5MI/dmdgCs3l6hoHrcUv41sRKew3jIwrp4qQDXiK99Utww==",
      "license": "MIT",
      "dependencies": {
        "ee-first": "1.1.1"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/ms": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.0.0.tgz",
      "integrity": "sha512-Tpp60P6IUJDTuOq/5Z8cdskzJujfwqfOTkrwIwj7IRISpnkJnT6SyJ4PCPnGMoFjC9ddhal5KVIYtAt97ix05A==",
      "license": "MIT"
    },
    "node_modules/natural-compare": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/natural-compare/-/natural-compare-1.4.0.tgz",
      "integrity": "sha512-OWND8ei3VtNC9h7V60qff3SVobHr996CTwgxubgyQYEpg290h9J0buyECNNJexkFm5sOajh5G116RYA1c8ZMSw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/negotiator": {
      "version": "0.6.4",
      "resolved": "https://registry.npmjs.org/negotiator/-/negotiator-0.6.4.tgz",
      "integrity": "sha512-myRT3DiWPHqho5PrJaIRyaMv2kgYf0mUVgBNOYMuCH5Ki1yEiQaf/ZJuQ62nvpc44wL5WDbTX7yGJi1Neevw8w==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/node-int64": {
      "version": "0.4.0",
      "resolved": "https://registry.npmjs.org/node-int64/-/node-int64-0.4.0.tgz",
      "integrity": "sha512-O5lz91xSOeoXP6DulyHfllpq+Eg00MWitZIbtPfoSEvqIHdl5gfcY6hYzDWnj0qD5tz52PI08u9qUvSVeUBeHw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/node-releases": {
      "version": "2.0.19",
      "resolved": "https://registry.npmjs.org/node-releases/-/node-releases-2.0.19.tgz",
      "integrity": "sha512-xxOWJsBKtzAq7DY0J+DTzuz58K8e7sJbdgwkbMWQe8UYB6ekmsQ45q0M/tJDsGaZmbC+l7n57UV8Hl5tHxO9uw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/nodemon": {
      "version": "3.1.9",
      "resolved": "https://registry.npmjs.org/nodemon/-/nodemon-3.1.9.tgz",
      "integrity": "sha512-hdr1oIb2p6ZSxu3PB2JWWYS7ZQ0qvaZsc3hK8DR8f02kRzc8rjYmxAIvdz+aYC+8F2IjNaB7HMcSDg8nQpJxyg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "chokidar": "^3.5.2",
        "debug": "^4",
        "ignore-by-default": "^1.0.1",
        "minimatch": "^3.1.2",
        "pstree.remy": "^1.1.8",
        "semver": "^7.5.3",
        "simple-update-notifier": "^2.0.0",
        "supports-color": "^5.5.0",
        "touch": "^3.1.0",
        "undefsafe": "^2.0.5"
      },
      "bin": {
        "nodemon": "bin/nodemon.js"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/nodemon"
      }
    },
    "node_modules/nodemon/node_modules/debug": {
      "version": "4.4.0",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.4.0.tgz",
      "integrity": "sha512-6WTZ/IxCY/T6BALoZHaE4ctp9xm+Z5kY/pzYaCHRFeyVhojxlrm+46y68HA6hr0TcwEssoxNiDEUJQjfPZ/RYA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/nodemon/node_modules/has-flag": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/has-flag/-/has-flag-3.0.0.tgz",
      "integrity": "sha512-sKJf1+ceQBr4SMkvQnBDNDtf4TXpVhVGateu0t918bl30FnbE2m4vNLX+VWe/dpjlb+HugGYzW7uQXH98HPEYw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/nodemon/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/nodemon/node_modules/semver": {
      "version": "7.7.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-7.7.1.tgz",
      "integrity": "sha512-hlq8tAfn0m/61p4BVRcPzIGr6LKiMwo4VM6dGi6pt4qcRkmNzTcWq6eCEjEh+qXjkMDvPlOFFSGwQjoEa6gyMA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/nodemon/node_modules/supports-color": {
      "version": "5.5.0",
      "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-5.5.0.tgz",
      "integrity": "sha512-QjVjwdXIt408MIiAqCX4oUKsgU2EqAGzs2Ppkm4aQYbjm+ZEWEcW4SfFNTr4uMNZma0ey4f5lgLrkB0aX0QMow==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "has-flag": "^3.0.0"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/normalize-path": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/normalize-path/-/normalize-path-3.0.0.tgz",
      "integrity": "sha512-6eZs5Ls3WtCisHWp9S2GUy8dqkpGi4BVSz3GaqiE6ezub0512ESztXUwUB6C6IKbQkY2Pnb/mD4WYojCRwcwLA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/npm-run-path": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/npm-run-path/-/npm-run-path-4.0.1.tgz",
      "integrity": "sha512-S48WzZW777zhNIrn7gxOlISNAqi9ZC/uQFnRdbeIHhZhCA6UqpkOT8T1G7BvfdgP4Er8gF4sUbaS0i7QvIfCWw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "path-key": "^3.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/object-assign": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/object-assign/-/object-assign-4.1.1.tgz",
      "integrity": "sha512-rJgTQnkUnH1sFw8yT6VSU3zD3sWmu6sZhIseY8VX+GRu3P6F7Fu+JNDoXfklElbLJSnc3FUQHVe4cU5hj+BcUg==",
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/object-inspect": {
      "version": "1.13.4",
      "resolved": "https://registry.npmjs.org/object-inspect/-/object-inspect-1.13.4.tgz",
      "integrity": "sha512-W67iLl4J2EXEGTbfeHCffrjDfitvLANg0UlX3wFUUSTx92KXRFegMHUVgSqE+wvhAbi4WqjGg9czysTV2Epbew==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/on-finished": {
      "version": "2.4.1",
      "resolved": "https://registry.npmjs.org/on-finished/-/on-finished-2.4.1.tgz",
      "integrity": "sha512-oVlzkg3ENAhCk2zdv7IJwd/QUD4z2RxRwpkcGY8psCVcCYZNq4wYnVWALHM+brtuJjePWiYF/ClmuDr8Ch5+kg==",
      "license": "MIT",
      "dependencies": {
        "ee-first": "1.1.1"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/on-headers": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/on-headers/-/on-headers-1.0.2.tgz",
      "integrity": "sha512-pZAE+FJLoyITytdqK0U5s+FIpjN0JP3OzFi/u8Rx+EV5/W+JTWGXG8xFzevE7AjBfDqHv/8vL8qQsIhHnqRkrA==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/once": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/once/-/once-1.4.0.tgz",
      "integrity": "sha512-lNaJgI+2Q5URQBkccEKHTQOPaXdUxnZZElQTZY0MFUAuaEqe1E+Nyvgdz/aIyNi6Z9MzO5dv1H8n58/GELp3+w==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "wrappy": "1"
      }
    },
    "node_modules/one-time": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/one-time/-/one-time-1.0.0.tgz",
      "integrity": "sha512-5DXOiRKwuSEcQ/l0kGCF6Q3jcADFv5tSmRaJck/OqkVFcOzutB134KRSfF0xDrL39MNnqxbHBbUUcjZIhTgb2g==",
      "license": "MIT",
      "dependencies": {
        "fn.name": "1.x.x"
      }
    },
    "node_modules/onetime": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/onetime/-/onetime-5.1.2.tgz",
      "integrity": "sha512-kbpaSSGJTWdAY5KPVeMOKXSrPtr8C8C7wodJbcsd51jRnmD+GZu8Y0VoU6Dm5Z4vWr0Ig/1NKuWRKf7j5aaYSg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "mimic-fn": "^2.1.0"
      },
      "engines": {
        "node": ">=6"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/p-limit": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-3.1.0.tgz",
      "integrity": "sha512-TYOanM3wGwNGsZN2cVTYPArw454xnXj5qmWF1bEoAc4+cU/ol7GVh7odevjp1FNHduHc3KZMcFduxU5Xc6uJRQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "yocto-queue": "^0.1.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/p-locate": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/p-locate/-/p-locate-4.1.0.tgz",
      "integrity": "sha512-R79ZZ/0wAxKGu3oYMlz8jy/kbhsNrS7SKZ7PxEHBgJ5+F2mtFW2fK2cOtBh1cHYkQsbzFV7I+EoRKe6Yt0oK7A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-limit": "^2.2.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/p-locate/node_modules/p-limit": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-2.3.0.tgz",
      "integrity": "sha512-//88mFWSJx8lxCzwdAABTJL2MyWB12+eIY7MDL2SqLmAkeKU9qxRvWuSyTjm3FUmpBEMuFfckAIqEaVGUDxb6w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-try": "^2.0.0"
      },
      "engines": {
        "node": ">=6"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/p-try": {
      "version": "2.2.0",
      "resolved": "https://registry.npmjs.org/p-try/-/p-try-2.2.0.tgz",
      "integrity": "sha512-R4nPAVTAU0B9D35/Gk3uJf/7XYbQcyohSKdvAxIRSNghFl4e71hVoGnBNQz9cWaXxO2I10KTC+3jMdvvoKw6dQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/parse-json": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/parse-json/-/parse-json-5.2.0.tgz",
      "integrity": "sha512-ayCKvm/phCGxOkYRSCM82iDwct8/EonSEgCSxWxD7ve6jHggsFl4fZVQBPRNgQoKiuV/odhFrGzQXZwbifC8Rg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/code-frame": "^7.0.0",
        "error-ex": "^1.3.1",
        "json-parse-even-better-errors": "^2.3.0",
        "lines-and-columns": "^1.1.6"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/parseurl": {
      "version": "1.3.3",
      "resolved": "https://registry.npmjs.org/parseurl/-/parseurl-1.3.3.tgz",
      "integrity": "sha512-CiyeOxFT/JZyN5m0z9PfXw4SCBJ6Sygz1Dpl0wqjlhDEGGBP1GnsUVEL0p63hoG1fcj3fHynXi9NYO4nWOL+qQ==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/path-exists": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/path-exists/-/path-exists-4.0.0.tgz",
      "integrity": "sha512-ak9Qy5Q7jYb2Wwcey5Fpvg2KoAc/ZIhLSLOSBmRmygPsGwkVVt0fZa0qrtMz+m6tJTAHfZQ8FnmB4MG4LWy7/w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/path-is-absolute": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/path-is-absolute/-/path-is-absolute-1.0.1.tgz",
      "integrity": "sha512-AVbw3UJ2e9bq64vSaS9Am0fje1Pa8pbGqTTsmXfaIiMpnr5DlDhfJOuLj9Sf95ZPVDAUerDfEk88MPmPe7UCQg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/path-key": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/path-key/-/path-key-3.1.1.tgz",
      "integrity": "sha512-ojmeN0qd+y0jszEtoY48r0Peq5dwMEkIlCOu6Q5f41lfkswXuKtYrhgoTpLnyIcHm24Uhqx+5Tqm2InSwLhE6Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/path-parse": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/path-parse/-/path-parse-1.0.7.tgz",
      "integrity": "sha512-LDJzPVEEEPR+y48z93A0Ed0yXb8pAByGWo/k5YYdYgpY2/2EsOsksJrq7lOHxryrVOn1ejG6oAp8ahvOIQD8sw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/path-to-regexp": {
      "version": "0.1.12",
      "resolved": "https://registry.npmjs.org/path-to-regexp/-/path-to-regexp-0.1.12.tgz",
      "integrity": "sha512-RA1GjUVMnvYFxuqovrEqZoxxW5NUZqbwKtYz/Tt7nXerk0LbLblQmrsgdeOxV5SFHf0UDggjS/bSeOZwt1pmEQ==",
      "license": "MIT"
    },
    "node_modules/picocolors": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/picocolors/-/picocolors-1.1.1.tgz",
      "integrity": "sha512-xceH2snhtb5M9liqDsmEw56le376mTZkEX/jEb/RxNFyegNul7eNslCXP9FDj/Lcu0X8KEyMceP2ntpaHrDEVA==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/picomatch": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/picomatch/-/picomatch-2.3.1.tgz",
      "integrity": "sha512-JU3teHTNjmE2VCGFzuY8EXzCDVwEqB2a8fsIvwaStHhAWJEeVd1o1QD80CU6+ZdEXXSLbSsuLwJjkCBWqRQUVA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8.6"
      },
      "funding": {
        "url": "https://github.com/sponsors/jonschlinkert"
      }
    },
    "node_modules/pirates": {
      "version": "4.0.6",
      "resolved": "https://registry.npmjs.org/pirates/-/pirates-4.0.6.tgz",
      "integrity": "sha512-saLsH7WeYYPiD25LDuLRRY/i+6HaPYr6G1OUlN39otzkSTxKnubR9RTxS3/Kk50s1g2JTgFwWQDQyplC5/SHZg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/pkg-dir": {
      "version": "4.2.0",
      "resolved": "https://registry.npmjs.org/pkg-dir/-/pkg-dir-4.2.0.tgz",
      "integrity": "sha512-HRDzbaKjC+AOWVXxAU/x54COGeIv9eb+6CkDSQoNTt4XyWoIJvuPsXizxu/Fr23EiekbtZwmh1IcIG/l/a10GQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "find-up": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/pretty-format": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/pretty-format/-/pretty-format-29.7.0.tgz",
      "integrity": "sha512-Pdlw/oPxN+aXdmM9R00JVC9WVFoCLTKJvDVLgmJ+qAffBMxsV85l/Lu7sNx4zSzPyoL2euImuEwHhOXdEgNFZQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/schemas": "^29.6.3",
        "ansi-styles": "^5.0.0",
        "react-is": "^18.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/pretty-format/node_modules/ansi-styles": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-5.2.0.tgz",
      "integrity": "sha512-Cxwpt2SfTzTtXcfOlzGEee8O+c+MmUgGrNiBcXnuWxuFJHe6a5Hz7qwhwe5OgaSYI0IJvkLqWX1ASG+cJOkEiA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/prom-client": {
      "version": "14.2.0",
      "resolved": "https://registry.npmjs.org/prom-client/-/prom-client-14.2.0.tgz",
      "integrity": "sha512-sF308EhTenb/pDRPakm+WgiN+VdM/T1RaHj1x+MvAuT8UiQP8JmOEbxVqtkbfR4LrvOg5n7ic01kRBDGXjYikA==",
      "license": "Apache-2.0",
      "dependencies": {
        "tdigest": "^0.1.1"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/prompts": {
      "version": "2.4.2",
      "resolved": "https://registry.npmjs.org/prompts/-/prompts-2.4.2.tgz",
      "integrity": "sha512-NxNv/kLguCA7p3jE8oL2aEBsrJWgAakBpgmgK6lpPWV+WuOmY6r2/zbAVnP+T8bQlA0nzHXSJSJW0Hq7ylaD2Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "kleur": "^3.0.3",
        "sisteransi": "^1.0.5"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/proxy-addr": {
      "version": "2.0.7",
      "resolved": "https://registry.npmjs.org/proxy-addr/-/proxy-addr-2.0.7.tgz",
      "integrity": "sha512-llQsMLSUDUPT44jdrU/O37qlnifitDP+ZwrmmZcoSKyLKvtZxpyV0n2/bD/N4tBAAZ/gJEdZU7KMraoK1+XYAg==",
      "license": "MIT",
      "dependencies": {
        "forwarded": "0.2.0",
        "ipaddr.js": "1.9.1"
      },
      "engines": {
        "node": ">= 0.10"
      }
    },
    "node_modules/pstree.remy": {
      "version": "1.1.8",
      "resolved": "https://registry.npmjs.org/pstree.remy/-/pstree.remy-1.1.8.tgz",
      "integrity": "sha512-77DZwxQmxKnu3aR542U+X8FypNzbfJ+C5XQDk3uWjWxn6151aIMGthWYRXTqT1E5oJvg+ljaa2OJi+VfvCOQ8w==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/pure-rand": {
      "version": "6.1.0",
      "resolved": "https://registry.npmjs.org/pure-rand/-/pure-rand-6.1.0.tgz",
      "integrity": "sha512-bVWawvoZoBYpp6yIoQtQXHZjmz35RSVHnUOTefl8Vcjr8snTPY1wnpSPMWekcFwbxI6gtmT7rSYPFvz71ldiOA==",
      "dev": true,
      "funding": [
        {
          "type": "individual",
          "url": "https://github.com/sponsors/dubzzz"
        },
        {
          "type": "opencollective",
          "url": "https://opencollective.com/fast-check"
        }
      ],
      "license": "MIT"
    },
    "node_modules/qs": {
      "version": "6.13.0",
      "resolved": "https://registry.npmjs.org/qs/-/qs-6.13.0.tgz",
      "integrity": "sha512-+38qI9SOr8tfZ4QmJNplMUxqjbe7LKvvZgWdExBOmd+egZTtjLB67Gu0HRX3u/XOq7UU2Nx6nsjvS16Z9uwfpg==",
      "license": "BSD-3-Clause",
      "dependencies": {
        "side-channel": "^1.0.6"
      },
      "engines": {
        "node": ">=0.6"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/range-parser": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/range-parser/-/range-parser-1.2.1.tgz",
      "integrity": "sha512-Hrgsx+orqoygnmhFbKaHE6c296J+HTAQXoxEF6gNupROmmGJRoyzfG3ccAveqCBrwr/2yxQ5BVd/GTl5agOwSg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/raw-body": {
      "version": "2.5.2",
      "resolved": "https://registry.npmjs.org/raw-body/-/raw-body-2.5.2.tgz",
      "integrity": "sha512-8zGqypfENjCIqGhgXToC8aB2r7YrBX+AQAfIPs/Mlk+BtPTztOvTS01NRW/3Eh60J+a48lt8qsCzirQ6loCVfA==",
      "license": "MIT",
      "dependencies": {
        "bytes": "3.1.2",
        "http-errors": "2.0.0",
        "iconv-lite": "0.4.24",
        "unpipe": "1.0.0"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/react-is": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-18.3.1.tgz",
      "integrity": "sha512-/LLMVyas0ljjAtoYiPqYiL8VWXzUUdThrmU5+n20DZv+a+ClRoevUzw5JxU+Ieh5/c87ytoTBV9G1FiKfNJdmg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/readable-stream": {
      "version": "3.6.2",
      "resolved": "https://registry.npmjs.org/readable-stream/-/readable-stream-3.6.2.tgz",
      "integrity": "sha512-9u/sniCrY3D5WdsERHzHE4G2YCXqoG5FTHUiCC4SIbr6XcLZBY05ya9EKjYek9O5xOAwjGq+1JdGBAS7Q9ScoA==",
      "license": "MIT",
      "dependencies": {
        "inherits": "^2.0.3",
        "string_decoder": "^1.1.1",
        "util-deprecate": "^1.0.1"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/readdirp": {
      "version": "3.6.0",
      "resolved": "https://registry.npmjs.org/readdirp/-/readdirp-3.6.0.tgz",
      "integrity": "sha512-hOS089on8RduqdbhvQ5Z37A0ESjsqz6qnRcffsMU3495FuTdqSm+7bhJ29JvIOsBDEEnan5DPu9t3To9VRlMzA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "picomatch": "^2.2.1"
      },
      "engines": {
        "node": ">=8.10.0"
      }
    },
    "node_modules/redis-errors": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/redis-errors/-/redis-errors-1.2.0.tgz",
      "integrity": "sha512-1qny3OExCf0UvUV/5wpYKf2YwPcOqXzkwKKSmKHiE6ZMQs5heeE/c8eXK+PNllPvmjgAbfnsbpkGZWy8cBpn9w==",
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/redis-parser": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/redis-parser/-/redis-parser-3.0.0.tgz",
      "integrity": "sha512-DJnGAeenTdpMEH6uAJRK/uiyEIH9WVsUmoLwzudwGJUwZPp80PDBWPHXSAGNPwNvIXAbe7MSUB1zQFugFml66A==",
      "license": "MIT",
      "dependencies": {
        "redis-errors": "^1.0.0"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/require-directory": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/require-directory/-/require-directory-2.1.1.tgz",
      "integrity": "sha512-fGxEI7+wsG9xrvdjsrlmL22OMTTiHRwAMroiEeMgq8gzoLC/PQr7RsRDSTLUg/bZAZtF+TVIkHc6/4RIKrui+Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/resolve": {
      "version": "1.22.10",
      "resolved": "https://registry.npmjs.org/resolve/-/resolve-1.22.10.tgz",
      "integrity": "sha512-NPRy+/ncIMeDlTAsuqwKIiferiawhefFJtkNSW0qZJEqMEb+qBt/77B/jGeeek+F0uOeN05CDa6HXbbIgtVX4w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-core-module": "^2.16.0",
        "path-parse": "^1.0.7",
        "supports-preserve-symlinks-flag": "^1.0.0"
      },
      "bin": {
        "resolve": "bin/resolve"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/resolve-cwd": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/resolve-cwd/-/resolve-cwd-3.0.0.tgz",
      "integrity": "sha512-OrZaX2Mb+rJCpH/6CpSqt9xFVpN++x01XnN2ie9g6P5/3xelLAkXWVADpdz1IHD/KFfEXyE6V0U01OQ3UO2rEg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "resolve-from": "^5.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/resolve-from": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/resolve-from/-/resolve-from-5.0.0.tgz",
      "integrity": "sha512-qYg9KP24dD5qka9J47d0aVky0N+b4fTU89LN9iDnjB5waksiC49rvMB0PrUJQGoTmH50XPiqOvAjDfaijGxYZw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/resolve.exports": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/resolve.exports/-/resolve.exports-2.0.3.tgz",
      "integrity": "sha512-OcXjMsGdhL4XnbShKpAcSqPMzQoYkYyhbEaeSko47MjRP9NfEQMhZkXL1DoFlt9LWQn4YttrdnV6X2OiyzBi+A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/safe-buffer": {
      "version": "5.2.1",
      "resolved": "https://registry.npmjs.org/safe-buffer/-/safe-buffer-5.2.1.tgz",
      "integrity": "sha512-rp3So07KcdmmKbGvgaNxQSJr7bGVSVk5S9Eq1F+ppbRo70+YeaDxkw5Dd8NPN+GD6bjnYm2VuPuCXmpuYvmCXQ==",
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ],
      "license": "MIT"
    },
    "node_modules/safe-stable-stringify": {
      "version": "2.5.0",
      "resolved": "https://registry.npmjs.org/safe-stable-stringify/-/safe-stable-stringify-2.5.0.tgz",
      "integrity": "sha512-b3rppTKm9T+PsVCBEOUR46GWI7fdOs00VKZ1+9c1EWDaDMvjQc6tUwuFyIprgGgTcWoVHSKrU8H31ZHA2e0RHA==",
      "license": "MIT",
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/safer-buffer": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/safer-buffer/-/safer-buffer-2.1.2.tgz",
      "integrity": "sha512-YZo3K82SD7Riyi0E1EQPojLz7kpepnSQI9IyPbHHg1XXXevb5dJI7tpyN2ADxGcQbHG7vcyRHk0cbwqcQriUtg==",
      "license": "MIT"
    },
    "node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/send": {
      "version": "0.19.0",
      "resolved": "https://registry.npmjs.org/send/-/send-0.19.0.tgz",
      "integrity": "sha512-dW41u5VfLXu8SJh5bwRmyYUbAoSB3c9uQh6L8h/KtsFREPWpbX1lrljJo186Jc4nmci/sGUZ9a0a0J2zgfq2hw==",
      "license": "MIT",
      "dependencies": {
        "debug": "2.6.9",
        "depd": "2.0.0",
        "destroy": "1.2.0",
        "encodeurl": "~1.0.2",
        "escape-html": "~1.0.3",
        "etag": "~1.8.1",
        "fresh": "0.5.2",
        "http-errors": "2.0.0",
        "mime": "1.6.0",
        "ms": "2.1.3",
        "on-finished": "2.4.1",
        "range-parser": "~1.2.1",
        "statuses": "2.0.1"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/send/node_modules/encodeurl": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/encodeurl/-/encodeurl-1.0.2.tgz",
      "integrity": "sha512-TPJXq8JqFaVYm2CWmPvnP2Iyo4ZSM7/QKcSmuMLDObfpH5fi7RUGmd/rTDf+rut/saiDiQEeVTNgAmJEdAOx0w==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/send/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "license": "MIT"
    },
    "node_modules/serve-static": {
      "version": "1.16.2",
      "resolved": "https://registry.npmjs.org/serve-static/-/serve-static-1.16.2.tgz",
      "integrity": "sha512-VqpjJZKadQB/PEbEwvFdO43Ax5dFBZ2UECszz8bQ7pi7wt//PWe1P6MN7eCnjsatYtBT6EuiClbjSWP2WrIoTw==",
      "license": "MIT",
      "dependencies": {
        "encodeurl": "~2.0.0",
        "escape-html": "~1.0.3",
        "parseurl": "~1.3.3",
        "send": "0.19.0"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/setprototypeof": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/setprototypeof/-/setprototypeof-1.2.0.tgz",
      "integrity": "sha512-E5LDX7Wrp85Kil5bhZv46j8jOeboKq5JMmYM3gVGdGH8xFpPWXUMsNrlODCrkoxMEeNi/XZIwuRvY4XNwYMJpw==",
      "license": "ISC"
    },
    "node_modules/shebang-command": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/shebang-command/-/shebang-command-2.0.0.tgz",
      "integrity": "sha512-kHxr2zZpYtdmrN1qDjrrX/Z1rR1kG8Dx+gkpK1G4eXmvXswmcE1hTWBWYUzlraYw1/yZp6YuDY77YtvbN0dmDA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "shebang-regex": "^3.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/shebang-regex": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/shebang-regex/-/shebang-regex-3.0.0.tgz",
      "integrity": "sha512-7++dFhtcx3353uBaq8DDR4NuxBetBzC7ZQOhmTQInHEd6bSrXdiEyzCvG07Z44UYdLShWUyXt5M/yhz8ekcb1A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/side-channel": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/side-channel/-/side-channel-1.1.0.tgz",
      "integrity": "sha512-ZX99e6tRweoUXqR+VBrslhda51Nh5MTQwou5tnUDgbtyM0dBgmhEDtWGP/xbKn6hqfPRHujUNwz5fy/wbbhnpw==",
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "object-inspect": "^1.13.3",
        "side-channel-list": "^1.0.0",
        "side-channel-map": "^1.0.1",
        "side-channel-weakmap": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/side-channel-list": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/side-channel-list/-/side-channel-list-1.0.0.tgz",
      "integrity": "sha512-FCLHtRD/gnpCiCHEiJLOwdmFP+wzCmDEkc9y7NsYxeF4u7Btsn1ZuwgwJGxImImHicJArLP4R0yX4c2KCrMrTA==",
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "object-inspect": "^1.13.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/side-channel-map": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/side-channel-map/-/side-channel-map-1.0.1.tgz",
      "integrity": "sha512-VCjCNfgMsby3tTdo02nbjtM/ewra6jPHmpThenkTYh8pG9ucZ/1P8So4u4FGBek/BjpOVsDCMoLA/iuBKIFXRA==",
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.5",
        "object-inspect": "^1.13.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/side-channel-weakmap": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/side-channel-weakmap/-/side-channel-weakmap-1.0.2.tgz",
      "integrity": "sha512-WPS/HvHQTYnHisLo9McqBHOJk2FkHO/tlpvldyrnem4aeQp4hai3gythswg6p01oSoTl58rcpiFAjF2br2Ak2A==",
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.5",
        "object-inspect": "^1.13.3",
        "side-channel-map": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/signal-exit": {
      "version": "3.0.7",
      "resolved": "https://registry.npmjs.org/signal-exit/-/signal-exit-3.0.7.tgz",
      "integrity": "sha512-wnD2ZE+l+SPC/uoS0vXeE9L1+0wuaMqKlfz9AMUo38JsyLSBWSFcHR1Rri62LZc12vLr1gb3jl7iwQhgwpAbGQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/simple-swizzle": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/simple-swizzle/-/simple-swizzle-0.2.2.tgz",
      "integrity": "sha512-JA//kQgZtbuY83m+xT+tXJkmJncGMTFT+C+g2h2R9uxkYIrE2yy9sgmcLhCnw57/WSD+Eh3J97FPEDFnbXnDUg==",
      "license": "MIT",
      "dependencies": {
        "is-arrayish": "^0.3.1"
      }
    },
    "node_modules/simple-swizzle/node_modules/is-arrayish": {
      "version": "0.3.2",
      "resolved": "https://registry.npmjs.org/is-arrayish/-/is-arrayish-0.3.2.tgz",
      "integrity": "sha512-eVRqCvVlZbuw3GrM63ovNSNAeA1K16kaR/LRY/92w0zxQ5/1YzwblUX652i4Xs9RwAGjW9d9y6X88t8OaAJfWQ==",
      "license": "MIT"
    },
    "node_modules/simple-update-notifier": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/simple-update-notifier/-/simple-update-notifier-2.0.0.tgz",
      "integrity": "sha512-a2B9Y0KlNXl9u/vsW6sTIu9vGEpfKu2wRV6l1H3XEas/0gUIzGzBoP/IouTcUQbm9JWZLH3COxyn03TYlFax6w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "semver": "^7.5.3"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/simple-update-notifier/node_modules/semver": {
      "version": "7.7.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-7.7.1.tgz",
      "integrity": "sha512-hlq8tAfn0m/61p4BVRcPzIGr6LKiMwo4VM6dGi6pt4qcRkmNzTcWq6eCEjEh+qXjkMDvPlOFFSGwQjoEa6gyMA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/sisteransi": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/sisteransi/-/sisteransi-1.0.5.tgz",
      "integrity": "sha512-bLGGlR1QxBcynn2d5YmDX4MGjlZvy2MRBDRNHLJ8VI6l6+9FUiyTFNJ0IveOSP0bcXgVDPRcfGqA0pjaqUpfVg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/slash": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/slash/-/slash-3.0.0.tgz",
      "integrity": "sha512-g9Q1haeby36OSStwb4ntCGGGaKsaVSjQ68fBxoQcutl5fS1vuY18H3wSt3jFyFtrkx+Kz0V1G85A4MyAdDMi2Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/socket.io": {
      "version": "4.8.1",
      "resolved": "https://registry.npmjs.org/socket.io/-/socket.io-4.8.1.tgz",
      "integrity": "sha512-oZ7iUCxph8WYRHHcjBEc9unw3adt5CmSNlppj/5Q4k2RIrhl8Z5yY2Xr4j9zj0+wzVZ0bxmYoGSzKJnRl6A4yg==",
      "license": "MIT",
      "dependencies": {
        "accepts": "~1.3.4",
        "base64id": "~2.0.0",
        "cors": "~2.8.5",
        "debug": "~4.3.2",
        "engine.io": "~6.6.0",
        "socket.io-adapter": "~2.5.2",
        "socket.io-parser": "~4.2.4"
      },
      "engines": {
        "node": ">=10.2.0"
      }
    },
    "node_modules/socket.io-adapter": {
      "version": "2.5.5",
      "resolved": "https://registry.npmjs.org/socket.io-adapter/-/socket.io-adapter-2.5.5.tgz",
      "integrity": "sha512-eLDQas5dzPgOWCk9GuuJC2lBqItuhKI4uxGgo9aIV7MYbk2h9Q6uULEh8WBzThoI7l+qU9Ast9fVUmkqPP9wYg==",
      "license": "MIT",
      "dependencies": {
        "debug": "~4.3.4",
        "ws": "~8.17.1"
      }
    },
    "node_modules/socket.io-adapter/node_modules/debug": {
      "version": "4.3.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.3.7.tgz",
      "integrity": "sha512-Er2nc/H7RrMXZBFCEim6TCmMk02Z8vLC2Rbi1KEBggpo0fS6l0S1nnapwmIi3yW/+GOJap1Krg4w0Hg80oCqgQ==",
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/socket.io-adapter/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "license": "MIT"
    },
    "node_modules/socket.io-parser": {
      "version": "4.2.4",
      "resolved": "https://registry.npmjs.org/socket.io-parser/-/socket.io-parser-4.2.4.tgz",
      "integrity": "sha512-/GbIKmo8ioc+NIWIhwdecY0ge+qVBSMdgxGygevmdHj24bsfgtCmcUUcQ5ZzcylGFHsN3k4HB4Cgkl96KVnuew==",
      "license": "MIT",
      "dependencies": {
        "@socket.io/component-emitter": "~3.1.0",
        "debug": "~4.3.1"
      },
      "engines": {
        "node": ">=10.0.0"
      }
    },
    "node_modules/socket.io-parser/node_modules/debug": {
      "version": "4.3.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.3.7.tgz",
      "integrity": "sha512-Er2nc/H7RrMXZBFCEim6TCmMk02Z8vLC2Rbi1KEBggpo0fS6l0S1nnapwmIi3yW/+GOJap1Krg4w0Hg80oCqgQ==",
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/socket.io-parser/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "license": "MIT"
    },
    "node_modules/socket.io/node_modules/debug": {
      "version": "4.3.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.3.7.tgz",
      "integrity": "sha512-Er2nc/H7RrMXZBFCEim6TCmMk02Z8vLC2Rbi1KEBggpo0fS6l0S1nnapwmIi3yW/+GOJap1Krg4w0Hg80oCqgQ==",
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/socket.io/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "license": "MIT"
    },
    "node_modules/source-map": {
      "version": "0.6.1",
      "resolved": "https://registry.npmjs.org/source-map/-/source-map-0.6.1.tgz",
      "integrity": "sha512-UjgapumWlbMhkBgzT7Ykc5YXUT46F0iKu8SGXq0bcwP5dz/h0Plj6enJqjz1Zbq2l5WaqYnrVbwWOWMyF3F47g==",
      "dev": true,
      "license": "BSD-3-Clause",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/source-map-support": {
      "version": "0.5.13",
      "resolved": "https://registry.npmjs.org/source-map-support/-/source-map-support-0.5.13.tgz",
      "integrity": "sha512-SHSKFHadjVA5oR4PPqhtAVdcBWwRYVd6g6cAXnIbRiIwc2EhPrTuKUBdSLvlEKyIP3GCf89fltvcZiP9MMFA1w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "buffer-from": "^1.0.0",
        "source-map": "^0.6.0"
      }
    },
    "node_modules/sprintf-js": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/sprintf-js/-/sprintf-js-1.0.3.tgz",
      "integrity": "sha512-D9cPgkvLlV3t3IzL0D0YLvGA9Ahk4PcvVwUbN0dSGr1aP0Nrt4AEnTUbuGvquEC0mA64Gqt1fzirlRs5ibXx8g==",
      "dev": true,
      "license": "BSD-3-Clause"
    },
    "node_modules/stack-trace": {
      "version": "0.0.10",
      "resolved": "https://registry.npmjs.org/stack-trace/-/stack-trace-0.0.10.tgz",
      "integrity": "sha512-KGzahc7puUKkzyMt+IqAep+TVNbKP+k2Lmwhub39m1AsTSkaDutx56aDCo+HLDzf/D26BIHTJWNiTG1KAJiQCg==",
      "license": "MIT",
      "engines": {
        "node": "*"
      }
    },
    "node_modules/stack-utils": {
      "version": "2.0.6",
      "resolved": "https://registry.npmjs.org/stack-utils/-/stack-utils-2.0.6.tgz",
      "integrity": "sha512-XlkWvfIm6RmsWtNJx+uqtKLS8eqFbxUg0ZzLXqY0caEy9l7hruX8IpiDnjsLavoBgqCCR71TqWO8MaXYheJ3RQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "escape-string-regexp": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/standard-as-callback": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/standard-as-callback/-/standard-as-callback-2.1.0.tgz",
      "integrity": "sha512-qoRRSyROncaz1z0mvYqIE4lCd9p2R90i6GxW3uZv5ucSu8tU7B5HXUP1gG8pVZsYNVaXjk8ClXHPttLyxAL48A==",
      "license": "MIT"
    },
    "node_modules/statuses": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/statuses/-/statuses-2.0.1.tgz",
      "integrity": "sha512-RwNA9Z/7PrK06rYLIzFMlaF+l73iwpzsqRIFgbMLbTcLD6cOao82TaWefPXQvB2fOC4AjuYSEndS7N/mTCbkdQ==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/string_decoder": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/string_decoder/-/string_decoder-1.3.0.tgz",
      "integrity": "sha512-hkRX8U1WjJFd8LsDJ2yQ/wWWxaopEsABU1XfkM8A+j0+85JAGppt16cr1Whg6KIbb4okU6Mql6BOj+uup/wKeA==",
      "license": "MIT",
      "dependencies": {
        "safe-buffer": "~5.2.0"
      }
    },
    "node_modules/string-length": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/string-length/-/string-length-4.0.2.tgz",
      "integrity": "sha512-+l6rNN5fYHNhZZy41RXsYptCjA2Igmq4EG7kZAYFQI1E1VTXarr6ZPXBg6eq7Y6eK4FEhY6AJlyuFIb/v/S0VQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "char-regex": "^1.0.2",
        "strip-ansi": "^6.0.0"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/string-width": {
      "version": "4.2.3",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz",
      "integrity": "sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "emoji-regex": "^8.0.0",
        "is-fullwidth-code-point": "^3.0.0",
        "strip-ansi": "^6.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/strip-ansi": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz",
      "integrity": "sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/strip-bom": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/strip-bom/-/strip-bom-4.0.0.tgz",
      "integrity": "sha512-3xurFv5tEgii33Zi8Jtp55wEIILR9eh34FAW00PZf+JnSsTmV/ioewSgQl97JHvgjoRGwPShsWm+IdrxB35d0w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/strip-final-newline": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/strip-final-newline/-/strip-final-newline-2.0.0.tgz",
      "integrity": "sha512-BrpvfNAE3dcvq7ll3xVumzjKjZQ5tI1sEUIKr3Uoks0XUl45St3FlatVqef9prk4jRDzhW6WZg+3bk93y6pLjA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/strip-json-comments": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/strip-json-comments/-/strip-json-comments-3.1.1.tgz",
      "integrity": "sha512-6fPc+R4ihwqP6N/aIv2f1gMH8lOVtWQHoqC4yK6oSDVVocumAsfCqjkXnqiYMhmMwS/mEHLp7Vehlt3ql6lEig==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/supports-color": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-7.2.0.tgz",
      "integrity": "sha512-qpCAvRl9stuOHveKsn7HncJRvv501qIacKzQlO/+Lwxc9+0q2wLyv4Dfvt80/DPn2pqOBsJdDiogXGR9+OvwRw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "has-flag": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/supports-preserve-symlinks-flag": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/supports-preserve-symlinks-flag/-/supports-preserve-symlinks-flag-1.0.0.tgz",
      "integrity": "sha512-ot0WnXS9fgdkgIcePe6RHNk1WA8+muPa6cSjeR3V8K27q9BB1rTE3R1p7Hv0z1ZyAc8s6Vvv8DIyWf681MAt0w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/tdigest": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/tdigest/-/tdigest-0.1.2.tgz",
      "integrity": "sha512-+G0LLgjjo9BZX2MfdvPfH+MKLCrxlXSYec5DaPYP1fe6Iyhf0/fSmJ0bFiZ1F8BT6cGXl2LpltQptzjXKWEkKA==",
      "license": "MIT",
      "dependencies": {
        "bintrees": "1.0.2"
      }
    },
    "node_modules/test-exclude": {
      "version": "6.0.0",
      "resolved": "https://registry.npmjs.org/test-exclude/-/test-exclude-6.0.0.tgz",
      "integrity": "sha512-cAGWPIyOHU6zlmg88jwm7VRyXnMN7iV68OGAbYDk/Mh/xC/pzVPlQtY6ngoIH/5/tciuhGfvESU8GrHrcxD56w==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "@istanbuljs/schema": "^0.1.2",
        "glob": "^7.1.4",
        "minimatch": "^3.0.4"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/text-hex": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/text-hex/-/text-hex-1.0.0.tgz",
      "integrity": "sha512-uuVGNWzgJ4yhRaNSiubPY7OjISw4sw4E5Uv0wbjp+OzcbmVU/rsT8ujgcXJhn9ypzsgr5vlzpPqP+MBBKcGvbg==",
      "license": "MIT"
    },
    "node_modules/tmpl": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/tmpl/-/tmpl-1.0.5.tgz",
      "integrity": "sha512-3f0uOEAQwIqGuWW2MVzYg8fV/QNnc/IpuJNG837rLuczAaLVHslWHZQj4IGiEl5Hs3kkbhwL9Ab7Hrsmuj+Smw==",
      "dev": true,
      "license": "BSD-3-Clause"
    },
    "node_modules/to-regex-range": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/to-regex-range/-/to-regex-range-5.0.1.tgz",
      "integrity": "sha512-65P7iz6X5yEr1cwcgvQxbbIw7Uk3gOy5dIdtZ4rDveLqhrdJP+Li/Hx6tyK0NEb+2GCyneCMJiGqrADCSNk8sQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-number": "^7.0.0"
      },
      "engines": {
        "node": ">=8.0"
      }
    },
    "node_modules/toidentifier": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/toidentifier/-/toidentifier-1.0.1.tgz",
      "integrity": "sha512-o5sSPKEkg/DIQNmH43V0/uerLrpzVedkUh8tGNvaeXpfpuwjKenlSox/2O/BTlZUtEe+JG7s5YhEz608PlAHRA==",
      "license": "MIT",
      "engines": {
        "node": ">=0.6"
      }
    },
    "node_modules/touch": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/touch/-/touch-3.1.1.tgz",
      "integrity": "sha512-r0eojU4bI8MnHr8c5bNo7lJDdI2qXlWWJk6a9EAFG7vbhTjElYhBVS3/miuE0uOuoLdb8Mc/rVfsmm6eo5o9GA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "nodetouch": "bin/nodetouch.js"
      }
    },
    "node_modules/triple-beam": {
      "version": "1.4.1",
      "resolved": "https://registry.npmjs.org/triple-beam/-/triple-beam-1.4.1.tgz",
      "integrity": "sha512-aZbgViZrg1QNcG+LULa7nhZpJTZSLm/mXnHXnbAbjmN5aSa0y7V+wvv6+4WaBtpISJzThKy+PIPxc1Nq1EJ9mg==",
      "license": "MIT",
      "engines": {
        "node": ">= 14.0.0"
      }
    },
    "node_modules/type-detect": {
      "version": "4.0.8",
      "resolved": "https://registry.npmjs.org/type-detect/-/type-detect-4.0.8.tgz",
      "integrity": "sha512-0fr/mIH1dlO+x7TlcMy+bIDqKPsw/70tVyeHW787goQjhmqaZe10uwLujubK9q9Lg6Fiho1KUKDYz0Z7k7g5/g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/type-fest": {
      "version": "0.21.3",
      "resolved": "https://registry.npmjs.org/type-fest/-/type-fest-0.21.3.tgz",
      "integrity": "sha512-t0rzBq87m3fVcduHDUFhKmyyX+9eo6WQjZvf51Ea/M0Q7+T374Jp1aUiyUl0GKxp8M/OETVHSDvmkyPgvX+X2w==",
      "dev": true,
      "license": "(MIT OR CC0-1.0)",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/type-is": {
      "version": "1.6.18",
      "resolved": "https://registry.npmjs.org/type-is/-/type-is-1.6.18.tgz",
      "integrity": "sha512-TkRKr9sUTxEH8MdfuCSP7VizJyzRNMjj2J2do2Jr3Kym598JVdEksuzPQCnlFPW4ky9Q+iA+ma9BGm06XQBy8g==",
      "license": "MIT",
      "dependencies": {
        "media-typer": "0.3.0",
        "mime-types": "~2.1.24"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/undefsafe": {
      "version": "2.0.5",
      "resolved": "https://registry.npmjs.org/undefsafe/-/undefsafe-2.0.5.tgz",
      "integrity": "sha512-WxONCrssBM8TSPRqN5EmsjVrsv4A8X12J4ArBiiayv3DyyG3ZlIg6yysuuSYdZsVz3TKcTg2fd//Ujd4CHV1iA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/undici-types": {
      "version": "6.20.0",
      "resolved": "https://registry.npmjs.org/undici-types/-/undici-types-6.20.0.tgz",
      "integrity": "sha512-Ny6QZ2Nju20vw1SRHe3d9jVu6gJ+4e3+MMpqu7pqE5HT6WsTSlce++GQmK5UXS8mzV8DSYHrQH+Xrf2jVcuKNg==",
      "license": "MIT"
    },
    "node_modules/unpipe": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/unpipe/-/unpipe-1.0.0.tgz",
      "integrity": "sha512-pjy2bYhSsufwWlKwPc+l3cN7+wuJlK6uz0YdJEOlQDbl6jo/YlPi4mb8agUkVC8BF7V8NuzeyPNqRksA3hztKQ==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/update-browserslist-db": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/update-browserslist-db/-/update-browserslist-db-1.1.3.tgz",
      "integrity": "sha512-UxhIZQ+QInVdunkDAaiazvvT/+fXL5Osr0JZlJulepYu6Jd7qJtDZjlur0emRlT71EN3ScPoE7gvsuIKKNavKw==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/browserslist"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "escalade": "^3.2.0",
        "picocolors": "^1.1.1"
      },
      "bin": {
        "update-browserslist-db": "cli.js"
      },
      "peerDependencies": {
        "browserslist": ">= 4.21.0"
      }
    },
    "node_modules/util-deprecate": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/util-deprecate/-/util-deprecate-1.0.2.tgz",
      "integrity": "sha512-EPD5q1uXyFxJpCrLnCc1nHnq3gOa6DZBocAIiI2TaSCA7VCJ1UJDMagCzIkXNsUYfD1daK//LTEQ8xiIbrHtcw==",
      "license": "MIT"
    },
    "node_modules/utils-merge": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/utils-merge/-/utils-merge-1.0.1.tgz",
      "integrity": "sha512-pMZTvIkT1d+TFGvDOqodOclx0QWkkgi6Tdoa8gC8ffGAAqz9pzPTZWAybbsHHoED/ztMtkv/VoYTYyShUn81hA==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4.0"
      }
    },
    "node_modules/v8-to-istanbul": {
      "version": "9.3.0",
      "resolved": "https://registry.npmjs.org/v8-to-istanbul/-/v8-to-istanbul-9.3.0.tgz",
      "integrity": "sha512-kiGUalWN+rgBJ/1OHZsBtU4rXZOfj/7rKQxULKlIzwzQSvMJUUNgPwJEEh7gU6xEVxC0ahoOBvN2YI8GH6FNgA==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "@jridgewell/trace-mapping": "^0.3.12",
        "@types/istanbul-lib-coverage": "^2.0.1",
        "convert-source-map": "^2.0.0"
      },
      "engines": {
        "node": ">=10.12.0"
      }
    },
    "node_modules/vary": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/vary/-/vary-1.1.2.tgz",
      "integrity": "sha512-BNGbWLfd0eUPabhkXUVm0j8uuvREyTh5ovRa/dyow/BqAbZJyC+5fU+IzQOzmAKzYqYRAISoRhdQr3eIZ/PXqg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/walker": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/walker/-/walker-1.0.8.tgz",
      "integrity": "sha512-ts/8E8l5b7kY0vlWLewOkDXMmPdLcVV4GmOQLyxuSswIJsweeFZtAsMF7k1Nszz+TYBQrlYRmzOnr398y1JemQ==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "makeerror": "1.0.12"
      }
    },
    "node_modules/which": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/which/-/which-2.0.2.tgz",
      "integrity": "sha512-BLI3Tl1TW3Pvl70l3yq3Y64i+awpwXqsGBYWkkqMtnbXgrMD+yj7rhW0kuEDxzJaYXGjEW5ogapKNMEKNMjibA==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "isexe": "^2.0.0"
      },
      "bin": {
        "node-which": "bin/node-which"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/winston": {
      "version": "3.17.0",
      "resolved": "https://registry.npmjs.org/winston/-/winston-3.17.0.tgz",
      "integrity": "sha512-DLiFIXYC5fMPxaRg832S6F5mJYvePtmO5G9v9IgUFPhXm9/GkXarH/TUrBAVzhTCzAj9anE/+GjrgXp/54nOgw==",
      "license": "MIT",
      "dependencies": {
        "@colors/colors": "^1.6.0",
        "@dabh/diagnostics": "^2.0.2",
        "async": "^3.2.3",
        "is-stream": "^2.0.0",
        "logform": "^2.7.0",
        "one-time": "^1.0.0",
        "readable-stream": "^3.4.0",
        "safe-stable-stringify": "^2.3.1",
        "stack-trace": "0.0.x",
        "triple-beam": "^1.3.0",
        "winston-transport": "^4.9.0"
      },
      "engines": {
        "node": ">= 12.0.0"
      }
    },
    "node_modules/winston-transport": {
      "version": "4.9.0",
      "resolved": "https://registry.npmjs.org/winston-transport/-/winston-transport-4.9.0.tgz",
      "integrity": "sha512-8drMJ4rkgaPo1Me4zD/3WLfI/zPdA9o2IipKODunnGDcuqbHwjsbB79ylv04LCGGzU0xQ6vTznOMpQGaLhhm6A==",
      "license": "MIT",
      "dependencies": {
        "logform": "^2.7.0",
        "readable-stream": "^3.6.2",
        "triple-beam": "^1.3.0"
      },
      "engines": {
        "node": ">= 12.0.0"
      }
    },
    "node_modules/wrap-ansi": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-7.0.0.tgz",
      "integrity": "sha512-YVGIj2kamLSTxw6NsZjoBxfSwsn0ycdesmc4p+Q21c5zPuZ1pl+NfxVdxPtdHvmNVOQ6XSYG4AUtyt/Fi7D16Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^4.0.0",
        "string-width": "^4.1.0",
        "strip-ansi": "^6.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/wrap-ansi?sponsor=1"
      }
    },
    "node_modules/wrappy": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/wrappy/-/wrappy-1.0.2.tgz",
      "integrity": "sha512-l4Sp/DRseor9wL6EvV2+TuQn63dMkPjZ/sp9XkghTEbV9KlPS1xUsZ3u7/IQO4wxtcFB4bgpQPRcR3QCvezPcQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/write-file-atomic": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/write-file-atomic/-/write-file-atomic-4.0.2.tgz",
      "integrity": "sha512-7KxauUdBmSdWnmpaGFg+ppNjKF8uNLry8LyzjauQDOVONfFLNKrKvQOxZ/VuTIcS/gge/YNahf5RIIQWTSarlg==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "imurmurhash": "^0.1.4",
        "signal-exit": "^3.0.7"
      },
      "engines": {
        "node": "^12.13.0 || ^14.15.0 || >=16.0.0"
      }
    },
    "node_modules/ws": {
      "version": "8.17.1",
      "resolved": "https://registry.npmjs.org/ws/-/ws-8.17.1.tgz",
      "integrity": "sha512-6XQFvXTkbfUOZOKKILFG1PDK2NDQs4azKQl26T0YS5CxqWLgXajbPZ+h4gZekJyRqFU8pvnbAbbs/3TgRPy+GQ==",
      "license": "MIT",
      "engines": {
        "node": ">=10.0.0"
      },
      "peerDependencies": {
        "bufferutil": "^4.0.1",
        "utf-8-validate": ">=5.0.2"
      },
      "peerDependenciesMeta": {
        "bufferutil": {
          "optional": true
        },
        "utf-8-validate": {
          "optional": true
        }
      }
    },
    "node_modules/y18n": {
      "version": "5.0.8",
      "resolved": "https://registry.npmjs.org/y18n/-/y18n-5.0.8.tgz",
      "integrity": "sha512-0pfFzegeDWJHJIAmTLRP2DwHjdF5s7jo9tuztdQxAhINCdvS+3nGINqPd00AphqJR/0LhANUS6/+7SCb98YOfA==",
      "dev": true,
      "license": "ISC",
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/yallist": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/yallist/-/yallist-3.1.1.tgz",
      "integrity": "sha512-a4UGQaWPH59mOXUYnAG2ewncQS4i4F43Tv3JoAM+s2VDAmS9NsK8GpDMLrCHPksFT7h3K6TOoUNn2pb7RoXx4g==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/yargs": {
      "version": "17.7.2",
      "resolved": "https://registry.npmjs.org/yargs/-/yargs-17.7.2.tgz",
      "integrity": "sha512-7dSzzRQ++CKnNI/krKnYRV7JKKPUXMEh61soaHKg9mrWEhzFWhFnxPxGl+69cD1Ou63C13NUPCnmIcrvqCuM6w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "cliui": "^8.0.1",
        "escalade": "^3.1.1",
        "get-caller-file": "^2.0.5",
        "require-directory": "^2.1.1",
        "string-width": "^4.2.3",
        "y18n": "^5.0.5",
        "yargs-parser": "^21.1.1"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/yargs-parser": {
      "version": "21.1.1",
      "resolved": "https://registry.npmjs.org/yargs-parser/-/yargs-parser-21.1.1.tgz",
      "integrity": "sha512-tVpsJW7DdjecAiFpbIB1e3qxIQsE6NoPc5/eTdrbbIC4h0LVsWhnoa3g+m2HclBIujHzsxZ4VJVA+GUuc2/LBw==",
      "dev": true,
      "license": "ISC",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/yocto-queue": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/yocto-queue/-/yocto-queue-0.1.0.tgz",
      "integrity": "sha512-rVksvsnNCdJ/ohGc6xgPwyN8eheCxsiLM8mxuE/t/mOVqJewPuO1miLpTHQiRgTKCLexL4MeAFVagts7HmNZ2Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    }
  }
}

```


### FILE: backend\node-service\package.json
```
{
  "name": "meeting-app-websocket",
  "version": "1.0.0",
  "description": "WebSocket service for the meeting application",
  "main": "src/server.js",
  "scripts": {
    "start": "node src/server.js",
    "dev": "nodemon src/server.js",
    "test": "jest"
  },
  "dependencies": {
    "compression": "^1.7.4",
    "cors": "^2.8.5",
    "dotenv": "^16.3.1",
    "express": "^4.18.2",
    "helmet": "^7.0.0",
    "ioredis": "^5.3.2",
    "jsonwebtoken": "^9.0.2",
    "morgan": "^1.10.0",
    "prom-client": "^14.2.0",
    "socket.io": "^4.7.2",
    "winston": "^3.10.0"
  },
  "devDependencies": {
    "jest": "^29.6.4",
    "nodemon": "^3.0.1"
  }
}

```


### FILE: backend\node-service\src\config.js
```
require('dotenv').config();

const config = {
  // Server configuration
  port: process.env.PORT || 3001,
  host: process.env.HOST || '0.0.0.0',

  // CORS configuration
  cors: {
    origin: process.env.CORS_ORIGIN || 'http://localhost:3000',
    methods: ['GET', 'POST'],
    credentials: true
  },

  // Redis configuration
  redis: {
    url: process.env.REDIS_URL || 'redis://redis:6379',
    options: {
      retryStrategy: (times) => {
        const delay = Math.min(times * 50, 2000);
        return delay;
      },
      maxRetriesPerRequest: 3
    }
  },

  // JWT configuration
  jwt: {
    secret: process.env.JWT_SECRET || 'your-secret-key',
    expiresIn: process.env.JWT_EXPIRES_IN || '24h'
  },

  // WebRTC configuration
  webrtc: {
    iceServers: [
      {
        urls: process.env.STUN_SERVERS?.split(',') || [
          'stun:stun.l.google.com:19302',
          'stun:stun1.l.google.com:19302'
        ]
      },
      {
        urls: process.env.TURN_SERVERS?.split(',') || [],
        username: process.env.TURN_USERNAME,
        credential: process.env.TURN_CREDENTIAL
      }
    ].filter(server => server.urls.length > 0)
  },

  // Metrics configuration
  metrics: {
    enabled: process.env.ENABLE_METRICS === 'true',
    prefix: 'meeting_app_',
    defaultLabels: {
      app: 'meeting-app',
      env: process.env.NODE_ENV || 'development'
    }
  },

  // Logging configuration
  logging: {
    level: process.env.LOG_LEVEL || 'info',
    format: process.env.LOG_FORMAT || 'json'
  },

  // File sharing configuration
  fileSharing: {
    maxSize: parseInt(process.env.MAX_FILE_SIZE) || 10 * 1024 * 1024, // 10MB
    allowedTypes: process.env.ALLOWED_FILE_TYPES?.split(',') || [
      'image/*',
      'application/pdf',
      'application/msword',
      'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
      'text/plain'
    ]
  },

  // Room configuration
  room: {
    maxParticipants: parseInt(process.env.MAX_ROOM_PARTICIPANTS) || 12,
    timeout: parseInt(process.env.ROOM_TIMEOUT) || 30 * 60 * 1000 // 30 minutes
  }
};

module.exports = config; 
```


### FILE: backend\node-service\src\server.js
```
// Initialize environment variables from .env file
try {
  require('dotenv').config();
} catch (error) {
  console.log('Error loading dotenv, using process.env variables:', error.message);
}

const express = require('express');
const http = require('http');
const socketIo = require('socket.io');
const cors = require('cors');
const Redis = require('ioredis');
const morgan = require('morgan');
const winston = require('winston');
const helmet = require('helmet');
const compression = require('compression');
const jwt = require('jsonwebtoken');
const WebRTCSignaling = require('./services/webrtc');
const ChatService = require('./services/chat');
const WhiteboardService = require('./services/whiteboard');
const config = require('./config');

// Setup logger
const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [
    new winston.transports.Console(),
    new winston.transports.File({ filename: 'logs/error.log', level: 'error' }),
    new winston.transports.File({ filename: 'logs/combined.log' })
  ]
});

// Initialize Express app
const app = express();
const server = http.createServer(app);

// Set port
const PORT = process.env.PORT || 3001;

// Middleware
app.use(cors());
app.use(helmet());
app.use(compression());
app.use(express.json());
app.use(morgan('dev'));

// Redis client
let redisClient;
let redisReconnectAttempts = 0;
const MAX_RECONNECT_ATTEMPTS = 10;

function connectRedis() {
  try {
    const redisUrl = process.env.REDIS_URL || 'redis://:dev-redis-123@redis:6379/0';
    logger.info(`Connecting to Redis at ${redisUrl.replace(/:[^:]*@/, ':****@')}`);
    
    redisClient = new Redis(redisUrl, {
      retryStrategy: (times) => {
        redisReconnectAttempts = times;
        if (times > MAX_RECONNECT_ATTEMPTS) {
          logger.error(`Redis connection failed after ${times} attempts. Giving up.`);
          return null; // stop retrying
        }
        const delay = Math.min(times * 1000, 5000);
        logger.info(`Redis reconnecting... attempt ${times}. Retrying in ${delay}ms`);
        return delay;
      }
    });

    redisClient.on('connect', () => {
      logger.info('Redis connection established');
      redisReconnectAttempts = 0;
    });

    redisClient.on('error', (err) => {
      logger.error(`Redis error: ${err.message}`);
    });

    return redisClient;
  } catch (error) {
    logger.error(`Redis connection error: ${error.message}`);
    return null;
  }
}

// Initialize Redis connection
connectRedis();

// Socket.io setup
const io = socketIo(server, {
  cors: {
    origin: '*',
    methods: ['GET', 'POST']
  }
});

// Initialize services
const webrtcService = new WebRTCSignaling(io);
const chatService = new ChatService(io);
const whiteboardService = new WhiteboardService(io);

// Health check endpoint
app.get('/health', (req, res) => {
  const healthInfo = {
    status: 'healthy',
    service: 'websocket',
    timestamp: new Date().toISOString(),
    environment: process.env.NODE_ENV || 'development',
    system_info: {
      node_version: process.version,
      platform: process.platform,
      arch: process.arch,
      hostname: require('os').hostname()
    },
    dependencies: {}
  };

  // Check Redis connectivity
  if (redisClient) {
    redisClient.ping()
      .then(() => {
        healthInfo.dependencies.redis = {
          status: 'connected',
          reconnect_attempts: redisReconnectAttempts
        };
        res.status(200).json(healthInfo);
      })
      .catch((err) => {
        healthInfo.status = 'degraded';
        healthInfo.dependencies.redis = {
          status: 'disconnected',
          error: err.message,
          reconnect_attempts: redisReconnectAttempts
        };
        res.status(200).json(healthInfo);
      });
  } else {
    healthInfo.status = 'degraded';
    healthInfo.dependencies.redis = {
      status: 'not_initialized'
    };
    res.status(200).json(healthInfo);
  }
});

// Socket.io event handlers
io.on('connection', (socket) => {
  logger.info(`User connected: ${socket.id}`);

  socket.on('join-meeting', (meetingId) => {
    socket.join(meetingId);
    logger.info(`User ${socket.id} joined meeting ${meetingId}`);
  });

  socket.on('leave-meeting', (meetingId) => {
    socket.leave(meetingId);
    logger.info(`User ${socket.id} left meeting ${meetingId}`);
  });

  socket.on('message', (data) => {
    io.to(data.meetingId).emit('message', data);
    logger.info(`Message sent in meeting ${data.meetingId} by ${socket.id}`);
  });

  socket.on('disconnect', () => {
    logger.info(`User disconnected: ${socket.id}`);
  });
});

// Start server
server.listen(PORT, () => {
  logger.info(`WebSocket service running on port ${PORT}`);
});

// Handle graceful shutdown
process.on('SIGTERM', () => {
  logger.info('SIGTERM signal received: closing HTTP server');
  server.close(() => {
    logger.info('HTTP server closed');
    if (redisClient) {
      redisClient.quit();
    }
    process.exit(0);
  });
}); 
```


### FILE: backend\node-service\src\services\chat.js
```
const { logger } = require('../utils/logger');
const { metrics } = require('../utils/metrics');

class ChatService {
  constructor(io) {
    this.io = io;
    this.messageHistory = new Map(); // roomId -> array of messages
    this.MAX_HISTORY = 100; // Maximum number of messages to keep per room
    this.typingUsers = new Map(); // roomId -> Set of typing users
  }

  // Initialize a new room's chat
  initRoom(roomId) {
    if (!this.messageHistory.has(roomId)) {
      this.messageHistory.set(roomId, []);
    }
  }

  // Handle new message
  handleMessage(socket, data) {
    const { roomId, message } = data;
    logger.info(`New message in room ${roomId} from user ${socket.id}`);
    
    this.io.to(roomId).emit('chat-message', {
      userId: socket.id,
      message,
      timestamp: Date.now()
    });
  }

  // Handle file sharing
  handleFileShare(socket, data) {
    const { roomId, fileInfo } = data;
    logger.info(`File shared in room ${roomId} by user ${socket.id}`);
    
    this.io.to(roomId).emit('file-shared', {
      userId: socket.id,
      fileInfo,
      timestamp: Date.now()
    });
  }

  // Get chat history
  getChatHistory(roomId) {
    return this.messageHistory.get(roomId) || [];
  }

  // Handle user typing status
  handleTyping(socket, data) {
    const { roomId, isTyping } = data;
    
    if (!this.typingUsers.has(roomId)) {
      this.typingUsers.set(roomId, new Set());
    }

    const roomTyping = this.typingUsers.get(roomId);
    if (isTyping) {
      roomTyping.add(socket.id);
    } else {
      roomTyping.delete(socket.id);
    }

    socket.to(roomId).emit('typing-update', {
      userId: socket.id,
      isTyping
    });
  }

  // Clean up room when it's empty
  cleanupRoom(roomId) {
    this.messageHistory.delete(roomId);
  }

  // Handle message reaction
  handleReaction(socket, data) {
    const { roomId, messageId, reaction } = data;
    
    this.io.to(roomId).emit('message-reaction', {
      userId: socket.id,
      messageId,
      reaction,
      timestamp: Date.now()
    });
  }

  handleDisconnect(socket) {
    // Remove user from typing lists in all rooms
    this.typingUsers.forEach((users, roomId) => {
      if (users.has(socket.id)) {
        users.delete(socket.id);
        if (users.size === 0) {
          this.typingUsers.delete(roomId);
        }
        // Notify room that user stopped typing
        socket.to(roomId).emit('typing-update', {
          userId: socket.id,
          isTyping: false
        });
      }
    });
  }
}

module.exports = ChatService; 
```


### FILE: backend\node-service\src\services\webrtc.js
```
const { logger } = require('../utils/logger');
const { metrics } = require('../utils/metrics');

class WebRTCSignaling {
  constructor(io) {
    this.io = io;
    this.rooms = new Map(); // roomId -> Set of socket IDs
  }

  handleJoin(socket, roomId) {
    logger.info(`User ${socket.id} joining room ${roomId}`);
    socket.join(roomId);
    
    if (!this.rooms.has(roomId)) {
      this.rooms.set(roomId, new Set());
    }
    this.rooms.get(roomId).add(socket.id);

    // Notify others in the room
    socket.to(roomId).emit('user-joined', { userId: socket.id });

    // Send list of existing peers to the new participant
    const peers = Array.from(this.rooms.get(roomId)).filter(id => id !== socket.id);
    socket.emit('room_users', {
      peers: peers.map(peerId => ({
        peerId,
        userId: this.io.sockets.sockets.get(peerId)?.userId,
        username: this.io.sockets.sockets.get(peerId)?.user?.username
      }))
    });

    logger.info(`User ${socket.userId} joined room ${roomId}`);
    metrics.activeRooms.set(this.rooms.size);
    metrics.usersPerRoom.set({ room: roomId }, this.rooms.get(roomId).size);
  }

  handleLeave(socket, roomId) {
    logger.info(`User ${socket.id} leaving room ${roomId}`);
    socket.leave(roomId);
    
    if (this.rooms.has(roomId)) {
      this.rooms.get(roomId).delete(socket.id);
      if (this.rooms.get(roomId).size === 0) {
        this.rooms.delete(roomId);
      }
    }

    // Notify others in the room
    socket.to(roomId).emit('user-left', { userId: socket.id });

    logger.info(`User ${socket.userId} left room ${roomId}`);
    metrics.activeRooms.set(this.rooms.size);
    metrics.usersPerRoom.set({ room: roomId }, this.rooms.get(roomId)?.size || 0);
  }

  handleOffer(socket, data) {
    const { targetId, offer } = data;
    logger.info(`Relaying offer from ${socket.id} to ${targetId}`);
    this.io.to(targetId).emit('offer', {
      userId: socket.id,
      offer
    });

    metrics.webrtcOffers.inc();
  }

  handleAnswer(socket, data) {
    const { targetId, answer } = data;
    logger.info(`Relaying answer from ${socket.id} to ${targetId}`);
    this.io.to(targetId).emit('answer', {
      userId: socket.id,
      answer
    });

    metrics.webrtcAnswers.inc();
  }

  handleIceCandidate(socket, data) {
    const { targetId, candidate } = data;
    logger.info(`Relaying ICE candidate from ${socket.id} to ${targetId}`);
    this.io.to(targetId).emit('ice-candidate', {
      userId: socket.id,
      candidate
    });

    metrics.iceCandidates.inc();
  }

  // Handle media stream events
  handleMediaStreamStart(socket, { roomId, type }) {
    socket.to(roomId).emit('media_stream_start', {
      userId: socket.userId,
      type // 'video', 'audio', or 'screen'
    });
  }

  handleMediaStreamStop(socket, { roomId, type }) {
    socket.to(roomId).emit('media_stream_stop', {
      userId: socket.userId,
      type
    });
  }

  // Handle connection state changes
  handleConnectionStateChange(socket, { roomId, state }) {
    socket.to(roomId).emit('peer_connection_state', {
      userId: socket.userId,
      state
    });
  }

  handleDisconnect(socket) {
    // Remove user from all rooms they were in
    this.rooms.forEach((users, roomId) => {
      if (users.has(socket.id)) {
        this.handleLeave(socket, roomId);
      }
    });
  }
}

module.exports = WebRTCSignaling; 
```


### FILE: backend\node-service\src\services\whiteboard.js
```
const { logger } = require('../utils/logger');
const { metrics } = require('../utils/metrics');

class WhiteboardService {
  constructor(io) {
    this.io = io;
    this.whiteboards = new Map();
  }

  handleDraw(socket, data) {
    const { roomId, path } = data;
    logger.info(`New drawing in room ${roomId} from user ${socket.id}`);
    
    if (!this.whiteboards.has(roomId)) {
      this.whiteboards.set(roomId, {
        paths: [],
        undoStack: [],
        redoStack: []
      });
    }

    const whiteboard = this.whiteboards.get(roomId);
    whiteboard.paths.push({
      userId: socket.id,
      path,
      timestamp: Date.now()
    });
    whiteboard.redoStack = []; // Clear redo stack on new draw

    this.io.to(roomId).emit('draw', {
      userId: socket.id,
      path
    });
  }

  handleClear(socket, data) {
    const { roomId } = data;
    logger.info(`Clearing whiteboard in room ${roomId}`);
    
    if (this.whiteboards.has(roomId)) {
      const whiteboard = this.whiteboards.get(roomId);
      whiteboard.undoStack.push([...whiteboard.paths]);
      whiteboard.paths = [];
      whiteboard.redoStack = [];
    }

    this.io.to(roomId).emit('clear', {
      userId: socket.id
    });
  }

  handleUndo(socket, data) {
    const { roomId } = data;
    
    if (this.whiteboards.has(roomId)) {
      const whiteboard = this.whiteboards.get(roomId);
      if (whiteboard.paths.length > 0) {
        const lastPath = whiteboard.paths.pop();
        whiteboard.undoStack.push(lastPath);
        
        this.io.to(roomId).emit('undo', {
          userId: socket.id,
          pathId: lastPath.timestamp
        });
      }
    }
  }

  handleRedo(socket, data) {
    const { roomId } = data;
    
    if (this.whiteboards.has(roomId)) {
      const whiteboard = this.whiteboards.get(roomId);
      if (whiteboard.undoStack.length > 0) {
        const pathToRedo = whiteboard.undoStack.pop();
        whiteboard.paths.push(pathToRedo);
        
        this.io.to(roomId).emit('redo', {
          userId: socket.id,
          path: pathToRedo.path
        });
      }
    }
  }

  handleDisconnect(socket) {
    // No cleanup needed for whiteboard data
    // Data persists until room is deleted
  }

  // Get current whiteboard state for a room
  getWhiteboardState(roomId) {
    return this.whiteboards.get(roomId) || { paths: [], undoStack: [], redoStack: [] };
  }
}

module.exports = WhiteboardService; 
```


### FILE: backend\node-service\src\utils\logger.js
```
const winston = require('winston');
const morgan = require('morgan');
const config = require('../config');

// Create Winston logger
const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [
    new winston.transports.Console(),
    new winston.transports.File({ 
      filename: 'logs/error.log', 
      level: 'error' 
    }),
    new winston.transports.File({ 
      filename: 'logs/combined.log' 
    })
  ]
});

// Create HTTP request logger middleware
const requestLogger = morgan('combined', {
  stream: {
    write: (message) => logger.http(message.trim())
  }
});

// Create WebSocket logger middleware
const wsLogger = (socket, next) => {
  const start = Date.now();
  const clientIp = socket.handshake.address;
  const query = socket.handshake.query;

  logger.info('WebSocket connection attempt', {
    clientIp,
    query,
    socketId: socket.id
  });

  // Log successful connection
  socket.on('connect', () => {
    logger.info('WebSocket connected', {
      clientIp,
      socketId: socket.id,
      connectionTime: Date.now() - start
    });
  });

  // Log disconnection
  socket.on('disconnect', (reason) => {
    logger.info('WebSocket disconnected', {
      clientIp,
      socketId: socket.id,
      reason,
      duration: Date.now() - start
    });
  });

  // Log errors
  socket.on('error', (error) => {
    logger.error('WebSocket error', {
      clientIp,
      socketId: socket.id,
      error: error.message,
      stack: error.stack
    });
  });

  next();
};

module.exports = {
  logger,
  requestLogger,
  wsLogger
}; 
```


### FILE: backend\node-service\src\utils\metrics.js
```
const promClient = require('prom-client');
const config = require('../config');

// Initialize metrics registry
const register = new promClient.Registry();

// Add default labels from config
register.setDefaultLabels(config.metrics.defaultLabels);

// Define metrics
const metrics = {
  // Connection metrics
  activeConnections: new promClient.Gauge({
    name: `${config.metrics.prefix}active_connections`,
    help: 'Number of active WebSocket connections',
    registers: [register]
  }),

  // Room metrics
  activeRooms: new promClient.Gauge({
    name: `${config.metrics.prefix}active_rooms`,
    help: 'Number of active meeting rooms',
    registers: [register]
  }),

  usersPerRoom: new promClient.Gauge({
    name: `${config.metrics.prefix}users_per_room`,
    help: 'Number of users in each room',
    labelNames: ['room'],
    registers: [register]
  }),

  // WebRTC metrics
  webrtcOffers: new promClient.Counter({
    name: `${config.metrics.prefix}webrtc_offers_total`,
    help: 'Total number of WebRTC offers sent',
    registers: [register]
  }),

  webrtcAnswers: new promClient.Counter({
    name: `${config.metrics.prefix}webrtc_answers_total`,
    help: 'Total number of WebRTC answers sent',
    registers: [register]
  }),

  iceCandidates: new promClient.Counter({
    name: `${config.metrics.prefix}ice_candidates_total`,
    help: 'Total number of ICE candidates exchanged',
    registers: [register]
  }),

  webrtcErrors: new promClient.Counter({
    name: `${config.metrics.prefix}webrtc_errors_total`,
    help: 'Total number of WebRTC errors',
    registers: [register]
  }),

  // Chat metrics
  chatMessages: new promClient.Counter({
    name: `${config.metrics.prefix}chat_messages_total`,
    help: 'Total number of chat messages sent',
    labelNames: ['type'],
    registers: [register]
  }),

  messageReactions: new promClient.Counter({
    name: `${config.metrics.prefix}message_reactions_total`,
    help: 'Total number of message reactions',
    registers: [register]
  }),

  // File sharing metrics
  fileShares: new promClient.Counter({
    name: `${config.metrics.prefix}file_shares_total`,
    help: 'Total number of files shared',
    registers: [register]
  }),

  fileShareBytes: new promClient.Counter({
    name: `${config.metrics.prefix}file_share_bytes_total`,
    help: 'Total bytes of shared files',
    registers: [register]
  }),

  // Whiteboard metrics
  whiteboardStrokes: new promClient.Counter({
    name: `${config.metrics.prefix}whiteboard_strokes_total`,
    help: 'Total number of whiteboard strokes',
    registers: [register]
  }),

  whiteboardClears: new promClient.Counter({
    name: `${config.metrics.prefix}whiteboard_clears_total`,
    help: 'Total number of whiteboard clears',
    registers: [register]
  }),

  whiteboardUndos: new promClient.Counter({
    name: `${config.metrics.prefix}whiteboard_undos_total`,
    help: 'Total number of whiteboard undos',
    registers: [register]
  }),

  whiteboardRedos: new promClient.Counter({
    name: `${config.metrics.prefix}whiteboard_redos_total`,
    help: 'Total number of whiteboard redos',
    registers: [register]
  })
};

// Create metrics middleware
const metricsMiddleware = async (req, res) => {
  try {
    res.set('Content-Type', register.contentType);
    res.end(await register.metrics());
  } catch (error) {
    res.status(500).end(error.message);
  }
};

module.exports = {
  metrics,
  metricsMiddleware,
  register
}; 
```


### FILE: config\.env.development
```
# Database Configuration
POSTGRES_DB=meetingapp
POSTGRES_USER=dev_user
POSTGRES_PASSWORD=dev-password-123
POSTGRES_HOST=postgres-db
POSTGRES_PORT=5432
DATABASE_URL=postgresql://dev_user:dev-password-123@postgres-db:5432/meetingapp

# Redis Configuration
REDIS_HOST=redis-cache
REDIS_PORT=6379
REDIS_PASSWORD=dev-redis-123
REDIS_URL=redis://:dev-redis-123@redis-cache:6379/0

# JWT Configuration
JWT_SECRET_KEY=dev-jwt-secret-key-123
JWT_EXPIRY_DAYS=1

# Frontend URLs
NEXT_PUBLIC_API_URL=http://localhost:30963
NEXT_PUBLIC_WS_URL=ws://localhost:30283
NEXT_PUBLIC_BASE_URL=http://localhost:30000

# Backend Configuration
FLASK_ENV=development
FLASK_APP=app.py
API_HOST=0.0.0.0
API_PORT=5000
WS_HOST=0.0.0.0
WS_PORT=3001

# CORS Configuration
CORS_ORIGINS=http://localhost:30000,http://meeting-app.local,http://localhost:3000

# Logging
LOG_LEVEL=debug 
```


### FILE: config\secrets.production
```
ï»¿ 
```


### FILE: frontend\.dockerignore
```
# Git
.git
.gitignore

# Node.js
node_modules/
npm-debug.log
yarn-debug.log
yarn-error.log
.npm/
.yarn/
*.tgz

# Next.js
.next/
out/
.vercel/

# Docker
Dockerfile*
docker-compose*
.dockerignore

# IDE
.idea/
.vscode/
*.swp
*.swo

# Logs
logs/
*.log

# Data
data/ 
```


### FILE: frontend\.env.local
```
NEXT_PUBLIC_API_URL=http://localhost:5000
NEXT_PUBLIC_AUTH_URL=http://localhost:5001
NEXT_PUBLIC_WS_URL=ws://localhost:3001
NEXT_PUBLIC_APP_NAME="Meeting App"
NEXT_PUBLIC_APP_VERSION=1.0.0
NEXT_PUBLIC_ENABLE_ANALYTICS=false
NEXT_PUBLIC_ENABLE_DEBUG_TOOLS=false
NEXT_PUBLIC_API_TIMEOUT_MS=30000
NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS=5000
NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB=5
NEXT_PUBLIC_BASE_URL=http://localhost:3000
NEXT_PUBLIC_GOOGLE_CLIENT_ID=1004556025731-dgnou2c5vdui47ffbfievlil9ncqsrue.apps.googleusercontent.com

```


### FILE: frontend\.env.production
```
NEXT_PUBLIC_API_URL=http://localhost:5000
NEXT_PUBLIC_AUTH_URL=http://localhost:5001
NEXT_PUBLIC_WS_URL=ws://localhost:3001
NEXT_PUBLIC_APP_NAME="Meeting App"
NEXT_PUBLIC_APP_VERSION=1.0.0
NEXT_PUBLIC_ENABLE_ANALYTICS=false
NEXT_PUBLIC_ENABLE_DEBUG_TOOLS=false
NEXT_PUBLIC_API_TIMEOUT_MS=30000
NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS=5000
NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB=5
NEXT_PUBLIC_BASE_URL=http://localhost:3000
NEXT_PUBLIC_GOOGLE_CLIENT_ID=1004556025731-dgnou2c5vdui47ffbfievlil9ncqsrue.apps.googleusercontent.com

```


### FILE: frontend\.eslintrc.json
```
{
  "extends": "next/core-web-vitals",
  "rules": {
    "react/no-unescaped-entities": "off",
    "@typescript-eslint/no-explicit-any": "off",
    "@typescript-eslint/no-unused-vars": "off",
    "react-hooks/exhaustive-deps": "off"
  }
} 
```


### FILE: frontend\DEBUGGING.md
```
# Frontend Debugging Guide

This document provides guidance on debugging the Next.js frontend application.

## Environment Setup

Before you begin, ensure that you have the correct environment variables set up. The application uses the following environment variables:

```
# Required environment variables
NEXT_PUBLIC_API_URL=http://localhost:5000
NEXT_PUBLIC_AUTH_URL=http://localhost:5001
NEXT_PUBLIC_WS_URL=ws://localhost:3001
NEXT_PUBLIC_APP_NAME=Meeting App
NEXT_PUBLIC_APP_VERSION=1.0.0

# Optional environment variables
NEXT_PUBLIC_ENABLE_DEBUG_TOOLS=true  # Enable debug tools (default: true in development, false in production)
NEXT_PUBLIC_ENABLE_ANALYTICS=false   # Enable analytics (default: false)
```

## Debugging Tools

### Built-in Debug Overlay

The application includes a built-in debug overlay that can be toggled by pressing `Ctrl+Shift+D` in development mode. The debug overlay provides:

- Current log level control
- Pending API requests
- Recent API responses
- Application state capture

### URL Parameters

You can control certain aspects of the application by adding query parameters to the URL:

- `?log_level=1` - Set log level (0=TRACE, 1=DEBUG, 2=INFO, 3=WARN, 4=ERROR, 5=NONE)
- `?debug=true` - Force enable debug mode

### Console Logging

The application uses a structured logging system with different log levels:

```typescript
import logger from '@/utils/logger';

// Different log levels
logger.trace('Detailed trace information');
logger.debug('Debugging information');
logger.info('General information');
logger.warn('Warning message');
logger.error('Error message');

// Logging with context
const componentLogger = createLogger('ComponentName');
componentLogger.info('Component initialized');
```

## Browser DevTools

### React Developer Tools

Install the [React Developer Tools](https://chrome.google.com/webstore/detail/react-developer-tools/fmkadmapgofadopljbjfkapdkoienihi) extension for Chrome or Firefox to inspect component props, state, and hierarchy.

### Network Tab

The Network tab in browser DevTools is essential for debugging API requests:

1. Open DevTools (F12 or Ctrl+Shift+I)
2. Go to the Network tab
3. Filter by "Fetch/XHR" to see only API requests
4. Look for the `X-Request-ID` header in requests to correlate with backend logs

### Debugging API Requests

All API requests include a unique `X-Request-ID` header that can be used to trace requests from the frontend to the backend.

Example of manually inspecting an API request:

```typescript
// Get a reference to the API client
import { apiClient } from '@/services/api/client';

// Make a request
const response = await apiClient.get('/api/meetings');

// Check response
console.log('Response:', response);

// If there was an error
if (response.error) {
  console.error('Error:', response.error);
}
```

## Error Handling

### Error Boundaries

The application uses React Error Boundaries to catch and display errors gracefully. You can wrap specific components with an error boundary for more granular error handling:

```typescript
import ErrorBoundary from '@/components/ErrorBoundary';

// In your component
return (
  <ErrorBoundary
    fallback={<div>Something went wrong with this component</div>}
    onError={(error) => console.error('Component error:', error)}
  >
    <YourComponent />
  </ErrorBoundary>
);
```

### Debugging Production Errors

For production debugging, check the browser console for error messages. All unhandled errors are logged and could be sent to an error tracking service.

## Debugging Specific Issues

### State Management Issues

Use the Debug Context to capture and inspect application state:

```typescript
import { useDebug } from '@/contexts/DebugContext';

function YourComponent() {
  const { captureState } = useDebug();
  
  // Capture state for debugging
  useEffect(() => {
    captureState('componentState', { 
      // Your component state here
    });
  }, [captureState, /* your dependencies */]);
  
  // ...
}
```

### Performance Issues

Use the `why-did-you-render` package to track unnecessary re-renders:

```typescript
// In your component file
import React from 'react';

if (process.env.NODE_ENV === 'development') {
  YourComponent.whyDidYouRender = true;
}

// Or enable globally for specific components in _app.tsx
```

### WebSocket Debugging

For WebSocket connection issues:

1. Check the browser console for connection errors
2. Verify the NEXT_PUBLIC_WS_URL environment variable
3. Use the Network tab in DevTools, filter by "WS" to see WebSocket connections
4. Look for the `X-Request-ID` and `X-Correlation-ID` headers in the initial WebSocket handshake

## Running in Debug Mode

To run the application with Node.js inspector for step-by-step debugging:

```bash
npm run start:debug
```

Then connect your IDE's debugger or open Chrome DevTools and navigate to chrome://inspect.

## Bundle Analysis

To analyze the bundle size:

```bash
npm run analyze
```

This will generate a report showing the size of each bundle and help identify large dependencies.

## TypeScript Type Checking

Run TypeScript type checking:

```bash
npx tsc --noEmit
```

## Common Issues and Solutions

1. **API Requests Failing**
   - Check network tab for status codes
   - Verify API URL environment variable
   - Check CORS settings
   - Look for authentication issues (expired tokens)

2. **Component Not Rendering**
   - Check if it's wrapped in a conditional that evaluates to false
   - Verify that parent components are rendering
   - Check for errors in the console

3. **Slow Performance**
   - Use React DevTools Profiler to identify slow components
   - Look for unnecessary re-renders
   - Check for expensive operations in render functions
   - Verify that proper memoization is used (useMemo, useCallback)

4. **Authentication Issues**
   - Check local storage for token expiration
   - Verify that tokens are being sent with requests
   - Look for CORS issues with credentials

## Useful Debugging Commands

```javascript
// In browser console

// Get current environment config
console.log(window.__NEXT_DATA__.props.pageProps.env);

// Get app state
console.log(window.__APP_STATE__);

// Force garbage collection (Chrome only, requires --enable-precise-memory-info flag)
window.gc();

// Check for memory leaks
performance.memory;

// Monitor events on an element
monitorEvents(document.querySelector('#your-element-id'));
``` 
```


### FILE: frontend\Dockerfile
```
# Build stage
FROM node:18-slim AS builder

WORKDIR /app

# Define build arguments for environment variables
ARG NEXT_PUBLIC_API_URL
ARG NEXT_PUBLIC_AUTH_URL
ARG NEXT_PUBLIC_WS_URL
ARG NEXT_PUBLIC_APP_NAME
ARG NEXT_PUBLIC_APP_VERSION
ARG NEXT_PUBLIC_GOOGLE_CLIENT_ID
ARG NEXT_PUBLIC_BASE_URL
ARG NEXT_PUBLIC_ENABLE_ANALYTICS
ARG NEXT_PUBLIC_ENABLE_DEBUG_TOOLS
ARG NEXT_PUBLIC_API_TIMEOUT_MS
ARG NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS
ARG NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB

# Set environment variables for build
ENV NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL}
ENV NEXT_PUBLIC_AUTH_URL=${NEXT_PUBLIC_AUTH_URL}
ENV NEXT_PUBLIC_WS_URL=${NEXT_PUBLIC_WS_URL}
ENV NEXT_PUBLIC_APP_NAME=${NEXT_PUBLIC_APP_NAME}
ENV NEXT_PUBLIC_APP_VERSION=${NEXT_PUBLIC_APP_VERSION}
ENV NEXT_PUBLIC_ENABLE_ANALYTICS=${NEXT_PUBLIC_ENABLE_ANALYTICS}
ENV NEXT_PUBLIC_ENABLE_DEBUG_TOOLS=${NEXT_PUBLIC_ENABLE_DEBUG_TOOLS}
ENV NEXT_PUBLIC_API_TIMEOUT_MS=${NEXT_PUBLIC_API_TIMEOUT_MS}
ENV NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS=${NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS}
ENV NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB=${NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB}
ENV NEXT_PUBLIC_GOOGLE_CLIENT_ID=${NEXT_PUBLIC_GOOGLE_CLIENT_ID}
ENV NEXT_PUBLIC_BASE_URL=${NEXT_PUBLIC_BASE_URL}

# Copy package files
COPY package*.json ./

# Install dependencies and ensure React types are installed
RUN npm install
RUN npm install --save-dev @types/react @types/react-dom

# Create necessary directories
RUN mkdir -p /app/public /app/src

# Copy app source by category to avoid Windows permission issues
COPY public/ /app/public/
COPY src/ /app/src/
COPY *.js /app/
COPY *.json /app/
COPY *.css /app/

# Build the application
RUN npm run build

# Production stage
FROM node:18-slim AS runner

WORKDIR /app

# Define build arguments for environment variables
ARG NEXT_PUBLIC_API_URL
ARG NEXT_PUBLIC_AUTH_URL
ARG NEXT_PUBLIC_WS_URL
ARG NEXT_PUBLIC_APP_NAME
ARG NEXT_PUBLIC_APP_VERSION
ARG NEXT_PUBLIC_GOOGLE_CLIENT_ID
ARG NEXT_PUBLIC_BASE_URL
ARG NEXT_PUBLIC_ENABLE_ANALYTICS
ARG NEXT_PUBLIC_ENABLE_DEBUG_TOOLS
ARG NEXT_PUBLIC_API_TIMEOUT_MS
ARG NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS
ARG NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB

# Set environment variables
ENV NODE_ENV=production
ENV PORT=3000
ENV HOST=0.0.0.0
ENV NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL}
ENV NEXT_PUBLIC_AUTH_URL=${NEXT_PUBLIC_AUTH_URL}
ENV NEXT_PUBLIC_WS_URL=${NEXT_PUBLIC_WS_URL}
ENV NEXT_PUBLIC_APP_NAME=${NEXT_PUBLIC_APP_NAME}
ENV NEXT_PUBLIC_APP_VERSION=${NEXT_PUBLIC_APP_VERSION}
ENV NEXT_PUBLIC_ENABLE_ANALYTICS=${NEXT_PUBLIC_ENABLE_ANALYTICS}
ENV NEXT_PUBLIC_ENABLE_DEBUG_TOOLS=${NEXT_PUBLIC_ENABLE_DEBUG_TOOLS}
ENV NEXT_PUBLIC_API_TIMEOUT_MS=${NEXT_PUBLIC_API_TIMEOUT_MS}
ENV NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS=${NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS}
ENV NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB=${NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB}
ENV NEXT_PUBLIC_GOOGLE_CLIENT_ID=${NEXT_PUBLIC_GOOGLE_CLIENT_ID}
ENV NEXT_PUBLIC_BASE_URL=${NEXT_PUBLIC_BASE_URL}

# Create public directory if it doesn't exist
RUN mkdir -p public

# Copy necessary files from builder
COPY --from=builder /app/next.config.js ./
COPY --from=builder /app/public/ ./public/
COPY --from=builder /app/.next/standalone ./
COPY --from=builder /app/.next/static ./.next/static

# Expose port
EXPOSE 3000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:3000/api/health || exit 1

# Start the application with explicit host binding
CMD ["node", "server.js"] 
```


### FILE: frontend\next-env.d.ts
```
/// <reference types="next" />
/// <reference types="next/image-types/global" />

// NOTE: This file should not be edited
// see https://nextjs.org/docs/pages/building-your-application/configuring/typescript for more information.

```


### FILE: frontend\next.config.js
```
const path = require('path');

/** @type {import('next').NextConfig} */
const nextConfig = {
  reactStrictMode: true,
  
  // Disable TypeScript checking during build
  typescript: {
    // !! WARN !!
    // Dangerously allow production builds to successfully complete even if
    // your project has type errors.
    // !! WARN !!
    ignoreBuildErrors: true,
  },
  
  // Disable ESLint during build
  eslint: {
    // Warning: This allows production builds to successfully complete even if
    // your project has ESLint errors.
    ignoreDuringBuilds: true,
  },
  
  // Disable static generation and export
  output: 'standalone',
  
  // Configure to avoid static generation issues
  experimental: {
    // Turn off static optimization for pages that use getServerSideProps
    serverComponents: false
  },
  
  // Server options to ensure binding to all network interfaces
  serverRuntimeConfig: {
    // Will only be available on the server side
    hostname: '0.0.0.0',
  },
  
  // Default environment variables
  env: {
    // App information
    NEXT_PUBLIC_APP_NAME: 'Meeting App',
    NEXT_PUBLIC_APP_VERSION: process.env.NEXT_PUBLIC_APP_VERSION || '1.0.0',
    
    // API endpoints with defaults
    NEXT_PUBLIC_API_URL: process.env.NEXT_PUBLIC_API_URL || 'http://localhost:5000',
    NEXT_PUBLIC_AUTH_URL: process.env.NEXT_PUBLIC_AUTH_URL || 'http://localhost:5001',
    NEXT_PUBLIC_WS_URL: process.env.NEXT_PUBLIC_WS_URL || 'ws://localhost:3001',
    
    // Feature flags
    NEXT_PUBLIC_ENABLE_ANALYTICS: process.env.NEXT_PUBLIC_ENABLE_ANALYTICS || 'false',
    NEXT_PUBLIC_ENABLE_DEBUG_TOOLS: process.env.NODE_ENV !== 'production' ? 'true' : (process.env.NEXT_PUBLIC_ENABLE_DEBUG_TOOLS || 'false'),
    
    // Timeouts and limits
    NEXT_PUBLIC_API_TIMEOUT_MS: process.env.NEXT_PUBLIC_API_TIMEOUT_MS || '30000',
    NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS: process.env.NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS || '5000',
    NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB: process.env.NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB || '5',
  },
  
  // Images configuration
  images: {
    domains: ['localhost'],
  },
  
  // Enable SWC minification
  swcMinify: true,
  
  // Disable source maps in production
  productionBrowserSourceMaps: false,
  
  // Configure webpack
  webpack: (config, { dev, isServer }) => {
    // External dependencies
    config.externals = [...config.externals, { 'simple-peer': 'SimplePeer' }];
    
    // Path aliases
    config.resolve = {
      ...config.resolve,
      alias: {
        ...config.resolve.alias,
        '@': path.join(__dirname, 'src'),
      },
    };
    
    // Example: Add environment variable injection through DefinePlugin
    // if (dev) {
    //   const webpack = require('webpack');
    //   config.plugins.push(
    //     new webpack.DefinePlugin({
    //       'process.env.APP_BUILD_TIME': JSON.stringify(new Date().toISOString()),
    //     })
    //   );
    // }
    
    return config;
  },
  
  // Header configurations
  async headers() {
    return [
      {
        source: '/(.*)',
        headers: [
          {
            key: 'X-Content-Type-Options',
            value: 'nosniff',
          },
          {
            key: 'X-Frame-Options',
            value: 'DENY',
          },
          {
            key: 'X-XSS-Protection',
            value: '1; mode=block',
          },
        ],
      },
      {
        source: '/:path*',
        headers: [
          { 
            key: 'Access-Control-Allow-Origin', 
            value: process.env.NODE_ENV === 'development' 
              ? 'http://localhost:5000' 
              : 'http://api.meeting-app.local' 
          },
          { key: 'Access-Control-Allow-Methods', value: 'GET,OPTIONS,PATCH,DELETE,POST,PUT' },
          { key: 'Access-Control-Allow-Headers', value: 'X-Requested-With, Content-Type, Authorization' },
          { key: 'Access-Control-Allow-Credentials', value: 'true' }
        ],
      },
    ];
  },
}

module.exports = nextConfig 
```


### FILE: frontend\package.json
```
{
  "name": "meeting-app-frontend",
  "version": "1.0.0",
  "description": "Frontend for the meeting application",
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint",
    "lint:fix": "next lint --fix",
    "format": "prettier --write \"**/*.{js,jsx,ts,tsx,json,md}\"",
    "format:check": "prettier --check \"**/*.{js,jsx,ts,tsx,json,md}\"",
    "analyze": "cross-env ANALYZE=true next build",
    "start:debug": "cross-env NODE_OPTIONS='--inspect' next dev"
  },
  "dependencies": {
    "next": "^13.4.19",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "socket.io-client": "^4.7.2",
    "axios": "^1.4.0",
    "@mui/material": "^5.14.5",
    "@mui/icons-material": "^5.14.5",
    "@emotion/react": "^11.11.1",
    "@emotion/styled": "^11.11.0",
    "formik": "^2.4.3",
    "yup": "^1.2.0",
    "@react-oauth/google": "^0.11.1",
    "simple-peer": "^9.11.1"
  },
  "devDependencies": {
    "@types/node": "^20.10.0",
    "@types/react": "^18.2.20",
    "@types/react-dom": "^18.2.7",
    "@types/fabric": "^5.3.7",
    "@types/simple-peer": "^9.11.8",
    "@types/socket.io-client": "^3.0.0",
    "typescript": "^5.3.0",
    "eslint": "^8.47.0",
    "eslint-config-next": "14.0.0",
    "tailwindcss": "^3.3.5",
    "postcss": "^8.4.31",
    "autoprefixer": "^10.4.16",
    "@typescript-eslint/eslint-plugin": "^6.4.0",
    "@typescript-eslint/parser": "^6.4.0",
    "cross-env": "^7.0.3",
    "eslint-plugin-react": "^7.33.2",
    "eslint-plugin-react-hooks": "^4.6.0",
    "prettier": "^3.0.2",
    "@welldone-software/why-did-you-render": "^7.0.1"
  }
} 
```


### FILE: frontend\postcss.config.js
```
module.exports = {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
} 
```


### FILE: frontend\tailwind.config.js
```
/** @type {import('tailwindcss').Config} */
module.exports = {
  content: [
    './src/pages/**/*.{js,ts,jsx,tsx}',
    './src/components/**/*.{js,ts,jsx,tsx}',
    './src/app/**/*.{js,ts,jsx,tsx}',
  ],
  theme: {
    extend: {},
  },
  plugins: [],
} 
```


### FILE: frontend\tsconfig.json
```
{
  "compilerOptions": {
    "target": "es5",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "forceConsistentCasingInFileNames": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["src/*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx"],
  "exclude": ["node_modules"]
} 
```


### FILE: frontend\src\components\ErrorBoundary.tsx
```
import React, { Component, ErrorInfo, ReactNode } from 'react';
import logger from '@/utils/logger';
import { isDevelopment } from '@/config/environment';

interface Props {
  children: ReactNode;
  fallback?: ReactNode | ((error: Error, errorInfo: ErrorInfo) => ReactNode);
  onError?: (error: Error, errorInfo: ErrorInfo) => void;
}

interface State {
  hasError: boolean;
  error?: Error;
  errorInfo?: ErrorInfo;
}

/**
 * Error boundary component to catch JavaScript errors in child component tree.
 * Displays a fallback UI instead of crashing the whole app.
 */
class ErrorBoundary extends Component<Props, State> {
  readonly state: State = { hasError: false };
  readonly props!: Props;

  constructor(props: Props) {
    super(props);
    this.state = { hasError: false };
  }

  static getDerivedStateFromError(error: Error): State {
    // Update state so the next render will show the fallback UI
    return { hasError: true, error };
  }

  componentDidCatch(error: Error, errorInfo: ErrorInfo): void {
    // Capture the error details
    this.setState({ errorInfo });
    
    // Log the error
    logger.error('Error caught by ErrorBoundary:', error);
    logger.error('Component stack:', errorInfo.componentStack);
    
    // Call the onError callback if provided
    if (this.props.onError) {
      this.props.onError(error, errorInfo);
    }
    
    // In development, log to console for easier debugging
    if (isDevelopment) {
      console.error('Error caught by ErrorBoundary:', error);
      console.error('Component stack:', errorInfo.componentStack);
    }
  }

  render(): ReactNode {
    const { hasError, error, errorInfo } = this.state;
    const { children, fallback } = this.props;

    if (hasError && error) {
      // Check for custom fallback render function
      if (typeof fallback === 'function' && errorInfo) {
        return fallback(error, errorInfo);
      }
      
      // Use provided fallback component
      if (fallback && typeof fallback !== 'function') {
        return fallback;
      }
      
      // Default fallback UI
      return (
        <div className="error-boundary">
          <div className="error-container">
            <h2>Something went wrong</h2>
            <p className="error-message">{error.message}</p>
            {isDevelopment && errorInfo && (
              <details className="error-details">
                <summary>Component Stack</summary>
                <pre>{errorInfo.componentStack}</pre>
              </details>
            )}
            <button
              className="error-reset-button"
              onClick={() => this.setState({ hasError: false, error: undefined, errorInfo: undefined })}
            >
              Try again
            </button>
          </div>
        </div>
      );
    }

    // When there's no error, render children normally
    return children;
  }
}

/**
 * Higher-order component that wraps a component with an ErrorBoundary
 */
export function withErrorBoundary<P extends object>(
  Component: React.ComponentType<P>,
  errorBoundaryProps?: Omit<Props, 'children'>
) {
  const displayName = Component.displayName || Component.name || 'Component';
  
  const WrappedComponent = (props: P) => (
    <ErrorBoundary {...errorBoundaryProps}>
      <Component {...props} />
    </ErrorBoundary>
  );
  
  WrappedComponent.displayName = `withErrorBoundary(${displayName})`;
  
  return WrappedComponent;
}

export default ErrorBoundary; 
```


### FILE: frontend\src\components\layout\Layout.tsx
```
import React from 'react';
import { useRouter } from 'next/router';
import { useAuth } from '@/contexts/AuthContext';

interface LayoutProps {
  children: React.ReactNode;
}

export default function Layout({ children }: LayoutProps) {
  const router = useRouter();
  const { user, logout } = useAuth();

  const handleLogout = async () => {
    await logout();
    router.push('/login');
  };

  const getUserDisplayName = () => {
    if (!user) return '';
    if (user.first_name && user.last_name) {
      return `${user.first_name} ${user.last_name}`;
    }
    return user.email;
  };

  return (
    <div className="min-h-screen bg-gray-100">
      {/* Navigation */}
      <nav className="bg-white shadow-sm">
        <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
          <div className="flex justify-between h-16">
            <div className="flex items-center">
              <button onClick={() => router.push('/')} className="text-xl font-bold text-blue-600">
                Meeting App
              </button>
            </div>
            <div className="flex items-center">
              {user ? (
                <div className="flex items-center space-x-4">
                  <span className="text-gray-700">{getUserDisplayName()}</span>
                  <button
                    onClick={handleLogout}
                    className="bg-red-500 hover:bg-red-600 text-white px-4 py-2 rounded-md text-sm font-medium"
                  >
                    Logout
                  </button>
                </div>
              ) : (
                <button
                  onClick={() => router.push('/login')}
                  className="bg-blue-500 hover:bg-blue-600 text-white px-4 py-2 rounded-md text-sm font-medium"
                >
                  Login
                </button>
              )}
            </div>
          </div>
        </div>
      </nav>

      {/* Main content */}
      <main className="py-10">
        <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
          {children}
        </div>
      </main>
    </div>
  );
} 
```


### FILE: frontend\src\components\meeting\Chat.tsx
```
import React, { useState, useEffect, useRef } from 'react';
import { useWebSocket } from '@/contexts/WebSocketContext';
import { useAuth } from '@/contexts/AuthContext';

interface Message {
  userId: number;
  message: string;
  timestamp: string;
}

interface ChatProps {
  roomId?: string;
}

export default function Chat({ roomId }: ChatProps) {
  const { socket, isConnected, sendMessage } = useWebSocket();
  const { user } = useAuth();
  const [messages, setMessages] = useState<Message[]>([]);
  const [newMessage, setNewMessage] = useState('');
  const messagesEndRef = useRef<HTMLDivElement>(null);

  // Scroll to bottom when new messages arrive
  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  // Listen for chat messages
  useEffect(() => {
    if (!socket || !isConnected || !roomId) return;

    const handleChatMessage = (message: Message) => {
      setMessages(prev => [...prev, message]);
    };

    socket.on('chat-message', handleChatMessage);

    return () => {
      socket.off('chat-message', handleChatMessage);
    };
  }, [socket, isConnected, roomId]);

  const handleSubmit = (e: React.FormEvent) => {
    e.preventDefault();
    if (!newMessage.trim() || !roomId) return;

    sendMessage(roomId, newMessage.trim());
    setNewMessage('');
  };

  return (
    <div className="flex flex-col h-full bg-white">
      {/* Messages */}
      <div className="flex-1 overflow-y-auto p-4 space-y-4">
        {messages.map((message, index) => (
          <div
            key={index}
            className={`flex ${
              message.userId === user?.id ? 'justify-end' : 'justify-start'
            }`}
          >
            <div
              className={`max-w-[70%] rounded-lg px-4 py-2 ${
                message.userId === user?.id
                  ? 'bg-blue-500 text-white'
                  : 'bg-gray-100 text-gray-900'
              }`}
            >
              <div className="text-sm">{message.message}</div>
              <div className="text-xs mt-1 opacity-75">
                {new Date(message.timestamp).toLocaleTimeString(undefined, {
                  hour: '2-digit',
                  minute: '2-digit',
                  hour12: true
                })}
              </div>
            </div>
          </div>
        ))}
        <div ref={messagesEndRef} />
      </div>

      {/* Input */}
      <form onSubmit={handleSubmit} className="border-t p-4">
        <div className="flex space-x-2">
          <input
            type="text"
            value={newMessage}
            onChange={(e) => setNewMessage(e.target.value)}
            placeholder="Type a message..."
            className="flex-1 rounded-lg border border-gray-300 px-4 py-2 focus:outline-none focus:ring-2 focus:ring-blue-500"
          />
          <button
            type="submit"
            disabled={!newMessage.trim()}
            className="bg-blue-500 text-white px-4 py-2 rounded-lg hover:bg-blue-600 focus:outline-none focus:ring-2 focus:ring-blue-500 disabled:opacity-50"
          >
            Send
          </button>
        </div>
      </form>
    </div>
  );
} 
```


### FILE: frontend\src\components\meeting\VideoConference.tsx
```
import React, { useEffect, useRef, useState } from 'react';
import SimplePeer from 'simple-peer';
import { useWebSocket } from '@/contexts/WebSocketContext';
import { useAuth } from '@/contexts/AuthContext';

interface Peer {
  userId: string;
  stream: MediaStream;
  peer: SimplePeer.Instance;
}

interface VideoConferenceProps {
  roomId: string;
}

interface UserConnectedEvent {
  userId: string;
}

interface UserDisconnectedEvent {
  userId: string;
}

interface SignalEvent {
  userId: string;
  signal: SimplePeer.SignalData;
}

export default function VideoConference({ roomId }: VideoConferenceProps) {
  const { socket, isConnected } = useWebSocket();
  const { user } = useAuth();
  const [peers, setPeers] = useState<Map<string, Peer>>(new Map());
  const [localStream, setLocalStream] = useState<MediaStream | null>(null);
  const [isMuted, setIsMuted] = useState(false);
  const [isVideoOff, setIsVideoOff] = useState(false);
  const localVideoRef = useRef<HTMLVideoElement>(null);

  // Initialize local media stream
  useEffect(() => {
    const initializeMedia = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: true,
          audio: true
        });
        setLocalStream(stream);
        if (localVideoRef.current) {
          localVideoRef.current.srcObject = stream;
        }
      } catch (err) {
        console.error('Failed to get media devices:', err);
      }
    };

    initializeMedia();

    return () => {
      localStream?.getTracks().forEach((track: MediaStreamTrack) => track.stop());
    };
  }, []);

  // Handle socket events
  useEffect(() => {
    if (!socket || !isConnected || !localStream) return;

    // Join the room
    socket.emit('join-room', { roomId });

    // Handle new user connections
    socket.on('user-connected', ({ userId }: UserConnectedEvent) => {
      if (userId === user?.id?.toString()) return;
      
      const peer = createPeer(userId, localStream);
      setPeers((prev: Map<string, Peer>) => new Map(prev).set(userId, {
        userId,
        stream: localStream,
        peer
      }));
    });

    // Handle user disconnections
    socket.on('user-disconnected', ({ userId }: UserDisconnectedEvent) => {
      if (peers.has(userId)) {
        peers.get(userId)?.peer.destroy();
        const newPeers = new Map(peers);
        newPeers.delete(userId);
        setPeers(newPeers);
      }
    });

    // Handle incoming signals
    socket.on('signal', ({ userId, signal }: SignalEvent) => {
      const peer = peers.get(userId)?.peer;
      if (peer) {
        peer.signal(signal);
      }
    });

    return () => {
      socket.off('user-connected');
      socket.off('user-disconnected');
      socket.off('signal');
      peers.forEach((peer: Peer) => peer.peer.destroy());
    };
  }, [socket, isConnected, localStream, roomId, user?.id]);

  // Create a new peer connection
  const createPeer = (userId: string, stream: MediaStream): SimplePeer.Instance => {
    const peer = new SimplePeer({
      initiator: true,
      trickle: false,
      stream
    });

    peer.on('signal', (signal: SimplePeer.SignalData) => {
      socket?.emit('signal', { userId, signal });
    });

    peer.on('stream', (remoteStream: MediaStream) => {
      setPeers((prev: Map<string, Peer>) => {
        const newPeers = new Map(prev);
        const peerData = newPeers.get(userId);
        if (peerData) {
          newPeers.set(userId, {
            ...peerData,
            stream: remoteStream
          });
        }
        return newPeers;
      });
    });

    return peer;
  };

  // Toggle audio
  const toggleAudio = () => {
    if (localStream) {
      localStream.getAudioTracks().forEach((track: MediaStreamTrack) => {
        track.enabled = !track.enabled;
      });
      setIsMuted(!isMuted);
    }
  };

  // Toggle video
  const toggleVideo = () => {
    if (localStream) {
      localStream.getVideoTracks().forEach((track: MediaStreamTrack) => {
        track.enabled = !track.enabled;
      });
      setIsVideoOff(!isVideoOff);
    }
  };

  return (
    <div className="h-full flex flex-col">
      {/* Controls */}
      <div className="bg-gray-800 p-4 flex items-center justify-center space-x-4">
        <button
          onClick={toggleAudio}
          className={`p-2 rounded-full ${isMuted ? 'bg-red-500' : 'bg-gray-600'}`}
        >
          {isMuted ? 'Unmute' : 'Mute'}
        </button>
        <button
          onClick={toggleVideo}
          className={`p-2 rounded-full ${isVideoOff ? 'bg-red-500' : 'bg-gray-600'}`}
        >
          {isVideoOff ? 'Start Video' : 'Stop Video'}
        </button>
      </div>

      {/* Video Grid */}
      <div className="flex-1 grid grid-cols-2 md:grid-cols-3 lg:grid-cols-4 gap-4 p-4">
        {/* Local Video */}
        <div className="relative aspect-video bg-gray-900 rounded-lg overflow-hidden">
          <video
            ref={localVideoRef}
            autoPlay
            playsInline
            muted
            className="w-full h-full object-cover"
          />
          <div className="absolute bottom-2 left-2 text-white text-sm bg-black bg-opacity-50 px-2 py-1 rounded">
            You
          </div>
        </div>

        {/* Remote Videos */}
        {Array.from(peers.values()).map((peer: Peer) => (
          <div key={peer.userId} className="relative aspect-video bg-gray-900 rounded-lg overflow-hidden">
            <video
              autoPlay
              playsInline
              ref={(video: HTMLVideoElement | null) => {
                if (video) video.srcObject = peer.stream;
              }}
              className="w-full h-full object-cover"
            />
            <div className="absolute bottom-2 left-2 text-white text-sm bg-black bg-opacity-50 px-2 py-1 rounded">
              User {peer.userId}
            </div>
          </div>
        ))}
      </div>
    </div>
  );
} 
```


### FILE: frontend\src\components\meeting\Whiteboard.tsx
```
import React, { useEffect, useRef, useState } from 'react';
import { useWebSocket } from '@/contexts/WebSocketContext';

interface WhiteboardProps {
  roomId?: string;
}

interface DrawData {
  type: 'start' | 'draw' | 'end';
  x: number;
  y: number;
  color: string;
  width: number;
}

export default function Whiteboard({ roomId }: WhiteboardProps) {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const contextRef = useRef<CanvasRenderingContext2D | null>(null);
  const { socket, isConnected, sendWhiteboardUpdate } = useWebSocket();
  const [isDrawing, setIsDrawing] = useState(false);
  const [color, setColor] = useState('#000000');
  const [lineWidth, setLineWidth] = useState(2);

  // Initialize canvas
  useEffect(() => {
    if (!canvasRef.current) return;

    const canvas = canvasRef.current;
    const context = canvas.getContext('2d');
    if (!context) return;

    // Set canvas size
    const parent = canvas.parentElement;
    if (parent) {
      canvas.width = parent.clientWidth;
      canvas.height = parent.clientHeight;
    }

    // Configure context
    context.lineCap = 'round';
    context.strokeStyle = color;
    context.lineWidth = lineWidth;
    contextRef.current = context;

    // Handle window resize
    const handleResize = () => {
      if (parent) {
        const imageData = context.getImageData(0, 0, canvas.width, canvas.height);
        canvas.width = parent.clientWidth;
        canvas.height = parent.clientHeight;
        context.putImageData(imageData, 0, 0);
        context.lineCap = 'round';
        context.strokeStyle = color;
        context.lineWidth = lineWidth;
      }
    };

    window.addEventListener('resize', handleResize);
    return () => window.removeEventListener('resize', handleResize);
  }, [color, lineWidth]);

  // Handle whiteboard updates from other users
  useEffect(() => {
    if (!socket || !isConnected || !roomId || !contextRef.current) return;

    const handleWhiteboardUpdate = ({ data }: { data: DrawData }) => {
      const context = contextRef.current;
      if (!context) return;

      context.strokeStyle = data.color;
      context.lineWidth = data.width;

      switch (data.type) {
        case 'start':
          context.beginPath();
          context.moveTo(data.x, data.y);
          break;
        case 'draw':
          context.lineTo(data.x, data.y);
          context.stroke();
          break;
        case 'end':
          context.closePath();
          break;
      }

      // Reset to current user's settings
      context.strokeStyle = color;
      context.lineWidth = lineWidth;
    };

    socket.on('whiteboard-update', handleWhiteboardUpdate);

    return () => {
      socket.off('whiteboard-update', handleWhiteboardUpdate);
    };
  }, [socket, isConnected, roomId, color, lineWidth]);

  const startDrawing = (e: React.MouseEvent<HTMLCanvasElement>) => {
    if (!contextRef.current || !roomId) return;

    const { offsetX, offsetY } = e.nativeEvent;
    contextRef.current.beginPath();
    contextRef.current.moveTo(offsetX, offsetY);
    setIsDrawing(true);

    sendWhiteboardUpdate(roomId, {
      type: 'start',
      x: offsetX,
      y: offsetY,
      color,
      width: lineWidth,
    });
  };

  const draw = (e: React.MouseEvent<HTMLCanvasElement>) => {
    if (!isDrawing || !contextRef.current || !roomId) return;

    const { offsetX, offsetY } = e.nativeEvent;
    contextRef.current.lineTo(offsetX, offsetY);
    contextRef.current.stroke();

    sendWhiteboardUpdate(roomId, {
      type: 'draw',
      x: offsetX,
      y: offsetY,
      color,
      width: lineWidth,
    });
  };

  const stopDrawing = () => {
    if (!contextRef.current || !roomId) return;

    contextRef.current.closePath();
    setIsDrawing(false);

    sendWhiteboardUpdate(roomId, {
      type: 'end',
      x: 0,
      y: 0,
      color,
      width: lineWidth,
    });
  };

  const clearCanvas = () => {
    if (!canvasRef.current || !contextRef.current) return;

    const canvas = canvasRef.current;
    const context = contextRef.current;
    context.clearRect(0, 0, canvas.width, canvas.height);
  };

  return (
    <div className="flex flex-col h-full">
      {/* Controls */}
      <div className="p-4 border-b flex items-center space-x-4">
        <input
          type="color"
          value={color}
          onChange={(e) => setColor(e.target.value)}
          className="w-8 h-8 rounded-full"
        />
        <select
          value={lineWidth}
          onChange={(e) => setLineWidth(Number(e.target.value))}
          className="border rounded px-2 py-1"
        >
          <option value="2">Thin</option>
          <option value="4">Medium</option>
          <option value="6">Thick</option>
        </select>
        <button
          onClick={clearCanvas}
          className="px-4 py-1 bg-red-500 text-white rounded hover:bg-red-600"
        >
          Clear
        </button>
      </div>

      {/* Canvas */}
      <div className="flex-1 relative">
        <canvas
          ref={canvasRef}
          onMouseDown={startDrawing}
          onMouseMove={draw}
          onMouseUp={stopDrawing}
          onMouseLeave={stopDrawing}
          className="absolute inset-0 bg-white cursor-crosshair"
        />
      </div>
    </div>
  );
} 
```


### FILE: frontend\src\config\environment.ts
```
/**
 * Centralized environment configuration.
 * This module provides consistent access to environment variables
 * and validates their presence at runtime.
 */

// Required environment variables that must be defined
interface RequiredEnvVars {
  // API URLs
  NEXT_PUBLIC_API_URL: string;
  NEXT_PUBLIC_AUTH_URL: string;
  NEXT_PUBLIC_WS_URL: string;
  
  // Other required configs
  NEXT_PUBLIC_APP_NAME: string;
  NEXT_PUBLIC_APP_VERSION: string;
}

// Optional environment variables with defaults
interface OptionalEnvVars {
  // Feature flags
  NEXT_PUBLIC_ENABLE_ANALYTICS: boolean;
  NEXT_PUBLIC_ENABLE_DEBUG_TOOLS: boolean;
  
  // Timeouts and limits
  NEXT_PUBLIC_API_TIMEOUT_MS: number;
  NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS: number;
  NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB: number;
}

// Environment configuration type
export type EnvConfig = RequiredEnvVars & OptionalEnvVars;

/**
 * Get environment variable with type checking
 */
function getEnvVar<T>(key: string, defaultValue?: T, parser?: (value: string) => T): T {
  const value = process.env[key];
  
  // Handle undefined values
  if (value === undefined) {
    if (defaultValue !== undefined) {
      return defaultValue;
    }
    throw new Error(`Environment variable ${key} is not defined`);
  }
  
  // Parse value if parser is provided
  if (parser) {
    try {
      return parser(value);
    } catch (error) {
      console.error(`Failed to parse environment variable ${key}:`, error);
      if (defaultValue !== undefined) {
        return defaultValue;
      }
      throw new Error(`Failed to parse environment variable ${key}`);
    }
  }
  
  // Return value as is
  return value as unknown as T;
}

/**
 * Boolean parser for environment variables
 */
function parseBoolean(value: string): boolean {
  return value.toLowerCase() === 'true';
}

/**
 * Number parser for environment variables
 */
function parseNumber(value: string): number {
  const parsed = Number(value);
  if (isNaN(parsed)) {
    throw new Error(`Value "${value}" cannot be parsed as a number`);
  }
  return parsed;
}

/**
 * Environment configuration
 */
export const env: EnvConfig = {
  // Required environment variables
  NEXT_PUBLIC_API_URL: getEnvVar('NEXT_PUBLIC_API_URL'),
  NEXT_PUBLIC_AUTH_URL: getEnvVar('NEXT_PUBLIC_AUTH_URL'),
  NEXT_PUBLIC_WS_URL: getEnvVar('NEXT_PUBLIC_WS_URL'),
  NEXT_PUBLIC_APP_NAME: getEnvVar('NEXT_PUBLIC_APP_NAME'),
  NEXT_PUBLIC_APP_VERSION: getEnvVar('NEXT_PUBLIC_APP_VERSION'),
  
  // Optional environment variables with defaults
  NEXT_PUBLIC_ENABLE_ANALYTICS: getEnvVar('NEXT_PUBLIC_ENABLE_ANALYTICS', false, parseBoolean),
  NEXT_PUBLIC_ENABLE_DEBUG_TOOLS: getEnvVar('NEXT_PUBLIC_ENABLE_DEBUG_TOOLS', process.env.NODE_ENV !== 'production', parseBoolean),
  NEXT_PUBLIC_API_TIMEOUT_MS: getEnvVar('NEXT_PUBLIC_API_TIMEOUT_MS', 30000, parseNumber),
  NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS: getEnvVar('NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS', 5000, parseNumber),
  NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB: getEnvVar('NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB', 5, parseNumber),
};

/**
 * Check if running in development mode
 */
export const isDevelopment = process.env.NODE_ENV === 'development';

/**
 * Check if running in production mode
 */
export const isProduction = process.env.NODE_ENV === 'production';

/**
 * Check if running in test mode
 */
export const isTest = process.env.NODE_ENV === 'test';

/**
 * Get base URL for the current environment
 */
export function getBaseUrl(): string {
  if (typeof window !== 'undefined') {
    return window.location.origin;
  }
  return env.NEXT_PUBLIC_API_URL;
}

export default env; 
```


### FILE: frontend\src\contexts\AuthContext.tsx
```
import { createContext, useContext, useState, useEffect, ReactNode } from 'react';
import { useRouter } from 'next/router';

interface User {
  id: number;
  email: string;
  first_name?: string;
  last_name?: string;
  profile_picture?: string;
  is_google_user: boolean;
}

interface AuthContextType {
  user: User | null;
  token: string | null;
  loading: boolean;
  error: string | null;
  login: (email: string, password: string) => Promise<void>;
  googleLogin: (token: string) => Promise<void>;
  logout: () => void;
  register: (email: string, password: string) => Promise<void>;
  resetPassword: (email: string) => Promise<void>;
  updatePassword: (email: string, token: string, newPassword: string) => Promise<void>;
  refreshToken: () => Promise<boolean>;
}

interface AuthProviderProps {
  children: ReactNode;
}

const AuthContext = createContext<AuthContextType | undefined>(undefined);

export function AuthProvider({ children }: AuthProviderProps) {
  const [user, setUser] = useState<User | null>(null);
  const [token, setToken] = useState<string | null>(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);
  const router = useRouter();

  const AUTH_API_URL = process.env.NEXT_PUBLIC_AUTH_URL || 'http://localhost:5001';

  useEffect(() => {
    // Check for stored token and validate it
    const storedToken = localStorage.getItem('auth_token');
    if (storedToken) {
      validateToken(storedToken);
    } else {
      setLoading(false);
    }
  }, []);

  const validateToken = async (authToken: string) => {
    try {
      const response = await fetch(`${AUTH_API_URL}/auth/validate`, {
        headers: {
          'Authorization': `Bearer ${authToken}`
        }
      });
      
      if (response.ok) {
        const userData = await response.json();
        setUser(userData);
        setToken(authToken);
      } else {
        localStorage.removeItem('auth_token');
        setToken(null);
        setUser(null);
      }
    } catch (err) {
      console.error('Token validation error:', err);
      localStorage.removeItem('auth_token');
      setToken(null);
      setUser(null);
    } finally {
      setLoading(false);
    }
  };

  const refreshToken = async (): Promise<boolean> => {
    try {
      const response = await fetch(`${AUTH_API_URL}/auth/refresh-token`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${token}`
        }
      });

      if (response.ok) {
        const data = await response.json();
        localStorage.setItem('auth_token', data.token);
        setToken(data.token);
        return true;
      }
      return false;
    } catch (err) {
      console.error('Token refresh error:', err);
      return false;
    }
  };

  const login = async (email: string, password: string) => {
    try {
      setError(null);
      const response = await fetch(`${AUTH_API_URL}/auth/login`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ email, password })
      });

      if (!response.ok) {
        const error = await response.json();
        throw new Error(error.error || 'Login failed');
      }

      const data = await response.json();
      localStorage.setItem('auth_token', data.token);
      setToken(data.token);
      setUser(data.user);
      router.push('/dashboard');
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Login failed');
      throw err;
    }
  };

  const googleLogin = async (token: string) => {
    try {
      setError(null);
      const response = await fetch(`${AUTH_API_URL}/auth/google/login`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ token })
      });

      if (!response.ok) {
        const error = await response.json();
        throw new Error(error.error || 'Google login failed');
      }

      const data = await response.json();
      localStorage.setItem('auth_token', data.token);
      setUser(data.user);
      router.push('/dashboard');
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Google login failed');
      throw err;
    }
  };

  const register = async (email: string, password: string) => {
    try {
      setError(null);
      const response = await fetch('http://localhost:5001/auth/register', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ email, password })
      });

      if (!response.ok) {
        const error = await response.json();
        throw new Error(error.error || 'Registration failed');
      }

      const data = await response.json();
      localStorage.setItem('auth_token', data.token);
      setUser(data.user);
      router.push('/dashboard');
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Registration failed');
      throw err;
    }
  };

  const resetPassword = async (email: string) => {
    try {
      setError(null);
      const response = await fetch('http://localhost:5001/auth/reset-password', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ email })
      });

      if (!response.ok) {
        const error = await response.json();
        throw new Error(error.error || 'Password reset failed');
      }
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Password reset failed');
      throw err;
    }
  };

  const updatePassword = async (email: string, token: string, newPassword: string) => {
    try {
      setError(null);
      const response = await fetch('http://localhost:5001/auth/reset-password', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ email, token, new_password: newPassword })
      });

      if (!response.ok) {
        const error = await response.json();
        throw new Error(error.error || 'Password update failed');
      }
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Password update failed');
      throw err;
    }
  };

  const logout = () => {
    localStorage.removeItem('auth_token');
    setUser(null);
    router.push('/login');
  };

  return (
    <AuthContext.Provider value={{
      user,
      token,
      loading,
      error,
      login,
      googleLogin,
      logout,
      register,
      resetPassword,
      updatePassword,
      refreshToken
    }}>
      {children}
    </AuthContext.Provider>
  );
}

export function useAuth() {
  const context = useContext(AuthContext);
  if (context === undefined) {
    throw new Error('useAuth must be used within an AuthProvider');
  }
  return context;
} 
```


### FILE: frontend\src\contexts\ChatContext.tsx
```
import React, { createContext, useContext, useEffect, useState } from 'react';
import { useWebSocket } from './WebSocketContext';

interface Message {
  id: string;
  userId: string;
  message: string;
  type: 'text' | 'file';
  fileUrl?: string;
  fileType?: string;
  fileSize?: number;
  timestamp: string;
  reactions?: Record<string, Set<string>>;
}

interface ChatContextType {
  messages: Message[];
  sendMessage: (message: string) => void;
  sendFile: (file: File) => Promise<void>;
  addReaction: (messageId: string, reaction: string) => void;
  isTyping: boolean;
  setIsTyping: (typing: boolean) => void;
  typingUsers: Set<string>;
}

interface UserTypingEvent {
  userId: string;
  isTyping: boolean;
}

interface MessageReactionEvent {
  messageId: string;
  reaction: string;
  userId: string;
  count: number;
}

const ChatContext = createContext<ChatContextType | undefined>(undefined);

export function ChatProvider({ children }: { children: React.ReactNode }) {
  const { socket } = useWebSocket();
  const [messages, setMessages] = useState<Message[]>([]);
  const [isTyping, setIsTyping] = useState(false);
  const [typingUsers, setTypingUsers] = useState<Set<string>>(new Set());
  const [typingTimeout, setTypingTimeout] = useState<ReturnType<typeof setTimeout> | null>(null);

  useEffect(() => {
    if (!socket) return;

    socket.on('chat_message', (message: Message) => {
      const messageWithUTC = {
        ...message,
        timestamp: new Date(message.timestamp).toISOString()
      };
      setMessages((prev: Message[]) => [...prev, messageWithUTC]);
    });

    socket.on('user_typing', ({ userId, isTyping }: UserTypingEvent) => {
      setTypingUsers((prev: Set<string>) => {
        const newSet = new Set(prev);
        if (isTyping) {
          newSet.add(userId);
        } else {
          newSet.delete(userId);
        }
        return newSet;
      });
    });

    socket.on('message_reaction', ({ messageId, reaction, userId, count }: MessageReactionEvent) => {
      setMessages((prev: Message[]) => {
        return prev.map((msg: Message) => {
          if (msg.id === messageId) {
            return {
              ...msg,
              reactions: {
                ...msg.reactions,
                [reaction]: new Set([...Array.from(msg.reactions?.[reaction] || []), userId])
              }
            };
          }
          return msg;
        });
      });
    });

    return () => {
      socket.off('chat_message');
      socket.off('user_typing');
      socket.off('message_reaction');
    };
  }, [socket]);

  const sendMessage = (message: string) => {
    if (!socket) return;
    socket.emit('chat_message', { message });
  };

  const sendFile = async (file: File) => {
    if (!socket) return;

    // Convert file to base64
    const reader = new FileReader();
    reader.readAsDataURL(file);

    reader.onload = () => {
      const base64 = reader.result as string;
      socket.emit('chat_message', {
        message: file.name,
        type: 'file',
        fileData: {
          name: file.name,
          type: file.type,
          size: file.size,
          url: base64
        }
      });
    };
  };

  const addReaction = (messageId: string, reaction: string) => {
    if (!socket) return;
    socket.emit('message_reaction', { messageId, reaction });
  };

  // Handle typing status
  useEffect(() => {
    if (!socket || !isTyping) return;

    socket.emit('user_typing', { isTyping: true });

    if (typingTimeout) {
      clearTimeout(typingTimeout);
    }

    const timeout = setTimeout(() => {
      socket.emit('user_typing', { isTyping: false });
      setIsTyping(false);
    }, 3000);

    setTypingTimeout(timeout);

    return () => {
      if (typingTimeout) {
        clearTimeout(typingTimeout);
      }
    };
  }, [isTyping, socket]);

  return (
    <ChatContext.Provider
      value={{
        messages,
        sendMessage,
        sendFile,
        addReaction,
        isTyping,
        setIsTyping,
        typingUsers
      }}
    >
      {children}
    </ChatContext.Provider>
  );
}

export function useChat() {
  const context = useContext(ChatContext);
  if (context === undefined) {
    throw new Error('useChat must be used within a ChatProvider');
  }
  return context;
} 
```


### FILE: frontend\src\contexts\DebugContext.tsx
```
import React, { createContext, useContext, useState, useEffect, useCallback } from 'react';
import { env, isDevelopment } from '@/config/environment';
import logger, { LogLevel, configureLogger } from '@/utils/logger';
import { getPendingRequests, abortAllRequests } from '@/services/api/client';

// Debug context state
interface DebugContextState {
  isDebugEnabled: boolean;
  toggleDebug: () => void;
  logLevel: LogLevel;
  setLogLevel: (level: LogLevel) => void;
  lastApiResponses: Array<{
    url: string;
    method: string;
    status: number;
    timestamp: number;
    duration: number;
  }>;
  pendingRequests: Array<{
    url: string;
    method: string;
    timestamp: number;
    duration: number;
  }>;
  appState: Record<string, any>;
  captureState: (key: string, value: any) => void;
  clearState: (key?: string) => void;
  abortAllRequests: () => void;
}

// Default context value
const defaultContext: DebugContextState = {
  isDebugEnabled: false,
  toggleDebug: () => {},
  logLevel: LogLevel.INFO,
  setLogLevel: () => {},
  lastApiResponses: [],
  pendingRequests: [],
  appState: {},
  captureState: () => {},
  clearState: () => {},
  abortAllRequests: () => {},
};

// Create context
const DebugContext = createContext<DebugContextState>(defaultContext);

// Maximum number of API responses to store
const MAX_API_RESPONSES = 100;

/**
 * Debug context provider component
 */
export const DebugProvider: React.FC<{
  children: React.ReactNode;
  initialEnabled?: boolean | string;
}> = ({ children, initialEnabled = env.NEXT_PUBLIC_ENABLE_DEBUG_TOOLS }) => {
  // Debug state
  const [isDebugEnabled, setIsDebugEnabled] = useState<boolean>(
    isDevelopment && (initialEnabled === true || initialEnabled === 'true')
  );
  
  // Log level state
  const [logLevel, setLogLevelState] = useState<LogLevel>(
    isDevelopment ? LogLevel.DEBUG : LogLevel.INFO
  );
  
  // API history state
  const [lastApiResponses, setLastApiResponses] = useState<Array<{
    url: string;
    method: string;
    status: number;
    timestamp: number;
    duration: number;
  }>>([]);
  
  // App state capture
  const [appState, setAppState] = useState<Record<string, any>>({});
  
  // Toggle debug mode
  const toggleDebug = useCallback(() => {
    setIsDebugEnabled(prev => !prev);
  }, []);
  
  // Set log level
  const setLogLevel = useCallback((level: LogLevel) => {
    setLogLevelState(level);
    configureLogger({ level });
    
    // Log the change
    logger.info(`Log level set to ${LogLevel[level]}`);
  }, []);
  
  // Capture application state for debugging
  const captureState = useCallback((key: string, value: any) => {
    setAppState(prev => ({
      ...prev,
      [key]: value,
      _lastUpdated: Date.now(),
    }));
  }, []);
  
  // Clear captured state
  const clearState = useCallback((key?: string) => {
    if (key) {
      setAppState(prev => {
        const newState = { ...prev };
        delete newState[key];
        return {
          ...newState,
          _lastUpdated: Date.now(),
        };
      });
    } else {
      setAppState({ _lastUpdated: Date.now() });
    }
  }, []);
  
  // Get pending requests
  const [pendingRequests, setPendingRequests] = useState<Array<{
    url: string;
    method: string;
    timestamp: number;
    duration: number;
  }>>([]);
  
  // Register API response listener
  useEffect(() => {
    if (!isDebugEnabled || !isDevelopment) {
      return;
    }
    
    // Register event listener for API responses
    const handleApiResponse = (event: CustomEvent) => {
      const { url, method, status, timestamp, duration } = event.detail;
      
      setLastApiResponses(prev => {
        const newResponses = [
          { url, method, status, timestamp, duration },
          ...prev,
        ].slice(0, MAX_API_RESPONSES);
        
        return newResponses;
      });
    };
    
    // Create custom event for API responses
    window.addEventListener('api-response', handleApiResponse as EventListener);
    
    // Clean up
    return () => {
      window.removeEventListener('api-response', handleApiResponse as EventListener);
    };
  }, [isDebugEnabled]);
  
  // Register keyboard shortcut for debug mode
  useEffect(() => {
    if (!isDevelopment) {
      return;
    }
    
    // Toggle debug mode with Ctrl+Shift+D
    const handleKeyDown = (event: KeyboardEvent) => {
      if (event.ctrlKey && event.shiftKey && event.key === 'D') {
        toggleDebug();
      }
    };
    
    window.addEventListener('keydown', handleKeyDown);
    
    // Clean up
    return () => {
      window.removeEventListener('keydown', handleKeyDown);
    };
  }, [toggleDebug]);
  
  // Update pending requests
  useEffect(() => {
    if (!isDebugEnabled || !isDevelopment) {
      return;
    }
    
    // Poll for pending requests
    const intervalId = setInterval(() => {
      const requests = getPendingRequests();
      const now = Date.now();
      
      setPendingRequests(
        requests.map(req => ({
          url: req.url,
          method: req.method,
          timestamp: req.timestamp,
          duration: now - req.timestamp,
        }))
      );
    }, 100);
    
    // Clean up
    return () => {
      clearInterval(intervalId);
    };
  }, [isDebugEnabled]);
  
  // Set initial log level
  useEffect(() => {
    configureLogger({ level: logLevel });
  }, [logLevel]);
  
  // Context value
  const contextValue: DebugContextState = {
    isDebugEnabled,
    toggleDebug,
    logLevel,
    setLogLevel,
    lastApiResponses,
    pendingRequests,
    appState,
    captureState,
    clearState,
    abortAllRequests,
  };
  
  return (
    <DebugContext.Provider value={contextValue}>
      {children}
      {isDebugEnabled && isDevelopment && (
        <DebugOverlay />
      )}
    </DebugContext.Provider>
  );
};

/**
 * Debug overlay component
 * Shown when debug mode is enabled
 */
const DebugOverlay: React.FC = () => {
  const [isExpanded, setIsExpanded] = useState<boolean>(false);
  const { logLevel, setLogLevel, lastApiResponses, pendingRequests, appState } = useContext(DebugContext);
  
  // Toggle expanded state
  const toggleExpanded = () => {
    setIsExpanded(prev => !prev);
  };
  
  // Format date
  const formatTime = (timestamp: number) => {
    const date = new Date(timestamp);
    return date.toLocaleTimeString();
  };
  
  // Handle log level change
  const handleLogLevelChange = (event: React.ChangeEvent<HTMLSelectElement>) => {
    setLogLevel(Number(event.target.value) as LogLevel);
  };
  
  // Minimize style
  if (!isExpanded) {
    return (
      <div className="debug-overlay-minimized">
        <button onClick={toggleExpanded}>ğŸ“Š Debug</button>
      </div>
    );
  }
  
  // Full debug overlay
  return (
    <div className="debug-overlay">
      <div className="debug-header">
        <h3>Debug Tools</h3>
        <button onClick={toggleExpanded}>Minimize</button>
      </div>
      
      <div className="debug-content">
        <div className="debug-section">
          <h4>Settings</h4>
          <div className="debug-setting">
            <label htmlFor="logLevel">Log Level:</label>
            <select 
              id="logLevel" 
              value={logLevel} 
              onChange={handleLogLevelChange}
            >
              <option value={LogLevel.TRACE}>Trace</option>
              <option value={LogLevel.DEBUG}>Debug</option>
              <option value={LogLevel.INFO}>Info</option>
              <option value={LogLevel.WARN}>Warning</option>
              <option value={LogLevel.ERROR}>Error</option>
              <option value={LogLevel.NONE}>None</option>
            </select>
          </div>
        </div>
        
        <div className="debug-section">
          <h4>Pending Requests ({pendingRequests.length})</h4>
          <div className="debug-requests">
            {pendingRequests.length === 0 ? (
              <p>No pending requests</p>
            ) : (
              <ul>
                {pendingRequests.map((request, index) => (
                  <li key={index}>
                    {request.method} {request.url} 
                    ({request.duration}ms, started at {formatTime(request.timestamp)})
                  </li>
                ))}
              </ul>
            )}
          </div>
        </div>
        
        <div className="debug-section">
          <h4>Recent API Responses</h4>
          <div className="debug-responses">
            {lastApiResponses.length === 0 ? (
              <p>No API responses yet</p>
            ) : (
              <ul>
                {lastApiResponses.slice(0, 5).map((response, index) => (
                  <li key={index} className={response.status >= 400 ? 'error' : 'success'}>
                    {response.method} {response.url} 
                    ({response.status}, {response.duration}ms, at {formatTime(response.timestamp)})
                  </li>
                ))}
              </ul>
            )}
          </div>
        </div>
        
        <div className="debug-section">
          <h4>Captured State</h4>
          <div className="debug-state">
            <pre>{JSON.stringify(appState, null, 2)}</pre>
          </div>
        </div>
      </div>
      
      <style jsx>{`
        .debug-overlay {
          position: fixed;
          bottom: 0;
          right: 0;
          width: 400px;
          max-height: 50vh;
          background-color: rgba(0, 0, 0, 0.8);
          color: white;
          border-top-left-radius: 8px;
          overflow: auto;
          z-index: 9999;
          font-family: monospace;
          font-size: 12px;
        }
        
        .debug-overlay-minimized {
          position: fixed;
          bottom: 10px;
          right: 10px;
          z-index: 9999;
        }
        
        .debug-header {
          display: flex;
          justify-content: space-between;
          align-items: center;
          padding: 8px;
          background-color: #333;
          border-bottom: 1px solid #555;
        }
        
        .debug-content {
          padding: 8px;
        }
        
        .debug-section {
          margin-bottom: 16px;
        }
        
        .debug-section h4 {
          margin-top: 0;
          margin-bottom: 8px;
          border-bottom: 1px solid #555;
        }
        
        .debug-requests, .debug-responses, .debug-state {
          max-height: 200px;
          overflow: auto;
        }
        
        ul {
          list-style: none;
          padding: 0;
          margin: 0;
        }
        
        li {
          padding: 4px 0;
          border-bottom: 1px solid #444;
        }
        
        li.error {
          color: #ff6b6b;
        }
        
        li.success {
          color: #69db7c;
        }
        
        .debug-setting {
          display: flex;
          align-items: center;
          margin-bottom: 8px;
        }
        
        .debug-setting label {
          margin-right: 8px;
        }
        
        button {
          background-color: #555;
          color: white;
          border: none;
          padding: 4px 8px;
          border-radius: 4px;
          cursor: pointer;
        }
        
        button:hover {
          background-color: #777;
        }
        
        pre {
          margin: 0;
          white-space: pre-wrap;
        }
      `}</style>
    </div>
  );
};

/**
 * Debug context hook
 */
export const useDebug = () => useContext(DebugContext);

export default DebugContext; 
```


### FILE: frontend\src\contexts\WebRTCContext.tsx
```
import React, { createContext, useContext, useEffect, useState, useCallback } from 'react';
import { useWebSocket } from './WebSocketContext';
import { useAuth } from './AuthContext';

interface MediaStreamError {
  name: string;
  message: string;
}

interface PeerConnection {
  userId: string;
  connection: RTCPeerConnection;
  stream: MediaStream;
}

interface SignalData {
  type: 'offer' | 'answer' | 'candidate';
  sdp?: string;
  candidate?: RTCIceCandidateInit;
}

interface WebRTCContextType {
  localStream: MediaStream | null;
  remoteStreams: Map<string, MediaStream>;
  error: MediaStreamError | null;
  startLocalStream: () => Promise<void>;
  stopLocalStream: () => void;
  toggleAudio: () => void;
  toggleVideo: () => void;
  startScreenShare: () => Promise<MediaStream | void>;
  stopScreenShare: () => void;
  isAudioEnabled: boolean;
  isVideoEnabled: boolean;
  isScreenSharing: boolean;
}

const WebRTCContext = createContext<WebRTCContextType>({
  localStream: null,
  remoteStreams: new Map(),
  error: null,
  startLocalStream: async () => {},
  stopLocalStream: () => {},
  toggleAudio: () => {},
  toggleVideo: () => {},
  startScreenShare: async () => {},
  stopScreenShare: () => {},
  isAudioEnabled: false,
  isVideoEnabled: false,
  isScreenSharing: false,
});

export const useWebRTC = () => useContext(WebRTCContext);

export const WebRTCProvider: React.FC<{ children: React.ReactNode }> = ({ children }) => {
  const [localStream, setLocalStream] = useState<MediaStream | null>(null);
  const [remoteStreams, setRemoteStreams] = useState<Map<string, MediaStream>>(new Map());
  const [error, setError] = useState<MediaStreamError | null>(null);
  const [isAudioEnabled, setIsAudioEnabled] = useState(true);
  const [isVideoEnabled, setIsVideoEnabled] = useState(true);
  const [isScreenSharing, setIsScreenSharing] = useState(false);
  const [screenStream, setScreenStream] = useState<MediaStream | null>(null);
  const [peerConnections] = useState<Map<string, PeerConnection>>(new Map());
  
  const { socket } = useWebSocket();
  const { user } = useAuth();

  const handleMediaError = (error: Error) => {
    setError({
      name: error.name,
      message: error.message
    });
    console.error('Media error:', error);
  };

  const startLocalStream = async () => {
    try {
      setError(null);
      const stream = await navigator.mediaDevices.getUserMedia({
        video: true,
        audio: true,
      });
      setLocalStream(stream);
      setIsAudioEnabled(true);
      setIsVideoEnabled(true);
    } catch (err) {
      handleMediaError(err instanceof Error ? err : new Error('Failed to access media devices'));
      throw err;
    }
  };

  const stopLocalStream = useCallback(() => {
    if (localStream) {
      localStream.getTracks().forEach(track => track.stop());
      setLocalStream(null);
      setIsAudioEnabled(false);
      setIsVideoEnabled(false);
    }
  }, [localStream]);

  const toggleAudio = useCallback(() => {
    if (localStream) {
      const audioTrack = localStream.getAudioTracks()[0];
      if (audioTrack) {
        audioTrack.enabled = !audioTrack.enabled;
        setIsAudioEnabled(audioTrack.enabled);
      }
    }
  }, [localStream]);

  const toggleVideo = useCallback(() => {
    if (localStream) {
      const videoTrack = localStream.getVideoTracks()[0];
      if (videoTrack) {
        videoTrack.enabled = !videoTrack.enabled;
        setIsVideoEnabled(videoTrack.enabled);
      }
    }
  }, [localStream]);

  const startScreenShare = async () => {
    try {
      setError(null);
      const stream = await navigator.mediaDevices.getDisplayMedia({
        video: true,
        audio: true
      });
      
      setScreenStream(stream);
      setIsScreenSharing(true);

      // Handle when user stops sharing via browser UI
      stream.getVideoTracks()[0].onended = () => {
        stopScreenShare();
      };

      return stream;
    } catch (err) {
      handleMediaError(err instanceof Error ? err : new Error('Failed to start screen sharing'));
      throw err;
    }
  };

  const stopScreenShare = useCallback(() => {
    if (screenStream) {
      screenStream.getTracks().forEach(track => track.stop());
      setScreenStream(null);
      setIsScreenSharing(false);
    }
  }, [screenStream]);

  // Clean up when component unmounts
  useEffect(() => {
    return () => {
      stopLocalStream();
      stopScreenShare();
      peerConnections.forEach(peer => {
        peer.connection.close();
      });
    };
  }, [stopLocalStream, stopScreenShare, peerConnections]);

  return (
    <WebRTCContext.Provider
      value={{
        localStream,
        remoteStreams,
        error,
        startLocalStream,
        stopLocalStream,
        toggleAudio,
        toggleVideo,
        startScreenShare,
        stopScreenShare,
        isAudioEnabled,
        isVideoEnabled,
        isScreenSharing,
      }}
    >
      {children}
    </WebRTCContext.Provider>
  );
}; 
```


### FILE: frontend\src\contexts\WebSocketContext.tsx
```
import React, { createContext, useContext, useEffect, useState, useCallback } from 'react';
import { io, Socket } from 'socket.io-client';
import { useAuth } from './AuthContext';

interface WebSocketContextType {
  socket: Socket | null;
  isConnected: boolean;
  connectionError: string | null;
  joinRoom: (roomId: string) => void;
  leaveRoom: (roomId: string) => void;
  sendMessage: (roomId: string, message: string) => void;
  sendSignal: (userId: string, signal: any) => void;
  sendWhiteboardUpdate: (roomId: string, data: any) => void;
}

const WebSocketContext = createContext<WebSocketContextType>({
  socket: null,
  isConnected: false,
  connectionError: null,
  joinRoom: () => {},
  leaveRoom: () => {},
  sendMessage: () => {},
  sendSignal: () => {},
  sendWhiteboardUpdate: () => {},
});

export const useWebSocket = () => useContext(WebSocketContext);

export const WebSocketProvider: React.FC<{ children: React.ReactNode }> = ({ children }) => {
  const [socket, setSocket] = useState<Socket | null>(null);
  const [isConnected, setIsConnected] = useState(false);
  const [connectionError, setConnectionError] = useState<string | null>(null);
  const [reconnectAttempts, setReconnectAttempts] = useState(0);
  const { token } = useAuth();

  const MAX_RECONNECT_ATTEMPTS = 5;
  const RECONNECT_INTERVAL = 5000;
  const WS_URL = process.env.NEXT_PUBLIC_WS_URL || 'ws://localhost:3001';

  const connectSocket = useCallback(() => {
    if (!token) return;

    try {
      const socketInstance = io(WS_URL, {
        auth: { token },
        transports: ['websocket'],
        reconnection: true,
        reconnectionAttempts: MAX_RECONNECT_ATTEMPTS,
        reconnectionDelay: RECONNECT_INTERVAL,
      });

      socketInstance.on('connect', () => {
        console.log('WebSocket connected');
        setIsConnected(true);
        setConnectionError(null);
        setReconnectAttempts(0);
      });

      socketInstance.on('disconnect', (reason) => {
        console.log('WebSocket disconnected:', reason);
        setIsConnected(false);
        if (reason === 'io server disconnect') {
          // Server initiated disconnect, attempt to reconnect
          setTimeout(() => {
            if (reconnectAttempts < MAX_RECONNECT_ATTEMPTS) {
              setReconnectAttempts(prev => prev + 1);
              socketInstance.connect();
            }
          }, RECONNECT_INTERVAL);
        }
      });

      socketInstance.on('connect_error', (error) => {
        console.error('WebSocket connection error:', error);
        setConnectionError(error.message);
        setIsConnected(false);
      });

      socketInstance.on('error', (error: Error) => {
        console.error('WebSocket error:', error);
        setConnectionError(error.message);
      });

      setSocket(socketInstance);

      return () => {
        socketInstance.disconnect();
      };
    } catch (error) {
      console.error('Error creating WebSocket connection:', error);
      setConnectionError(error instanceof Error ? error.message : 'Unknown error');
      return undefined;
    }
  }, [token, reconnectAttempts]);

  useEffect(() => {
    const cleanup = connectSocket();
    return () => cleanup?.();
  }, [connectSocket]);

  const joinRoom = useCallback((roomId: string) => {
    if (socket && isConnected) {
      socket.emit('join-room', { roomId });
    }
  }, [socket, isConnected]);

  const leaveRoom = useCallback((roomId: string) => {
    if (socket && isConnected) {
      socket.emit('leave-room', { roomId });
    }
  }, [socket, isConnected]);

  const sendMessage = useCallback((roomId: string, message: string) => {
    if (socket && isConnected) {
      socket.emit('send-message', { roomId, message });
    }
  }, [socket, isConnected]);

  const sendSignal = useCallback((userId: string, signal: any) => {
    if (socket && isConnected) {
      socket.emit('signal', { userId, signal });
    }
  }, [socket, isConnected]);

  const sendWhiteboardUpdate = useCallback((roomId: string, data: any) => {
    if (socket && isConnected) {
      socket.emit('whiteboard-update', { roomId, data });
    }
  }, [socket, isConnected]);

  return (
    <WebSocketContext.Provider
      value={{
        socket,
        isConnected,
        connectionError,
        joinRoom,
        leaveRoom,
        sendMessage,
        sendSignal,
        sendWhiteboardUpdate,
      }}
    >
      {children}
    </WebSocketContext.Provider>
  );
}; 
```


### FILE: frontend\src\contexts\WhiteboardContext.tsx
```
import React, { createContext, useContext, useEffect, useRef, useState, useCallback } from 'react';
import { fabric } from 'fabric';
import { useWebSocket } from './WebSocketContext';

interface Point {
  x: number;
  y: number;
}

interface DrawingPath {
  points: Point[];
  color: string;
  width: number;
  type: 'brush' | 'eraser';
}

interface DrawingObject {
  type: string;
  options: fabric.IObjectOptions & {
    path?: DrawingPath;
    points?: Point[];
    radius?: number;
    width?: number;
    height?: number;
    text?: string;
  };
}

interface FabricCanvasJSON {
  version: string;
  objects: fabric.Object[];
  background?: string;
}

interface CanvasState extends FabricCanvasJSON {
  // Additional state properties if needed
}

interface WhiteboardState {
  objects: fabric.Object[];
  background: string;
  dimensions: {
    width: number;
    height: number;
  };
}

interface WhiteboardContextType {
  canvas: fabric.Canvas | null;
  currentColor: string;
  setCurrentColor: (color: string) => void;
  currentBrushSize: number;
  setCurrentBrushSize: (size: number) => void;
  clearCanvas: () => void;
  undo: () => void;
  redo: () => void;
  addText: (text: string) => void;
  addShape: (type: 'rectangle' | 'circle' | 'line') => void;
  setMode: (mode: 'draw' | 'erase' | 'select') => void;
  currentMode: string;
  canUndo: boolean;
  canRedo: boolean;
  saveState: () => WhiteboardState;
  loadState: (state: WhiteboardState) => void;
}

const WhiteboardContext = createContext<WhiteboardContextType | undefined>(undefined);

export function WhiteboardProvider({ children }: { children: React.ReactNode }) {
  const { socket } = useWebSocket();
  const [canvas, setCanvas] = useState<fabric.Canvas | null>(null);
  const [currentColor, setCurrentColor] = useState('#000000');
  const [currentBrushSize, setCurrentBrushSize] = useState(2);
  const [currentMode, setCurrentMode] = useState<string>('draw');
  const [canUndo, setCanUndo] = useState(false);
  const [canRedo, setCanRedo] = useState(false);
  
  const canvasRef = useRef<HTMLCanvasElement | null>(null);
  const historyRef = useRef<CanvasState[]>([]);
  const redoHistoryRef = useRef<CanvasState[]>([]);

  useEffect(() => {
    if (!canvasRef.current) return;

    const newCanvas = new fabric.Canvas(canvasRef.current, {
      isDrawingMode: true,
      width: window.innerWidth * 0.8,
      height: window.innerHeight * 0.8,
      backgroundColor: '#ffffff'
    });

    newCanvas.freeDrawingBrush.color = currentColor;
    newCanvas.freeDrawingBrush.width = currentBrushSize;

    newCanvas.on('object:added', () => {
      const rawState = canvas?.toJSON() as FabricCanvasJSON;
      if (rawState) {
        const state: CanvasState = {
          version: rawState.version || '5.3.0',
          objects: rawState.objects || [],
          background: rawState.background
        };
        historyRef.current.push(state);
        redoHistoryRef.current = [];
        updateUndoRedoState();
      }
    });

    setCanvas(newCanvas);

    const handleResize = () => {
      newCanvas.setDimensions({
        width: window.innerWidth * 0.8,
        height: window.innerHeight * 0.8
      });
      newCanvas.renderAll();
    };

    window.addEventListener('resize', handleResize);

    return () => {
      window.removeEventListener('resize', handleResize);
      newCanvas.dispose();
    };
  }, []);

  const updateUndoRedoState = useCallback(() => {
    setCanUndo(historyRef.current.length > 0);
    setCanRedo(redoHistoryRef.current.length > 0);
  }, []);

  const setMode = useCallback((mode: 'draw' | 'erase' | 'select') => {
    if (!canvas) return;

    setCurrentMode(mode);
    canvas.isDrawingMode = mode === 'draw';

    if (mode === 'erase') {
      canvas.freeDrawingBrush = new fabric.PencilBrush(canvas);
      canvas.freeDrawingBrush.color = '#ffffff';
      canvas.freeDrawingBrush.width = 20;
      canvas.isDrawingMode = true;
    } else if (mode === 'draw') {
      canvas.freeDrawingBrush = new fabric.PencilBrush(canvas);
      canvas.freeDrawingBrush.color = currentColor;
      canvas.freeDrawingBrush.width = currentBrushSize;
    }

    canvas.selection = mode === 'select';
    canvas.renderAll();
  }, [canvas, currentColor, currentBrushSize]);

  const clearCanvas = useCallback(() => {
    if (!canvas) return;
    
    canvas.clear();
    canvas.backgroundColor = '#ffffff';
    canvas.renderAll();
    
    // Save state for undo
    const state = canvas.toJSON() as CanvasState;
    if (state) {
      historyRef.current.push(state);
      updateUndoRedoState();
    }

    // Emit clear event
    socket?.emit('whiteboard-clear');
  }, [canvas, socket, updateUndoRedoState]);

  const undo = useCallback(() => {
    if (!canvas || historyRef.current.length === 0) return;

    const currentState = canvas.toJSON() as CanvasState;
    redoHistoryRef.current.push(currentState);
    
    const previousState = historyRef.current.pop();
    if (previousState) {
      canvas.loadFromJSON(previousState, () => {
        canvas.renderAll();
        updateUndoRedoState();
      });
    }
  }, [canvas, updateUndoRedoState]);

  const redo = useCallback(() => {
    if (!canvas || redoHistoryRef.current.length === 0) return;

    const currentState = canvas.toJSON() as CanvasState;
    historyRef.current.push(currentState);
    
    const nextState = redoHistoryRef.current.pop();
    if (nextState) {
      canvas.loadFromJSON(nextState, () => {
        canvas.renderAll();
        updateUndoRedoState();
      });
    }
  }, [canvas, updateUndoRedoState]);

  const addText = useCallback((text: string) => {
    if (!canvas) return;

    const textObject = new fabric.IText(text, {
      left: canvas.width! / 2,
      top: canvas.height! / 2,
      fontSize: 20,
      fill: currentColor
    });

    canvas.add(textObject);
    canvas.setActiveObject(textObject);
    canvas.renderAll();
  }, [canvas, currentColor]);

  const addShape = useCallback((type: 'rectangle' | 'circle' | 'line') => {
    if (!canvas) return;

    let shape: fabric.Object;

    switch (type) {
      case 'rectangle':
        shape = new fabric.Rect({
          left: canvas.width! / 2 - 25,
          top: canvas.height! / 2 - 25,
          width: 50,
          height: 50,
          fill: 'transparent',
          stroke: currentColor,
          strokeWidth: 2
        });
        break;
      case 'circle':
        shape = new fabric.Circle({
          left: canvas.width! / 2 - 25,
          top: canvas.height! / 2 - 25,
          radius: 25,
          fill: 'transparent',
          stroke: currentColor,
          strokeWidth: 2
        });
        break;
      case 'line':
        shape = new fabric.Line([50, 50, 200, 50], {
          left: canvas.width! / 2 - 75,
          top: canvas.height! / 2,
          stroke: currentColor,
          strokeWidth: 2
        });
        break;
      default:
        return;
    }

    canvas.add(shape);
    canvas.setActiveObject(shape);
    canvas.renderAll();
  }, [canvas, currentColor]);

  const saveState = (): WhiteboardState => {
    if (!canvas) {
      return {
        objects: [],
        background: '#ffffff',
        dimensions: { width: 800, height: 600 }
      };
    }

    const rawState = canvas.toJSON() as FabricCanvasJSON;
    return {
      objects: rawState.objects,
      background: rawState.background || '#ffffff',
      dimensions: {
        width: canvas.getWidth(),
        height: canvas.getHeight()
      }
    };
  };

  const loadState = useCallback((state: WhiteboardState) => {
    if (!canvas) return;

    canvas.clear();
    canvas.backgroundColor = state.background;
    canvas.setDimensions(state.dimensions);

    canvas.loadFromJSON({ objects: state.objects }, () => {
      canvas.renderAll();
      historyRef.current = [canvas.toJSON() as CanvasState];
      redoHistoryRef.current = [];
      updateUndoRedoState();
    });
  }, [canvas, updateUndoRedoState]);

  return (
    <WhiteboardContext.Provider
      value={{
        canvas,
        currentColor,
        setCurrentColor,
        currentBrushSize,
        setCurrentBrushSize,
        clearCanvas,
        undo,
        redo,
        addText,
        addShape,
        setMode,
        currentMode,
        canUndo,
        canRedo,
        saveState,
        loadState
      }}
    >
      {children}
    </WhiteboardContext.Provider>
  );
}

export function useWhiteboard() {
  const context = useContext(WhiteboardContext);
  if (context === undefined) {
    throw new Error('useWhiteboard must be used within a WhiteboardProvider');
  }
  return context;
} 
```


### FILE: frontend\src\pages\_app.tsx
```
import React from 'react';
import type { AppProps } from 'next/app';
import Head from 'next/head';
import { GoogleOAuthProvider } from '@react-oauth/google';
import ErrorBoundary from '@/components/ErrorBoundary';
import { DebugProvider } from '@/contexts/DebugContext';
import { AuthProvider } from '@/contexts/AuthContext';
import logger from '@/utils/logger';
import { env, isDevelopment } from '@/config/environment';
import '@/styles/globals.css';

// Report unhandled promise rejections
if (typeof window !== 'undefined') {
  window.addEventListener('unhandledrejection', (event) => {
    logger.error('Unhandled Promise Rejection:', event.reason);
    
    // Track with analytics or error reporting service
    // if (!isDevelopment) {
    //   // Example: send to error tracking service
    //   // errorTrackingService.captureException(event.reason);
    // }
  });
  
  // Report uncaught errors
  window.addEventListener('error', (event) => {
    logger.error('Uncaught Error:', event.error || event.message);
    
    // Track with analytics or error reporting service
    // if (!isDevelopment) {
    //   // Example: send to error tracking service
    //   // errorTrackingService.captureException(event.error);
    // }
  });
}

// Custom error handler for error boundary
const handleError = (error: Error) => {
  logger.error('Error caught by root ErrorBoundary:', error);
  
  // Track with analytics or error reporting service
  // if (!isDevelopment) {
  //   // Example: send to error tracking service
  //   // errorTrackingService.captureException(error);
  // }
};

function MyApp({ Component, pageProps }: AppProps) {
  // Log when app renders (helpful for debugging during refreshes/navigation)
  React.useEffect(() => {
    logger.debug(`App rendered at ${new Date().toISOString()}`);
  }, []);
  
  return (
    <>
      <Head>
        <title>{env.NEXT_PUBLIC_APP_NAME}</title>
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <meta name="description" content="A comprehensive meeting management application" />
      </Head>
      
      <DebugProvider>
        <ErrorBoundary onError={handleError}>
          <GoogleOAuthProvider clientId={process.env.NEXT_PUBLIC_GOOGLE_CLIENT_ID || ''}>
            <AuthProvider>
              <Component {...pageProps} />
            </AuthProvider>
          </GoogleOAuthProvider>
        </ErrorBoundary>
      </DebugProvider>
    </>
  );
}

export default MyApp; 
```


### FILE: frontend\src\pages\_error.tsx
```
import React from 'react';
import { NextPage } from 'next';
import Head from 'next/head';
import Link from 'next/link';
import { useRouter } from 'next/router';
import logger from '@/utils/logger';

interface ErrorProps {
  statusCode?: number;
  message?: string;
  hasGetInitialPropsRun?: boolean;
  err?: Error;
}

/**
 * Custom Next.js error page that handles both 404s and other error codes.
 */
const ErrorPage: NextPage<ErrorProps> = ({ statusCode, message, hasGetInitialPropsRun, err }) => {
  const router = useRouter();
  
  // Log the error when component mounts
  React.useEffect(() => {
    // Only log if we have an actual error (skip 404s for non-existent routes)
    if (statusCode && statusCode !== 404) {
      logger.error(`Error page displayed with status: ${statusCode}, URL: ${router.asPath}`);
      
      if (err) {
        logger.error('Error details:', err);
      }
    }
  }, [statusCode, err, router.asPath]);

  // Handle 404 errors
  if (statusCode === 404) {
    return (
      <>
        <Head>
          <title>Page Not Found | Meeting App</title>
        </Head>
        <div className="error-page not-found">
          <div className="error-container">
            <h1>404</h1>
            <h2>Page Not Found</h2>
            <p>Sorry, we couldn't find the page you're looking for.</p>
            <div className="error-actions">
              <Link href="/" className="btn btn-primary">
                Go to Home
              </Link>
              <button 
                className="btn btn-secondary" 
                onClick={() => router.back()}
              >
                Go Back
              </button>
            </div>
          </div>
        </div>
      </>
    );
  }

  // Handle other errors
  return (
    <>
      <Head>
        <title>Error | Meeting App</title>
      </Head>
      <div className="error-page">
        <div className="error-container">
          <h1>{statusCode || 'Error'}</h1>
          <h2>Something went wrong</h2>
          <p>{message || 'An unexpected error occurred'}</p>
          
          {process.env.NODE_ENV === 'development' && err && (
            <details className="error-details">
              <summary>Error Details</summary>
              <pre>{err.message}</pre>
              <pre>{err.stack}</pre>
            </details>
          )}
          
          <div className="error-actions">
            <Link href="/" className="btn btn-primary">
              Go to Home
            </Link>
            <button 
              className="btn btn-secondary" 
              onClick={() => router.reload()}
            >
              Reload Page
            </button>
          </div>
        </div>
      </div>
    </>
  );
};

// This gets called on server-side errors
ErrorPage.getInitialProps = async ({ res, err, asPath }) => {
  const errorInitialProps: ErrorProps = {
    hasGetInitialPropsRun: true,
    statusCode: res?.statusCode || (err ? 500 : 404),
  };
  
  // Keep the original error for debugging in development
  if (process.env.NODE_ENV === 'development' && err) {
    errorInitialProps.err = err;
    errorInitialProps.message = err.message;
    
    // Log the error on the server side
    console.error(`Server-side error occurred on ${asPath}:`, err);
  }
  
  return errorInitialProps;
};

export default ErrorPage; 
```


### FILE: frontend\src\pages\config.js
```
// This file disables static generation for all pages
export const config = {
  unstable_runtimeJS: true,
  unstable_JsPreload: false
}

// Export a dummy function to make this a valid module
export default function Config() {
  return null;
} 
```


### FILE: frontend\src\pages\dashboard.tsx
```
/// <reference types="node" />
import React, { useState, useEffect, FormEvent, ChangeEvent } from 'react';
import { useRouter } from 'next/router';
import { useAuth } from '@/contexts/AuthContext';
import Layout from '@/components/layout/Layout';

interface Meeting {
  id: number;
  title: string;
  description: string;
  start_time: string;
  end_time: string;
  created_by: number;
  created_at: string;
  updated_at: string;
  ended_at: string | null;
}

declare global {
  namespace NodeJS {
    interface ProcessEnv {
      NEXT_PUBLIC_API_URL: string;
    }
  }
}

export default function Dashboard() {
  const router = useRouter();
  const { token } = useAuth();
  const [meetings, setMeetings] = useState<Meeting[]>([]);
  const [isCreating, setIsCreating] = useState(false);
  const [isJoining, setIsJoining] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [title, setTitle] = useState('');
  const [description, setDescription] = useState('');
  const [startTime, setStartTime] = useState('');
  const [endTime, setEndTime] = useState('');
  const [meetingId, setMeetingId] = useState('');
  const [error, setError] = useState('');

  useEffect(() => {
    if (token) {
      fetchMeetings();
    }
  }, [token]);

  const fetchMeetings = async () => {
    setIsLoading(true);
    try {
      const apiUrl = process.env.NEXT_PUBLIC_API_URL;
      if (!apiUrl) {
        throw new Error('API URL is not configured');
      }

      const response = await fetch(`${apiUrl}/api/meetings/list?active_only=true`, {
        headers: {
          Authorization: `Bearer ${token}`
        }
      });

      if (!response.ok) {
        const errorData = await response.json();
        throw new Error(errorData.error || 'Failed to fetch meetings');
      }

      const data = await response.json();
      setMeetings(data);
    } catch (err) {
      console.error('Error fetching meetings:', err);
      setError(err instanceof Error ? err.message : 'Failed to fetch meetings');
    } finally {
      setIsLoading(false);
    }
  };

  const handleCreateMeeting = async (e: FormEvent<HTMLFormElement>) => {
    e.preventDefault();
    setError('');
    
    try {
      // Enhanced client-side validation
      const trimmedTitle = title.trim();
      const trimmedDesc = description.trim();
      
      if (!trimmedTitle) {
        setError('Meeting title is required');
        return;
      }

      if (trimmedTitle.length > 200) {
        setError('Meeting title cannot exceed 200 characters');
        return;
      }

      if (trimmedDesc.length > 2000) {
        setError('Meeting description cannot exceed 2000 characters');
        return;
      }

      if (!startTime || !endTime) {
        setError('Start time and end time are required');
        return;
      }

      const startDate = new Date(startTime);
      const endDate = new Date(endTime);
      const now = new Date();

      if (isNaN(startDate.getTime()) || isNaN(endDate.getTime())) {
        setError('Invalid date format');
        return;
      }

      if (startDate < now) {
        setError('Meeting cannot start in the past');
        return;
      }

      if (startDate >= endDate) {
        setError('Start time must be before end time');
        return;
      }

      const duration = (endDate.getTime() - startDate.getTime()) / 1000; // in seconds
      if (duration < 300) { // 5 minutes
        setError('Meeting must be at least 5 minutes long');
        return;
      }

      if (duration > 86400) { // 24 hours
        setError('Meeting cannot be longer than 24 hours');
        return;
      }

      const oneYearFromNow = new Date();
      oneYearFromNow.setFullYear(oneYearFromNow.getFullYear() + 1);
      if (startDate > oneYearFromNow) {
        setError('Cannot schedule meetings more than 1 year in advance');
        return;
      }

      setIsCreating(true);
      const apiUrl = process.env.NEXT_PUBLIC_API_URL;
      if (!apiUrl) {
        throw new Error('API URL is not configured');
      }

      const response = await fetch(`${apiUrl}/api/meetings/create`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          Authorization: `Bearer ${token}`
        },
        body: JSON.stringify({
          title: trimmedTitle,
          description: trimmedDesc,
          start_time: startDate.toISOString(),
          end_time: endDate.toISOString()
        })
      });

      const data = await response.json();
      
      if (!response.ok) {
        throw new Error(data.error || 'Failed to create meeting');
      }

      // Update meetings list and reset form
      setMeetings((prevMeetings: Meeting[]) => [...prevMeetings, data]);
      setTitle('');
      setDescription('');
      setStartTime('');
      setEndTime('');
      setError('');
      
      // Show success message or redirect
      router.push(`/meeting/${data.id}`);
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to create meeting');
    } finally {
      setIsCreating(false);
    }
  };

  const handleJoinMeeting = async (e: FormEvent<HTMLFormElement>) => {
    e.preventDefault();
    setError('');

    try {
      // Validate meeting ID
      const meetingIdNum = parseInt(meetingId);
      if (isNaN(meetingIdNum) || meetingIdNum <= 0) {
        setError('Please enter a valid meeting ID');
        return;
      }

      setIsJoining(true);
      const apiUrl = process.env.NEXT_PUBLIC_API_URL;
      if (!apiUrl) {
        throw new Error('API URL is not configured');
      }

      const response = await fetch(`${apiUrl}/api/meetings/join/${meetingIdNum}`, {
        headers: {
          Authorization: `Bearer ${token}`
        }
      });

      const data = await response.json();

      if (!response.ok) {
        // Handle specific error cases
        if (data.starts_in_minutes) {
          setError(`Meeting starts in ${data.starts_in_minutes} minutes`);
        } else {
          throw new Error(data.error || 'Failed to join meeting');
        }
        return;
      }

      // Check if meeting is about to end
      if (data.time_remaining_minutes < 5) {
        setError('Warning: Meeting will end in less than 5 minutes');
        // Continue anyway after warning
      }

      router.push(`/meeting/${meetingIdNum}`);
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to join meeting');
    } finally {
      setIsJoining(false);
    }
  };

  const dashboardContent = (
    <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
      <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
        {/* Create Meeting */}
        <div className="bg-white shadow rounded-lg p-6">
          <h2 className="text-lg font-semibold mb-4">Create New Meeting</h2>
          <form onSubmit={handleCreateMeeting}>
            <div className="mb-4">
              <label htmlFor="title" className="block text-sm font-medium text-gray-700">
                Meeting Title
              </label>
              <input
                type="text"
                id="title"
                value={title}
                onChange={(e: ChangeEvent<HTMLInputElement>) => setTitle(e.target.value)}
                className="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                required
              />
            </div>
            <div className="mb-4">
              <label htmlFor="description" className="block text-sm font-medium text-gray-700">
                Description
              </label>
              <textarea
                id="description"
                value={description}
                onChange={(e: ChangeEvent<HTMLTextAreaElement>) => setDescription(e.target.value)}
                className="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                rows={3}
              />
            </div>
            <div className="mb-4">
              <label htmlFor="startTime" className="block text-sm font-medium text-gray-700">
                Start Time
              </label>
              <input
                type="datetime-local"
                id="startTime"
                value={startTime}
                onChange={(e: ChangeEvent<HTMLInputElement>) => setStartTime(e.target.value)}
                className="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                required
              />
            </div>
            <div className="mb-4">
              <label htmlFor="endTime" className="block text-sm font-medium text-gray-700">
                End Time
              </label>
              <input
                type="datetime-local"
                id="endTime"
                value={endTime}
                onChange={(e: ChangeEvent<HTMLInputElement>) => setEndTime(e.target.value)}
                className="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                required
              />
            </div>
            <button
              type="submit"
              disabled={isCreating}
              className="w-full flex justify-center py-2 px-4 border border-transparent rounded-md shadow-sm text-sm font-medium text-white bg-blue-600 hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500 disabled:opacity-50"
            >
              {isCreating ? 'Creating...' : 'Create Meeting'}
            </button>
          </form>
        </div>

        {/* Join Meeting */}
        <div className="bg-white shadow rounded-lg p-6">
          <h2 className="text-lg font-semibold mb-4">Join Meeting</h2>
          <form onSubmit={handleJoinMeeting}>
            <div className="mb-4">
              <label htmlFor="meetingId" className="block text-sm font-medium text-gray-700">
                Meeting ID
              </label>
              <input
                type="number"
                id="meetingId"
                value={meetingId}
                onChange={(e: ChangeEvent<HTMLInputElement>) => setMeetingId(e.target.value)}
                className="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                required
              />
            </div>
            <button
              type="submit"
              disabled={isJoining}
              className="w-full flex justify-center py-2 px-4 border border-transparent rounded-md shadow-sm text-sm font-medium text-white bg-green-600 hover:bg-green-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-green-500 disabled:opacity-50"
            >
              {isJoining ? 'Joining...' : 'Join Meeting'}
            </button>
          </form>
        </div>
      </div>

      {error && (
        <div className="mt-6 bg-red-50 border border-red-400 text-red-700 px-4 py-3 rounded relative">
          {error}
        </div>
      )}

      {/* Recent Meetings */}
      <div className="mt-8">
        <h2 className="text-lg font-semibold mb-4">Recent Meetings</h2>
        <div className="bg-white shadow overflow-hidden sm:rounded-md">
          {isLoading ? (
            <div className="px-4 py-4 sm:px-6 text-center text-gray-500">
              <div className="animate-spin rounded-full h-8 w-8 border-t-2 border-b-2 border-blue-500 mx-auto"></div>
              <p className="mt-2">Loading meetings...</p>
            </div>
          ) : (
            <ul className="divide-y divide-gray-200">
              {meetings.map((meeting: Meeting) => (
                <li key={meeting.id}>
                  <div className="px-4 py-4 sm:px-6">
                    <div className="flex items-center justify-between">
                      <div className="flex-1 min-w-0">
                        <p className="text-sm font-medium text-blue-600 truncate">
                          {meeting.title}
                        </p>
                        <p className="mt-1 text-sm text-gray-500">
                          {new Date(meeting.start_time).toLocaleString()} - {new Date(meeting.end_time).toLocaleString()}
                        </p>
                        {meeting.description && (
                          <p className="mt-1 text-sm text-gray-500 truncate">
                            {meeting.description}
                          </p>
                        )}
                      </div>
                      <div className="ml-4 flex-shrink-0">
                        <button
                          onClick={() => router.push(`/meeting/${meeting.id}`)}
                          className="inline-flex items-center px-3 py-2 border border-transparent text-sm leading-4 font-medium rounded-md text-white bg-blue-600 hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500"
                        >
                          Join
                        </button>
                      </div>
                    </div>
                  </div>
                </li>
              ))}
              {meetings.length === 0 && (
                <li>
                  <div className="px-4 py-4 sm:px-6 text-center text-gray-500">
                    No recent meetings
                  </div>
                </li>
              )}
            </ul>
          )}
        </div>
      </div>
    </div>
  );

  return <Layout>{dashboardContent}</Layout>;
} 
```


### FILE: frontend\src\pages\forgot-password.tsx
```
import { useState } from 'react';
import { useAuth } from '@/contexts/AuthContext';
import Link from 'next/link';

export default function ForgotPassword() {
  const [email, setEmail] = useState('');
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState('');
  const [message, setMessage] = useState('');
  const { resetPassword } = useAuth();

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    setError('');
    setMessage('');
    setLoading(true);

    try {
      await resetPassword(email);
      setMessage('Check your email for password reset instructions');
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to reset password');
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="min-h-screen flex items-center justify-center bg-gray-50 py-12 px-4 sm:px-6 lg:px-8">
      <div className="max-w-md w-full space-y-8">
        <div>
          <h2 className="mt-6 text-center text-3xl font-extrabold text-gray-900">
            Reset your password
          </h2>
          <p className="mt-2 text-center text-sm text-gray-600">
            Enter your email address and we'll send you a link to reset your password.
          </p>
        </div>

        <form className="mt-8 space-y-6" onSubmit={handleSubmit}>
          <div>
            <label htmlFor="email" className="sr-only">Email address</label>
            <input
              id="email"
              name="email"
              type="email"
              required
              className="appearance-none rounded relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 sm:text-sm"
              placeholder="Email address"
              value={email}
              onChange={(e) => setEmail(e.target.value)}
            />
          </div>

          {error && (
            <div className="text-red-500 text-sm text-center">
              {error}
            </div>
          )}

          {message && (
            <div className="text-green-500 text-sm text-center">
              {message}
            </div>
          )}

          <div>
            <button
              type="submit"
              disabled={loading}
              className="group relative w-full flex justify-center py-2 px-4 border border-transparent text-sm font-medium rounded-md text-white bg-indigo-600 hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-indigo-500 disabled:opacity-50"
            >
              {loading ? 'Sending...' : 'Send reset link'}
            </button>
          </div>

          <div className="text-sm text-center">
            <Link href="/login" className="font-medium text-indigo-600 hover:text-indigo-500">
              Back to login
            </Link>
          </div>
        </form>
      </div>
    </div>
  );
} 
```


### FILE: frontend\src\pages\index.tsx
```
import { useEffect } from 'react';
import { useRouter } from 'next/router';

export default function Home() {
  const router = useRouter();

  useEffect(() => {
    console.log('Index page mounted, redirecting to /login');
    router.replace('/login');
  }, []);

  return (
    <div className="min-h-screen flex items-center justify-center">
      <p>Redirecting to login...</p>
    </div>
  );
} 
```


### FILE: frontend\src\pages\login.tsx
```
import { useState, FormEvent } from 'react';
import { useAuth } from '@/contexts/AuthContext';
import { useRouter } from 'next/router';
import Link from 'next/link';
import { GoogleLogin } from '@react-oauth/google';
import type { FormInputEvent } from '@/types/events';

export default function Login() {
  const [email, setEmail] = useState('');
  const [password, setPassword] = useState('');
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState('');
  const { login, googleLogin } = useAuth();
  const router = useRouter();

  const handleSubmit = async (e: FormEvent<HTMLFormElement>) => {
    e.preventDefault();
    setError('');
    setLoading(true);

    try {
      await login(email, password);
      router.push('/dashboard');
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Login failed');
    } finally {
      setLoading(false);
    }
  };

  const handleGoogleSuccess = async (credentialResponse: { credential: string }) => {
    try {
      await googleLogin(credentialResponse.credential);
      router.push('/dashboard');
    } catch (err) {
      setError('Google login failed');
    }
  };

  return (
    <div className="min-h-screen flex items-center justify-center bg-gray-50 py-12 px-4 sm:px-6 lg:px-8">
      <div className="max-w-md w-full space-y-8">
        <div>
          <h2 className="mt-6 text-center text-3xl font-extrabold text-gray-900">
            Sign in to your account
          </h2>
        </div>
        
        <form className="mt-8 space-y-6" onSubmit={handleSubmit}>
          <div className="rounded-md shadow-sm -space-y-px">
            <div>
              <label htmlFor="email" className="sr-only">Email address</label>
              <input
                id="email"
                name="email"
                type="email"
                required
                className="appearance-none rounded-none relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 rounded-t-md focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 focus:z-10 sm:text-sm"
                placeholder="Email address"
                value={email}
                onChange={(e) => setEmail(e.target.value)}
              />
            </div>
            <div>
              <label htmlFor="password" className="sr-only">Password</label>
              <input
                id="password"
                name="password"
                type="password"
                required
                className="appearance-none rounded-none relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 rounded-b-md focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 focus:z-10 sm:text-sm"
                placeholder="Password"
                value={password}
                onChange={(e) => setPassword(e.target.value)}
              />
            </div>
          </div>

          {error && (
            <div className="text-red-500 text-sm text-center">
              {error}
            </div>
          )}

          <div className="flex items-center justify-between">
            <div className="text-sm">
              <Link href="/forgot-password" className="font-medium text-indigo-600 hover:text-indigo-500">
                Forgot your password?
              </Link>
            </div>
            <div className="text-sm">
              <Link href="/register" className="font-medium text-indigo-600 hover:text-indigo-500">
                Create an account
              </Link>
            </div>
          </div>

          <div>
            <button
              type="submit"
              disabled={loading}
              className="group relative w-full flex justify-center py-2 px-4 border border-transparent text-sm font-medium rounded-md text-white bg-indigo-600 hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-indigo-500 disabled:opacity-50"
            >
              {loading ? 'Signing in...' : 'Sign in'}
            </button>
          </div>
        </form>

        <div className="mt-6">
          <div className="relative">
            <div className="absolute inset-0 flex items-center">
              <div className="w-full border-t border-gray-300" />
            </div>
            <div className="relative flex justify-center text-sm">
              <span className="px-2 bg-gray-50 text-gray-500">
                Or continue with
              </span>
            </div>
          </div>

          <div className="mt-6">
            <GoogleLogin
              onSuccess={handleGoogleSuccess}
              onError={() => setError('Google login failed')}
            />
          </div>
        </div>
      </div>
    </div>
  );
} 
```


### FILE: frontend\src\pages\register.tsx
```
import { useState } from 'react';
import { useAuth } from '@/contexts/AuthContext';
import { useRouter } from 'next/router';
import Link from 'next/link';

const PASSWORD_REQUIREMENTS = [
  { id: 1, text: 'At least 12 characters long' },
  { id: 2, text: 'Contains at least one uppercase letter' },
  { id: 3, text: 'Contains at least one lowercase letter' },
  { id: 4, text: 'Contains at least one number' },
  { id: 5, text: 'Contains at least one special character (@$!%*?&)' }
];

export default function Register() {
  const [email, setEmail] = useState('');
  const [password, setPassword] = useState('');
  const [confirmPassword, setConfirmPassword] = useState('');
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState('');
  const { register } = useAuth();
  const router = useRouter();

  const validatePassword = (password: string) => {
    const hasMinLength = password.length >= 12;
    const hasUpperCase = /[A-Z]/.test(password);
    const hasLowerCase = /[a-z]/.test(password);
    const hasNumber = /\d/.test(password);
    const hasSpecialChar = /[@$!%*?&]/.test(password);

    return hasMinLength && hasUpperCase && hasLowerCase && hasNumber && hasSpecialChar;
  };

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    setError('');

    if (password !== confirmPassword) {
      setError('Passwords do not match');
      return;
    }

    if (!validatePassword(password)) {
      setError('Password does not meet requirements');
      return;
    }

    setLoading(true);

    try {
      await register(email, password);
      router.push('/dashboard');
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Registration failed');
    } finally {
      setLoading(false);
    }
  };

  const checkPasswordRequirement = (requirement: string) => {
    switch (requirement) {
      case 'At least 12 characters long':
        return password.length >= 12;
      case 'Contains at least one uppercase letter':
        return /[A-Z]/.test(password);
      case 'Contains at least one lowercase letter':
        return /[a-z]/.test(password);
      case 'Contains at least one number':
        return /\d/.test(password);
      case 'Contains at least one special character (@$!%*?&)':
        return /[@$!%*?&]/.test(password);
      default:
        return false;
    }
  };

  return (
    <div className="min-h-screen flex items-center justify-center bg-gray-50 py-12 px-4 sm:px-6 lg:px-8">
      <div className="max-w-md w-full space-y-8">
        <div>
          <h2 className="mt-6 text-center text-3xl font-extrabold text-gray-900">
            Create your account
          </h2>
        </div>

        <form className="mt-8 space-y-6" onSubmit={handleSubmit}>
          <div className="rounded-md shadow-sm -space-y-px">
            <div>
              <label htmlFor="email" className="sr-only">Email address</label>
              <input
                id="email"
                name="email"
                type="email"
                required
                className="appearance-none rounded-none relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 rounded-t-md focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 focus:z-10 sm:text-sm"
                placeholder="Email address"
                value={email}
                onChange={(e) => setEmail(e.target.value)}
              />
            </div>
            <div>
              <label htmlFor="password" className="sr-only">Password</label>
              <input
                id="password"
                name="password"
                type="password"
                required
                className="appearance-none rounded-none relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 focus:z-10 sm:text-sm"
                placeholder="Password"
                value={password}
                onChange={(e) => setPassword(e.target.value)}
              />
            </div>
            <div>
              <label htmlFor="confirm-password" className="sr-only">Confirm Password</label>
              <input
                id="confirm-password"
                name="confirm-password"
                type="password"
                required
                className="appearance-none rounded-none relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 rounded-b-md focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 focus:z-10 sm:text-sm"
                placeholder="Confirm Password"
                value={confirmPassword}
                onChange={(e) => setConfirmPassword(e.target.value)}
              />
            </div>
          </div>

          <div className="rounded-md bg-gray-50 p-4">
            <h3 className="text-sm font-medium text-gray-900">Password Requirements</h3>
            <ul className="mt-2 text-sm text-gray-600 space-y-1">
              {PASSWORD_REQUIREMENTS.map((req) => (
                <li key={req.id} className="flex items-center">
                  <span className={`mr-2 ${checkPasswordRequirement(req.text) ? 'text-green-500' : 'text-gray-400'}`}>
                    {checkPasswordRequirement(req.text) ? 'âœ“' : 'â—‹'}
                  </span>
                  {req.text}
                </li>
              ))}
            </ul>
          </div>

          {error && (
            <div className="text-red-500 text-sm text-center">
              {error}
            </div>
          )}

          <div>
            <button
              type="submit"
              disabled={loading}
              className="group relative w-full flex justify-center py-2 px-4 border border-transparent text-sm font-medium rounded-md text-white bg-indigo-600 hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-indigo-500 disabled:opacity-50"
            >
              {loading ? 'Creating account...' : 'Create account'}
            </button>
          </div>

          <div className="text-sm text-center">
            Already have an account?{' '}
            <Link href="/login" className="font-medium text-indigo-600 hover:text-indigo-500">
              Sign in
            </Link>
          </div>
        </form>
      </div>
    </div>
  );
} 
```


### FILE: frontend\src\pages\resend-verification.tsx
```
import React, { useState, FormEvent } from 'react';
import Link from 'next/link';

export default function ResendVerification() {
  const [email, setEmail] = useState('');
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState('');
  const [success, setSuccess] = useState('');

  const handleSubmit = async (e: FormEvent<HTMLFormElement>) => {
    e.preventDefault();
    setError('');
    setSuccess('');
    setLoading(true);

    try {
      const response = await fetch(`${process.env.NEXT_PUBLIC_AUTH_API_URL}/auth/resend-verification`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ email }),
      });

      const data = await response.json();

      if (response.ok) {
        setSuccess(data.message || 'Verification email sent successfully');
        setEmail('');
      } else {
        setError(data.error || 'Failed to send verification email');
      }
    } catch (err) {
      setError('An error occurred while sending the verification email');
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="min-h-screen flex items-center justify-center bg-gray-50 py-12 px-4 sm:px-6 lg:px-8">
      <div className="max-w-md w-full space-y-8">
        <div>
          <h2 className="mt-6 text-center text-3xl font-extrabold text-gray-900">
            Resend Verification Email
          </h2>
          <p className="mt-2 text-center text-sm text-gray-600">
            Enter your email address and we&apos;ll send you a new verification link.
          </p>
        </div>

        <form className="mt-8 space-y-6" onSubmit={handleSubmit}>
          <div>
            <label htmlFor="email" className="sr-only">Email address</label>
            <input
              id="email"
              name="email"
              type="email"
              required
              className="appearance-none rounded relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 sm:text-sm"
              placeholder="Email address"
              value={email}
              onChange={(e) => setEmail(e.target.value)}
            />
          </div>

          {error && (
            <div className="rounded-md bg-red-50 p-4">
              <div className="flex">
                <div className="flex-shrink-0">
                  <svg className="h-5 w-5 text-red-400" viewBox="0 0 20 20" fill="currentColor">
                    <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM8.707 7.293a1 1 0 00-1.414 1.414L8.586 10l-1.293 1.293a1 1 0 101.414 1.414L10 11.414l1.293 1.293a1 1 0 001.414-1.414L11.414 10l1.293-1.293a1 1 0 00-1.414-1.414L10 8.586 8.707 7.293z" clipRule="evenodd" />
                  </svg>
                </div>
                <div className="ml-3">
                  <p className="text-sm font-medium text-red-800">{error}</p>
                </div>
              </div>
            </div>
          )}

          {success && (
            <div className="rounded-md bg-green-50 p-4">
              <div className="flex">
                <div className="flex-shrink-0">
                  <svg className="h-5 w-5 text-green-400" viewBox="0 0 20 20" fill="currentColor">
                    <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z" clipRule="evenodd" />
                  </svg>
                </div>
                <div className="ml-3">
                  <p className="text-sm font-medium text-green-800">{success}</p>
                </div>
              </div>
            </div>
          )}

          <div>
            <button
              type="submit"
              disabled={loading}
              className="group relative w-full flex justify-center py-2 px-4 border border-transparent text-sm font-medium rounded-md text-white bg-indigo-600 hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-indigo-500 disabled:opacity-50"
            >
              {loading ? 'Sending...' : 'Resend verification email'}
            </button>
          </div>

          <div className="text-sm text-center">
            <Link href="/login" className="font-medium text-indigo-600 hover:text-indigo-500">
              Return to login
            </Link>
          </div>
        </form>
      </div>
    </div>
  );
} 
```


### FILE: frontend\src\pages\api\health.ts
```
import type { NextApiRequest, NextApiResponse } from 'next'

export default function handler(req: NextApiRequest, res: NextApiResponse) {
  res.status(200).json({ status: 'healthy' });
} 
```


### FILE: frontend\src\pages\meeting\[id].tsx
```
import React, { useState, useEffect } from 'react';
import { useRouter } from 'next/router';
import { useAuth } from '@/contexts/AuthContext';
import Layout from '@/components/layout/Layout';
import VideoConference from '@/components/meeting/VideoConference';
import Whiteboard from '@/components/meeting/Whiteboard';
import Chat from '@/components/meeting/Chat';

interface Meeting {
  id: number;
  title: string;
  description: string;
  start_time: string;
  end_time: string;
  created_by: number;
  created_at: string;
  updated_at: string;
}

export default function MeetingRoom() {
  const router = useRouter();
  const { id } = router.query;
  const { token, user } = useAuth();
  const [meeting, setMeeting] = useState<Meeting | null>(null);
  const [activeTab, setActiveTab] = useState<'whiteboard' | 'chat'>('chat');
  const [error, setError] = useState('');

  useEffect(() => {
    if (id && token) {
      fetchMeetingDetails();
    }
  }, [id, token]);

  const fetchMeetingDetails = async () => {
    try {
      const response = await fetch(`${process.env.NEXT_PUBLIC_API_URL}/api/meetings/join/${id}`, {
        headers: {
          Authorization: `Bearer ${token}`
        }
      });

      if (!response.ok) {
        const errorData = await response.json();
        throw new Error(errorData.error || 'Meeting not found or inactive');
      }

      const data = await response.json();
      setMeeting(data);
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to join meeting');
      router.push('/dashboard');
    }
  };

  const handleEndMeeting = async () => {
    if (!meeting || meeting.created_by !== user?.id) return;

    try {
      const response = await fetch(`${process.env.NEXT_PUBLIC_API_URL}/api/meetings/end/${id}`, {
        method: 'POST',
        headers: {
          Authorization: `Bearer ${token}`
        }
      });

      if (!response.ok) {
        const errorData = await response.json();
        throw new Error(errorData.error || 'Failed to end meeting');
      }

      router.push('/dashboard');
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to end meeting');
    }
  };

  const MeetingInfo = ({ meeting }: { meeting: Meeting }) => (
    <div className="bg-white border-b px-4 py-2 flex items-center justify-between">
      <div>
        <h1 className="text-xl font-semibold">{meeting.title}</h1>
        <p className="text-sm text-gray-500">ID: {meeting.id}</p>
        <p className="text-sm text-gray-500">
          {new Date(meeting.start_time).toLocaleString()} - {new Date(meeting.end_time).toLocaleString()}
        </p>
      </div>
      <div className="flex items-center space-x-4">
        {meeting.created_by === user?.id && (
          <button
            onClick={handleEndMeeting}
            className="px-4 py-2 bg-red-500 text-white rounded hover:bg-red-600"
          >
            End Meeting
          </button>
        )}
        <button
          onClick={() => router.push('/dashboard')}
          className="px-4 py-2 bg-gray-100 text-gray-700 rounded hover:bg-gray-200"
        >
          Leave
        </button>
      </div>
    </div>
  );

  if (!meeting) {
    return (
      <Layout>
        <div className="flex items-center justify-center h-screen">
          <div className="animate-spin rounded-full h-32 w-32 border-t-2 border-b-2 border-blue-500" />
        </div>
      </Layout>
    );
  }

  return (
    <Layout>
      <div className="h-screen flex flex-col">
        {/* Header */}
        <MeetingInfo meeting={meeting} />

        {/* Main Content */}
        <div className="flex-grow grid grid-cols-12 gap-4 p-4">
          {/* Video Conference */}
          <div className="col-span-8 bg-gray-900 rounded-lg overflow-hidden">
            <VideoConference roomId={meeting.id.toString()} />
          </div>

          {/* Sidebar */}
          <div className="col-span-4 flex flex-col bg-white rounded-lg overflow-hidden">
            {/* Tabs */}
            <div className="flex border-b">
              <button
                onClick={() => setActiveTab('whiteboard')}
                className={`flex-1 px-4 py-2 text-sm font-medium ${
                  activeTab === 'whiteboard'
                    ? 'border-b-2 border-blue-500 text-blue-600'
                    : 'text-gray-500 hover:text-gray-700'
                }`}
              >
                Whiteboard
              </button>
              <button
                onClick={() => setActiveTab('chat')}
                className={`flex-1 px-4 py-2 text-sm font-medium ${
                  activeTab === 'chat'
                    ? 'border-b-2 border-blue-500 text-blue-600'
                    : 'text-gray-500 hover:text-gray-700'
                }`}
              >
                Chat
              </button>
            </div>

            {/* Tab Content */}
            <div className="flex-grow">
              {activeTab === 'whiteboard' ? <Whiteboard /> : <Chat roomId={meeting.id.toString()} />}
            </div>
          </div>
        </div>

        {error && (
          <div className="fixed bottom-4 right-4 bg-red-50 border border-red-400 text-red-700 px-4 py-3 rounded">
            {error}
          </div>
        )}
      </div>
    </Layout>
  );
} 
```


### FILE: frontend\src\pages\reset-password\[token].tsx
```
import { useState, useEffect } from 'react';
import { useAuth } from '@/contexts/AuthContext';
import { useRouter } from 'next/router';
import Link from 'next/link';

const PASSWORD_REQUIREMENTS = [
  { id: 1, text: 'At least 12 characters long' },
  { id: 2, text: 'Contains at least one uppercase letter' },
  { id: 3, text: 'Contains at least one lowercase letter' },
  { id: 4, text: 'Contains at least one number' },
  { id: 5, text: 'Contains at least one special character (@$!%*?&)' }
];

export default function ResetPassword() {
  const [email, setEmail] = useState('');
  const [password, setPassword] = useState('');
  const [confirmPassword, setConfirmPassword] = useState('');
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState('');
  const [message, setMessage] = useState('');
  const { updatePassword } = useAuth();
  const router = useRouter();
  const { token } = router.query;

  const validatePassword = (password: string) => {
    const hasMinLength = password.length >= 12;
    const hasUpperCase = /[A-Z]/.test(password);
    const hasLowerCase = /[a-z]/.test(password);
    const hasNumber = /\d/.test(password);
    const hasSpecialChar = /[@$!%*?&]/.test(password);

    return hasMinLength && hasUpperCase && hasLowerCase && hasNumber && hasSpecialChar;
  };

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    setError('');
    setMessage('');

    if (!token || typeof token !== 'string') {
      setError('Invalid reset token');
      return;
    }

    if (password !== confirmPassword) {
      setError('Passwords do not match');
      return;
    }

    if (!validatePassword(password)) {
      setError('Password does not meet requirements');
      return;
    }

    setLoading(true);

    try {
      await updatePassword(email, token, password);
      setMessage('Password updated successfully');
      setTimeout(() => {
        router.push('/login');
      }, 2000);
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to update password');
    } finally {
      setLoading(false);
    }
  };

  const checkPasswordRequirement = (requirement: string) => {
    switch (requirement) {
      case 'At least 12 characters long':
        return password.length >= 12;
      case 'Contains at least one uppercase letter':
        return /[A-Z]/.test(password);
      case 'Contains at least one lowercase letter':
        return /[a-z]/.test(password);
      case 'Contains at least one number':
        return /\d/.test(password);
      case 'Contains at least one special character (@$!%*?&)':
        return /[@$!%*?&]/.test(password);
      default:
        return false;
    }
  };

  return (
    <div className="min-h-screen flex items-center justify-center bg-gray-50 py-12 px-4 sm:px-6 lg:px-8">
      <div className="max-w-md w-full space-y-8">
        <div>
          <h2 className="mt-6 text-center text-3xl font-extrabold text-gray-900">
            Reset your password
          </h2>
        </div>

        <form className="mt-8 space-y-6" onSubmit={handleSubmit}>
          <div className="rounded-md shadow-sm -space-y-px">
            <div>
              <label htmlFor="email" className="sr-only">Email address</label>
              <input
                id="email"
                name="email"
                type="email"
                required
                className="appearance-none rounded-none relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 rounded-t-md focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 focus:z-10 sm:text-sm"
                placeholder="Email address"
                value={email}
                onChange={(e) => setEmail(e.target.value)}
              />
            </div>
            <div>
              <label htmlFor="password" className="sr-only">New Password</label>
              <input
                id="password"
                name="password"
                type="password"
                required
                className="appearance-none rounded-none relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 focus:z-10 sm:text-sm"
                placeholder="New Password"
                value={password}
                onChange={(e) => setPassword(e.target.value)}
              />
            </div>
            <div>
              <label htmlFor="confirm-password" className="sr-only">Confirm New Password</label>
              <input
                id="confirm-password"
                name="confirm-password"
                type="password"
                required
                className="appearance-none rounded-none relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 rounded-b-md focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 focus:z-10 sm:text-sm"
                placeholder="Confirm New Password"
                value={confirmPassword}
                onChange={(e) => setConfirmPassword(e.target.value)}
              />
            </div>
          </div>

          <div className="rounded-md bg-gray-50 p-4">
            <h3 className="text-sm font-medium text-gray-900">Password Requirements</h3>
            <ul className="mt-2 text-sm text-gray-600 space-y-1">
              {PASSWORD_REQUIREMENTS.map((req) => (
                <li key={req.id} className="flex items-center">
                  <span className={`mr-2 ${checkPasswordRequirement(req.text) ? 'text-green-500' : 'text-gray-400'}`}>
                    {checkPasswordRequirement(req.text) ? 'âœ“' : 'â—‹'}
                  </span>
                  {req.text}
                </li>
              ))}
            </ul>
          </div>

          {error && (
            <div className="text-red-500 text-sm text-center">
              {error}
            </div>
          )}

          {message && (
            <div className="text-green-500 text-sm text-center">
              {message}
            </div>
          )}

          <div>
            <button
              type="submit"
              disabled={loading}
              className="group relative w-full flex justify-center py-2 px-4 border border-transparent text-sm font-medium rounded-md text-white bg-indigo-600 hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-indigo-500 disabled:opacity-50"
            >
              {loading ? 'Updating password...' : 'Update password'}
            </button>
          </div>

          <div className="text-sm text-center">
            <Link href="/login" className="font-medium text-indigo-600 hover:text-indigo-500">
              Back to login
            </Link>
          </div>
        </form>
      </div>
    </div>
  );
} 
```


### FILE: frontend\src\pages\verify-email\[token].tsx
```
import { useEffect, useState } from 'react';
import { useRouter } from 'next/router';
import Link from 'next/link';

export default function VerifyEmail() {
  const [status, setStatus] = useState<'loading' | 'success' | 'error'>('loading');
  const [message, setMessage] = useState('');
  const router = useRouter();
  const { token } = router.query;

  useEffect(() => {
    if (!token) return;

    const verifyEmail = async () => {
      try {
        const response = await fetch(`${process.env.NEXT_PUBLIC_AUTH_API_URL}/auth/verify-email/${token}`, {
          method: 'GET',
          headers: {
            'Content-Type': 'application/json',
          },
        });

        const data = await response.json();

        if (response.ok) {
          setStatus('success');
          setMessage(data.message);
          // Redirect to login after 3 seconds
          setTimeout(() => {
            router.push('/login');
          }, 3000);
        } else {
          setStatus('error');
          setMessage(data.error || 'Verification failed');
        }
      } catch (err) {
        setStatus('error');
        setMessage('An error occurred during verification');
      }
    };

    verifyEmail();
  }, [token, router]);

  return (
    <div className="min-h-screen flex items-center justify-center bg-gray-50 py-12 px-4 sm:px-6 lg:px-8">
      <div className="max-w-md w-full space-y-8">
        <div>
          <h2 className="mt-6 text-center text-3xl font-extrabold text-gray-900">
            Email Verification
          </h2>
        </div>

        <div className="mt-8 space-y-6">
          {status === 'loading' && (
            <div className="text-center">
              <div className="animate-spin rounded-full h-12 w-12 border-b-2 border-indigo-600 mx-auto"></div>
              <p className="mt-4 text-gray-600">Verifying your email...</p>
            </div>
          )}

          {status === 'success' && (
            <div className="rounded-md bg-green-50 p-4">
              <div className="flex">
                <div className="flex-shrink-0">
                  <svg className="h-5 w-5 text-green-400" viewBox="0 0 20 20" fill="currentColor">
                    <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z" clipRule="evenodd" />
                  </svg>
                </div>
                <div className="ml-3">
                  <p className="text-sm font-medium text-green-800">{message}</p>
                  <p className="mt-2 text-sm text-green-700">
                    Redirecting to login page...
                  </p>
                </div>
              </div>
            </div>
          )}

          {status === 'error' && (
            <div className="rounded-md bg-red-50 p-4">
              <div className="flex">
                <div className="flex-shrink-0">
                  <svg className="h-5 w-5 text-red-400" viewBox="0 0 20 20" fill="currentColor">
                    <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM8.707 7.293a1 1 0 00-1.414 1.414L8.586 10l-1.293 1.293a1 1 0 101.414 1.414L10 11.414l1.293 1.293a1 1 0 001.414-1.414L11.414 10l1.293-1.293a1 1 0 00-1.414-1.414L10 8.586 8.707 7.293z" clipRule="evenodd" />
                  </svg>
                </div>
                <div className="ml-3">
                  <p className="text-sm font-medium text-red-800">{message}</p>
                  <div className="mt-2">
                    <Link href="/resend-verification" className="text-sm font-medium text-red-600 hover:text-red-500">
                      Resend verification email
                    </Link>
                  </div>
                </div>
              </div>
            </div>
          )}

          <div className="text-sm text-center">
            <Link href="/login" className="font-medium text-indigo-600 hover:text-indigo-500">
              Return to login
            </Link>
          </div>
        </div>
      </div>
    </div>
  );
} 
```


### FILE: frontend\src\services\api\client.ts
```
/**
 * API client with interceptors for debugging and error tracking.
 * Provides a standardized way to make API requests with automatic error handling.
 */

import { env, isDevelopment } from '@/config/environment';
import logger from '@/utils/logger';

// Request options type
export interface ApiRequestOptions extends RequestInit {
  params?: Record<string, string | number | boolean | undefined>;
  timeout?: number;
}

// Response type
export interface ApiResponse<T = any> {
  data: T;
  status: number;
  statusText: string;
  headers: Headers;
  error?: Error;
}

// Request tracking
interface PendingRequest {
  timestamp: number;
  url: string;
  method: string;
  abortController: AbortController;
}

// Global request tracking for debugging
const pendingRequests: PendingRequest[] = [];

/**
 * Creates a query string from params object
 */
function createQueryString(params?: Record<string, string | number | boolean | undefined>): string {
  if (!params) return '';
  
  const queryParams = new URLSearchParams();
  
  Object.entries(params).forEach(([key, value]) => {
    if (value !== undefined) {
      queryParams.append(key, String(value));
    }
  });
  
  const queryString = queryParams.toString();
  return queryString ? `?${queryString}` : '';
}

/**
 * Adds request ID header to requests
 */
function addRequestId(headers: Headers): Headers {
  // Generate a unique request ID if not already present
  if (!headers.has('X-Request-ID')) {
    headers.set('X-Request-ID', `frontend-${Date.now()}-${Math.random().toString(36).substring(2, 10)}`);
  }
  
  return headers;
}

/**
 * Formats the API URL based on the environment
 */
function formatUrl(path: string): string {
  // If the path is already a full URL, return it as is
  if (path.startsWith('http://') || path.startsWith('https://')) {
    return path;
  }
  
  // Remove leading slash if present
  const cleanPath = path.startsWith('/') ? path.substring(1) : path;
  
  // Combine API URL with path
  return `${env.NEXT_PUBLIC_API_URL}/${cleanPath}`;
}

/**
 * Fetch API with timeout and automatic error handling
 */
async function fetchWithTimeout(
  url: string, 
  options: ApiRequestOptions = {}
): Promise<Response> {
  const { timeout = env.NEXT_PUBLIC_API_TIMEOUT_MS, ...fetchOptions } = options;
  
  // Create abort controller for timeout
  const controller = new AbortController();
  const signal = controller.signal;
  
  // Set up timeout
  const timeoutId = setTimeout(() => {
    controller.abort();
  }, timeout);
  
  try {
    // Track request for debugging
    const pendingRequest: PendingRequest = {
      timestamp: Date.now(),
      url,
      method: options.method || 'GET',
      abortController: controller
    };
    
    pendingRequests.push(pendingRequest);
    
    // Make the request
    const response = await fetch(url, {
      ...fetchOptions,
      signal,
    });
    
    return response;
  } finally {
    // Clean up timeout and pending request
    clearTimeout(timeoutId);
    
    // Remove from pending requests
    const index = pendingRequests.findIndex(req => 
      req.url === url && req.abortController === controller
    );
    
    if (index !== -1) {
      pendingRequests.splice(index, 1);
    }
  }
}

/**
 * Make an API request with standardized error handling and logging
 */
export async function apiRequest<T = any>(
  path: string,
  options: ApiRequestOptions = {}
): Promise<ApiResponse<T>> {
  const startTime = performance.now();
  
  // Create a headers object to extract request ID if present
  const headersObj = new Headers(options.headers || {});
  const requestId = headersObj.get('X-Request-ID') || `req-${Date.now()}`;
  
  // Prepare request
  const { params, ...fetchOptions } = options;
  
  // Create URL with query parameters
  const queryString = createQueryString(params);
  const url = `${formatUrl(path)}${queryString}`;
  
  // Prepare headers with request ID
  const headers = new Headers(options.headers || {});
  addRequestId(headers);
  
  // Log request in development
  if (isDevelopment) {
    logger.debug(`API Request [${requestId}]: ${options.method || 'GET'} ${url}`);
    if (options.body) {
      try {
        let bodyContent = options.body;
        if (typeof bodyContent === 'string') {
          bodyContent = JSON.parse(bodyContent);
        }
        logger.debug(`Request body [${requestId}]:`, bodyContent);
      } catch (e) {
        // Ignore parsing errors for non-JSON bodies
      }
    }
  }
  
  try {
    // Make the request
    const response = await fetchWithTimeout(url, {
      ...fetchOptions,
      headers,
    });
    
    // Parse response data (handle different content types)
    let data: T;
    const contentType = response.headers.get('content-type');
    
    if (contentType?.includes('application/json')) {
      data = await response.json();
    } else if (contentType?.includes('text/')) {
      data = await response.text() as unknown as T;
    } else {
      // Handle binary data or other formats
      data = await response.blob() as unknown as T;
    }
    
    // Calculate request time
    const endTime = performance.now();
    const requestTime = endTime - startTime;
    
    // Log response in development
    if (isDevelopment) {
      logger.debug(
        `API Response [${requestId}]: ${response.status} ${response.statusText} (${requestTime.toFixed(2)}ms)`
      );
      logger.debug(`Response data [${requestId}]:`, data);
    }
    
    // Check if response is an error
    if (!response.ok) {
      // Format error for consistent handling
      const error = new Error(
        `API Error ${response.status}: ${response.statusText}`
      );
      
      // Add response data to error object for more details
      Object.assign(error, { response, data });
      
      // Log error
      logger.error(`API Error [${requestId}]: ${response.status} ${url}`, error);
      
      return {
        data,
        status: response.status,
        statusText: response.statusText,
        headers: response.headers,
        error,
      };
    }
    
    // Return successful response
    return {
      data,
      status: response.status,
      statusText: response.statusText,
      headers: response.headers,
    };
  } catch (error) {
    // Handle fetch errors (network, timeout, etc.)
    const apiError = error instanceof Error ? error : new Error(String(error));
    
    // Log error
    logger.error(`API Request Failed [${requestId}]: ${url}`, apiError);
    
    // Return error response
    return {
      data: null as unknown as T,
      status: apiError.name === 'AbortError' ? 408 : 0,
      statusText: apiError.name === 'AbortError' ? 'Request Timeout' : 'Network Error',
      headers: new Headers(),
      error: apiError,
    };
  }
}

/**
 * Helper for GET requests
 */
export function get<T = any>(
  path: string, 
  options: Omit<ApiRequestOptions, 'method' | 'body'> = {}
): Promise<ApiResponse<T>> {
  return apiRequest<T>(path, { ...options, method: 'GET' });
}

/**
 * Helper for POST requests
 */
export function post<T = any>(
  path: string, 
  data?: any, 
  options: Omit<ApiRequestOptions, 'method' | 'body'> = {}
): Promise<ApiResponse<T>> {
  const headers = new Headers(options.headers || {});
  if (data && !(data instanceof FormData)) {
    headers.set('Content-Type', 'application/json');
  }
  
  return apiRequest<T>(path, {
    ...options,
    method: 'POST',
    headers,
    body: data instanceof FormData ? data : data ? JSON.stringify(data) : undefined,
  });
}

/**
 * Helper for PUT requests
 */
export function put<T = any>(
  path: string, 
  data?: any, 
  options: Omit<ApiRequestOptions, 'method' | 'body'> = {}
): Promise<ApiResponse<T>> {
  const headers = new Headers(options.headers || {});
  if (data && !(data instanceof FormData)) {
    headers.set('Content-Type', 'application/json');
  }
  
  return apiRequest<T>(path, {
    ...options,
    method: 'PUT',
    headers,
    body: data instanceof FormData ? data : data ? JSON.stringify(data) : undefined,
  });
}

/**
 * Helper for DELETE requests
 */
export function del<T = any>(
  path: string, 
  options: Omit<ApiRequestOptions, 'method'> = {}
): Promise<ApiResponse<T>> {
  return apiRequest<T>(path, { ...options, method: 'DELETE' });
}

/**
 * Helper for PATCH requests
 */
export function patch<T = any>(
  path: string, 
  data?: any, 
  options: Omit<ApiRequestOptions, 'method' | 'body'> = {}
): Promise<ApiResponse<T>> {
  const headers = new Headers(options.headers || {});
  if (data && !(data instanceof FormData)) {
    headers.set('Content-Type', 'application/json');
  }
  
  return apiRequest<T>(path, {
    ...options,
    method: 'PATCH',
    headers,
    body: data instanceof FormData ? data : data ? JSON.stringify(data) : undefined,
  });
}

/**
 * Debug utility to get all pending requests
 */
export function getPendingRequests(): PendingRequest[] {
  return [...pendingRequests];
}

/**
 * Debug utility to abort all pending requests
 */
export function abortAllRequests(): void {
  pendingRequests.forEach(request => {
    request.abortController.abort();
  });
}

/**
 * Export API client with all methods
 */
export const apiClient = {
  request: apiRequest,
  get,
  post,
  put,
  delete: del,
  patch,
  getPendingRequests,
  abortAllRequests,
};

export default apiClient; 
```


### FILE: frontend\src\styles\globals.css
```
@tailwind base;
@tailwind components;
@tailwind utilities; 
```


### FILE: frontend\src\types\custom.d.ts
```
declare namespace NodeJS {
  interface ProcessEnv {
    NEXT_PUBLIC_AUTH_API_URL: string;
    NEXT_PUBLIC_GOOGLE_CLIENT_ID: string;
  }
}

declare module '@react-oauth/google' {
  export interface GoogleLoginResponse {
    credential: string;
  }

  export interface GoogleLoginProps {
    onSuccess: (response: GoogleLoginResponse) => void;
    onError: () => void;
  }

  export const GoogleLogin: React.FC<GoogleLoginProps>;
  export const GoogleOAuthProvider: React.FC<{
    clientId: string;
    children: React.ReactNode;
  }>;
} 
```


### FILE: frontend\src\types\events.ts
```
import { ChangeEvent, FormEvent } from 'react';

export type FormInputEvent = ChangeEvent<HTMLInputElement>;
export type FormSubmitEvent = FormEvent<HTMLFormElement>; 
```


### FILE: frontend\src\types\globals.d.ts
```
/**
 * Global declarations for the application.
 * This file provides type definitions for globals that may not be properly recognized.
 */

// Declare process.env for TypeScript
declare namespace NodeJS {
  interface ProcessEnv {
    NODE_ENV: 'development' | 'production' | 'test';
    NEXT_PUBLIC_API_URL: string;
    NEXT_PUBLIC_AUTH_URL: string;
    NEXT_PUBLIC_WS_URL: string;
    NEXT_PUBLIC_APP_NAME: string;
    NEXT_PUBLIC_APP_VERSION: string;
    NEXT_PUBLIC_ENABLE_ANALYTICS?: string;
    NEXT_PUBLIC_ENABLE_DEBUG_TOOLS?: string;
    NEXT_PUBLIC_API_TIMEOUT_MS?: string;
    NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS?: string;
    NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB?: string;
  }
}

// Make sure TypeScript knows process exists globally
declare const process: NodeJS.Process; 
```


### FILE: frontend\src\types\jsx.d.ts
```
import React from 'react';

declare global {
  namespace JSX {
    interface IntrinsicElements {
      [elemName: string]: any;
    }
  }
} 
```


### FILE: frontend\src\types\user.ts
```
export interface User {
  id: number;
  email: string;
  name: string;
  created_at: string;
  updated_at: string;
} 
```


### FILE: frontend\src\utils\logger.ts
```
/**
 * Logger utility for consistent logging across the application.
 * Provides different log levels and structured log format.
 */

import { env, isDevelopment } from '@/config/environment';

// Log levels
export enum LogLevel {
  TRACE = 0,
  DEBUG = 1,
  INFO = 2,
  WARN = 3,
  ERROR = 4,
  NONE = 5,
}

// Logger configuration
interface LoggerConfig {
  level: LogLevel;
  enableConsole: boolean;
  prefix?: string;
  includeTimestamp: boolean;
}

// Default configuration
const defaultConfig: LoggerConfig = {
  level: isDevelopment ? LogLevel.DEBUG : LogLevel.INFO,
  enableConsole: true,
  includeTimestamp: true,
};

// Current logger configuration
let currentConfig: LoggerConfig = { ...defaultConfig };

/**
 * Set logger configuration
 */
export function configureLogger(config: Partial<LoggerConfig>): void {
  currentConfig = { ...currentConfig, ...config };
}

/**
 * Format log message with timestamp and prefix
 */
function formatLogMessage(message: string, level: string): string {
  const parts: string[] = [];
  
  // Add timestamp
  if (currentConfig.includeTimestamp) {
    parts.push(`[${new Date().toISOString()}]`);
  }
  
  // Add log level
  parts.push(`[${level}]`);
  
  // Add prefix if available
  if (currentConfig.prefix) {
    parts.push(`[${currentConfig.prefix}]`);
  }
  
  // Add message
  parts.push(message);
  
  return parts.join(' ');
}

/**
 * Create console method with structured format
 */
function createLogMethod(
  level: LogLevel,
  methodName: 'log' | 'info' | 'debug' | 'warn' | 'error',
  levelName: string
) {
  return function(...args: any[]): void {
    // Skip if log level is too low
    if (level < currentConfig.level) {
      return;
    }
    
    // Skip if console logging is disabled
    if (!currentConfig.enableConsole) {
      return;
    }
    
    // Get message
    const message = args.map(arg => {
      if (typeof arg === 'object') {
        try {
          return JSON.stringify(arg);
        } catch (e) {
          return String(arg);
        }
      }
      return String(arg);
    }).join(' ');
    
    // Format message
    const formattedMessage = formatLogMessage(message, levelName);
    
    // Log to console
    console[methodName](formattedMessage);
    
    // Send to remote logging service if in production
    if (!isDevelopment && level >= LogLevel.ERROR) {
      // Here you would integrate with a service like Sentry
      // if (typeof window !== 'undefined' && window.Sentry) {
      //   window.Sentry.captureMessage(message, levelName.toLowerCase());
      // }
    }
  };
}

/**
 * Create debug context with custom prefix
 */
export function createLogger(prefix: string): Logger {
  return {
    trace: (...args: any[]) => {
      const prevPrefix = currentConfig.prefix;
      currentConfig.prefix = prefix;
      trace(...args);
      currentConfig.prefix = prevPrefix;
    },
    debug: (...args: any[]) => {
      const prevPrefix = currentConfig.prefix;
      currentConfig.prefix = prefix;
      debug(...args);
      currentConfig.prefix = prevPrefix;
    },
    info: (...args: any[]) => {
      const prevPrefix = currentConfig.prefix;
      currentConfig.prefix = prefix;
      info(...args);
      currentConfig.prefix = prevPrefix;
    },
    warn: (...args: any[]) => {
      const prevPrefix = currentConfig.prefix;
      currentConfig.prefix = prefix;
      warn(...args);
      currentConfig.prefix = prevPrefix;
    },
    error: (...args: any[]) => {
      const prevPrefix = currentConfig.prefix;
      currentConfig.prefix = prefix;
      error(...args);
      currentConfig.prefix = prevPrefix;
    },
  };
}

// Logger interface
export interface Logger {
  trace: (...args: any[]) => void;
  debug: (...args: any[]) => void;
  info: (...args: any[]) => void;
  warn: (...args: any[]) => void;
  error: (...args: any[]) => void;
}

// Create log methods
export const trace = createLogMethod(LogLevel.TRACE, 'debug', 'TRACE');
export const debug = createLogMethod(LogLevel.DEBUG, 'debug', 'DEBUG');
export const info = createLogMethod(LogLevel.INFO, 'info', 'INFO');
export const warn = createLogMethod(LogLevel.WARN, 'warn', 'WARN');
export const error = createLogMethod(LogLevel.ERROR, 'error', 'ERROR');

// Default logger
const logger: Logger = {
  trace,
  debug,
  info,
  warn,
  error,
};

// Initialize logger
if (typeof window !== 'undefined') {
  // Set log level from URL params for debugging
  const params = new URLSearchParams(window.location.search);
  const logLevel = params.get('log_level');
  if (logLevel) {
    const level = parseInt(logLevel, 10);
    if (!isNaN(level) && level >= 0 && level <= 5) {
      configureLogger({ level: level as LogLevel });
      debug(`Log level set to ${LogLevel[level]}`);
    }
  }
  
  // Log app initialization
  info(
    `App initialized: ${env.NEXT_PUBLIC_APP_NAME} ${env.NEXT_PUBLIC_APP_VERSION} - ${window.location.href}`
  );
}

export default logger; 
```


### FILE: frontend\src\utils\runtimeConfig.ts
```
/**
 * Runtime configuration for client-side environment variables.
 * This approach ensures environment variables are available in the browser.
 */

export interface RuntimeConfig {
  // API URLs
  NEXT_PUBLIC_API_URL: string;
  NEXT_PUBLIC_AUTH_URL: string;
  NEXT_PUBLIC_WS_URL: string;
  NEXT_PUBLIC_BASE_URL: string;
  
  // App information
  NEXT_PUBLIC_APP_NAME: string;
  NEXT_PUBLIC_APP_VERSION: string;
  
  // Feature flags
  NEXT_PUBLIC_ENABLE_ANALYTICS: boolean;
  NEXT_PUBLIC_ENABLE_DEBUG_TOOLS: boolean;
  
  // Timeouts and limits
  NEXT_PUBLIC_API_TIMEOUT_MS: number;
  NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS: number;
  NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB: number;
  
  // OAuth
  NEXT_PUBLIC_GOOGLE_CLIENT_ID: string;
  
  // Allow indexing with string
  [key: string]: string | number | boolean;
}

const runtimeConfig: RuntimeConfig = {
  // API URLs
  NEXT_PUBLIC_API_URL: 'http://localhost:5000',
  NEXT_PUBLIC_AUTH_URL: 'http://localhost:5001',
  NEXT_PUBLIC_WS_URL: 'ws://localhost:3001',
  NEXT_PUBLIC_BASE_URL: 'http://localhost:3000',
  
  // App information
  NEXT_PUBLIC_APP_NAME: 'Meeting App',
  NEXT_PUBLIC_APP_VERSION: '1.0.0',
  
  // Feature flags
  NEXT_PUBLIC_ENABLE_ANALYTICS: false,
  NEXT_PUBLIC_ENABLE_DEBUG_TOOLS: false,
  
  // Timeouts and limits
  NEXT_PUBLIC_API_TIMEOUT_MS: 30000,
  NEXT_PUBLIC_WS_RECONNECT_INTERVAL_MS: 5000,
  NEXT_PUBLIC_MAX_UPLOAD_SIZE_MB: 5,
  
  // OAuth
  NEXT_PUBLIC_GOOGLE_CLIENT_ID: '1004556025731-dgnou2c5vdui47ffbfievlil9ncqsrue.apps.googleusercontent.com',
};

// Allow overriding config from server-provided environment variables if available
if (typeof window !== 'undefined') {
  // Only runs in browser
  try {
    // Check if window.__NEXT_DATA__.props.pageProps.runtimeConfig exists
    const serverRuntimeConfig = (window as any).__NEXT_DATA__?.props?.pageProps?.runtimeConfig;
    if (serverRuntimeConfig) {
      Object.assign(runtimeConfig, serverRuntimeConfig);
    }
  } catch (e) {
    console.warn('Failed to load server runtime config:', e);
  }
}

export default runtimeConfig; 
```


### FILE: meeting_shared\README.md
```
# Meeting Shared Package

A shared package for common functionality used across microservices in the Meeting App.

## Overview

This package contains shared utilities, middleware, models, and other components that are used by multiple microservices in the Meeting App. By centralizing these components, we ensure consistency across services and reduce code duplication.

## Installation

To install this package in development mode:

```bash
pip install -e /path/to/meeting_shared
```

Or add the following to your requirements.txt:

```
-e ../relative/path/to/meeting_shared
```

## Components

- **shared_logging**: Structured JSON logging with request ID tracking
- **middleware**: Flask middleware components (request ID, auth, etc.)
- **discovery**: Service discovery utilities
- **models**: Shared data models
- **schemas**: Shared API schemas
- **secrets**: Secret management utilities
- **utils**: General utility functions

## Usage

Import components from the package:

```python
from meeting_shared.shared_logging import setup_logging
from meeting_shared.middleware import register_middleware
```

## Features

### Service Discovery

The package includes a flexible service discovery system that supports multiple providers:

- **Static Discovery**: Uses environment variables or static configuration
- **Kubernetes Discovery**: Discovers services in a Kubernetes cluster

Service discovery includes health checks to detect unhealthy services:

```python
from meeting_shared.discovery import get_service_url

# Get URL for a service
auth_url = get_service_url('auth-service')

# Service details including health status
auth_service = get_service('auth-service')
if auth_service['status'] == 'healthy':
    # Service is healthy
```

### JWT Authentication

The package provides JWT authentication middleware with support for secret key rotation:

```python
from meeting_shared.middleware.auth import jwt_required

@app.route('/protected')
@jwt_required
def protected_route():
    return "This route is protected"
```

For Kubernetes deployments, use the included secret rotation script:

```bash
./k8s/scripts/manage-secrets.sh rotate -s jwt-secret
```

### Structured Logging

The package includes structured JSON logging with request ID tracking and correlation IDs:

```python
from meeting_shared.shared_logging import setup_logging

# Initialize logging
logger = setup_logging(app, service_name="my-service")

# Log with structured data
logger.info("User logged in", extra={"user_id": user.id})
```

### Log Sampling

For high-volume endpoints, the package includes log sampling to reduce log volume:

```python
from meeting_shared.shared_logging import setup_logging
from meeting_shared.shared_logging.sampling import SamplingConfig

# Configure sampling rates
sampling_config = SamplingConfig(
    default_rate=1.0,  # Log everything by default
    path_rates={
        r'^/api/health': 0.1,  # Log only 10% of health check requests
        r'^/api/metrics': 0.05  # Log only 5% of metrics requests
    },
    method_rates={
        'GET': 0.5  # Log 50% of GET requests
    },
    level_rates={
        'DEBUG': 0.1  # Log only 10% of DEBUG messages
    }
)

# Initialize logging with sampling
logger = setup_logging(
    app, 
    service_name="my-service",
    enable_sampling=True,
    sampling_config=sampling_config
)
```

## Development

When making changes to this shared package, remember to update all services that depend on it. 
```


### FILE: meeting_shared\__init__.py
```
"""
Meeting Shared Package
=====================

A shared package for common functionality used across microservices in the Meeting App.
This includes utilities for logging, configuration, database access, and more.
"""

__version__ = '0.1.0' 
```


### FILE: meeting_shared\config.py
```
"""
Standardized configuration module for backend services.
Provides consistent configuration across different services.
"""

import os
from pathlib import Path

class BaseConfig:
    """Base configuration settings shared across all environments"""
    # Environment settings
    DEBUG = False
    TESTING = False
    ENV = 'production'
    
    # Application settings
    API_PREFIX = "/api"
    
    # Security settings
    SECRET_KEY = os.environ.get("SECRET_KEY")
    JWT_SECRET_KEY = os.environ.get("JWT_SECRET_KEY")
    SERVICE_KEY = os.environ.get("SERVICE_KEY")
    JWT_ALGORITHM = "HS256"
    JWT_ACCESS_TOKEN_EXPIRES = 60 * 60  # 1 hour
    JWT_REFRESH_TOKEN_EXPIRES = 30 * 24 * 60 * 60  # 30 days
    BCRYPT_LOG_ROUNDS = 13
    
    # Database settings
    SQLALCHEMY_TRACK_MODIFICATIONS = False
    
    # Redis settings
    REDIS_URL = os.environ.get("REDIS_URL", "redis://localhost:6379/0")
    REDIS_TOKEN_BLACKLIST_DB = 1
    
    # CORS settings
    CORS_ORIGINS = os.environ.get("CORS_ORIGINS", "http://localhost:3000").split(",")
    CORS_METHODS = ["GET", "POST", "PUT", "DELETE", "OPTIONS"]
    CORS_HEADERS = ["Content-Type", "Authorization", "X-Service-Key", "X-Request-ID", "X-Correlation-ID"]
    
    # Logging settings
    LOG_LEVEL = "INFO"
    JSON_LOGS = os.environ.get("JSON_LOGS", "true").lower() == "true"
    LOG_TO_FILE = os.environ.get("LOG_TO_FILE", "false").lower() == "true"
    LOG_FILE = os.environ.get("LOG_FILE", "logs/app.log")
    
    # Service discovery settings
    SERVICE_DISCOVERY_PROVIDER = os.environ.get("SERVICE_DISCOVERY_PROVIDER", "env")
    
    # Secret management settings
    SECRET_MANAGER_TYPE = os.environ.get("SECRET_MANAGER_TYPE", "env")
    
    # File paths
    ROOT_DIR = Path("/app")
    LOG_DIR = ROOT_DIR / "logs"
    
    # Ensure directories exist
    LOG_DIR.mkdir(parents=True, exist_ok=True)
    
    # Service URLs
    AUTH_SERVICE_URL = os.environ.get("AUTH_SERVICE_URL", "http://auth-service:5001")
    BACKEND_SERVICE_URL = os.environ.get("BACKEND_SERVICE_URL", "http://backend:5000")
    WEBSOCKET_SERVICE_URL = os.environ.get("WEBSOCKET_SERVICE_URL", "http://websocket:3001")
    FRONTEND_URL = os.environ.get("FRONTEND_URL", "http://localhost:3000")


class DevelopmentConfig(BaseConfig):
    """Development environment specific configuration"""
    DEBUG = True
    ENV = 'development'
    LOG_LEVEL = "DEBUG"
    
    # More lenient security settings for development
    BCRYPT_LOG_ROUNDS = 4
    JWT_ACCESS_TOKEN_EXPIRES = 24 * 60 * 60  # 24 hours in development
    
    # Enable detailed error messages and SQL query logging
    SQLALCHEMY_ECHO = True
    
    # Development-specific settings
    PRESERVE_CONTEXT_ON_EXCEPTION = False
    
    # Extended CORS settings for development
    CORS_ORIGINS = os.environ.get("CORS_ORIGINS", 
                                "http://localhost:3000,http://127.0.0.1:3000").split(",")


class TestingConfig(BaseConfig):
    """Testing environment specific configuration"""
    TESTING = True
    DEBUG = True
    ENV = 'testing'
    
    # Use in-memory database for testing
    SQLALCHEMY_DATABASE_URI = "sqlite:///:memory:"
    
    # Disable CSRF protection for testing
    WTF_CSRF_ENABLED = False
    
    # Faster password hashing for tests
    BCRYPT_LOG_ROUNDS = 4
    
    # Shorter token expiration for testing
    JWT_ACCESS_TOKEN_EXPIRES = 300  # 5 minutes
    JWT_REFRESH_TOKEN_EXPIRES = 600  # 10 minutes
    
    # Mock external services
    REDIS_URL = "redis://localhost:6379/2"
    
    # Disable email sending in tests
    MAIL_SUPPRESS_SEND = True


class ProductionConfig(BaseConfig):
    """Production environment specific configuration"""
    LOG_LEVEL = "INFO"
    
    # Production security settings
    WTF_CSRF_SSL_STRICT = True
    PREFERRED_URL_SCHEME = 'https'
    
    # Set stricter CORS
    CORS_ORIGINS = os.environ.get("CORS_ORIGINS", "https://yourdomain.com").split(",")
    
    # Production database settings
    SQLALCHEMY_ENGINE_OPTIONS = {
        'pool_size': 10,
        'pool_recycle': 300,
        'pool_pre_ping': True,
        'max_overflow': 15
    }
    
    # Enhanced logging for production
    LOG_TO_FILE = True


class AuthServiceConfig(BaseConfig):
    """Auth service specific configuration"""
    APP_NAME = "Auth Service"
    SQLALCHEMY_DATABASE_URI = os.environ.get("AUTH_DATABASE_URL")
    OAUTH_PROVIDERS = {
        'google': {
            'client_id': os.environ.get("GOOGLE_CLIENT_ID"),
            'client_secret': os.environ.get("GOOGLE_CLIENT_SECRET")
        }
    }


class FlaskServiceConfig(BaseConfig):
    """Flask service specific configuration"""
    APP_NAME = "Meeting API Service"
    SQLALCHEMY_DATABASE_URI = os.environ.get("DATABASE_URL")


class WebsocketServiceConfig(BaseConfig):
    """Websocket service specific configuration"""
    APP_NAME = "Websocket Service"
    WEBSOCKET_PORT = int(os.environ.get("WEBSOCKET_PORT", 3001))


# Config dictionary mapping
config = {
    'development': DevelopmentConfig,
    'testing': TestingConfig,
    'production': ProductionConfig,
    'default': DevelopmentConfig,
    'auth': AuthServiceConfig,
    'flask': FlaskServiceConfig,
    'websocket': WebsocketServiceConfig,
}


def get_config(env_name=None):
    """
    Get configuration based on environment name.
    
    Args:
        env_name: Environment name ('development', 'testing', 'production')
        
    Returns:
        Configuration class
    """
    if not env_name:
        env_name = os.environ.get('FLASK_ENV', 'development')
    
    # Combine service-specific config with env-specific config
    service_type = os.environ.get('SERVICE_TYPE', 'default')
    base_config = config.get(env_name, config['default'])
    service_config = config.get(service_type, config['default'])
    
    # If both configs are the same, just return that config
    if service_config == base_config:
        return service_config
    
    # Create a new config class that inherits from both
    class CombinedConfig(service_config, base_config):
        pass
    
    return CombinedConfig 
```


### FILE: meeting_shared\database.py
```
from contextlib import contextmanager
from sqlalchemy.exc import SQLAlchemyError
from flask_sqlalchemy import SQLAlchemy

db = SQLAlchemy()

@contextmanager
def transaction():
    """
    Context manager for database transactions.
    Automatically handles commit/rollback based on exceptions.
    
    Usage:
        with transaction():
            db.session.add(some_model)
            db.session.add(another_model)
    """
    try:
        yield
        db.session.commit()
    except SQLAlchemyError as e:
        db.session.rollback()
        raise e
    except Exception as e:
        db.session.rollback()
        raise e

# Alias for backward compatibility
transaction_context = transaction

def init_db(app):
    """Initialize the database with the app"""
    db.init_app(app)
    
    with app.app_context():
        db.create_all() 
```


### FILE: meeting_shared\errors.py
```
"""
Standardized error handling for backend services.
Provides common error classes and utilities for consistent error responses.
"""

import logging
import traceback
from datetime import datetime
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)

# Try to import request ID functionality
try:
    from meeting_shared.middleware.request_id import get_request_id
    HAS_REQUEST_ID = True
except ImportError:
    HAS_REQUEST_ID = False

class APIError(Exception):
    """Base exception class for API errors with status code and message"""
    
    def __init__(self, message: str, status_code: int = 400, details: Optional[Dict[str, Any]] = None):
        """
        Initialize API error.
        
        Args:
            message: Error message
            status_code: HTTP status code
            details: Additional error details
        """
        self.message = message
        self.status_code = status_code
        self.details = details or {}
        self.timestamp = datetime.utcnow().isoformat() + 'Z'
        
        # Add request ID if available
        if HAS_REQUEST_ID:
            self.request_id = get_request_id()
        else:
            self.request_id = None
    
    def to_dict(self) -> Dict[str, Any]:
        """
        Convert exception to dictionary representation.
        
        Returns:
            Dictionary with error details
        """
        error_dict = {
            'error': True,
            'status_code': self.status_code,
            'message': self.message,
            'timestamp': self.timestamp
        }
        
        # Include request ID if available
        if hasattr(self, 'request_id') and self.request_id:
            error_dict['request_id'] = self.request_id
        
        # Include additional details if provided
        if self.details:
            error_dict['details'] = self.details
        
        return error_dict

# --- User and Authentication Errors ---

class ValidationError(APIError):
    """Exception for data validation errors"""
    
    def __init__(self, message: str = "Validation error", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=422, details=details)

class AuthenticationError(APIError):
    """Exception for authentication failures"""
    
    def __init__(self, message: str = "Authentication required", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=401, details=details)

class AuthorizationError(APIError):
    """Exception for authorization failures"""
    
    def __init__(self, message: str = "Not authorized", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=403, details=details)

class UserExistsError(APIError):
    """Exception for duplicate user registration"""
    
    def __init__(self, message: str = "User already exists", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=409, details=details)

class UserNotFoundError(APIError):
    """Exception for user not found"""
    
    def __init__(self, message: str = "User not found", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=404, details=details)

class TokenError(APIError):
    """Exception for token validation failures"""
    
    def __init__(self, message: str = "Invalid or expired token", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=401, details=details)

# --- Resource Errors ---

class ResourceNotFoundError(APIError):
    """Exception for resource not found"""
    
    def __init__(self, message: str = "Resource not found", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=404, details=details)

class ResourceExistsError(APIError):
    """Exception for duplicate resource"""
    
    def __init__(self, message: str = "Resource already exists", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=409, details=details)

# --- Service Errors ---

class ServiceError(APIError):
    """Exception for service failures"""
    
    def __init__(self, message: str = "Service error", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=500, details=details)

class ConfigurationError(APIError):
    """Exception for configuration errors"""
    
    def __init__(self, message: str = "Configuration error", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=500, details=details)

class DependencyError(APIError):
    """Exception for dependency failures"""
    
    def __init__(self, message: str = "Dependency error", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=503, details=details)

class RateLimitError(APIError):
    """Exception for rate limiting"""
    
    def __init__(self, message: str = "Rate limit exceeded", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=429, details=details)

class EmailError(APIError):
    """Exception for email sending failures"""
    
    def __init__(self, message: str = "Failed to send email", details: Optional[Dict[str, Any]] = None):
        super().__init__(message, status_code=500, details=details)

# Export all error classes
__all__ = [
    'APIError',
    'ValidationError',
    'AuthenticationError',
    'AuthorizationError',
    'UserExistsError',
    'UserNotFoundError',
    'TokenError',
    'ResourceNotFoundError',
    'ResourceExistsError',
    'ServiceError',
    'ConfigurationError',
    'DependencyError',
    'RateLimitError',
    'EmailError',
] 
```


### FILE: meeting_shared\setup.py
```
"""
Setup script for the meeting_shared package.
"""

from setuptools import setup, find_packages

setup(
    name="meeting_shared",
    version="0.1.0",
    description="Shared utilities for Meeting App microservices",
    author="Meeting App Team",
    packages=find_packages(),
    install_requires=[
        "flask>=2.0.0",
        "sqlalchemy>=1.4.0",
        "requests>=2.25.0",
        "pydantic>=2.0.0",
        "redis>=4.0.0",
        "PyJWT>=2.0.0",
        "hvac>=1.0.0",  # For Vault integration
        "kubernetes>=20.0.0",  # For Kubernetes integration
        "PyYAML>=6.0.0",  # For YAML config support
    ],
    extras_require={
        'dev': [
            'pytest>=7.0.0',
            'pytest-cov>=4.0.0',
            'black>=22.0.0',
            'isort>=5.0.0',
            'flake8>=4.0.0',
        ]
    },
    python_requires='>=3.9',
    classifiers=[
        "Development Status :: 3 - Alpha",
        "Intended Audience :: Developers",
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.9",
    ],
) 
```


### FILE: meeting_shared\discovery\__init__.py
```
"""
Service discovery module for backend services.
Provides abstractions for discovering and registering services.
"""

import os
import logging
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)

# Import discovery providers
try:
    from .static import StaticServiceDiscovery
    HAS_STATIC = True
except ImportError:
    HAS_STATIC = False

try:
    from .kubernetes import KubernetesServiceDiscovery
    HAS_K8S = True
except ImportError:
    HAS_K8S = False

# Global discovery provider instance
_discovery_provider = None

def get_discovery_provider(provider_type=None):
    """
    Get a service discovery provider instance.
    
    Args:
        provider_type: The type of provider to use.
            Options: 'static', 'kubernetes'
            If None, will try to determine from environment variables.
            
    Returns:
        A service discovery provider instance.
    """
    # Try to determine the provider type from environment variables
    if provider_type is None:
        provider_type = os.environ.get('SERVICE_DISCOVERY_PROVIDER', 'env').lower()
    
    if provider_type == 'static' and HAS_STATIC:
        return StaticServiceDiscovery()
    elif provider_type == 'kubernetes' and HAS_K8S:
        return KubernetesServiceDiscovery()
    else:
        logger.warning(f"Unsupported or unavailable service discovery provider: {provider_type}")
        return None

def get_service_url(service_name, default=None):
    """
    Get the URL for a service by name.
    
    Args:
        service_name: The service name to look up
        default: Default URL if service not found
        
    Returns:
        Service URL or default if not found
    """
    global _discovery_provider
    
    if _discovery_provider is None:
        _discovery_provider = get_discovery_provider()
        
    if _discovery_provider is None:
        # Fallback to environment variables
        env_var = f"{service_name.upper()}_URL"
        return os.environ.get(env_var, default)
        
    service = _discovery_provider.get_service(service_name)
    if service:
        return service.get('url', default)
    return default

def get_service(service_name, default=None):
    """
    Get detailed information for a service by name.
    
    Args:
        service_name: The service name to look up
        default: Default value if service not found
        
    Returns:
        Dictionary with service details, or default if not found
    """
    global _discovery_provider
    
    if _discovery_provider is None:
        _discovery_provider = get_discovery_provider()
        
    return _discovery_provider.get_service(service_name, default)

def get_services():
    """
    Get all available services.
    
    Returns:
        Dictionary of service name to service details
    """
    global _discovery_provider
    
    if _discovery_provider is None:
        _discovery_provider = get_discovery_provider()
        
    return _discovery_provider.get_services()

def register_service(name: str, url: str, metadata: Optional[Dict[str, Any]] = None):
    """
    Register a service with the discovery provider.
    
    Args:
        name: Service name
        url: Service URL
        metadata: Optional service metadata
    """
    global _discovery_provider
    
    if _discovery_provider is None:
        _discovery_provider = get_discovery_provider()
        
    if _discovery_provider:
        _discovery_provider.register_service(name, url, metadata)
    else:
        logger.warning(f"No service discovery provider available, cannot register service: {name}")

def set_discovery_provider(provider):
    """
    Explicitly set the service discovery provider to use.
    
    Args:
        provider: An instance of a ServiceDiscovery class
    """
    global _discovery_provider
    _discovery_provider = provider
    logger.info(f"Service discovery provider explicitly set to {provider.__class__.__name__}")

# Export public interface
__all__ = [
    'get_service_url',
    'get_service',
    'get_services',
    'register_service',
    'set_discovery_provider',
    'get_discovery_provider'
] 
```


### FILE: meeting_shared\discovery\kubernetes.py
```
"""
Kubernetes service discovery provider.
Uses the Kubernetes API for service discovery.
"""

import os
import logging
import requests
from typing import Dict, Any, Optional, List
import time
import json

logger = logging.getLogger(__name__)

class KubernetesServiceDiscovery:
    """
    Kubernetes service discovery provider.
    Uses the Kubernetes API for service discovery.
    """
    
    def __init__(self):
        """Initialize Kubernetes service discovery."""
        self.services = {}
        self.namespace = os.environ.get('KUBERNETES_NAMESPACE', 'default')
        self.health_check_interval = int(os.environ.get('SERVICE_HEALTH_CHECK_INTERVAL', '60'))
        self.health_check_timeout = int(os.environ.get('SERVICE_HEALTH_CHECK_TIMEOUT', '5'))
        self.last_health_check = {}
        
        # Kubernetes API details
        self.api_host = os.environ.get('KUBERNETES_SERVICE_HOST')
        self.api_port = os.environ.get('KUBERNETES_SERVICE_PORT')
        self.token_path = '/var/run/secrets/kubernetes.io/serviceaccount/token'
        self.ca_cert_path = '/var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
        
        # Check if we're running in Kubernetes
        if not self.api_host or not self.api_port:
            logger.warning("Not running in Kubernetes, or Kubernetes API environment variables not set")
            return
        
        # Load services from Kubernetes API
        self._load_services_from_kubernetes()
        
        logger.info(f"Initialized Kubernetes service discovery with {len(self.services)} services")
    
    def _load_services_from_kubernetes(self):
        """Load services from Kubernetes API."""
        try:
            # Read the service account token
            with open(self.token_path, 'r') as f:
                token = f.read().strip()
            
            # Build the API URL
            api_url = f"https://{self.api_host}:{self.api_port}/api/v1/namespaces/{self.namespace}/services"
            
            # Make the API request
            headers = {'Authorization': f'Bearer {token}'}
            response = requests.get(
                api_url,
                headers=headers,
                verify=self.ca_cert_path,
                timeout=10
            )
            
            if response.status_code != 200:
                logger.error(f"Failed to get services from Kubernetes API: {response.status_code} {response.text}")
                return
            
            # Parse the response
            services_data = response.json()
            
            # Register each service
            for item in services_data.get('items', []):
                service_name = item.get('metadata', {}).get('name')
                if not service_name:
                    continue
                
                # Get service ports
                ports = item.get('spec', {}).get('ports', [])
                if not ports:
                    continue
                
                # Use the first port for the service URL
                port = ports[0].get('port')
                
                # Build the service URL
                service_url = f"http://{service_name}.{self.namespace}.svc.cluster.local:{port}"
                
                # Register the service
                self.register_service(service_name, service_url)
                
        except Exception as e:
            logger.error(f"Error loading services from Kubernetes: {str(e)}")
    
    def get_service(self, service_name: str, default: Any = None) -> Optional[Dict[str, Any]]:
        """
        Get service details by name.
        
        Args:
            service_name: The service name to look up
            default: Default value if service not found
            
        Returns:
            Service details or default if not found
        """
        service = self.services.get(service_name)
        if not service:
            return default
        
        # Check if we need to perform a health check
        current_time = time.time()
        last_check = self.last_health_check.get(service_name, 0)
        
        if current_time - last_check > self.health_check_interval:
            self._check_service_health(service_name, service)
            self.last_health_check[service_name] = current_time
        
        return service
    
    def get_services(self) -> Dict[str, Dict[str, Any]]:
        """
        Get all registered services.
        
        Returns:
            Dictionary of service name to service details
        """
        return self.services
    
    def register_service(self, name: str, url: str, metadata: Optional[Dict[str, Any]] = None) -> None:
        """
        Register a service.
        
        Args:
            name: Service name
            url: Service URL
            metadata: Optional service metadata
        """
        if not metadata:
            metadata = {}
        
        # Add health check URL if not provided
        if 'health_check_url' not in metadata:
            # Default health check URL is service URL + /health
            if url.endswith('/'):
                health_url = f"{url}health"
            else:
                health_url = f"{url}/health"
            metadata['health_check_url'] = health_url
        
        self.services[name] = {
            'name': name,
            'url': url,
            'metadata': metadata,
            'status': 'unknown'
        }
        
        logger.info(f"Registered service: {name} at {url}")
    
    def _check_service_health(self, service_name: str, service: Dict[str, Any]) -> None:
        """
        Check the health of a service.
        
        Args:
            service_name: Service name
            service: Service details
        """
        health_url = service.get('metadata', {}).get('health_check_url')
        if not health_url:
            logger.warning(f"No health check URL for service: {service_name}")
            return
        
        try:
            response = requests.get(health_url, timeout=self.health_check_timeout)
            
            if response.status_code == 200:
                service['status'] = 'healthy'
                logger.debug(f"Service {service_name} is healthy")
            else:
                service['status'] = 'unhealthy'
                logger.warning(f"Service {service_name} health check failed with status: {response.status_code}")
                
            # Store the last health check response
            service['last_health_check'] = {
                'timestamp': time.time(),
                'status_code': response.status_code,
                'response': response.text[:200]  # Store first 200 chars of response
            }
            
        except requests.RequestException as e:
            service['status'] = 'unavailable'
            logger.error(f"Health check failed for service {service_name}: {str(e)}")
            
            # Store the error
            service['last_health_check'] = {
                'timestamp': time.time(),
                'error': str(e)
            } 
```


### FILE: meeting_shared\discovery\static.py
```
"""
Static service discovery provider.
Uses a static configuration for service discovery.
"""

import os
import logging
import requests
from typing import Dict, Any, Optional, List
import time

logger = logging.getLogger(__name__)

class StaticServiceDiscovery:
    """
    Static service discovery provider.
    Uses a static configuration for service discovery.
    """
    
    def __init__(self):
        """Initialize static service discovery."""
        self.services = {}
        self.health_check_interval = int(os.environ.get('SERVICE_HEALTH_CHECK_INTERVAL', '60'))
        self.health_check_timeout = int(os.environ.get('SERVICE_HEALTH_CHECK_TIMEOUT', '5'))
        self.last_health_check = {}
        
        # Load services from environment variables
        self._load_services_from_env()
        
        logger.info(f"Initialized static service discovery with {len(self.services)} services")
    
    def _load_services_from_env(self):
        """Load services from environment variables."""
        # Look for environment variables in the format SERVICE_NAME_URL
        for key, value in os.environ.items():
            if key.endswith('_URL') and not key.startswith('DATABASE') and not key.startswith('REDIS'):
                service_name = key[:-4].lower().replace('_', '-')
                self.register_service(service_name, value)
    
    def get_service(self, service_name: str, default: Any = None) -> Optional[Dict[str, Any]]:
        """
        Get service details by name.
        
        Args:
            service_name: The service name to look up
            default: Default value if service not found
            
        Returns:
            Service details or default if not found
        """
        service = self.services.get(service_name)
        if not service:
            return default
        
        # Check if we need to perform a health check
        current_time = time.time()
        last_check = self.last_health_check.get(service_name, 0)
        
        if current_time - last_check > self.health_check_interval:
            self._check_service_health(service_name, service)
            self.last_health_check[service_name] = current_time
        
        return service
    
    def get_services(self) -> Dict[str, Dict[str, Any]]:
        """
        Get all registered services.
        
        Returns:
            Dictionary of service name to service details
        """
        return self.services
    
    def register_service(self, name: str, url: str, metadata: Optional[Dict[str, Any]] = None) -> None:
        """
        Register a service.
        
        Args:
            name: Service name
            url: Service URL
            metadata: Optional service metadata
        """
        if not metadata:
            metadata = {}
        
        # Add health check URL if not provided
        if 'health_check_url' not in metadata:
            # Default health check URL is service URL + /health
            if url.endswith('/'):
                health_url = f"{url}health"
            else:
                health_url = f"{url}/health"
            metadata['health_check_url'] = health_url
        
        self.services[name] = {
            'name': name,
            'url': url,
            'metadata': metadata,
            'status': 'unknown'
        }
        
        logger.info(f"Registered service: {name} at {url}")
    
    def _check_service_health(self, service_name: str, service: Dict[str, Any]) -> None:
        """
        Check the health of a service.
        
        Args:
            service_name: Service name
            service: Service details
        """
        health_url = service.get('metadata', {}).get('health_check_url')
        if not health_url:
            logger.warning(f"No health check URL for service: {service_name}")
            return
        
        try:
            response = requests.get(health_url, timeout=self.health_check_timeout)
            
            if response.status_code == 200:
                service['status'] = 'healthy'
                logger.debug(f"Service {service_name} is healthy")
            else:
                service['status'] = 'unhealthy'
                logger.warning(f"Service {service_name} health check failed with status: {response.status_code}")
                
            # Store the last health check response
            service['last_health_check'] = {
                'timestamp': time.time(),
                'status_code': response.status_code,
                'response': response.text[:200]  # Store first 200 chars of response
            }
            
        except requests.RequestException as e:
            service['status'] = 'unavailable'
            logger.error(f"Health check failed for service {service_name}: {str(e)}")
            
            # Store the error
            service['last_health_check'] = {
                'timestamp': time.time(),
                'error': str(e)
            } 
```


### FILE: meeting_shared\middleware\__init__.py
```
"""
Shared middleware module for backend services.
Provides middleware for request ID tracking, logging, and more.
"""

from typing import List, Callable, Dict, Any, Optional, Type
import logging
import importlib

logger = logging.getLogger(__name__)

# Define middleware interface
class Middleware:
    """Base class for all middleware"""
    
    def __init__(self, app=None, **kwargs):
        """Initialize middleware with optional app"""
        self.app = app
        if app is not None:
            self.init_app(app, **kwargs)
    
    def init_app(self, app, **kwargs):
        """Initialize middleware with app"""
        raise NotImplementedError("Middleware must implement init_app")
        
    def process_request(self, request):
        """Process request before it reaches the view"""
        return None
        
    def process_response(self, request, response):
        """Process response after it leaves the view"""
        return response
        
    def __call__(self, environ, start_response):
        """WSGI middleware interface"""
        raise NotImplementedError("Middleware must implement __call__")


# Try to import specific middleware modules
# If not available, provide dummy implementations
try:
    from .request_id import RequestIdMiddleware
except ImportError:
    class RequestIdMiddleware(Middleware):
        """Dummy implementation of RequestIdMiddleware"""
        def init_app(self, app, **kwargs):
            logger.warning("Using dummy RequestIdMiddleware")
            
        def __call__(self, environ, start_response):
            return self.app(environ, start_response)


# Default middleware configuration
DEFAULT_MIDDLEWARE = {
    'request_id': {
        'class': RequestIdMiddleware,
        'kwargs': {
            'request_id_header': 'X-Request-ID',
            'correlation_id_header': 'X-Correlation-ID'
        }
    }
}


def register_middleware(app, middleware_list=None):
    """
    Register middleware with a Flask application.
    
    Args:
        app: Flask application
        middleware_list: List of middleware configurations or None for defaults
        
    Returns:
        Flask application with middleware registered
    """
    # Use default middleware if none specified
    if middleware_list is None:
        middleware_list = list(DEFAULT_MIDDLEWARE.values())
    
    # Add each middleware to the application
    for middleware_config in middleware_list:
        if isinstance(middleware_config, dict):
            middleware_class = middleware_config.get('class')
            kwargs = middleware_config.get('kwargs', {})
            
            if middleware_class:
                try:
                    middleware = middleware_class()
                    middleware.init_app(app, **kwargs)
                    logger.info(f"Registered middleware: {middleware_class.__name__}")
                except Exception as e:
                    logger.error(f"Failed to register middleware {middleware_class.__name__}: {str(e)}")
        elif isinstance(middleware_config, Middleware):
            # If middleware instance is provided directly
            try:
                middleware_config.init_app(app)
                logger.info(f"Registered middleware: {middleware_config.__class__.__name__}")
            except Exception as e:
                logger.error(f"Failed to register middleware {middleware_config.__class__.__name__}: {str(e)}")
    
    return app


# Import specific middleware to make them available at package level
__all__ = [
    'Middleware',
    'RequestIdMiddleware', 
    'register_middleware'
] 
```


### FILE: meeting_shared\middleware\auth.py
```
from functools import wraps
from flask import request, jsonify, current_app, g
import jwt
from meeting_shared.schemas.base import ErrorResponse
import logging

logger = logging.getLogger(__name__)

def jwt_required(f):
    """Decorator to require JWT token for route access"""
    @wraps(f)
    def decorated(*args, **kwargs):
        token = None
        if 'Authorization' in request.headers:
            token = request.headers['Authorization'].split(' ')[1]
        
        if not token:
            response = ErrorResponse(
                error="Authentication Error",
                message="Token is missing"
            )
            return jsonify(response.model_dump()), 401
        
        try:
            payload = jwt.decode(
                token, 
                current_app.config['JWT_SECRET_KEY'], 
                algorithms=['HS256']
            )
            g.current_user_id = payload['user_id']
            g.current_token = token
            
        except jwt.ExpiredSignatureError:
            response = ErrorResponse(
                error="Authentication Error",
                message="Token has expired"
            )
            return jsonify(response.model_dump()), 401
            
        except jwt.InvalidTokenError:
            response = ErrorResponse(
                error="Authentication Error",
                message="Invalid token"
            )
            return jsonify(response.model_dump()), 401
        
        return f(*args, **kwargs)
    
    return decorated

def service_auth_required(f):
    """Decorator to require service authentication"""
    @wraps(f)
    def decorated(*args, **kwargs):
        service_key = request.headers.get('X-Service-Key')
        expected_key = current_app.config.get('SERVICE_KEY')
        
        if not service_key or service_key != expected_key:
            response = ErrorResponse(
                error="Authentication Error",
                message="Invalid service key"
            )
            return jsonify(response.model_dump()), 403
            
        return f(*args, **kwargs)
    
    return decorated

def roles_required(*roles):
    """Decorator to require specific roles for route access"""
    def decorator(f):
        @wraps(f)
        def decorated(*args, **kwargs):
            if not hasattr(g, 'current_user_id'):
                response = ErrorResponse(
                    error="Authentication Error",
                    message="No authenticated user"
                )
                return jsonify(response.model_dump()), 401
            
            # This should be implemented based on your role management system
            user_roles = get_user_roles(g.current_user_id)
            
            if not any(role in user_roles for role in roles):
                response = ErrorResponse(
                    error="Authorization Error",
                    message="Insufficient permissions"
                )
                return jsonify(response.model_dump()), 403
                
            return f(*args, **kwargs)
        return decorated
    return decorator

def get_user_roles(user_id: int) -> list:
    """Get user roles - implement based on your role management system"""
    # This is a placeholder - implement based on your system
    return [] 
```


### FILE: meeting_shared\middleware\error_handler.py
```
from functools import wraps
from flask import jsonify, current_app, request
from pydantic import ValidationError
from sqlalchemy.exc import SQLAlchemyError, IntegrityError
from jwt.exceptions import PyJWTError
from meeting_shared.schemas.base import ErrorResponse
import logging

logger = logging.getLogger(__name__)

class APIError(Exception):
    """Base exception for API errors"""
    def __init__(self, message: str, status_code: int = 400, details: dict = None):
        self.message = message
        self.status_code = status_code
        self.details = details
        super().__init__(message)

def handle_api_errors(app):
    """Register error handlers for the Flask app"""
    
    @app.errorhandler(APIError)
    def handle_api_error(error):
        response = ErrorResponse(
            error="API Error",
            message=error.message,
            details=error.details
        )
        return jsonify(response.model_dump()), error.status_code

    @app.errorhandler(ValidationError)
    def handle_validation_error(error):
        response = ErrorResponse(
            error="Validation Error",
            message="Invalid request data",
            details={"errors": error.errors()}
        )
        return jsonify(response.model_dump()), 400

    @app.errorhandler(PyJWTError)
    def handle_jwt_error(error):
        response = ErrorResponse(
            error="Authentication Error",
            message=str(error)
        )
        return jsonify(response.model_dump()), 401

    @app.errorhandler(IntegrityError)
    def handle_integrity_error(error):
        response = ErrorResponse(
            error="Database Error",
            message="Data integrity violation",
            details={"error": str(error.orig)}
        )
        return jsonify(response.model_dump()), 409

    @app.errorhandler(SQLAlchemyError)
    def handle_db_error(error):
        logger.error(f"Database error: {str(error)}")
        response = ErrorResponse(
            error="Database Error",
            message="An error occurred while processing your request"
        )
        return jsonify(response.model_dump()), 500

    @app.errorhandler(404)
    def handle_404(error):
        response = ErrorResponse(
            error="Not Found",
            message="The requested resource was not found"
        )
        return jsonify(response.model_dump()), 404

    @app.errorhandler(405)
    def handle_405(error):
        response = ErrorResponse(
            error="Method Not Allowed",
            message=f"The {request.method} method is not allowed for this endpoint"
        )
        return jsonify(response.model_dump()), 405

    @app.errorhandler(500)
    def handle_500(error):
        logger.error(f"Internal server error: {str(error)}")
        response = ErrorResponse(
            error="Internal Server Error",
            message="An unexpected error occurred"
        )
        return jsonify(response.model_dump()), 500

def error_handler(f):
    """Decorator to handle errors in routes"""
    @wraps(f)
    def decorated(*args, **kwargs):
        try:
            return f(*args, **kwargs)
        except Exception as e:
            logger.error(f"Error in {f.__name__}: {str(e)}")
            if not isinstance(e, APIError):
                e = APIError(str(e), 500)
            response = ErrorResponse(
                error=e.__class__.__name__,
                message=str(e),
                details=getattr(e, 'details', None)
            )
            return jsonify(response.model_dump()), e.status_code
    return decorated 
```


### FILE: meeting_shared\middleware\rate_limiter.py
```
from functools import wraps
from flask import request, jsonify, current_app
from redis import Redis
from datetime import datetime
import logging
from meeting_shared.schemas.base import ErrorResponse

logger = logging.getLogger(__name__)

class RateLimiter:
    def __init__(self, redis_url=None):
        self.redis = Redis.from_url(
            redis_url or current_app.config.get('REDIS_URL', 'redis://localhost:6379/0')
        )

    def is_rate_limited(self, key: str, limit: int, window: int) -> tuple[bool, int]:
        """
        Check if request is rate limited
        
        Args:
            key: Rate limit key
            limit: Maximum number of requests
            window: Time window in seconds
            
        Returns:
            Tuple of (is_limited, remaining_requests)
        """
        pipe = self.redis.pipeline()
        now = datetime.utcnow().timestamp()
        window_start = now - window
        
        # Remove old entries
        pipe.zremrangebyscore(key, '-inf', window_start)
        # Add current request
        pipe.zadd(key, {str(now): now})
        # Count requests in window
        pipe.zcard(key)
        # Set expiry
        pipe.expire(key, window)
        
        _, _, count, _ = pipe.execute()
        
        return count > limit, max(0, limit - count)

def rate_limit(limit: int, window: int, key_func=None):
    """
    Rate limiting decorator
    
    Args:
        limit: Maximum number of requests
        window: Time window in seconds
        key_func: Optional function to generate rate limit key
    """
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            limiter = RateLimiter()
            
            # Get rate limit key
            if key_func:
                key = f"rate_limit:{f.__name__}:{key_func(request)}"
            else:
                key = f"rate_limit:{f.__name__}:{request.remote_addr}"
            
            is_limited, remaining = limiter.is_rate_limited(key, limit, window)
            
            if is_limited:
                response = ErrorResponse(
                    error="Rate Limit Exceeded",
                    message="Too many requests",
                    details={
                        "limit": limit,
                        "window": window,
                        "retry_after": window
                    }
                )
                return jsonify(response.model_dump()), 429
            
            # Add rate limit headers
            response = f(*args, **kwargs)
            if isinstance(response, tuple):
                response, status_code = response
            else:
                status_code = 200
                
            response.headers['X-RateLimit-Limit'] = str(limit)
            response.headers['X-RateLimit-Remaining'] = str(remaining)
            response.headers['X-RateLimit-Reset'] = str(int(datetime.utcnow().timestamp() + window))
            
            return response, status_code
            
        return decorated_function
    return decorator 
```


### FILE: meeting_shared\middleware\request_id.py
```
"""
Request ID middleware module for tracking requests across services.
Generates and propagates request and correlation IDs.
"""

import logging
import uuid
import threading
from functools import wraps
from flask import Flask, request, g, has_request_context, current_app
from werkzeug.wsgi import ClosingIterator
from werkzeug.exceptions import HTTPException
from typing import Optional, Dict, Any, Callable, Union, List, Tuple

try:
    from . import Middleware
except (ImportError, ValueError):
    # Fallback if parent module not available
    class Middleware:
        """Base middleware class fallback"""
        def __init__(self, app=None, **kwargs):
            self.app = app
            if app is not None:
                self.init_app(app, **kwargs)
                
        def init_app(self, app, **kwargs):
            pass

# Thread-local storage for request ID when Flask context is not available
_request_id_local = threading.local()

logger = logging.getLogger(__name__)

class RequestIdMiddleware(Middleware):
    """
    WSGI middleware that assigns a unique request ID to each incoming request.
    Optionally preserves request ID from request header if present.
    """
    
    def __init__(self, app=None, **kwargs):
        """Initialize middleware with optional app"""
        self.app = app
        self.request_id_header = 'X-Request-ID'
        self.correlation_id_header = 'X-Correlation-ID'
        self.include_in_response = True
        
        if app is not None:
            self.init_app(app, **kwargs)
            
    def init_app(self, app: Flask, **kwargs):
        """
        Initialize middleware with Flask application.
        
        Args:
            app: Flask application
            request_id_header: Name of header containing request ID
            correlation_id_header: Name of header containing correlation ID
            include_in_response: Whether to include request/correlation IDs in response
        """
        # Store configuration
        self.request_id_header = kwargs.get('request_id_header', self.request_id_header)
        self.correlation_id_header = kwargs.get('correlation_id_header', self.correlation_id_header)
        self.include_in_response = kwargs.get('include_in_response', self.include_in_response)
        
        # Register middleware with Flask
        app.before_request(self.before_request)
        app.after_request(self.after_request)
        app.teardown_request(self.teardown_request)
        
        # Add endpoint to get current request ID (useful for testing/debugging)
        app.add_url_rule('/_request_id', '_request_id', self.request_id_endpoint)
        
        # Wrap application with WSGI middleware
        if not hasattr(app, 'wsgi_app_wrapped_by_request_id') or not app.wsgi_app_wrapped_by_request_id:
            original_wsgi_app = app.wsgi_app
            app.wsgi_app = self
            app.wsgi_app_wrapped_by_request_id = True
            self.app = original_wsgi_app
            
        logger.info(f"RequestIdMiddleware initialized with headers: {self.request_id_header}, {self.correlation_id_header}")
        
    def __call__(self, environ, start_response):
        """
        WSGI middleware implementation.
        
        Args:
            environ: WSGI environment
            start_response: WSGI start_response function
            
        Returns:
            WSGI response
        """
        # Extract request ID from environment or generate new one
        request_id = environ.get('HTTP_' + self.request_id_header.replace('-', '_').upper())
        correlation_id = environ.get('HTTP_' + self.correlation_id_header.replace('-', '_').upper())
        
        # Generate IDs if not present
        if not request_id:
            request_id = str(uuid.uuid4())
        
        if not correlation_id:
            correlation_id = request_id
            
        # Store in environment for downstream WSGI applications
        environ['request_id'] = request_id
        environ['correlation_id'] = correlation_id
        
        # Store in thread-local for access outside request context
        _request_id_local.request_id = request_id
        _request_id_local.correlation_id = correlation_id
        
        # Function to intercept the status and headers
        def custom_start_response(status, headers, exc_info=None):
            # Add request ID header to response if configured
            if self.include_in_response:
                headers_list = list(headers)
                headers_list.append((self.request_id_header, request_id))
                headers_list.append((self.correlation_id_header, correlation_id))
                headers = headers_list
            
            return start_response(status, headers, exc_info)
        
        # Process request
        try:
            return ClosingIterator(
                self.app(environ, custom_start_response),
                self.cleanup_request
            )
        except Exception as e:
            # Clean up if an exception occurs
            self.cleanup_request()
            raise
    
    def before_request(self):
        """Before request handler for Flask."""
        # Get request ID from headers or generate new one
        request_id = request.headers.get(self.request_id_header)
        correlation_id = request.headers.get(self.correlation_id_header)
        
        # Generate IDs if not present
        if not request_id:
            request_id = str(uuid.uuid4())
        
        if not correlation_id:
            correlation_id = request_id
        
        # Store in Flask g for access within request
        g.request_id = request_id
        g.correlation_id = correlation_id
        
        # Store in thread-local for access outside request context
        _request_id_local.request_id = request_id
        _request_id_local.correlation_id = correlation_id
        
        logger.debug(f"Request {request_id} started: {request.method} {request.path}")
    
    def after_request(self, response):
        """
        After request handler for Flask.
        
        Args:
            response: Flask response
            
        Returns:
            Modified response with request ID headers
        """
        # Add request ID headers to response if configured
        if self.include_in_response:
            response.headers.setdefault(
                self.request_id_header, 
                getattr(g, 'request_id', 'unknown')
            )
            response.headers.setdefault(
                self.correlation_id_header, 
                getattr(g, 'correlation_id', 'unknown')
            )
        
        logger.debug(f"Request {getattr(g, 'request_id', 'unknown')} completed with status {response.status_code}")
        return response
    
    def teardown_request(self, exception=None):
        """
        Teardown request handler for Flask.
        
        Args:
            exception: Exception if an error occurred during request processing
        """
        if exception:
            logger.error(f"Request {getattr(g, 'request_id', 'unknown')} failed: {str(exception)}")
    
    def cleanup_request(self):
        """Clean up request resources."""
        # Clear thread-local storage
        if hasattr(_request_id_local, 'request_id'):
            del _request_id_local.request_id
        if hasattr(_request_id_local, 'correlation_id'):
            del _request_id_local.correlation_id
    
    def request_id_endpoint(self):
        """Endpoint that returns the current request ID."""
        return {
            'request_id': get_request_id(),
            'correlation_id': get_correlation_id()
        }


# Helper functions to access request IDs outside middleware
def get_request_id() -> str:
    """
    Get the current request ID.
    
    Returns:
        str: Request ID from Flask g, or thread-local, or None
    """
    if has_request_context():
        return getattr(g, 'request_id', None)
    
    return getattr(_request_id_local, 'request_id', None)


def get_correlation_id() -> str:
    """
    Get the current correlation ID.
    
    Returns:
        str: Correlation ID from Flask g, or thread-local, or None
    """
    if has_request_context():
        return getattr(g, 'correlation_id', None)
    
    return getattr(_request_id_local, 'correlation_id', None)


def with_request_id(func):
    """
    Decorator that ensures a request ID exists for the decorated function.
    
    Args:
        func: Function to decorate
        
    Returns:
        Decorated function
    """
    @wraps(func)
    def wrapper(*args, **kwargs):
        # Generate request ID if none exists
        if not get_request_id():
            request_id = str(uuid.uuid4())
            _request_id_local.request_id = request_id
            _request_id_local.correlation_id = request_id
        
        return func(*args, **kwargs)
    
    return wrapper 
```


### FILE: meeting_shared\middleware\validation.py
```
from functools import wraps
from flask import request, jsonify
from pydantic import BaseModel, ValidationError
from typing import Type, List, Union, Dict, Any
from meeting_shared.schemas.base import ErrorResponse
import logging
from meeting_shared.database import transaction

logger = logging.getLogger(__name__)

def validate_schema(schema_class: Type[BaseModel], allow_bulk: bool = False):
    """
    Enhanced decorator to validate request data against a Pydantic schema
    
    Args:
        schema_class: Pydantic model class to validate against
        allow_bulk: Whether to allow bulk validation of a list of items
    """
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            try:
                # Get request data based on content type
                if request.is_json:
                    data = request.get_json()
                elif request.form:
                    data = request.form.to_dict()
                else:
                    data = request.args.to_dict()
                
                # Handle bulk validation if allowed and data is a list
                if allow_bulk and isinstance(data, list):
                    validated_data = [schema_class(**item) for item in data]
                else:
                    validated_data = schema_class(**data)
                
                # Add validated data to kwargs
                kwargs['data'] = validated_data
                
                # Wrap the function call in a transaction
                with transaction():
                    return f(*args, **kwargs)
                
            except ValidationError as e:
                logger.error(f"Validation error: {str(e)}")
                response = ErrorResponse(
                    error="Validation Error",
                    message="Invalid request data",
                    details={"errors": e.errors()}
                )
                return jsonify(response.model_dump()), 400
                
            except Exception as e:
                logger.error(f"Error validating request data: {str(e)}")
                response = ErrorResponse(
                    error="Validation Error",
                    message="Error processing request data"
                )
                return jsonify(response.model_dump()), 400
                
        return decorated_function
    return decorator

def validate_nested_schema(schema_class: Type[BaseModel], field_path: str):
    """
    Decorator to validate nested data in request against a Pydantic schema
    
    Args:
        schema_class: Pydantic model class to validate against
        field_path: Dot-notation path to the nested data (e.g. "user.profile")
    """
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            try:
                data = request.get_json()
                
                # Navigate to nested data using field path
                nested_data = data
                for field in field_path.split('.'):
                    nested_data = nested_data.get(field, {})
                
                # Validate nested data
                validated_data = schema_class(**nested_data)
                
                # Add validated data to kwargs using field path
                kwargs[field_path.replace('.', '_')] = validated_data
                
                # Wrap the function call in a transaction
                with transaction():
                    return f(*args, **kwargs)
                
            except ValidationError as e:
                logger.error(f"Validation error in nested schema: {str(e)}")
                response = ErrorResponse(
                    error="Validation Error",
                    message=f"Invalid data in {field_path}",
                    details={"errors": e.errors()}
                )
                return jsonify(response.model_dump()), 400
                
            except Exception as e:
                logger.error(f"Error validating nested data: {str(e)}")
                response = ErrorResponse(
                    error="Validation Error",
                    message="Error processing request data"
                )
                return jsonify(response.model_dump()), 400
                
        return decorated_function
    return decorator

def validate_query_params(*required_params):
    """
    Decorator to validate required query parameters
    
    Args:
        *required_params: Names of required query parameters
    """
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            missing_params = [
                param for param in required_params 
                if param not in request.args
            ]
            
            if missing_params:
                response = ErrorResponse(
                    error="Validation Error",
                    message="Missing required query parameters",
                    details={"missing_params": missing_params}
                )
                return jsonify(response.model_dump()), 400
                
            return f(*args, **kwargs)
        return decorated_function
    return decorator 
```


### FILE: meeting_shared\models\__init__.py
```
"""
Shared data models for backend services.
"""

# Package exports
__all__ = [] 
```


### FILE: meeting_shared\schemas\__init__.py
```
"""
Shared schema definitions for API requests and responses.
"""

# Package exports
__all__ = [] 
```


### FILE: meeting_shared\schemas\base.py
```
"""
Base schemas for API responses.
"""

from typing import Optional, Dict, Any
from pydantic import BaseModel

class BaseSchema(BaseModel):
    """Base schema that all other schemas should inherit from."""
    class Config:
        orm_mode = True
        validate_assignment = True
        arbitrary_types_allowed = True
        extra = "forbid"

class ErrorResponse(BaseModel):
    """Standard error response model."""
    error: str
    message: str
    details: Optional[Dict[str, Any]] = None 

class SuccessResponse(BaseModel):
    """Standard success response model."""
    success: bool = True
    data: Optional[Dict[str, Any]] = {}
    message: Optional[str] = "Operation completed successfully" 
```


### FILE: meeting_shared\secrets\__init__.py
```
"""
Secrets management module.
Provides a unified interface for accessing secrets from various backends.
"""

import os
import logging

logger = logging.getLogger(__name__)

# Import secret managers
try:
    from .env import EnvSecretManager
    HAS_ENV = True
except ImportError:
    HAS_ENV = False

try:
    from .file import FileSecretManager
    HAS_FILE = True
except ImportError:
    HAS_FILE = False

try:
    from .vault import VaultSecretManager
    HAS_VAULT = True
except ImportError:
    HAS_VAULT = False

try:
    from .aws import AWSSecretManager
    HAS_AWS = True
except ImportError:
    HAS_AWS = False

# Global secret manager instance
_secret_manager = None

def get_secret_manager(manager_type=None):
    """
    Get a secret manager instance.
    
    Args:
        manager_type: The type of secret manager to use.
            Options: 'env', 'file', 'vault', 'aws'
            If None, will try to determine from environment variables.
            
    Returns:
        A secret manager instance.
    """
    # Try to determine the manager type from environment variables
    if manager_type is None:
        manager_type = os.environ.get('SECRET_MANAGER_TYPE', 'env').lower()
    
    if manager_type == 'env' and HAS_ENV:
        return EnvSecretManager()
    elif manager_type == 'file' and HAS_FILE:
        return FileSecretManager()
    elif manager_type == 'vault' and HAS_VAULT:
        return VaultSecretManager()
    elif manager_type == 'aws' and HAS_AWS:
        return AWSSecretManager()
    else:
        logger.warning(f"Unsupported or unavailable secret manager: {manager_type}")
        return None

def _get_manager():
    """
    Get the global secret manager instance, creating it if necessary.
    
    Returns:
        The global secret manager instance.
    """
    global _secret_manager
    if _secret_manager is None:
        _secret_manager = get_secret_manager()
    return _secret_manager

def set_secret_manager(manager):
    """
    Set the global secret manager instance.
    
    Args:
        manager: A secret manager instance.
    """
    global _secret_manager
    _secret_manager = manager

def get_secret(key, default=None):
    """
    Get a secret by key.
    
    Args:
        key: The secret key.
        default: The default value to return if the secret is not found.
        
    Returns:
        The secret value, or default if not found.
    """
    manager = _get_manager()
    if manager is None:
        logger.error(f"No secret manager available, cannot get secret: {key}")
        return default
    return manager.get_secret(key, default)

def get_secrets(keys):
    """
    Get multiple secrets by keys.
    
    Args:
        keys: A list of secret keys.
        
    Returns:
        A dictionary of secret keys to values.
    """
    manager = _get_manager()
    if manager is None:
        logger.error(f"No secret manager available, cannot get secrets: {keys}")
        return {}
    return manager.get_secrets(keys)

def has_secret(key):
    """
    Check if a secret exists.
    
    Args:
        key: The secret key.
        
    Returns:
        True if the secret exists, False otherwise.
    """
    manager = _get_manager()
    if manager is None:
        logger.error(f"No secret manager available, cannot check secret: {key}")
        return False
    return manager.has_secret(key)

# Export public interface
__all__ = [
    'get_secret',
    'get_secrets',
    'has_secret',
    'set_secret_manager',
    'get_secret_manager'
] 
```


### FILE: meeting_shared\secrets\file.py
```
"""
File-based secret manager.
Retrieves secrets from files in a directory.
"""

import os
import json
import logging
from pathlib import Path
from .base import SecretManager

logger = logging.getLogger(__name__)

class FileSecretManager(SecretManager):
    """
    Secret manager that retrieves secrets from files.
    
    This is useful for Docker and Kubernetes environments that mount secrets as files.
    """
    
    def __init__(self, path='/app/secrets'):
        """
        Initialize the file-based secret manager.
        
        Args:
            path: Path to the secrets directory (default: '/app/secrets').
                 Can be a directory containing individual secret files,
                 or a JSON file containing multiple secrets.
        """
        self.path = Path(path)
        self._cache = {}
        self._is_json_file = self.path.is_file() and self.path.suffix.lower() == '.json'
        
        if self._is_json_file:
            logger.info(f"Initialized file-based secret manager with JSON file: {self.path}")
            self._load_json_file()
        else:
            logger.info(f"Initialized file-based secret manager with directory: {self.path}")
    
    def _load_json_file(self):
        """
        Load secrets from a JSON file.
        """
        try:
            if not self.path.exists():
                logger.warning(f"Secrets file does not exist: {self.path}")
                return
            
            with open(self.path, 'r') as f:
                self._cache = json.load(f)
            
            logger.debug(f"Loaded {len(self._cache)} secrets from JSON file")
        except Exception as e:
            logger.error(f"Error loading secrets from JSON file: {str(e)}")
    
    def _get_file_path(self, key):
        """
        Get the file path for a secret key.
        
        Args:
            key: The secret key.
            
        Returns:
            The file path.
        """
        # Replace dots with slashes
        key_path = key.replace('.', '/')
        
        # Ensure the key doesn't start with a slash
        if key_path.startswith('/'):
            key_path = key_path[1:]
        
        return self.path / key_path
    
    def get_secret(self, key, default=None):
        """
        Get a secret from a file.
        
        Args:
            key: The secret key.
            default: The default value to return if the secret is not found.
            
        Returns:
            The secret value, or default if not found.
        """
        if self._is_json_file:
            # For JSON files, use the cache
            value = self._cache.get(key)
            if value is None:
                logger.debug(f"Secret not found in JSON file: {key}")
                return default
            
            logger.debug(f"Retrieved secret from JSON file: {key}")
            return value
        else:
            # For directories, read the file
            file_path = self._get_file_path(key)
            
            if not file_path.exists():
                logger.debug(f"Secret file does not exist: {file_path}")
                return default
            
            try:
                with open(file_path, 'r') as f:
                    value = f.read().strip()
                
                logger.debug(f"Retrieved secret from file: {file_path}")
                return value
            except Exception as e:
                logger.error(f"Error reading secret file: {str(e)}")
                return default
    
    def get_secrets(self, keys):
        """
        Get multiple secrets.
        
        Args:
            keys: List of secret keys.
            
        Returns:
            Dictionary of key-value pairs.
        """
        return {key: self.get_secret(key) for key in keys}
    
    def has_secret(self, key):
        """
        Check if a secret exists.
        
        Args:
            key: The secret key.
            
        Returns:
            True if the secret exists, False otherwise.
        """
        if self._is_json_file:
            return key in self._cache
        else:
            return self._get_file_path(key).exists() 
```


### FILE: meeting_shared\secrets\vault.py
```
"""
HashiCorp Vault secret manager.
Retrieves secrets from HashiCorp Vault.
"""

import os
import logging
from .base import SecretManager

try:
    import hvac
    HAS_HVAC = True
except ImportError:
    HAS_HVAC = False

logger = logging.getLogger(__name__)

class VaultSecretManager(SecretManager):
    """
    Secret manager that retrieves secrets from HashiCorp Vault.
    Requires the hvac package to be installed.
    """
    
    def __init__(self, 
                 url=None, 
                 token=None, 
                 path_prefix='secret/',
                 auth_method='token',
                 role_id=None,
                 secret_id=None):
        """
        Initialize HashiCorp Vault secret manager.
        
        Args:
            url: Vault server URL (defaults to VAULT_ADDR env var)
            token: Vault token (defaults to VAULT_TOKEN env var)
            path_prefix: Path prefix for secrets (defaults to 'secret/')
            auth_method: Authentication method ('token', 'approle', etc.)
            role_id: AppRole role ID (for 'approle' auth method)
            secret_id: AppRole secret ID (for 'approle' auth method)
        """
        if not HAS_HVAC:
            raise ImportError("hvac package is required for VaultSecretManager")
        
        self.url = url or os.environ.get('VAULT_ADDR')
        if not self.url:
            raise ValueError("Vault URL not provided and VAULT_ADDR environment variable not set")
        
        self.token = token or os.environ.get('VAULT_TOKEN')
        self.path_prefix = path_prefix.rstrip('/') + '/'
        self.auth_method = auth_method
        self.role_id = role_id or os.environ.get('VAULT_ROLE_ID')
        self.secret_id = secret_id or os.environ.get('VAULT_SECRET_ID')
        
        self.client = None
        self._initialize_client()
    
    def _initialize_client(self):
        """Initialize the Vault client and authenticate."""
        try:
            self.client = hvac.Client(url=self.url)
            
            if self.auth_method == 'token' and self.token:
                self.client.token = self.token
            elif self.auth_method == 'approle' and self.role_id and self.secret_id:
                self.client.auth.approle.login(
                    role_id=self.role_id,
                    secret_id=self.secret_id
                )
            else:
                raise ValueError(f"Unsupported auth method: {self.auth_method}")
                
            if not self.client.is_authenticated():
                raise ValueError("Failed to authenticate with Vault")
                
            logger.info(f"Successfully authenticated with Vault at {self.url}")
        except Exception as e:
            logger.error(f"Failed to initialize Vault client: {str(e)}")
            raise
    
    def _get_path(self, key):
        """
        Get the full path for a secret key.
        
        Args:
            key: The secret key.
            
        Returns:
            The full path in Vault.
        """
        return f"{self.path_prefix}{key}"
    
    def get_secret(self, key, default=None):
        """
        Get a secret from Vault.
        
        Args:
            key: The secret key.
            default: The default value to return if the secret is not found.
            
        Returns:
            The secret value, or default if not found.
        """
        try:
            path = self._get_path(key)
            secret = self.client.secrets.kv.v2.read_secret_version(path=path)
            
            if secret and 'data' in secret['data']:
                return secret['data']['data'].get('value', default)
            
            return default
        except Exception as e:
            logger.error(f"Error retrieving secret from Vault: {str(e)}")
            return default
    
    def get_secrets(self, keys):
        """
        Get multiple secrets from Vault.
        
        Args:
            keys: List of secret keys.
            
        Returns:
            Dictionary of key-value pairs.
        """
        return {key: self.get_secret(key) for key in keys}
    
    def has_secret(self, key):
        """
        Check if a secret exists in Vault.
        
        Args:
            key: The secret key.
            
        Returns:
            True if the secret exists, False otherwise.
        """
        try:
            path = self._get_path(key)
            self.client.secrets.kv.v2.read_secret_version(path=path)
            return True
        except Exception:
            return False 
```


### FILE: meeting_shared\shared_logging\__init__.py
```
"""
Shared logging module for backend services.
Provides structured JSON logging and request ID tracking.
"""

# Import standard logging to ensure it's fully initialized
import logging

# Define exports without importing from config.py
__all__ = [
    'setup_logging',
    'get_log_config',
    'JSONFormatter',
    'RequestIDLogFilter',
    'configure_library_loggers'
]

# Define a simple setup_logging function that can be used as a fallback
def setup_logging(app=None, service_name=None, log_level=None, json_logs=True, log_to_file=False, log_file=None):
    """
    Simple fallback logging setup function.
    The real implementation is in config.py
    """
    # Configure basic logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # Try to import the real setup_logging function
    try:
        from .config import setup_logging as real_setup_logging
        return real_setup_logging(app, service_name, log_level, json_logs, log_to_file, log_file)
    except ImportError:
        logging.warning("Could not import logging config module. Using basic logging setup.")
        return None 
```


### FILE: meeting_shared\shared_logging\config.py
```
"""
Standardized logging configuration for all backend services.
Supports structured JSON logging and request ID tracking.
"""

import os
import sys
import json
import logging
import logging.config
from datetime import datetime
from functools import partial

# Try to import sampling module
try:
    from .sampling import SamplingLogFilter, SamplingConfig
    HAS_SAMPLING = True
except ImportError:
    HAS_SAMPLING = False

# Configure third-party library logging
def configure_library_loggers():
    """Configure third-party library loggers to reduce noise"""
    # Set higher log levels for noisy libraries
    logging.getLogger("werkzeug").setLevel(logging.WARNING)
    logging.getLogger("sqlalchemy.engine").setLevel(logging.WARNING)
    logging.getLogger("sqlalchemy.pool").setLevel(logging.WARNING)
    logging.getLogger("urllib3").setLevel(logging.WARNING)
    logging.getLogger("botocore").setLevel(logging.WARNING)
    logging.getLogger("boto3").setLevel(logging.WARNING)
    logging.getLogger("requests").setLevel(logging.WARNING)


class RequestIDLogFilter(logging.Filter):
    """Log filter that adds request and correlation IDs to log records."""
    
    def filter(self, record):
        """Add request_id and correlation_id fields to log records."""
        # Import Flask modules inside the method to avoid circular imports
        try:
            # Dynamically import Flask to avoid circular imports
            from flask import g, request, has_request_context
            
            # Default values
            record.request_id = "no_request_id"
            record.correlation_id = "no_correlation_id"
            record.user_id = "no_user"
            record.path = "/"
            record.method = "NONE"
            
            # Add request context if available
            if has_request_context():
                record.request_id = getattr(g, 'request_id', request.headers.get('X-Request-ID', 'no_request_id'))
                record.correlation_id = getattr(g, 'correlation_id', request.headers.get('X-Correlation-ID', 'no_correlation_id'))
                record.user_id = getattr(g, 'user_id', 'anonymous')
                record.path = request.path
                record.method = request.method
        except (ImportError, RuntimeError):
            # If Flask is not available or not in request context, use default values
            record.request_id = "no_request_id"
            record.correlation_id = "no_correlation_id"
            record.user_id = "no_user"
            record.path = "/"
            record.method = "NONE"
        
        # Add taskName attribute if missing
        if not hasattr(record, 'taskName'):
            record.taskName = None
            
        return True


class JSONFormatter(logging.Formatter):
    """
    JSON log formatter that outputs logs in a structured format.
    Includes service name, timestamp, level, message, and additional context.
    """
    
    def __init__(self, service_name=None):
        """
        Initialize the formatter with service name.
        
        Args:
            service_name: Optional service name to include in logs
        """
        super().__init__()
        self.service_name = service_name or os.environ.get('SERVICE_NAME', 'unknown')
    
    def format(self, record):
        """
        Format the log record as a JSON object.
        
        Args:
            record: The log record to format
            
        Returns:
            JSON formatted log string
        """
        log_data = {
            'timestamp': datetime.utcnow().isoformat(),
            'service': self.service_name,
            'level': record.levelname,
            'message': record.getMessage(),
            'logger': record.name,
            'module': record.module,
            'function': record.funcName,
            'line': record.lineno,
        }
        
        # Add request context if available
        if hasattr(record, 'request_id'):
            log_data['request_id'] = record.request_id
        
        if hasattr(record, 'correlation_id'):
            log_data['correlation_id'] = record.correlation_id
            
        if hasattr(record, 'user_id'):
            log_data['user_id'] = record.user_id
            
        if hasattr(record, 'path'):
            log_data['path'] = record.path
            
        if hasattr(record, 'method'):
            log_data['method'] = record.method
        
        # Add exception info if available
        if record.exc_info:
            log_data['exception'] = {
                'type': record.exc_info[0].__name__,
                'message': str(record.exc_info[1]),
                'traceback': self.formatException(record.exc_info)
            }
        
        # Add any extra attributes
        for key, value in record.__dict__.items():
            if key not in ['args', 'asctime', 'created', 'exc_info', 'exc_text', 'filename',
                          'funcName', 'id', 'levelname', 'levelno', 'lineno', 'module',
                          'msecs', 'message', 'msg', 'name', 'pathname', 'process',
                          'processName', 'relativeCreated', 'stack_info', 'thread', 'threadName',
                          'request_id', 'correlation_id', 'user_id', 'path', 'method']:
                log_data[key] = value
        
        return json.dumps(log_data)


def get_log_config(service_name=None, log_level=None, json_logs=True, log_to_file=False, log_file=None, enable_sampling=False, sampling_config=None):
    """
    Get logging configuration dictionary.
    
    Args:
        service_name: Service name for logs
        log_level: Log level (DEBUG, INFO, etc.)
        json_logs: Whether to use JSON formatting
        log_to_file: Whether to log to a file
        log_file: Log file path
        enable_sampling: Whether to enable log sampling
        sampling_config: Sampling configuration
        
    Returns:
        Logging configuration dictionary
    """
    # Set defaults
    service_name = service_name or os.environ.get('SERVICE_NAME', 'app')
    log_level = log_level or os.environ.get('LOG_LEVEL', 'INFO').upper()
    json_logs = json_logs if json_logs is not None else os.environ.get('JSON_LOGS', 'true').lower() == 'true'
    log_to_file = log_to_file if log_to_file is not None else os.environ.get('LOG_TO_FILE', 'false').lower() == 'true'
    log_file = log_file or os.environ.get('LOG_FILE', f'logs/{service_name}.log')
    enable_sampling = enable_sampling if enable_sampling is not None else os.environ.get('ENABLE_LOG_SAMPLING', 'false').lower() == 'true'
    
    # Define formatters
    formatters = {
        'standard': {
            'format': '%(asctime)s [%(levelname)s] %(name)s: %(message)s'
        },
        'json': {
            '()': JSONFormatter,
            'service_name': service_name
        }
    }
    
    # Define handlers
    handlers = {
        'console': {
            'class': 'logging.StreamHandler',
            'level': log_level,
            'formatter': 'json' if json_logs else 'standard',
            'stream': 'ext://sys.stdout'
        }
    }
    
    # Add file handler if enabled
    if log_to_file:
        handlers['file'] = {
            'class': 'logging.handlers.RotatingFileHandler',
            'level': log_level,
            'formatter': 'json' if json_logs else 'standard',
            'filename': log_file,
            'maxBytes': 10485760,  # 10MB
            'backupCount': 5,
            'encoding': 'utf8'
        }
    
    # Define filters
    filters = {
        'request_id': {
            '()': RequestIDLogFilter
        }
    }
    
    # Add sampling filter if enabled
    if enable_sampling and HAS_SAMPLING:
        filters['sampling'] = {
            '()': SamplingLogFilter
        }
    
    # Create filter list
    filter_list = ['request_id']
    if enable_sampling and HAS_SAMPLING:
        filter_list.append('sampling')
    
    # Create config dictionary
    log_config = {
        'version': 1,
        'disable_existing_loggers': False,
        'formatters': formatters,
        'filters': filters,
        'handlers': handlers,
        'loggers': {
            '': {  # Root logger
                'level': log_level,
                'handlers': ['console'] + (['file'] if log_to_file else []),
                'filters': filter_list,
                'propagate': False
            },
            service_name: {
                'level': log_level,
                'handlers': ['console'] + (['file'] if log_to_file else []),
                'filters': filter_list,
                'propagate': False
            },
            'werkzeug': {
                'level': 'WARNING',
                'handlers': ['console'] + (['file'] if log_to_file else []),
                'propagate': False
            },
            'sqlalchemy': {
                'level': 'WARNING',
                'handlers': ['console'] + (['file'] if log_to_file else []),
                'propagate': False
            }
        }
    }
    
    return log_config


def setup_logging(app=None, service_name=None, log_level=None, json_logs=True, log_to_file=False, log_file=None, enable_sampling=False, sampling_config=None):
    """
    Set up logging configuration.
    
    Args:
        app: Flask application (optional)
        service_name: Service name for logs
        log_level: Log level (DEBUG, INFO, etc.)
        json_logs: Whether to use JSON formatting
        log_to_file: Whether to log to a file
        log_file: Log file path
        enable_sampling: Whether to enable log sampling
        sampling_config: Sampling configuration
        
    Returns:
        Configured logger
    """
    # Get service name from app if available
    if app and not service_name:
        service_name = app.name
    
    # Get log level from app if available
    if app and not log_level:
        log_level = app.config.get('LOG_LEVEL', 'INFO')
    
    # Get log config
    log_config = get_log_config(
        service_name=service_name,
        log_level=log_level,
        json_logs=json_logs,
        log_to_file=log_to_file,
        log_file=log_file,
        enable_sampling=enable_sampling,
        sampling_config=sampling_config
    )
    
    # Configure logging
    logging.config.dictConfig(log_config)
    
    # Configure sampling if enabled
    if enable_sampling and HAS_SAMPLING and sampling_config:
        from .sampling import configure_sampling
        configure_sampling(sampling_config)
    
    # Configure library loggers
    configure_library_loggers()
    
    # Get logger for service
    logger = logging.getLogger(service_name)
    
    # Log startup message
    logger.info(f"Logging configured for {service_name} at level {log_level}")
    
    return logger 
```


### FILE: meeting_shared\shared_logging\sampling.py
```
"""
Log sampling module for reducing log volume on high-traffic endpoints.
Provides configurable sampling rates for different endpoints and log levels.
"""

import logging
import random
import re
from typing import Dict, List, Optional, Union, Pattern
import threading
import time

logger = logging.getLogger(__name__)

class SamplingConfig:
    """Configuration for log sampling."""
    
    def __init__(self, 
                 default_rate: float = 1.0,
                 path_rates: Optional[Dict[str, float]] = None,
                 method_rates: Optional[Dict[str, float]] = None,
                 level_rates: Optional[Dict[str, float]] = None):
        """
        Initialize sampling configuration.
        
        Args:
            default_rate: Default sampling rate (0.0-1.0) where 1.0 means log everything
            path_rates: Dict mapping path patterns to sampling rates
            method_rates: Dict mapping HTTP methods to sampling rates
            level_rates: Dict mapping log levels to sampling rates
        """
        self.default_rate = max(0.0, min(1.0, default_rate))
        self.path_rates = path_rates or {}
        self.method_rates = method_rates or {}
        self.level_rates = level_rates or {}
        
        # Compile path patterns
        self.path_patterns = {}
        for path, rate in self.path_rates.items():
            try:
                self.path_patterns[re.compile(path)] = max(0.0, min(1.0, rate))
            except re.error:
                logger.warning(f"Invalid path pattern: {path}")
        
        # Normalize method rates
        for method, rate in self.method_rates.items():
            self.method_rates[method.upper()] = max(0.0, min(1.0, rate))
        
        # Normalize level rates
        for level, rate in self.level_rates.items():
            if isinstance(level, str):
                level_num = logging.getLevelName(level.upper())
                if isinstance(level_num, int):
                    self.level_rates[level_num] = max(0.0, min(1.0, rate))
                else:
                    logger.warning(f"Invalid log level: {level}")
            else:
                self.level_rates[level] = max(0.0, min(1.0, rate))
    
    def get_rate_for_path(self, path: str) -> float:
        """
        Get sampling rate for a path.
        
        Args:
            path: Request path
            
        Returns:
            Sampling rate (0.0-1.0)
        """
        for pattern, rate in self.path_patterns.items():
            if pattern.search(path):
                return rate
        return self.default_rate
    
    def get_rate_for_method(self, method: str) -> float:
        """
        Get sampling rate for an HTTP method.
        
        Args:
            method: HTTP method
            
        Returns:
            Sampling rate (0.0-1.0)
        """
        return self.method_rates.get(method.upper(), self.default_rate)
    
    def get_rate_for_level(self, level: Union[int, str]) -> float:
        """
        Get sampling rate for a log level.
        
        Args:
            level: Log level (int or string)
            
        Returns:
            Sampling rate (0.0-1.0)
        """
        if isinstance(level, str):
            level = logging.getLevelName(level.upper())
        
        return self.level_rates.get(level, self.default_rate)


class LogSampler:
    """Log sampler for reducing log volume."""
    
    def __init__(self, config: Optional[SamplingConfig] = None):
        """
        Initialize log sampler.
        
        Args:
            config: Sampling configuration
        """
        self.config = config or SamplingConfig()
        self.request_counts = {}
        self.request_counts_lock = threading.Lock()
        
        # Clean up request counts periodically
        self.cleanup_interval = 300  # 5 minutes
        self.last_cleanup = time.time()
    
    def should_log(self, 
                  path: Optional[str] = None, 
                  method: Optional[str] = None,
                  level: Optional[Union[int, str]] = None) -> bool:
        """
        Determine if a log entry should be included based on sampling rates.
        
        Args:
            path: Request path
            method: HTTP method
            level: Log level
            
        Returns:
            True if the log entry should be included, False otherwise
        """
        # Clean up request counts if needed
        current_time = time.time()
        if current_time - self.last_cleanup > self.cleanup_interval:
            with self.request_counts_lock:
                self.request_counts = {}
                self.last_cleanup = current_time
        
        # Get sampling rates
        path_rate = self.config.default_rate
        if path:
            path_rate = self.config.get_rate_for_path(path)
        
        method_rate = self.config.default_rate
        if method:
            method_rate = self.config.get_rate_for_method(method)
        
        level_rate = self.config.default_rate
        if level:
            level_rate = self.config.get_rate_for_level(level)
        
        # Use the most restrictive rate
        rate = min(path_rate, method_rate, level_rate)
        
        # Always log if rate is 1.0
        if rate >= 1.0:
            return True
        
        # Never log if rate is 0.0
        if rate <= 0.0:
            return False
        
        # Generate a request key for counting
        request_key = f"{path or ''}:{method or ''}:{level or ''}"
        
        # Increment request count
        with self.request_counts_lock:
            count = self.request_counts.get(request_key, 0) + 1
            self.request_counts[request_key] = count
        
        # Deterministic sampling based on count
        return (count % int(1.0 / rate)) == 0


class SamplingLogFilter(logging.Filter):
    """Log filter that applies sampling to reduce log volume."""
    
    def __init__(self, sampler: Optional[LogSampler] = None):
        """
        Initialize sampling log filter.
        
        Args:
            sampler: Log sampler instance
        """
        super().__init__()
        self.sampler = sampler or LogSampler()
    
    def filter(self, record):
        """
        Filter log records based on sampling configuration.
        
        Args:
            record: Log record
            
        Returns:
            True if the record should be logged, False otherwise
        """
        # Get path and method from record if available
        path = getattr(record, 'path', None)
        method = getattr(record, 'method', None)
        
        # Check if we should log this record
        return self.sampler.should_log(path, method, record.levelno)


# Default sampler instance
_default_sampler = None

def get_default_sampler() -> LogSampler:
    """
    Get the default log sampler instance.
    
    Returns:
        Default log sampler
    """
    global _default_sampler
    if _default_sampler is None:
        _default_sampler = LogSampler()
    return _default_sampler

def configure_sampling(config: SamplingConfig) -> None:
    """
    Configure the default log sampler.
    
    Args:
        config: Sampling configuration
    """
    global _default_sampler
    _default_sampler = LogSampler(config)

def should_log(path: Optional[str] = None, 
              method: Optional[str] = None,
              level: Optional[Union[int, str]] = None) -> bool:
    """
    Determine if a log entry should be included based on sampling rates.
    
    Args:
        path: Request path
        method: HTTP method
        level: Log level
        
    Returns:
        True if the log entry should be included, False otherwise
    """
    return get_default_sampler().should_log(path, method, level) 
```


### FILE: meeting_shared\utils\__init__.py
```
"""
Utility functions for backend services.
Includes HTTP helpers, database utilities, and more.
"""

# Package exports
__all__ = [] 
```


### FILE: meeting_shared\utils\database.py
```
"""
Shared database utilities for transaction management across services.
"""
from contextlib import contextmanager
from sqlalchemy.orm import Session
from functools import wraps
from typing import Any, Callable, Optional, TypeVar, Dict, List, Union
import logging

logger = logging.getLogger(__name__)

T = TypeVar('T')

@contextmanager
def transaction_context(session: Session):
    """
    Context manager for database transactions.
    Commits the transaction if no exceptions occur, rolls back otherwise.
    
    Args:
        session: SQLAlchemy session object
        
    Yields:
        The session object
    """
    try:
        yield session
        session.commit()
    except Exception as e:
        session.rollback()
        logger.error(f"Transaction error: {str(e)}")
        raise

def with_transaction(func):
    """
    Decorator for functions that need a transaction.
    Automatically commits or rolls back the transaction.
    
    Args:
        func: The function to decorate
        
    Returns:
        The decorated function
    """
    @wraps(func)
    def wrapper(session, *args, **kwargs):
        with transaction_context(session) as tx_session:
            return func(tx_session, *args, **kwargs)
    return wrapper

class DatabaseManager:
    """
    Database utility class for managing database operations.
    Provides a unified interface for database operations across services.
    """
    def __init__(self, db):
        self.db = db
        self.session = db.session
        self.logger = logging.getLogger(__name__)
    
    def commit(self) -> bool:
        """Safely commit database changes"""
        try:
            self.session.commit()
            return True
        except Exception as e:
            self.session.rollback()
            self.logger.error(f"Database commit error: {str(e)}")
            return False
            
    def add(self, obj: Any, auto_commit: bool = True) -> bool:
        """Safely add an object to the database"""
        try:
            self.session.add(obj)
            if auto_commit:
                return self.commit()
            return True
        except Exception as e:
            self.session.rollback()
            self.logger.error(f"Database add error: {str(e)}")
            return False
            
    def delete(self, obj: Any, auto_commit: bool = True) -> bool:
        """Safely delete an object from the database"""
        try:
            self.session.delete(obj)
            if auto_commit:
                return self.commit()
            return True
        except Exception as e:
            self.session.rollback()
            self.logger.error(f"Database delete error: {str(e)}")
            return False 
```


### FILE: monitoring\prometheus\prometheus.yml
```
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'auth-service'
    static_configs:
      - targets: ['auth-service:5001']

  - job_name: 'backend'
    static_configs:
      - targets: ['backend:5000']

  - job_name: 'websocket'
    static_configs:
      - targets: ['websocket:3001'] 
```


### FILE: scripts\Generate-Secrets.ps1
```
param(
    [string]$DbUser = "dev_user",
    [string]$DbPassword = "dev-password-123",
    [string]$JwtSecret = "dev-jwt-secret-123",
    [string]$RedisPassword = "dev-redis-123",
    [string]$GrafanaPassword = "dev-grafana-123"
)

# Function to generate secure random string if needed
function Generate-Secret {
    $random = [System.Security.Cryptography.RandomNumberGenerator]::Create()
    $bytes = New-Object byte[] 32
    $random.GetBytes($bytes)
    return [Convert]::ToBase64String($bytes)
}

# Use provided values
$PROD_DB_USER = $DbUser
$PROD_DB_PASSWORD = $DbPassword
$PROD_JWT_SECRET = $JwtSecret
$PROD_REDIS_PASSWORD = $RedisPassword
$PROD_GRAFANA_PASSWORD = $GrafanaPassword

# Create config directory if it doesn't exist
New-Item -ItemType Directory -Force -Path "./config" | Out-Null

# Create secrets file
@"
PROD_DB_USER=$PROD_DB_USER
PROD_DB_PASSWORD=$PROD_DB_PASSWORD
PROD_JWT_SECRET=$PROD_JWT_SECRET
PROD_REDIS_PASSWORD=$PROD_REDIS_PASSWORD
PROD_GRAFANA_PASSWORD=$PROD_GRAFANA_PASSWORD
"@ | Out-File -FilePath "./config/secrets.production" -Encoding UTF8

# Set appropriate permissions
$acl = Get-Acl "./config/secrets.production"
$acl.SetAccessRuleProtection($true, $false)
$rule = New-Object System.Security.AccessControl.FileSystemAccessRule($env:USERNAME, "Read,Write", "Allow")
$acl.AddAccessRule($rule)
Set-Acl "./config/secrets.production" $acl

Write-Host "Production secrets saved to ./config/secrets.production"
Write-Host "IMPORTANT: Store these secrets securely and never commit them to version control!"
Write-Host "Make sure to securely transfer these secrets to your production environment."

# Display usage instructions
Write-Host "`nUsage examples:"
Write-Host "1. Use default (development) values:"
Write-Host "   .\Generate-Secrets.ps1"
Write-Host "2. Use your own secrets:"
Write-Host "   .\Generate-Secrets.ps1 -DbUser 'myuser' -DbPassword 'mypass' -JwtSecret 'myjwt' -RedisPassword 'myredis' -GrafanaPassword 'mygrafana'" 
```


### FILE: scripts\Set-Environment.ps1
```
param(
    [Parameter(Mandatory=$true)]
    [ValidateSet('development','test','production')]
    [string]$Environment
)

Write-Host "Setting up $Environment environment..."

# Copy appropriate env file
Copy-Item "./config/.env.$Environment" ".env"

# If production environment, load secrets
if ($Environment -eq "production") {
    $secretsPath = "./config/secrets.production"
    if (Test-Path $secretsPath) {
        Write-Host "Loading production secrets..."
        
        # Read secrets file
        $secrets = Get-Content $secretsPath | ConvertFrom-StringData
        
        # Read .env file
        $envContent = Get-Content ".env"
        
        # Replace placeholders with actual values
        $envContent = $envContent -replace '\${PROD_DB_USER}', $secrets.PROD_DB_USER
        $envContent = $envContent -replace '\${PROD_DB_PASSWORD}', $secrets.PROD_DB_PASSWORD
        $envContent = $envContent -replace '\${PROD_JWT_SECRET}', $secrets.PROD_JWT_SECRET
        $envContent = $envContent -replace '\${PROD_REDIS_PASSWORD}', $secrets.PROD_REDIS_PASSWORD
        $envContent = $envContent -replace '\${PROD_GRAFANA_PASSWORD}', $secrets.PROD_GRAFANA_PASSWORD
        
        # Write updated content back to .env
        $envContent | Set-Content ".env"
    }
    else {
        Write-Error "Production secrets file not found. Run Generate-Secrets.ps1 first."
        exit 1
    }
}

# Apply Kubernetes configurations if they exist
$k8sConfigPath = "k8s/config/$Environment"
if (Test-Path $k8sConfigPath) {
    Write-Host "Applying Kubernetes configurations for $Environment environment..."
    kubectl apply -f $k8sConfigPath
}

Write-Host "Environment set to $Environment"
Write-Host "Configuration loaded from ./config/.env.$Environment" 
```


### FILE: scripts\deploy-meeting-app.ps1
```
# Simple deployment script for Meeting App
Set-StrictMode -Version Latest
$ErrorActionPreference = "Stop"

Write-Host "ğŸš€ Cleaning up previous deployment..." -ForegroundColor Cyan

try {
    # Clean up previous deployment
    Write-Host "1ï¸âƒ£ Removing previous Kubernetes resources..." -ForegroundColor Cyan
    kubectl delete -f k8s/config/development/ --ignore-not-found
    kubectl delete namespace meeting-app --ignore-not-found
    
    Write-Host "2ï¸âƒ£ Cleaning up Docker containers..." -ForegroundColor Cyan
    docker ps -aq | ForEach-Object { docker stop $_ }
    docker container prune -f
    
    Start-Sleep -Seconds 5  # Wait for resources to be cleaned up
    
    Write-Host "ğŸš€ Starting fresh deployment..." -ForegroundColor Cyan
    
    # 1. Set environment variables
    Write-Host "3ï¸âƒ£ Setting environment variables..." -ForegroundColor Cyan
    .\scripts\Set-Environment.ps1 -Environment development
    
    # 2. Build Docker images
    Write-Host "4ï¸âƒ£ Building Docker images..." -ForegroundColor Cyan
    docker build -t meeting-app-backend:dev -f backend/flask-service/Dockerfile ./backend/flask-service
    docker build -t meeting-app-frontend:dev -f frontend/Dockerfile ./frontend
    
    # 3. Apply Kubernetes configurations
    Write-Host "5ï¸âƒ£ Applying Kubernetes configurations..." -ForegroundColor Cyan
    
    # Create namespace if it doesn't exist
    kubectl create namespace meeting-app --dry-run=client -o yaml | kubectl apply -f -
    
    # Apply configurations
    kubectl apply -f k8s/config/development/configmap.yaml
    kubectl apply -f k8s/config/development/secrets.yaml
    kubectl apply -f k8s/config/development/deployment.yaml
    
    # 4. Verify deployment
    Write-Host "6ï¸âƒ£ Verifying deployment..." -ForegroundColor Cyan
    Write-Host "`nServices:" -ForegroundColor Yellow
    kubectl get services
    
    Write-Host "`nPods:" -ForegroundColor Yellow
    kubectl get pods
    
    Write-Host "`nâœ… Deployment completed!" -ForegroundColor Green
    Write-Host @"

ğŸŒ Access the application:
   Frontend: http://localhost:30000
   API: http://localhost:30963
   WebSocket: ws://localhost:30283

ğŸ“‹ Useful commands:
   - View all resources: kubectl get all
   - View logs: kubectl logs <pod-name>
   - Delete all: kubectl delete -f k8s/config/development/
"@ -ForegroundColor Cyan
    
} catch {
    Write-Host "âŒ Deployment failed: $_" -ForegroundColor Red
    exit 1
} 
```


### FILE: scripts\setup-local-dev.ps1
```
# Function to handle errors
function Write-ErrorAndExit {
    param($message)
    Write-Host "Error: $message" -ForegroundColor Red
    exit 1
}

# Function to check prerequisites
function Test-Prerequisites {
    Write-Host "Checking prerequisites..."
    
    # Check if running as Administrator
    $isAdmin = ([Security.Principal.WindowsPrincipal] [Security.Principal.WindowsIdentity]::GetCurrent()).IsInRole([Security.Principal.WindowsBuiltInRole]::Administrator)
    if (-not $isAdmin) {
        Write-ErrorAndExit "This script must be run as Administrator"
    }
    
    # Check Docker
    try {
        docker version | Out-Null
    } catch {
        Write-ErrorAndExit "Docker is not running. Please start Docker Desktop"
    }
    
    # Check Kubernetes
    try {
        kubectl version | Out-Null
    } catch {
        Write-ErrorAndExit "Kubernetes is not running. Please enable Kubernetes in Docker Desktop"
    }
    
    # Check Minikube
    try {
        minikube status | Out-Null
    } catch {
        Write-ErrorAndExit "Minikube is not running. Please start Minikube"
    }
}

# Function to setup networking
function Setup-Networking {
    Write-Host "Setting up networking..."
    
    # Get Minikube IP
    try {
        $MINIKUBE_IP = minikube ip
        Write-Host "Minikube IP: $MINIKUBE_IP"
    } catch {
        Write-ErrorAndExit "Failed to get Minikube IP"
    }
    
    # Update hosts file
    try {
        $hostsPath = "$env:windir\System32\drivers\etc\hosts"
        $hostsContent = Get-Content $hostsPath
        
        # Backup hosts file
        Copy-Item $hostsPath "$hostsPath.bak"
        
        # Remove old entries
        $hostsContent = $hostsContent | Where-Object { $_ -notmatch 'meeting-app.local' }
        
        # Add new entries
        $newEntries = @"
$MINIKUBE_IP meeting-app.local
$MINIKUBE_IP api.meeting-app.local
$MINIKUBE_IP ws.meeting-app.local
"@
        $newEntries | Add-Content $hostsPath
    } catch {
        Write-ErrorAndExit "Failed to update hosts file"
    }
    
    # Enable ingress
    Write-Host "Enabling ingress addon..."
    minikube addons enable ingress
    
    # Wait for ingress controller
    Write-Host "Waiting for ingress controller..."
    kubectl wait --namespace ingress-nginx --for=condition=ready pod --selector=app.kubernetes.io/component=controller --timeout=180s
}

# Function to build images
function Build-Images {
    Write-Host "Building Docker images..."
    
    try {
        # Point Docker to Minikube's Docker daemon
        Write-Host "Configuring Docker environment..."
        minikube docker-env | Invoke-Expression
        
        # Build images
        docker build -t meeting-app-frontend:dev ./frontend
        docker build -t meeting-app-backend:dev ./backend/flask-service
        docker build -t meeting-app-websocket:dev ./backend/node-service
    } catch {
        Write-ErrorAndExit "Failed to build Docker images"
    }
}

# Function to deploy services
function Deploy-Services {
    Write-Host "Deploying services..."
    
    try {
        # Apply configurations
        kubectl apply -f k8s/config/development/
        
        # Wait for core services
        Write-Host "Waiting for core services..."
        kubectl wait --for=condition=ready pod -l app=postgres --timeout=180s
        kubectl wait --for=condition=ready pod -l app=redis --timeout=180s
        
        # Initialize database if needed
        Write-Host "Checking database initialization..."
        $dbPod = kubectl get pod -l app=postgres -o jsonpath="{.items[0].metadata.name}"
        $initDbResult = kubectl exec $dbPod -- psql -U dev_user -d meetingapp -c "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'users')" -t
        if ($initDbResult -notmatch "t") {
            Write-Host "Initializing database..."
            kubectl exec $dbPod -- psql -U dev_user -d meetingapp -f /docker-entrypoint-initdb.d/init.sql
        }
        
        # Wait for application services
        Write-Host "Waiting for application services..."
        kubectl wait --for=condition=ready pod -l app=meeting-app --timeout=180s
        kubectl wait --for=condition=ready pod -l app=meeting-app-frontend --timeout=180s
    } catch {
        Write-ErrorAndExit "Failed to deploy services"
    }
}

# Function to verify deployment
function Test-Deployment {
    Write-Host "Verifying deployment..."
    
    # Wait for services to be ready
    Start-Sleep -Seconds 10
    
    # Test endpoints
    try {
        $frontendHealth = Invoke-WebRequest "http://localhost:30000/health" -UseBasicParsing
        $apiHealth = Invoke-WebRequest "http://localhost:30963/health" -UseBasicParsing
        
        if ($frontendHealth.StatusCode -ne 200 -or $apiHealth.StatusCode -ne 200) {
            Write-Host "Warning: Some health checks failed" -ForegroundColor Yellow
        }
        
        # Test database connection
        $dbHealth = Invoke-WebRequest "http://localhost:30963/health/db" -UseBasicParsing
        if ($dbHealth.StatusCode -ne 200) {
            Write-Host "Warning: Database health check failed" -ForegroundColor Yellow
        }
        
        # Test Redis connection
        $redisHealth = Invoke-WebRequest "http://localhost:30963/health/redis" -UseBasicParsing
        if ($redisHealth.StatusCode -ne 200) {
            Write-Host "Warning: Redis health check failed" -ForegroundColor Yellow
        }
    } catch {
        Write-Host "Warning: Could not verify all endpoints" -ForegroundColor Yellow
    }
}

# Main execution
try {
    Test-Prerequisites
    Setup-Networking
    Build-Images
    Deploy-Services
    Test-Deployment
    
    Write-Host @"
Local Kubernetes development environment is ready!

Access Methods:
1. Port-based access (recommended for local development):
   - Frontend: http://localhost:30000
   - API: http://localhost:30963
   - WebSocket: ws://localhost:30283

2. Domain-based access (alternative):
   - Frontend: http://meeting-app.local
   - API: http://api.meeting-app.local
   - WebSocket: ws://ws.meeting-app.local

Internal Services:
- PostgreSQL: Running in cluster
- Redis: Running in cluster

Monitoring:
- Kubernetes Dashboard: Run 'minikube dashboard'
- Grafana: http://localhost:3000 (admin/admin123)

Useful Commands:
- View pods: kubectl get pods
- View logs: kubectl logs <pod-name>
- Shell access: kubectl exec -it <pod-name> -- /bin/sh
- View services: kubectl get services
- View ingress: kubectl get ingress

Keep this terminal window open to maintain port forwarding.
Press Enter to stop and cleanup.
"@

    # Wait for user input
    Read-Host "Press Enter to stop the local development environment..."
} catch {
    Write-ErrorAndExit $_.Exception.Message
} finally {
    # Cleanup
    Write-Host "Cleaning up..."
    Get-Job | Stop-Job
    Get-Job | Remove-Job
} 
```


### FILE: scripts\verify_auth_flow.py
```
#!/usr/bin/env python
"""
Authentication Flow Verification Script.
Tests JWT token creation, verification, service integration, and error handling.
"""

import os
import sys
import json
import requests
from datetime import datetime, timedelta
import time

# Default URLs (can be overridden with environment variables)
BASE_URL = os.environ.get("BACKEND_URL", "http://localhost:5000/api")
AUTH_URL = os.environ.get("AUTH_URL", "http://localhost:5001/api/auth")

# Test credentials (should be updated with valid credentials)
TEST_EMAIL = os.environ.get("TEST_EMAIL", "admin@example.com")
TEST_PASSWORD = os.environ.get("TEST_PASSWORD", "admin123")

def log_response(response, operation):
    """Log API response details."""
    print(f"\n--- {operation} Response ---")
    print(f"Status: {response.status_code}")
    
    # Check for request ID in headers
    request_id = response.headers.get('X-Request-ID', 'Not present')
    correlation_id = response.headers.get('X-Correlation-ID', 'Not present')
    print(f"Request ID: {request_id}")
    print(f"Correlation ID: {correlation_id}")
    
    try:
        print(f"Body: {json.dumps(response.json(), indent=2)}")
    except:
        print(f"Body: {response.text[:200]}...")

def verify_auth_flow():
    """Test the JWT authentication flow and service integration."""
    print("\n=== Starting Authentication Flow Verification ===")
    
    # 1. Get auth token
    print("\nStep 1: Authenticating...")
    auth_response = requests.post(f"{AUTH_URL}/login", json={
        "email": TEST_EMAIL,
        "password": TEST_PASSWORD
    })
    
    if auth_response.status_code != 200:
        log_response(auth_response, "Authentication")
        print("âŒ Authentication failed")
        return False
    
    token = auth_response.json().get("access_token")
    if not token:
        print("âŒ No access token in response")
        return False
        
    headers = {"Authorization": f"Bearer {token}"}
    print("âœ… Authentication successful")
    
    # 2. Verify token with auth service
    print("\nStep 2: Verifying token with auth service...")
    verify_response = requests.post(f"{AUTH_URL}/validate-token", 
                                  json={"token": token},
                                  headers={"X-Service-Key": os.environ.get("SERVICE_KEY", "test-service-key")})
    
    if verify_response.status_code != 200:
        log_response(verify_response, "Token Verification")
        print("âŒ Token verification failed")
        return False
    
    print("âœ… Token verification successful")
    
    # 3. Test protected endpoint
    print("\nStep 3: Accessing protected endpoint...")
    protected_response = requests.get(f"{BASE_URL}/meetings", headers=headers)
    
    if protected_response.status_code != 200:
        log_response(protected_response, "Protected Endpoint")
        print("âŒ Protected endpoint access failed")
        return False
    
    print("âœ… Protected endpoint access successful")
    
    # 4. Test expired/invalid token
    print("\nStep 4: Testing invalid token handling...")
    invalid_token = token + "invalid"
    invalid_headers = {"Authorization": f"Bearer {invalid_token}"}
    
    invalid_response = requests.get(f"{BASE_URL}/meetings", headers=invalid_headers)
    
    if invalid_response.status_code != 401:
        log_response(invalid_response, "Invalid Token")
        print("âŒ Invalid token test failed - expected 401 status")
        return False
    
    # Check for proper error structure
    try:
        error_data = invalid_response.json()
        if "error" not in error_data or "message" not in error_data:
            print("âŒ Error response missing required fields")
            return False
    except:
        print("âŒ Error response not in JSON format")
        return False
    
    print("âœ… Invalid token handling successful")
    
    # 5. Test service integration
    print("\nStep 5: Testing service integration...")
    
    # Test with missing service key
    service_response = requests.post(f"{AUTH_URL}/validate-token", 
                                   json={"token": token})
    
    if service_response.status_code != 403:
        log_response(service_response, "Missing Service Key")
        print("âŒ Service key test failed - expected 403 status")
        return False
    
    print("âœ… Service integration test successful")
    
    # 6. Test request ID propagation
    print("\nStep 6: Testing request ID propagation...")
    custom_request_id = f"test-{int(time.time())}"
    custom_headers = headers.copy()
    custom_headers["X-Request-ID"] = custom_request_id
    
    req_id_response = requests.get(f"{BASE_URL}/meetings", headers=custom_headers)
    
    if req_id_response.status_code != 200:
        log_response(req_id_response, "Request ID Test")
        print("âŒ Request ID test failed")
        return False
    
    response_req_id = req_id_response.headers.get("X-Request-ID")
    if response_req_id != custom_request_id:
        print(f"âŒ Request ID not propagated correctly. Expected: {custom_request_id}, Got: {response_req_id}")
        return False
    
    print("âœ… Request ID propagation successful")
    
    # 7. Test correlation ID propagation
    print("\nStep 7: Testing correlation ID propagation...")
    custom_correlation_id = f"corr-{int(time.time())}"
    custom_headers = headers.copy()
    custom_headers["X-Correlation-ID"] = custom_correlation_id
    
    corr_id_response = requests.get(f"{BASE_URL}/meetings", headers=custom_headers)
    
    if corr_id_response.status_code != 200:
        log_response(corr_id_response, "Correlation ID Test")
        print("âŒ Correlation ID test failed")
        return False
    
    response_corr_id = corr_id_response.headers.get("X-Correlation-ID")
    if response_corr_id != custom_correlation_id:
        print(f"âŒ Correlation ID not propagated correctly. Expected: {custom_correlation_id}, Got: {response_corr_id}")
        return False
    
    print("âœ… Correlation ID propagation successful")
    
    # 8. Test service discovery
    print("\nStep 8: Testing service discovery...")
    try:
        discovery_response = requests.get(f"{BASE_URL}/services")
        
        if discovery_response.status_code != 200:
            log_response(discovery_response, "Service Discovery")
            print("âš ï¸ Service discovery endpoint not available (this may be expected)")
        else:
            services = discovery_response.json()
            if not services or not isinstance(services, dict):
                print("âš ï¸ Service discovery returned unexpected format")
            else:
                print(f"âœ… Service discovery returned {len(services)} services")
    except Exception as e:
        print(f"âš ï¸ Service discovery test failed: {str(e)}")
    
    print("\n=== Authentication Flow verification completed successfully! ===")
    return True

if __name__ == "__main__":
    try:
        if verify_auth_flow():
            sys.exit(0)
        else:
            sys.exit(1)
    except Exception as e:
        print(f"\nâŒ Error during verification: {str(e)}")
        sys.exit(1) 
```


### FILE: scripts\verify_db.py
```
#!/usr/bin/env python
"""
Database connection verification script.
Tests connections to both auth and backend databases.
"""

import os
import sys
from flask import Flask
import psycopg2

# Add project root to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from meeting_shared.config import get_config
from meeting_shared.database import init_db, db

def verify_database_connection(service_type='flask'):
    """Verify database connection with current configuration."""
    app = Flask(__name__)
    
    # Get appropriate config based on service type
    if service_type == 'auth':
        config = get_config('auth')
        db_env_var = 'AUTH_DATABASE_URL'
        service_name = 'Auth Service'
        default_url = 'postgresql://postgres:postgres@localhost:5433/auth_db'
    else:
        config = get_config('flask')
        db_env_var = 'DATABASE_URL'
        service_name = 'Flask Service'
        default_url = 'postgresql://dev_user:dev-password-123@localhost:5432/meetingapp'
    
    # Apply configuration
    app.config.from_object(config)
    
    # Override with environment variable if present
    if os.environ.get(db_env_var):
        app.config['SQLALCHEMY_DATABASE_URI'] = os.environ.get(db_env_var)
    else:
        # Use default URL for local execution
        app.config['SQLALCHEMY_DATABASE_URI'] = default_url
    
    print(f"\n=== Verifying {service_name} Database Connection ===")
    
    # Print critical config values (sanitized)
    db_url = app.config.get('SQLALCHEMY_DATABASE_URI', '')
    if '://' in db_url:
        # Sanitize credentials in URL
        parts = db_url.split('://')
        if '@' in parts[1]:
            credentials_server = parts[1].split('@')
            sanitized_url = f"{parts[0]}://***:***@{credentials_server[1]}"
        else:
            sanitized_url = f"{parts[0]}://***:***@{parts[1]}"
    else:
        sanitized_url = db_url
    
    print(f"Using database: {sanitized_url}")
    
    # Try direct connection with psycopg2
    try:
        # Parse connection string
        if 'postgres' in db_url.lower():
            # Extract connection parameters from URL
            if '://' in db_url:
                # postgresql://username:password@hostname:port/dbname
                parts = db_url.split('://')
                auth_host = parts[1].split('@')
                if len(auth_host) > 1:
                    auth = auth_host[0].split(':')
                    host_port_db = auth_host[1].split('/')
                    host_port = host_port_db[0].split(':')
                    
                    username = auth[0]
                    password = auth[1] if len(auth) > 1 else ''
                    hostname = host_port[0]
                    port = host_port[1] if len(host_port) > 1 else '5432'
                    dbname = host_port_db[1]
                    
                    # Use localhost instead of container names for local execution
                    if hostname in ['postgres', 'auth-db']:
                        hostname = 'localhost'
                        if hostname == 'auth-db':
                            port = '5433'
                    
                    # Connect directly with psycopg2
                    conn = psycopg2.connect(
                        dbname=dbname,
                        user=username,
                        password=password,
                        host=hostname,
                        port=port
                    )
                    cursor = conn.cursor()
                    cursor.execute('SELECT 1')
                    result = cursor.fetchone()[0]
                    print(f"Direct database connection successful, result: {result}")
                    
                    cursor.execute('SELECT version()')
                    version = cursor.fetchone()[0]
                    print(f"Database version: {version}")
                    
                    cursor.close()
                    conn.close()
                    return True
        
        # If direct connection fails or not postgres, try SQLAlchemy
        init_db(app)
        with app.app_context():
            result = db.session.execute('SELECT 1').scalar()
            print(f"SQLAlchemy database connection successful, result: {result}")
            
            # Get database version
            if 'postgres' in db_url.lower():
                version = db.session.execute('SELECT version()').scalar()
                print(f"Database version: {version}")
            elif 'sqlite' in db_url.lower():
                version = db.session.execute('SELECT sqlite_version()').scalar()
                print(f"SQLite version: {version}")
            
            return True
    except Exception as e:
        print(f"Database connection failed: {str(e)}")
        return False

if __name__ == "__main__":
    # Check if specific service was requested
    service = 'both'
    if len(sys.argv) > 1:
        service = sys.argv[1].lower()
    
    if service in ['both', 'flask']:
        flask_result = verify_database_connection('flask')
    else:
        flask_result = True
        
    if service in ['both', 'auth']:
        auth_result = verify_database_connection('auth')
    else:
        auth_result = True
    
    # Exit with appropriate status code
    if not (flask_result and auth_result):
        print("\nâŒ Database verification failed")
        sys.exit(1)
    else:
        print("\nâœ… All database connections verified successfully")
        sys.exit(0) 
```


### FILE: scripts\verify_meeting_crud.py
```
#!/usr/bin/env python
"""
Meeting CRUD verification script.
Tests the complete meeting management workflow.
"""

import os
import sys
import json
import requests
from datetime import datetime, timedelta
import time

# Default URLs (can be overridden with environment variables)
BASE_URL = os.environ.get("BACKEND_URL", "http://localhost:5000/api")
AUTH_URL = os.environ.get("AUTH_URL", "http://localhost:5001/api/auth")

# Test credentials (should be updated with valid credentials)
TEST_EMAIL = os.environ.get("TEST_EMAIL", "admin@example.com")
TEST_PASSWORD = os.environ.get("TEST_PASSWORD", "admin123")

def log_response(response, operation):
    """Log API response details."""
    print(f"\n--- {operation} Response ---")
    print(f"Status: {response.status_code}")
    print(f"Headers: {json.dumps(dict(response.headers), indent=2)}")
    
    try:
        print(f"Body: {json.dumps(response.json(), indent=2)}")
    except:
        print(f"Body: {response.text[:200]}...")

def verify_meeting_crud():
    """Test the complete meeting CRUD workflow."""
    print("\n=== Starting Meeting CRUD Verification ===")
    
    # 1. Get auth token
    print("\nStep 1: Authenticating...")
    auth_response = requests.post(f"{AUTH_URL}/login", json={
        "email": TEST_EMAIL,
        "password": TEST_PASSWORD
    })
    
    if auth_response.status_code != 200:
        log_response(auth_response, "Authentication")
        print("âŒ Authentication failed")
        return False
    
    token = auth_response.json().get("access_token")
    headers = {"Authorization": f"Bearer {token}"}
    print("âœ… Authentication successful")
    
    # 2. Create meeting
    print("\nStep 2: Creating meeting...")
    meeting_data = {
        "title": "Test Meeting",
        "description": "Testing CRUD operations",
        "start_time": (datetime.utcnow() + timedelta(days=1)).isoformat(),
        "end_time": (datetime.utcnow() + timedelta(days=1, hours=1)).isoformat(),
        "location": "Conference Room A",
        "meeting_type": "team"
    }
    
    create_response = requests.post(f"{BASE_URL}/meetings", 
                                  json=meeting_data,
                                  headers=headers)
    
    if create_response.status_code != 201:
        log_response(create_response, "Create Meeting")
        print("âŒ Meeting creation failed")
        return False
    
    meeting_id = create_response.json().get("id")
    print(f"âœ… Created meeting with ID: {meeting_id}")
    
    # 3. Read meeting
    print("\nStep 3: Reading meeting...")
    read_response = requests.get(f"{BASE_URL}/meetings/{meeting_id}", headers=headers)
    if read_response.status_code != 200:
        log_response(read_response, "Read Meeting")
        print("âŒ Meeting read failed")
        return False
    
    print("âœ… Meeting read successful")
    
    # 4. Add participants
    print("\nStep 4: Adding participants...")
    participants = [
        {"user_id": 2, "role": "attendee"},
        {"user_id": 3, "role": "presenter"}
    ]
    
    participants_response = requests.post(
        f"{BASE_URL}/meetings/{meeting_id}/participants",
        json=participants,
        headers=headers
    )
    
    if participants_response.status_code not in [200, 201]:
        log_response(participants_response, "Add Participants")
        print("âš ï¸ Adding participants failed (continuing test)")
    else:
        print("âœ… Participants added successfully")
    
    # 5. Update meeting
    print("\nStep 5: Updating meeting...")
    update_data = {"title": "Updated Test Meeting"}
    update_response = requests.put(f"{BASE_URL}/meetings/{meeting_id}", 
                                 json=update_data,
                                 headers=headers)
    
    if update_response.status_code != 200:
        log_response(update_response, "Update Meeting")
        print("âŒ Meeting update failed")
        return False
    
    print("âœ… Meeting update successful")
    
    # 6. Delete meeting
    print("\nStep 6: Deleting meeting...")
    delete_response = requests.delete(f"{BASE_URL}/meetings/{meeting_id}", headers=headers)
    if delete_response.status_code != 204:
        log_response(delete_response, "Delete Meeting")
        print("âŒ Meeting deletion failed")
        return False
    
    print("âœ… Meeting deletion successful")
    
    # 7. Verify deletion
    print("\nStep 7: Verifying deletion...")
    verify_response = requests.get(f"{BASE_URL}/meetings/{meeting_id}", headers=headers)
    if verify_response.status_code != 404:
        log_response(verify_response, "Verify Deletion")
        print("âŒ Deletion verification failed")
        return False
        
    print("âœ… Deletion verification successful")
    print("\n=== Meeting CRUD verification completed successfully! ===")
    return True

if __name__ == "__main__":
    try:
        if verify_meeting_crud():
            sys.exit(0)
        else:
            sys.exit(1)
    except Exception as e:
        print(f"\nâŒ Error during verification: {str(e)}")
        sys.exit(1) 
```


## SUMMARY
- Total files found: 222
- Files processed: 214
- Files skipped: 8
- Script version: 1.1.0
